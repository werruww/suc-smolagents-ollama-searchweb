# -*- coding: utf-8 -*-
"""suc_GO_ollama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H3ZzgyALLbV3NLDXbyBkUMewbvG4hgXW
"""





curl -fsSL https://ollama.com/install.sh | sh
nohup ollama serve &
ollama pull llama3:8b
ollama list
nohup ollama serve &
ollama pull llama3:8b
ollama list

!curl -fsSL https://ollama.com/install.sh | sh

!nohup ollama serve &
!ollama pull llama2

!ollama list

!wget https://go.dev/dl/go1.22.5.linux-amd64.tar.gz
!tar -C /usr/local -xzf go1.22.5.linux-amd64.tar.gz

# Commented out IPython magic to ensure Python compatibility.
!tar -C /usr/local -xzf go1.22.5.linux-amd64.tar.gz

# تحديث PATH بشكل مباشر للـ shell
# %env PATH=/usr/local/go/bin:$PATH

# الآن نتحقق
!go version

!source /etc/profile.d/go.sh

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/mygoapp

!go mod init mygoapp

!ls

ls

!go get github.com/tmc/langchaingo/llms

!go get github.com/tmc/langchaingo/llms/ollama

#!nohup ollama serve &
!go run main.go

!go run main.go

#!nohup ollama serve &
!ollama pull gemma3

!ollama run gemma3

!ollama

!nohup ollama serve &

package main

import (
  "context"
  "fmt"
  "log"

  "github.com/tmc/langchaingo/llms"
  "github.com/tmc/langchaingo/llms/ollama"
)

func main() {
  llm, err := ollama.New(ollama.WithModel("llama2"))
  if err != nil {
    log.Fatal(err)
  }

  query := "very briefly, tell me the difference between a comet and a meteor"

  ctx := context.Background()
  completion, err := llms.GenerateFromSinglePrompt(ctx, llm, query)
  if err != nil {
    log.Fatal(err)
  }

  fmt.Println("Response:\n", completion)
}