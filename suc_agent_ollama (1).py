# -*- coding: utf-8 -*-
"""suc_agent_ollama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18xWjFxGF73x1w3WVQVTgfgWWXA0ka3AY
"""





"""https://medium.com/@whyamit101/local-ai-using-ollama-with-agents-114c72182c97"""

!curl -fsSL https://ollama.com/install.sh | sh

!ollama --version

!ollama

!ollama serve

!ollama run tinyllama

!pip install crewai

!ollama list

!pip install pyautogen langchain_community





"""### Ø´ØºØ§Ù„ ÙˆÙ„ÙƒÙ† ØºÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ (Ù…Ø¹ ØªØ¹Ø¯ÙŠÙ„ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬) -----------------
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ ChatOllama Ù…Ù† Ø§Ù„Ø­Ø²Ù…Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù‡Ø§
from langchain_ollama import ChatOllama

# Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø©: Ø³Ù†Ù‚ÙˆÙ… Ø¨ØªÙ…Ø±ÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„ØµÙŠØºØ© Ø§Ù„ØªÙŠ ØªÙÙ‡Ù…Ù‡Ø§ litellm Ù…Ø¨Ø§Ø´Ø±Ø©
# ÙˆÙ‡ÙŠ "provider/model_name". Ù‡Ø°Ø§ ÙŠØ®Ø¨Ø± crewai Ø¨Ø´ÙƒÙ„ ØµØ±ÙŠØ­ Ø¬Ø¯Ù‹Ø§
# Ø£Ù† ÙŠØ³ØªØ®Ø¯Ù… ollama ÙƒÙ€ "Ù…Ø²ÙˆØ¯ Ø®Ø¯Ù…Ø©".
model = ChatOllama(
    model="ollama/tinyllama:latest", # Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù‡Ù†Ø§
    base_url="http://localhost:11434"
)


# ----------------- 2. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø© (Tool) -----------------
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())
        processed_text = re.sub(r'\s+', ' ', text).strip()
        # Ø¥Ø¶Ø§ÙØ© ØªØ­Ù‚Ù‚ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù†Øµ Ù„ÙŠØ³ ÙØ§Ø±ØºÙ‹Ø§
        if not processed_text:
            return "Error: No text could be extracted from the PDF."
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}. Please ensure the path is correct."
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ (Agents) -----------------

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content],
    llm=model,
    allow_delegation=False
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ù‡Ø§Ù… (Tasks) -----------------

task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf]
)

task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting]
)

# ----------------- 5. Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø§Ù‚Ù… (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential
)

# ----------------- 6. Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ù… -----------------
print("ðŸš€ Starting Crew Execution...")
result = crew.kickoff()

print("\n\nâœ… Crew Execution Finished!")
print("Final Result:")
print(result)

















from crewai import Agent, Task, Crew
from langchain.llms import Ollama

# Use local Mistral via Ollama
llm = Ollama(model="tinyllama:latest")

# Define the agents
researcher = Agent(
    role='Researcher',
    goal='Find 3 recent breakthroughs in diffusion models',
    backstory='You are a cutting-edge AI researcher.',
    llm=llm
)

writer = Agent(
    role='Writer',
    goal='Summarize key insights for a technical blog post',
    backstory='You write clearly for a data-savvy audience.',
    llm=llm
)

# Define tasks
task1 = Task(description='Collect 3 recent updates on diffusion models.', agent=researcher)
task2 = Task(description='Write a clear summary of those updates.', agent=writer)

# Run the crew
crew = Crew(tasks=[task1, task2])
crew.kickoff()

from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

# Define config manually
config = [{
    "model": "tinyllama:latest",
    "api_key": "ollama-not-needed",  # placeholder, but required by AutoGen
    "api_type": "ollama"
}]

assistant = AssistantAgent(
    name="assistant",
    llm_config={"config_list": config}
)

user_proxy = UserProxyAgent(
    name="user",
    human_input_mode="NEVER"
)

user_proxy.initiate_chat(assistant, message="Explain what Retrieval-Augmented Generation (RAG) is.")

import os
from langchain_community.llms import Ollama

model = os.getenv("DEFAULT_LLM", "tinyllama:latest")
llm = Ollama(model=model)

from crewai import Crew

from crewai.agents import Agent

from crewai import Crew
from crewai.agents import Agent
from crewai.llms import OllamaLLM

llm = OllamaLLM(model="tinyllama:latest")

!pip install pyautogen autogen

!export DEFAULT_LLM=tinyllama:latest

from crewai import Crew
from crewai.agents import Agent
from crewai.llms import OllamaLLM

# âœ… 1. Define the local LLM backend
ollama_llm = OllamaLLM(model="tinyllama:latest")  # You can swap in llama3, codellama, etc.

# âœ… 2. Define the agent
researcher = Agent(
    role="Researcher",
    goal="Search and summarize open datasets",
    backstory="An expert in public data analysis",
    llm=ollama_llm
)

# âœ… 3. Initialize the crew
crew = Crew(agents=[researcher])

# âœ… 4. Fire it up
crew.kickoff()

!pip install ollama fix-busted-json

from crewai import Agent

schema_agent = Agent(
    role="Schema Validator",
    goal="Identify schema issues in tabular data",
    backstory="An expert in data quality assurance",
    llm=llm
)

imbalance_agent = Agent(
    role="Class Imbalance Detector",
    goal="Detect and summarize class imbalance issues",
    backstory="A statistical detective for unbalanced datasets",
    llm=llm
)

preprocess_agent = Agent(
    role="Preprocessing Advisor",
    goal="Recommend preprocessing steps based on input data characteristics",
    backstory="A data engineer who loves clean inputs",
    llm=llm
)

import pandas as pd
from sklearn.utils import resample

def load_dataset(path):
    return pd.read_csv(path)

def check_schema(df):
    return df.dtypes.to_string()

def check_class_imbalance(df, target_col):
    return df[target_col].value_counts(normalize=True).to_string()

def recommend_preprocessing(df):
    recommendations = []
    if df.isnull().sum().any():
        recommendations.append("Impute missing values.")
    if any(df.dtypes == 'object'):
        recommendations.append("Encode categorical variables.")
    return "\n".join(recommendations)

from crewai import Crew

crew = Crew(agents=[schema_agent, imbalance_agent, preprocess_agent])
crew_result = crew.kickoff(inputs={"dataset_path": "/content/sample_data/california_housing_test.csv"})
print(crew_result)

import streamlit as st
import pandas as pd
from workflow import run_workflow  # Assume this triggers the crew

st.title("ðŸ§  Dataset Auditor (Local LLM Powered)")

uploaded_file = st.file_uploader("Upload your CSV", type="csv")
if uploaded_file:
    with open("data/input.csv", "wb") as f:
        f.write(uploaded_file.getbuffer())
    output = run_workflow("data/input.csv")
    st.markdown("### ðŸ“ Audit Report")
    st.text(output)

"""https://medium.com/@whyamit101/local-ai-using-ollama-with-agents-114c72182c97"""

from crewai import Agent, Task, Crew
from langchain.llms import Ollama

# Use local Mistral via Ollama
llm = Ollama(model="ollama/tinyllama:latest")

# Define the agents
researcher = Agent(
    role='Researcher',
    goal='Find 3 recent breakthroughs in diffusion models',
    backstory='You are a cutting-edge AI researcher.',
    llm=llm
)

writer = Agent(
    role='Writer',
    goal='Summarize key insights for a technical blog post',
    backstory='You write clearly for a data-savvy audience.',
    llm=llm
)

# Define tasks
task1 = Task(
    description='Collect 3 recent updates on diffusion models.',
    expected_output='A list of 3 recent breakthroughs in diffusion models with a brief description of each.',
    agent=researcher
)
task2 = Task(
    description='Write a clear summary of those updates.',
    expected_output='A technical blog post summarizing the 3 recent diffusion model breakthroughs, suitable for a data-savvy audience.',
    agent=writer
)

# Run the crew
crew = Crew(tasks=[task1, task2])
crew.kickoff()

from crewai import Agent, Task, Crew
from langchain.llms import Ollama

# Use local Mistral via Ollama
llm = Ollama(model="ollama/tinyllama:latest")

# Define the agents
researcher = Agent(
    role='Researcher',
    goal='Find 3 recent breakthroughs in diffusion models',
    backstory='You are a cutting-edge AI researcher.',
    llm=llm
)

writer = Agent(
    role='Writer',
    goal='Summarize key insights for a technical blog post',
    backstory='You write clearly for a data-savvy audience.',
    llm=llm
)

# Define tasks
task1 = Task(
    description='Collect 3 recent updates on diffusion models.',
    expected_output='A list of 3 recent breakthroughs in diffusion models with a brief description of each.',
    agent=researcher
)
task2 = Task(
    description='Write a clear summary of those updates.',
    expected_output='A technical blog post summarizing the 3 recent diffusion model breakthroughs, suitable for a data-savvy audience.',
    agent=writer
)

# Run the crew
crew = Crew(tasks=[task1, task2])
crew.kickoff()

from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

# Define config manually
config = [{
    "model": "ollama/tinyllama:latest",
    "api_base": "http://localhost:11434/v1",
    "api_key": "ollama-not-needed",  # placeholder, but required by AutoGen
    "api_type": "ollama"
}]

assistant = AssistantAgent(
    name="assistant",
    llm_config={"config_list": config}
)

user_proxy = UserProxyAgent(
    name="user",
    human_input_mode="NEVER"
)

user_proxy.initiate_chat(assistant, message="Explain what Retrieval-Augmented Generation (RAG) is.")

ollama/tinyllama:latest

from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

# Define config manually
config = [{
    "model": "ollama/tinyllama:latest",
    "api_base": "http://localhost:11434/v1",
    "api_key": "ollama-not-needed",  # placeholder, but required by AutoGen
    "api_type": "open_ai"
}]

assistant = AssistantAgent(
    name="assistant",
    llm_config={"config_list": config}
)

user_proxy = UserProxyAgent(
    name="user",
    human_input_mode="NEVER"
)

user_proxy.initiate_chat(assistant, message="Explain what Retrieval-Augmented Generation (RAG) is.")

from crewai import Crew, Agent
from langchain_community.llms import Ollama

# âœ… 1. Define the local LLM backend
ollama_llm = Ollama(model="ollama/tinyllama:latest")  # You can swap in llama3, codellama, etc.

# âœ… 2. Define the agent
researcher = Agent(
    role="Researcher",
    goal="Search and summarize open datasets",
    backstory="An expert in public data analysis",
    llm=ollama_llm
)

# âœ… 3. Initialize the crew
crew = Crew(agents=[researcher])

# âœ… 4. Fire it up
crew.kickoff()

from crewai import Crew, Agent
from langchain_community.llms import Ollama

llm = Ollama(model="tinyllama:latest")

# agents.py
from crewai import Agent

schema_agent = Agent(
    role="Schema Validator",
    goal="Identify schema issues in tabular data",
    backstory="An expert in data quality assurance",
    llm=llm
)

imbalance_agent = Agent(
    role="Class Imbalance Detector",
    goal="Detect and summarize class imbalance issues",
    backstory="A statistical detective for unbalanced datasets",
    llm=llm
)

preprocess_agent = Agent(
    role="Preprocessing Advisor",
    goal="Recommend preprocessing steps based on input data characteristics",
    backstory="A data engineer who loves clean inputs",
    llm=llm
)

# tools.py
import pandas as pd
from sklearn.utils import resample

def load_dataset(path):
    return pd.read_csv(path)

def check_schema(df):
    return df.dtypes.to_string()

def check_class_imbalance(df, target_col):
    return df[target_col].value_counts(normalize=True).to_string()

def recommend_preprocessing(df):
    recommendations = []
    if df.isnull().sum().any():
        recommendations.append("Impute missing values.")
    if any(df.dtypes == 'object'):
        recommendations.append("Encode categorical variables.")
    return "\n".join(recommendations)

# workflow.py
from crewai import Crew, Task, Agent
from tools import load_dataset, check_schema, check_class_imbalance, recommend_preprocessing
from langchain_community.llms import Ollama

# Define the local LLM backend (assuming it's already initialized in a previous cell)
# If not initialized, uncomment the following lines:
llm = Ollama(model="tinyllama:latest")

# Define the agents
schema_agent = Agent(
    role="Schema Validator",
    goal="Identify schema issues in tabular data",
    backstory="An expert in data quality assurance",
    llm=llm
)

imbalance_agent = Agent(
    role="Class Imbalance Detector",
    goal="Detect and summarize class imbalance issues",
    backstory="A statistical detective for unbalanced datasets",
    llm=llm
)

preprocess_agent = Agent(
    role="Preprocessing Advisor",
    goal="Recommend preprocessing steps based on input data characteristics",
    backstory="A data engineer who loves clean inputs",
    llm=llm
)


# Define tasks using the agents and tools
schema_check_task = Task(
    description="Load the dataset from {dataset_path} and check its schema.",
    expected_output="A string representation of the dataset's schema (data types of columns).",
    agent=schema_agent,
    tools=[load_dataset, check_schema]
)

imbalance_check_task = Task(
    description="Load the dataset from {dataset_path} and check for class imbalance in the 'ocean_proximity' column. The target column is 'ocean_proximity'.",
    expected_output="A string representation of the value counts and their normalized distribution for the 'ocean_proximity' column.",
    agent=imbalance_agent,
    tools=[load_dataset, check_class_imbalance],
    context=[schema_check_task] # This task depends on the schema check
)

preprocessing_recommendation_task = Task(
    description="Load the dataset from {dataset_path} and recommend preprocessing steps based on missing values and categorical features.",
    expected_output="A list of recommended preprocessing steps, such as imputation for missing values and encoding for categorical variables.",
    agent=preprocess_agent,
    tools=[load_dataset, recommend_preprocessing],
    context=[schema_check_task] # This task depends on the schema check
)


crew = Crew(
    agents=[schema_agent, imbalance_agent, preprocess_agent],
    tasks=[schema_check_task, imbalance_check_task, preprocessing_recommendation_task],
    verbose=2 # Add verbose to see the execution process
)
crew_result = crew.kickoff(inputs={"dataset_path": "/content/sample_data/california_housing_test.csv"})
print(crew_result)

# Commented out IPython magic to ensure Python compatibility.
# # Save the content of cell Mf0jRy6DbAUZ to tools.py
# %%writefile tools.py
# import pandas as pd
# from sklearn.utils import resample
# from crewai import tool
# 
# @tool
# def load_dataset(path):
#     """Loads a dataset from a given path."""
#     print(f"Loading dataset from: {path}")
#     return pd.read_csv(path)
# 
# @tool
# def check_schema(df):
#     """Checks the schema (data types) of a pandas DataFrame."""
#     print("Checking schema...")
#     return df.dtypes.to_string()
# 
# @tool
# def check_class_imbalance(df: pd.DataFrame, target_col: str):
#     """Checks for class imbalance in a specified target column of a pandas DataFrame."""
#     print(f"Checking class imbalance for column: {target_col}")
#     if target_col not in df.columns:
#         return f"Error: Target column '{target_col}' not found in the dataset."
#     return df[target_col].value_counts(normalize=True).to_string()
# 
# @tool
# def recommend_preprocessing(df):
#     """Recommends preprocessing steps for a pandas DataFrame based on missing values and categorical features."""
#     print("Recommending preprocessing steps...")
#     recommendations = []
#     if df.isnull().sum().any():
#         recommendations.append("Impute missing values.")
#     if any(df.dtypes == 'object'):
#         recommendations.append("Encode categorical variables.")
#     return "\n".join(recommendations)

# Commented out IPython magic to ensure Python compatibility.
# # Save the content of cell BiG7KmG4atXZ to agents.py
# %%writefile agents.py
# from crewai import Agent
# 
# schema_agent = Agent(
#     role="Schema Validator",
#     goal="Identify schema issues in tabular data",
#     backstory="An expert in data quality assurance",
#     llm=llm
# )
# 
# imbalance_agent = Agent(
#     role="Class Imbalance Detector",
#     goal="Detect and summarize class imbalance issues",
#     backstory="A statistical detective for unbalanced datasets",
#     llm=llm
# )
# 
# preprocess_agent = Agent(
#     role="Preprocessing Advisor",
#     goal="Recommend preprocessing steps based on input data characteristics",
#     backstory="A data engineer who loves clean inputs",
#     llm=llm
# )

# streamlit_app.py
import streamlit as st
import pandas as pd
from workflow import run_workflow  # Assume this triggers the crew

st.title("ðŸ§  Dataset Auditor (Local LLM Powered)")

uploaded_file = st.file_uploader("Upload your CSV", type="csv")
if uploaded_file:
    with open("/content/sample_data/california_housing_test.csv", "wb") as f:
        f.write(uploaded_file.getbuffer())
    output = run_workflow("data/input.csv")
    st.markdown("### ðŸ“ Audit Report")
    st.text(output)



!pip install streamlit

from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from PyPDF2 import PdfReader
import re

!pip install langchain-openai

from langchain_community.llms import Ollama

model = Ollama(model="tinyllama:latest")

!pip install pypdf2

# Tool for loading and reading a PDF locally
from crewai.tools import tool
from PyPDF2 import PdfReader
import re

@tool
def fetch_pdf_content(pdf_path: str):
    """
    Reads a local PDF and returns the content
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())

        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

"""https://pub.towardsai.net/build-your-first-ai-agent-in-5-easy-steps-100-local-2fb771438a8f"""

from crewai import Agent
from langchain_openai import ChatOpenAI # Assuming ChatOpenAI is used for the model

# Assuming 'model' (ChatOpenAI instance) is defined in a previous cell

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF located in current local directory',
    backstory='Specializes in handling and interpreting PDF documents',
    verbose=True,
    tools=[fetch_pdf_content], # Now fetch_pdf_content is a crewai tool
    allow_delegation=False,
    llm=model
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article',
    backstory='Expert in creating informative and engaging articles',
    verbose=True,
    allow_delegation=False,
    llm=model
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling title for the article',
    backstory='Skilled in crafting engaging and relevant titles',
    verbose=True,
    allow_delegation=False,
    llm=model
)

def pdf_reading_task(pdf):
    return Task(
        description=f"Read and preprocess the PDF at this local path: {{pdf}}", # Use the 'pdf' argument
        agent=pdf_reader,
        expected_output="Extracted and preprocessed text from a PDF",
    )

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content.",
    agent=article_writer,
    expected_output="8-10 paragraphs describing the key points of the PDF",
    tools=[] # Add an empty tools list
)

task_title_generation = Task(
    description="Generate an engaging and relevant title for the article.",
    agent=title_creator,
    expected_output="A Title of About 5-7 Words",
    tools=[] # Add an empty tools list
)

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[pdf_reading_task(pdf="/content/Understanding_Climate_Change.pdf"), # Call the function with the actual PDF path
    task_article_drafting,
    task_title_generation],
    verbose=True # Change verbose to True
)

# Let's start!
result = crew.kickoff()





















from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from PyPDF2 import PdfReader
import re

from langchain_community.llms import Ollama

model = Ollama(model="tinyllama:latest")

# Tool for loading and reading a PDF locally
from crewai.tools import tool
from PyPDF2 import PdfReader
import re

@tool
def fetch_pdf_content(pdf_path: str):
    """
    Reads a local PDF and returns the content
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())

        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

from crewai import Agent
from langchain_openai import ChatOpenAI # Assuming ChatOpenAI is used for the model

# Assuming 'model' (ChatOpenAI instance) is defined in a previous cell

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF located in current local directory',
    backstory='Specializes in handling and interpreting PDF documents',
    verbose=True,
    tools=[fetch_pdf_content], # Now fetch_pdf_content is a crewai tool
    allow_delegation=False,
    llm=model
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article',
    backstory='Expert in creating informative and engaging articles',
    verbose=True,
    allow_delegation=False,
    llm=model
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling title for the article',
    backstory='Skilled in crafting engaging and relevant titles',
    verbose=True,
    allow_delegation=False,
    llm=model
)

def pdf_reading_task(pdf):
    return Task(
        description=f"Read and preprocess the PDF at this local path: {{pdf}}", # Use the 'pdf' argument
        agent=pdf_reader,
        expected_output="Extracted and preprocessed text from a PDF",
    )

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content.",
    agent=article_writer,
    expected_output="8-10 paragraphs describing the key points of the PDF",
    tools=[] # Add an empty tools list
)

task_title_generation = Task(
    description="Generate an engaging and relevant title for the article.",
    agent=title_creator,
    expected_output="A Title of About 5-7 Words",
    tools=[] # Add an empty tools list
)

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[pdf_reading_task(pdf="/content/Understanding_Climate_Change.pdf"), # Call the function with the actual PDF path
    task_article_drafting,
    task_title_generation],
    verbose=True # Change verbose to True
)

# Let's start!
result = crew.kickoff()











import re
from crewai import Agent, Task, Crew, Process
from langchain_community.chat_models import ChatOllama
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ -----------------
# ØªÙ… Ø§Ù„ØªØºÙŠÙŠØ± Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ChatOllama Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ollama Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ CrewAI
model = ChatOllama(model="tinyllama:latest")

# ----------------- 2. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø© (Tool) -----------------
# Ø£Ø¯Ø§Ø© Ù…Ø®ØµØµØ© Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù PDF Ù…Ù† Ù…Ø³Ø§Ø± Ù…Ø­Ù„ÙŠ
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            # Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù†Øµ Ù…Ù† ÙƒÙ„ Ø§Ù„ØµÙØ­Ø§Øª ÙˆØ¯Ù…Ø¬Ù‡Ø§
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())

        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ (Agents) -----------------

# ÙˆÙƒÙŠÙ„ Ù…ØªØ®ØµØµ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª PDF
pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content], # ØªØ²ÙˆÙŠØ¯ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø¨Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„ØªÙŠ Ø¹Ø±ÙÙ†Ø§Ù‡Ø§
    llm=model,
    allow_delegation=False
)

# ÙˆÙƒÙŠÙ„ Ù…ØªØ®ØµØµ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ÙˆÙƒÙŠÙ„ Ù…ØªØ®ØµØµ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ù‡Ø§Ù… (Tasks) -----------------

# Ù…Ù‡Ù…Ø© Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù PDF
# ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ÙˆØµÙ Ù„ÙŠÙ…Ø±Ø± Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

# Ù…Ù‡Ù…Ø© ØµÙŠØ§ØºØ© Ù…Ø³ÙˆØ¯Ø© Ø§Ù„Ù…Ù‚Ø§Ù„
task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf] # Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
)

# Ù…Ù‡Ù…Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting] # Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
)

# ----------------- 5. Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø§Ù‚Ù… (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential # ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ø§Ù… Ø¨Ø´ÙƒÙ„ Ù…ØªØ³Ù„Ø³Ù„
)

# ----------------- 6. Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ù… -----------------
print("ðŸš€ Starting Crew Execution...")
result = crew.kickoff()

print("\n\nâœ… Crew Execution Finished!")
print("Final Result:")
print(result)

!pip install -U langchain-ollama

# ----------------- 0. ØªØ«Ø¨ÙŠØª Ø§Ù„Ø­Ø²Ù…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© -----------------
# Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± ÙÙŠ Ø§Ù„Ø·Ø±ÙÙŠØ© (Terminal) Ø£Ùˆ ÙÙŠ Ø®Ù„ÙŠØ© Ù…Ù†ÙØµÙ„Ø© Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
# !pip install -U langchain-ollama py-pdf crewai

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ (Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© ÙˆØ§Ù„Ø­Ø¯ÙŠØ«Ø©) -----------------
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ ChatOllama Ù…Ù† Ø§Ù„Ø­Ø²Ù…Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù‡Ø§
from langchain_ollama import ChatOllama

# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙƒÙ…Ø§ Ù‡ÙˆØŒ Ù„ÙƒÙ† Ø§Ù„Ø¢Ù† Ø³ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„ÙŠÙ‡ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
model = ChatOllama(model="tinyllama:latest")


# ----------------- 2. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø© (Tool) -----------------
# Ø£Ø¯Ø§Ø© Ù…Ø®ØµØµØ© Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù PDF Ù…Ù† Ù…Ø³Ø§Ø± Ù…Ø­Ù„ÙŠ
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            # Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù†Øµ Ù…Ù† ÙƒÙ„ Ø§Ù„ØµÙØ­Ø§Øª ÙˆØ¯Ù…Ø¬Ù‡Ø§
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())

        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ (Agents) -----------------

# ÙˆÙƒÙŠÙ„ Ù…ØªØ®ØµØµ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª PDF
pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content], # ØªØ²ÙˆÙŠØ¯ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø¨Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„ØªÙŠ Ø¹Ø±ÙÙ†Ø§Ù‡Ø§
    llm=model,
    allow_delegation=False
)

# ÙˆÙƒÙŠÙ„ Ù…ØªØ®ØµØµ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ÙˆÙƒÙŠÙ„ Ù…ØªØ®ØµØµ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ù‡Ø§Ù… (Tasks) -----------------

# Ù…Ù‡Ù…Ø© Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù PDF
task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

# Ù…Ù‡Ù…Ø© ØµÙŠØ§ØºØ© Ù…Ø³ÙˆØ¯Ø© Ø§Ù„Ù…Ù‚Ø§Ù„
task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf] # Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
)

# Ù…Ù‡Ù…Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting] # Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‡Ù…Ø© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
)

# ----------------- 5. Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø§Ù‚Ù… (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential # ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ø§Ù… Ø¨Ø´ÙƒÙ„ Ù…ØªØ³Ù„Ø³Ù„
)

# ----------------- 6. Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ù… -----------------
print("ðŸš€ Starting Crew Execution...")
result = crew.kickoff()

print("\n\nâœ… Crew Execution Finished!")
print("Final Result:")
print(result)

!!pip install -U crewai langchain-ollama pypdf2

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ (Ù…Ø¹ ØªÙƒÙˆÙŠÙ† ØµØ±ÙŠØ­) -----------------
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ ChatOllama Ù…Ù† Ø§Ù„Ø­Ø²Ù…Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù‡Ø§
from langchain_ollama import ChatOllama

# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø¹Ù†ÙˆØ§Ù† URL Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ø®Ø§Ø¯Ù… Ollama Ø¨Ø´ÙƒÙ„ ØµØ±ÙŠØ­
# Ù‡Ø°Ø§ ÙŠØ¶Ù…Ù† Ø£Ù† crewai ÙŠØ¹Ø±Ù Ø¨Ø§Ù„Ø¶Ø¨Ø· Ø£ÙŠÙ† ÙŠØ±Ø³Ù„ Ø§Ù„Ø·Ù„Ø¨
model = ChatOllama(
    model="tinyllama:latest",
    base_url="http://localhost:11434" # Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù€ Ollama
)


# ----------------- 2. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø© (Tool) -----------------
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())
        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ (Agents) -----------------
# Ù„Ø§ ØªØºÙŠÙŠØ± Ù‡Ù†Ø§ØŒ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ ÙŠØ¹ØªÙ…Ø¯ÙˆÙ† Ø¹Ù„Ù‰ ÙƒØ§Ø¦Ù† 'model' Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ¹Ø±ÙŠÙÙ‡ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ Ø§Ù„Ø¢Ù†

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content],
    llm=model,
    allow_delegation=False
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ù‡Ø§Ù… (Tasks) -----------------

task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf]
)

task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting]
)

# ----------------- 5. Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø§Ù‚Ù… (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential
)

# ----------------- 6. Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ù… -----------------
print("ðŸš€ Starting Crew Execution...")
result = crew.kickoff()

print("\n\nâœ… Crew Execution Finished!")
print("Final Result:")
print(result)

"""### Ø´ØºØ§Ù„ ÙˆÙ„ÙƒÙ† ØºÙŠØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ (Ù…Ø¹ ØªØ¹Ø¯ÙŠÙ„ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬) -----------------
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ ChatOllama Ù…Ù† Ø§Ù„Ø­Ø²Ù…Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù‡Ø§
from langchain_ollama import ChatOllama

# Ø§Ù„ÙØ±Ø¶ÙŠØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø©: Ø³Ù†Ù‚ÙˆÙ… Ø¨ØªÙ…Ø±ÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„ØµÙŠØºØ© Ø§Ù„ØªÙŠ ØªÙÙ‡Ù…Ù‡Ø§ litellm Ù…Ø¨Ø§Ø´Ø±Ø©
# ÙˆÙ‡ÙŠ "provider/model_name". Ù‡Ø°Ø§ ÙŠØ®Ø¨Ø± crewai Ø¨Ø´ÙƒÙ„ ØµØ±ÙŠØ­ Ø¬Ø¯Ù‹Ø§
# Ø£Ù† ÙŠØ³ØªØ®Ø¯Ù… ollama ÙƒÙ€ "Ù…Ø²ÙˆØ¯ Ø®Ø¯Ù…Ø©".
model = ChatOllama(
    model="ollama/tinyllama:latest", # Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù‡Ù†Ø§
    base_url="http://localhost:11434"
)


# ----------------- 2. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø© (Tool) -----------------
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())
        processed_text = re.sub(r'\s+', ' ', text).strip()
        # Ø¥Ø¶Ø§ÙØ© ØªØ­Ù‚Ù‚ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù†Øµ Ù„ÙŠØ³ ÙØ§Ø±ØºÙ‹Ø§
        if not processed_text:
            return "Error: No text could be extracted from the PDF."
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}. Please ensure the path is correct."
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ (Agents) -----------------

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content],
    llm=model,
    allow_delegation=False
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ù‡Ø§Ù… (Tasks) -----------------

task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf]
)

task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting]
)

# ----------------- 5. Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø§Ù‚Ù… (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential
)

# ----------------- 6. Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ù… -----------------
print("ðŸš€ Starting Crew Execution...")
result = crew.kickoff()

print("\n\nâœ… Crew Execution Finished!")
print("Final Result:")
print(result)



"""https://pub.towardsai.net/build-your-first-ai-agent-in-5-easy-steps-100-local-2fb771438a8f

Ù†Ø¹Ù…ØŒ ØªØ­Ù„ÙŠÙ„Ùƒ ÙÙŠ Ù…ÙƒØ§Ù†Ù‡ ØªÙ…Ø§Ù…Ù‹Ø§. Ø§Ù„ÙƒÙˆØ¯ Ù„Ù… ÙŠÙ†Ø¬Ø­ ÙÙŠ ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ØŒ ÙˆØ§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù‡Ùˆ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ø§ Ø°ÙƒØ±ØªÙ‡: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (tinyllama) ØµØºÙŠØ± Ø¬Ø¯Ù‹Ø§ ÙˆØºÙŠØ± Ù‚Ø§Ø¯Ø± Ø¹Ù„Ù‰ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø§Ù„ØªÙŠ ÙŠØªØ·Ù„Ø¨Ù‡Ø§ Ù‡Ø°Ø§ Ø§Ù„Ø·Ø§Ù‚Ù….

Ø£Ù†Øª Ù„Ù… ØªÙØ´Ù„ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„ÙƒÙˆØ¯ØŒ Ø¨Ù„ ÙˆØµÙ„Øª Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù‚ØµÙˆÙ‰ Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡. Ø¯Ø¹Ù†Ø§ Ù†Ø­Ù„Ù„ Ù…Ø§ Ø­Ø¯Ø« Ø¨Ø§Ù„ØªÙØµÙŠÙ„ØŒ Ù„Ø£Ù† Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„ØªÙŠ Ø£Ø±Ø³Ù„ØªÙ‡Ø§ Ù‡ÙŠ Ù…Ø«Ø§Ù„ Ø±Ø§Ø¦Ø¹ Ø¬Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ "Ù‡Ù„ÙˆØ³Ø©" Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØµØºÙŠØ±Ø©.

ØªØ­Ù„ÙŠÙ„ Ù…Ø§ Ø­Ø¯Ø« Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©:

Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ (Ù…Ø³ØªØ®Ø±Ø¬ PDF): ÙØ´Ù„ ÙƒØ§Ø±Ø«ÙŠ

Ø§Ù„Ù…Ù‡Ù…Ø©: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯Ø§Ø© fetch_pdf_content Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù.

Ù…Ø§Ø°Ø§ ÙØ¹Ù„ØŸ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¯Ø§Ø©ØŒ Ù‡Ùˆ "Ù‡Ù„ÙˆØ³" Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„. Ù„Ù‚Ø¯ ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø¯Ø§Ø© ØªÙ…Ø§Ù…Ù‹Ø§ ÙˆÙ‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø© Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ø¯Ù„ÙŠÙ„ Ø¥Ø±Ø´Ø§Ø¯ÙŠ Ø¹Ø§Ù… Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù†ØµÙˆØµ. Ø¥Ø¬Ø§Ø¨ØªÙ‡ "I am unable to perform actions..." Ù‡ÙŠ Ø¹Ù„Ø§Ù…Ø© ÙˆØ§Ø¶Ø­Ø© Ø¹Ù„Ù‰ Ø£Ù†Ù‡ Ù„Ù… ÙŠÙÙ‡Ù… ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù‡.

Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù†Øµ Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù€ PDF.

Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø«Ø§Ù†ÙŠ (ÙƒØ§ØªØ¨ Ø§Ù„Ù…Ù‚Ø§Ù„): Ù‡Ù„ÙˆØ³Ø© Ù…Ø¨ØªÙƒØ±Ø©

Ø§Ù„Ù…Ù‡Ù…Ø©: ÙƒØªØ§Ø¨Ø© Ù…Ù‚Ø§Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©.

Ù…Ø§Ø°Ø§ Ø§Ø³ØªÙ„Ù…ØŸ Ø§Ø³ØªÙ„Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ø¥Ø±Ø´Ø§Ø¯ÙŠ Ø§Ù„Ø®Ø§Ø·Ø¦ Ù…Ù† Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„.

Ù…Ø§Ø°Ø§ ÙØ¹Ù„ØŸ Ù‡Ù†Ø§ Ø­Ø¯Ø« Ø´ÙŠØ¡ Ù…Ø«ÙŠØ± Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù…. Ø§Ù„ÙˆÙƒÙŠÙ„ ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø®Ø§Ø·Ø¦Ø© Ø§Ù„ØªÙŠ Ø§Ø³ØªÙ„Ù…Ù‡Ø§ØŒ ÙˆÙ„ÙƒÙ†Ù‡ ØªØ°ÙƒØ± Ø£Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¹Ø§Ù… Ù‡Ùˆ "Understanding Climate Change" (Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ÙˆÙˆØµÙ Ø§Ù„Ù…Ù‡Ù…Ø©). ÙÙ‚Ø§Ù… Ø¨ØªØ£Ù„ÙŠÙ Ù…Ù‚Ø§Ù„ ÙƒØ§Ù…Ù„ Ø­ÙˆÙ„ ØªØºÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø® Ù…Ù† Ù…Ø¹Ø±ÙØªÙ‡ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø©. Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ø°ÙŠ ØªØ±Ø§Ù‡ Ù„Ù… ÙŠØ£ØªÙ Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù€ PDF Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØŒ Ø¨Ù„ Ù‡Ùˆ Ù…Ù† ØªØ£Ù„ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„.

Ø§Ù„Ù†ØªÙŠØ¬Ø©: ÙƒØªØ¨ Ù…Ù‚Ø§Ù„Ø§Ù‹ØŒ Ù„ÙƒÙ†Ù‡ Ù„ÙŠØ³ Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨. ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆÙ‡ÙŠ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ¯Ø±.

Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø«Ø§Ù„Ø« (Ù…Ù†Ø´Ø¦ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†): ÙØ´Ù„ ÙƒØ§Ù…Ù„

Ø§Ù„Ù…Ù‡Ù…Ø©: Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù† 5-7 ÙƒÙ„Ù…Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ø°ÙŠ ØªÙ…Øª ÙƒØªØ§Ø¨ØªÙ‡.

Ù…Ø§Ø°Ø§ Ø§Ø³ØªÙ„Ù…ØŸ Ø§Ø³ØªÙ„Ù… Ø§Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„Ù…Ø¤Ù„Ù Ù…Ù† Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø«Ø§Ù†ÙŠ.

Ù…Ø§Ø°Ø§ ÙØ¹Ù„ØŸ ØªÙ…Ø§Ù…Ù‹Ø§ Ù…Ø«Ù„ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ØŒ ÙØ´Ù„ ÙÙŠ Ø£Ø¯Ø§Ø¡ Ù…Ù‡Ù…ØªÙ‡. ÙˆØ¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø¥Ø¹Ø·Ø§Ø¡ Ø¹Ù†ÙˆØ§Ù† Ù…Ø«Ù„ "Understanding Our Changing Climate"ØŒ Ù‚Ø§Ù… Ù‡Ùˆ Ø§Ù„Ø¢Ø®Ø± Ø¨Ø§Ù„Ù‡Ù„ÙˆØ³Ø© ÙˆØ£Ø¹Ø·Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø­ÙˆÙ„ ÙƒÙŠÙÙŠØ© ÙƒØªØ§Ø¨Ø© Ø¹Ù†ÙˆØ§Ù† Ø¬ÙŠØ¯!.

Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙŠ Ø¹Ù†ÙˆØ§Ù†.

Ø§Ù„Ø®Ù„Ø§ØµØ© ÙˆØ±Ø£ÙŠÙŠ

Ø±Ø£ÙŠÙŠ Ù‡Ùˆ Ø£Ù† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ ØµØ­ÙŠØ­ Ù…Ù† Ø­ÙŠØ« Ø§Ù„Ù‡ÙŠÙƒÙ„ ÙˆØ§Ù„Ù…Ù†Ø·Ù‚. Ù„Ù‚Ø¯ Ù‚Ù…Øª Ø¨ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ§Ù„ÙˆÙƒÙ„Ø§Ø¡ ÙˆØ§Ù„Ù…Ù‡Ø§Ù… Ø¨Ø´ÙƒÙ„ Ø³Ù„ÙŠÙ… ØªÙ…Ø§Ù…Ù‹Ø§. Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù„ÙŠØ³Øª ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ØŒ Ø¨Ù„ ÙÙŠ "Ø§Ù„Ø¹Ù‚Ù„" Ø§Ù„Ø°ÙŠ ÙŠÙ‚ÙˆØ¯ Ù‡Ø¤Ù„Ø§Ø¡ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡.

Ø£Ù†Øª Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙƒÙ…Ù† Ù‚Ø§Ù… Ø¨Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ø±Ø© Ø³Ø¨Ø§Ù‚ Ù…Ø«Ø§Ù„ÙŠØ© (Ù‡ÙŠÙƒÙ„ Ø§Ù„ÙƒÙˆØ¯)ØŒ ÙˆÙ„ÙƒÙ† ÙˆØ¶Ø¹ Ø¨Ø¯Ø§Ø®Ù„Ù‡Ø§ Ù…Ø­Ø±Ùƒ Ø¬Ø²Ø§Ø²Ø© Ø¹Ø´Ø¨ ØµØºÙŠØ±Ø© (tinyllama). Ø§Ù„Ø³ÙŠØ§Ø±Ø© Ù„Ù† ØªÙ†Ø·Ù„Ù‚ Ø¨Ø§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.

Ù„Ù‡Ø°Ø§ØŒ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ Ù‡ÙŠ: Ù†Ø¹Ù…ØŒ Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙØ¶Ù„ (ÙˆÙ†ØªØ§Ø¦Ø¬ Ù†Ø§Ø¬Ø­Ø©) Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ Ø£ÙØ¶Ù„ ÙˆØ£ÙƒØ¨Ø±.

Ø¥Ø°Ø§ Ù‚Ù…Øª Ø¨ØªØºÙŠÙŠØ± Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ:

code
Python
download
content_copy
expand_less

model = ChatOllama(
    model="ollama/llama3:latest", # Ø£Ùˆ mistral Ø£Ùˆ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ ÙƒØ¨ÙŠØ± Ø¢Ø®Ø±
    base_url="http://localhost:11434"
)

...ÙˆØªØ±ÙƒØª ÙƒÙ„ Ø´ÙŠØ¡ Ø¢Ø®Ø± ÙƒÙ…Ø§ Ù‡ÙˆØŒ Ø³ØªØ¬Ø¯ Ø£Ù†:

Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ Ø³ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¯Ø§Ø© Ø¨Ù†Ø¬Ø§Ø­ ÙˆÙŠÙ‚Ø±Ø£ Ø§Ù„Ù…Ù„Ù.

Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø«Ø§Ù†ÙŠ Ø³ÙŠÙƒØªØ¨ Ù…Ù‚Ø§Ù„Ø§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù…Ù„Ù.

Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø«Ø§Ù„Ø« Ø³ÙŠØ¹Ø·ÙŠÙƒ Ø¹Ù†ÙˆØ§Ù†Ù‹Ø§ ÙØ¹Ù„ÙŠÙ‹Ø§ Ù„Ù„Ù…Ù‚Ø§Ù„.

Ù„Ù‚Ø¯ Ù‚Ù…Øª Ø¨Ø¹Ù…Ù„ Ø±Ø§Ø¦Ø¹ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‡ÙŠÙƒÙ„ ÙˆØªØµØ­ÙŠØ­ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„. Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ù„Ùƒ Ù‡ÙŠ ÙÙ‚Ø· ØªØ±Ù‚ÙŠØ© "Ø§Ù„Ù…Ø­Ø±Ùƒ" (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ).
"""







Ù„Ù‡Ø°Ø§ØŒ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ Ù‡ÙŠ: Ù†Ø¹Ù…ØŒ Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø³ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙØ¶Ù„ (ÙˆÙ†ØªØ§Ø¦Ø¬ Ù†Ø§Ø¬Ø­Ø©) Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ Ø£ÙØ¶Ù„ ÙˆØ£ÙƒØ¨Ø±.
Ø¥Ø°Ø§ Ù‚Ù…Øª Ø¨ØªØºÙŠÙŠØ± Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ:
code
Python
model = ChatOllama(
    model="ollama/llama3:latest", # Ø£Ùˆ mistral Ø£Ùˆ Ø£ÙŠ Ù†Ù…ÙˆØ°Ø¬ ÙƒØ¨ÙŠØ± Ø¢Ø®Ø±
    base_url="http://localhost:11434"
)
...ÙˆØªØ±ÙƒØª ÙƒÙ„ Ø´ÙŠØ¡ Ø¢Ø®Ø± ÙƒÙ…Ø§ Ù‡ÙˆØŒ Ø³ØªØ¬Ø¯ Ø£Ù†:
Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ Ø³ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¯Ø§Ø© Ø¨Ù†Ø¬Ø§Ø­ ÙˆÙŠÙ‚Ø±Ø£ Ø§Ù„Ù…Ù„Ù.
Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø«Ø§Ù†ÙŠ Ø³ÙŠÙƒØªØ¨ Ù…Ù‚Ø§Ù„Ø§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù…Ù„Ù.
Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø«Ø§Ù„Ø« Ø³ÙŠØ¹Ø·ÙŠÙƒ Ø¹Ù†ÙˆØ§Ù†Ù‹Ø§ ÙØ¹Ù„ÙŠÙ‹Ø§ Ù„Ù„Ù…Ù‚Ø§Ù„.
Ù„Ù‚Ø¯ Ù‚Ù…Øª Ø¨Ø¹Ù…Ù„ Ø±Ø§Ø¦Ø¹ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‡ÙŠÙƒÙ„ ÙˆØªØµØ­ÙŠØ­ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„. Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ù„Ùƒ Ù‡ÙŠ ÙÙ‚Ø· ØªØ±Ù‚ÙŠØ© "Ø§Ù„Ù…Ø­Ø±Ùƒ" (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ)









ollama run llama3

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„Ø¥ÙŠÙ‚Ø§Ù Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø®Ø·Ø£ ØºÙŠØ± Ø§Ù„Ù‡Ø§Ù…Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
from crewai import Telemetry
Telemetry.disable_telemetry()


# ----------------- 1. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø£Ø°ÙƒÙ‰) -----------------
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ ChatOllama Ù…Ù† Ø§Ù„Ø­Ø²Ù…Ø© Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù‡Ø§
from langchain_ollama import ChatOllama

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ llama3 Ù„Ø£Ù†Ù‡ Ø£ÙƒØ«Ø± Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª
# ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ùƒ Ù‚Ù…Øª Ø¨ØªØ´ØºÙŠÙ„ `ollama run llama3` ÙÙŠ Ø§Ù„Ø·Ø±ÙÙŠØ© Ù…Ù† Ù‚Ø¨Ù„
model = ChatOllama(
    model="ollama/llama3:latest", # ØªÙ… Ø§Ù„ØªØºÙŠÙŠØ± Ø¥Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ø£ÙƒØ«Ø± Ù‚ÙˆØ©
    base_url="http://localhost:11434"
)


# ----------------- 2. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø© (Tool) -----------------
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    This tool is essential for reading the required document.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())
        processed_text = re.sub(r'\s+', ' ', text).strip()
        if not processed_text:
            return "Error: No text could be extracted from the PDF."
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}. Please ensure the path is correct."
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ (Agents) -----------------

pdf_reader = Agent(
    role='Expert PDF Content Extractor',
    goal='Use the fetch_pdf_content tool to extract all text from the PDF file located at the specified path.',
    backstory='You are a machine focused on one single task: executing the fetch_pdf_content tool. You do not answer questions; you only use your tool to read PDF files.',
    verbose=True,
    tools=[fetch_pdf_content],
    llm=model,
    allow_delegation=False
)

article_writer = Agent(
    role='Professional Article Writer',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in structuring information and writing clear, informative articles.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

title_creator = Agent(
    role='Creative Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…Ù‡Ø§Ù… (Tasks) -----------------

task_read_pdf = Task(
    description='Use the fetch_pdf_content tool to read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf".',
    agent=pdf_reader,
    expected_output="The full, raw text extracted from the PDF file, which will be passed to the writer."
)

task_article_drafting = Task(
    description="Based on the text provided from the PDF, write a comprehensive article of 8-10 paragraphs.",
    agent=article_writer,
    expected_output="A well-structured article with 8 to 10 paragraphs summarizing the key points from the text.",
    context=[task_read_pdf]
)

task_title_generation = Task(
    description="Generate an engaging title of about 5-7 words for the article you just read.",
    agent=title_creator,
    expected_output="A single, compelling title for the article.",
    context=[task_article_drafting]
)

# ----------------- 5. Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø§Ù‚Ù… (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential
)

# ----------------- 6. Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ù… -----------------
print("ðŸš€ Starting Crew Execution with a more capable model...")
result = crew.kickoff()

print("\n\nâœ… Crew Execution Finished!")
print("Final Result:")
print(result)