# -*- coding: utf-8 -*-
"""suc_agent_ollama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18xWjFxGF73x1w3WVQVTgfgWWXA0ka3AY
"""





"""https://medium.com/@whyamit101/local-ai-using-ollama-with-agents-114c72182c97"""

!curl -fsSL https://ollama.com/install.sh | sh

!ollama --version

!ollama

!ollama serve

!ollama run tinyllama

!pip install crewai

!ollama list

!pip install pyautogen langchain_community





"""### ÿ¥ÿ∫ÿßŸÑ ŸàŸÑŸÉŸÜ ÿ∫Ÿäÿ± ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨"""

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸä (ŸÖÿπ ÿ™ÿπÿØŸäŸÑ ÿßÿ≥ŸÖ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨) -----------------
# ÿßÿ≥ÿ™Ÿäÿ±ÿßÿØ ChatOllama ŸÖŸÜ ÿßŸÑÿ≠ÿ≤ŸÖÿ© ÿßŸÑŸÖÿÆÿµÿµÿ© ŸÑŸáÿß
from langchain_ollama import ChatOllama

# ÿßŸÑŸÅÿ±ÿ∂Ÿäÿ© ÿßŸÑÿ£ÿÆŸäÿ±ÿ©: ÿ≥ŸÜŸÇŸàŸÖ ÿ®ÿ™ŸÖÿ±Ÿäÿ± ÿßÿ≥ŸÖ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿ®ÿßŸÑÿµŸäÿ∫ÿ© ÿßŸÑÿ™Ÿä ÿ™ŸÅŸáŸÖŸáÿß litellm ŸÖÿ®ÿßÿ¥ÿ±ÿ©
# ŸàŸáŸä "provider/model_name". Ÿáÿ∞ÿß ŸäÿÆÿ®ÿ± crewai ÿ®ÿ¥ŸÉŸÑ ÿµÿ±Ÿäÿ≠ ÿ¨ÿØŸãÿß
# ÿ£ŸÜ Ÿäÿ≥ÿ™ÿÆÿØŸÖ ollama ŸÉŸÄ "ŸÖÿ≤ŸàÿØ ÿÆÿØŸÖÿ©".
model = ChatOllama(
    model="ollama/tinyllama:latest", # ÿßŸÑÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä ŸáŸÜÿß
    base_url="http://localhost:11434"
)


# ----------------- 2. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑÿ£ÿØÿßÿ© (Tool) -----------------
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())
        processed_text = re.sub(r'\s+', ' ', text).strip()
        # ÿ•ÿ∂ÿßŸÅÿ© ÿ™ÿ≠ŸÇŸÇ ŸÑŸÑÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑŸÜÿµ ŸÑŸäÿ≥ ŸÅÿßÿ±ÿ∫Ÿãÿß
        if not processed_text:
            return "Error: No text could be extracted from the PDF."
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}. Please ensure the path is correct."
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸàŸÉŸÑÿßÿ° (Agents) -----------------

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content],
    llm=model,
    allow_delegation=False
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÖŸáÿßŸÖ (Tasks) -----------------

task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf]
)

task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting]
)

# ----------------- 5. ÿ•ŸÜÿ¥ÿßÿ° Ÿàÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑÿ∑ÿßŸÇŸÖ (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential
)

# ----------------- 6. ÿ®ÿØÿ° ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ∑ÿßŸÇŸÖ -----------------
print("üöÄ Starting Crew Execution...")
result = crew.kickoff()

print("\n\n‚úÖ Crew Execution Finished!")
print("Final Result:")
print(result)

















from crewai import Agent, Task, Crew
from langchain.llms import Ollama

# Use local Mistral via Ollama
llm = Ollama(model="tinyllama:latest")

# Define the agents
researcher = Agent(
    role='Researcher',
    goal='Find 3 recent breakthroughs in diffusion models',
    backstory='You are a cutting-edge AI researcher.',
    llm=llm
)

writer = Agent(
    role='Writer',
    goal='Summarize key insights for a technical blog post',
    backstory='You write clearly for a data-savvy audience.',
    llm=llm
)

# Define tasks
task1 = Task(description='Collect 3 recent updates on diffusion models.', agent=researcher)
task2 = Task(description='Write a clear summary of those updates.', agent=writer)

# Run the crew
crew = Crew(tasks=[task1, task2])
crew.kickoff()

from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

# Define config manually
config = [{
    "model": "tinyllama:latest",
    "api_key": "ollama-not-needed",  # placeholder, but required by AutoGen
    "api_type": "ollama"
}]

assistant = AssistantAgent(
    name="assistant",
    llm_config={"config_list": config}
)

user_proxy = UserProxyAgent(
    name="user",
    human_input_mode="NEVER"
)

user_proxy.initiate_chat(assistant, message="Explain what Retrieval-Augmented Generation (RAG) is.")

import os
from langchain_community.llms import Ollama

model = os.getenv("DEFAULT_LLM", "tinyllama:latest")
llm = Ollama(model=model)

from crewai import Crew

from crewai.agents import Agent

from crewai import Crew
from crewai.agents import Agent
from crewai.llms import OllamaLLM

llm = OllamaLLM(model="tinyllama:latest")

!pip install pyautogen autogen

!export DEFAULT_LLM=tinyllama:latest

from crewai import Crew
from crewai.agents import Agent
from crewai.llms import OllamaLLM

# ‚úÖ 1. Define the local LLM backend
ollama_llm = OllamaLLM(model="tinyllama:latest")  # You can swap in llama3, codellama, etc.

# ‚úÖ 2. Define the agent
researcher = Agent(
    role="Researcher",
    goal="Search and summarize open datasets",
    backstory="An expert in public data analysis",
    llm=ollama_llm
)

# ‚úÖ 3. Initialize the crew
crew = Crew(agents=[researcher])

# ‚úÖ 4. Fire it up
crew.kickoff()

!pip install ollama fix-busted-json

from crewai import Agent

schema_agent = Agent(
    role="Schema Validator",
    goal="Identify schema issues in tabular data",
    backstory="An expert in data quality assurance",
    llm=llm
)

imbalance_agent = Agent(
    role="Class Imbalance Detector",
    goal="Detect and summarize class imbalance issues",
    backstory="A statistical detective for unbalanced datasets",
    llm=llm
)

preprocess_agent = Agent(
    role="Preprocessing Advisor",
    goal="Recommend preprocessing steps based on input data characteristics",
    backstory="A data engineer who loves clean inputs",
    llm=llm
)

import pandas as pd
from sklearn.utils import resample

def load_dataset(path):
    return pd.read_csv(path)

def check_schema(df):
    return df.dtypes.to_string()

def check_class_imbalance(df, target_col):
    return df[target_col].value_counts(normalize=True).to_string()

def recommend_preprocessing(df):
    recommendations = []
    if df.isnull().sum().any():
        recommendations.append("Impute missing values.")
    if any(df.dtypes == 'object'):
        recommendations.append("Encode categorical variables.")
    return "\n".join(recommendations)

from crewai import Crew

crew = Crew(agents=[schema_agent, imbalance_agent, preprocess_agent])
crew_result = crew.kickoff(inputs={"dataset_path": "/content/sample_data/california_housing_test.csv"})
print(crew_result)

import streamlit as st
import pandas as pd
from workflow import run_workflow  # Assume this triggers the crew

st.title("üß† Dataset Auditor (Local LLM Powered)")

uploaded_file = st.file_uploader("Upload your CSV", type="csv")
if uploaded_file:
    with open("data/input.csv", "wb") as f:
        f.write(uploaded_file.getbuffer())
    output = run_workflow("data/input.csv")
    st.markdown("### üìù Audit Report")
    st.text(output)

"""https://medium.com/@whyamit101/local-ai-using-ollama-with-agents-114c72182c97"""

from crewai import Agent, Task, Crew
from langchain.llms import Ollama

# Use local Mistral via Ollama
llm = Ollama(model="ollama/tinyllama:latest")

# Define the agents
researcher = Agent(
    role='Researcher',
    goal='Find 3 recent breakthroughs in diffusion models',
    backstory='You are a cutting-edge AI researcher.',
    llm=llm
)

writer = Agent(
    role='Writer',
    goal='Summarize key insights for a technical blog post',
    backstory='You write clearly for a data-savvy audience.',
    llm=llm
)

# Define tasks
task1 = Task(
    description='Collect 3 recent updates on diffusion models.',
    expected_output='A list of 3 recent breakthroughs in diffusion models with a brief description of each.',
    agent=researcher
)
task2 = Task(
    description='Write a clear summary of those updates.',
    expected_output='A technical blog post summarizing the 3 recent diffusion model breakthroughs, suitable for a data-savvy audience.',
    agent=writer
)

# Run the crew
crew = Crew(tasks=[task1, task2])
crew.kickoff()

from crewai import Agent, Task, Crew
from langchain.llms import Ollama

# Use local Mistral via Ollama
llm = Ollama(model="ollama/tinyllama:latest")

# Define the agents
researcher = Agent(
    role='Researcher',
    goal='Find 3 recent breakthroughs in diffusion models',
    backstory='You are a cutting-edge AI researcher.',
    llm=llm
)

writer = Agent(
    role='Writer',
    goal='Summarize key insights for a technical blog post',
    backstory='You write clearly for a data-savvy audience.',
    llm=llm
)

# Define tasks
task1 = Task(
    description='Collect 3 recent updates on diffusion models.',
    expected_output='A list of 3 recent breakthroughs in diffusion models with a brief description of each.',
    agent=researcher
)
task2 = Task(
    description='Write a clear summary of those updates.',
    expected_output='A technical blog post summarizing the 3 recent diffusion model breakthroughs, suitable for a data-savvy audience.',
    agent=writer
)

# Run the crew
crew = Crew(tasks=[task1, task2])
crew.kickoff()

from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

# Define config manually
config = [{
    "model": "ollama/tinyllama:latest",
    "api_base": "http://localhost:11434/v1",
    "api_key": "ollama-not-needed",  # placeholder, but required by AutoGen
    "api_type": "ollama"
}]

assistant = AssistantAgent(
    name="assistant",
    llm_config={"config_list": config}
)

user_proxy = UserProxyAgent(
    name="user",
    human_input_mode="NEVER"
)

user_proxy.initiate_chat(assistant, message="Explain what Retrieval-Augmented Generation (RAG) is.")

ollama/tinyllama:latest

from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

# Define config manually
config = [{
    "model": "ollama/tinyllama:latest",
    "api_base": "http://localhost:11434/v1",
    "api_key": "ollama-not-needed",  # placeholder, but required by AutoGen
    "api_type": "open_ai"
}]

assistant = AssistantAgent(
    name="assistant",
    llm_config={"config_list": config}
)

user_proxy = UserProxyAgent(
    name="user",
    human_input_mode="NEVER"
)

user_proxy.initiate_chat(assistant, message="Explain what Retrieval-Augmented Generation (RAG) is.")

from crewai import Crew, Agent
from langchain_community.llms import Ollama

# ‚úÖ 1. Define the local LLM backend
ollama_llm = Ollama(model="ollama/tinyllama:latest")  # You can swap in llama3, codellama, etc.

# ‚úÖ 2. Define the agent
researcher = Agent(
    role="Researcher",
    goal="Search and summarize open datasets",
    backstory="An expert in public data analysis",
    llm=ollama_llm
)

# ‚úÖ 3. Initialize the crew
crew = Crew(agents=[researcher])

# ‚úÖ 4. Fire it up
crew.kickoff()

from crewai import Crew, Agent
from langchain_community.llms import Ollama

llm = Ollama(model="tinyllama:latest")

# agents.py
from crewai import Agent

schema_agent = Agent(
    role="Schema Validator",
    goal="Identify schema issues in tabular data",
    backstory="An expert in data quality assurance",
    llm=llm
)

imbalance_agent = Agent(
    role="Class Imbalance Detector",
    goal="Detect and summarize class imbalance issues",
    backstory="A statistical detective for unbalanced datasets",
    llm=llm
)

preprocess_agent = Agent(
    role="Preprocessing Advisor",
    goal="Recommend preprocessing steps based on input data characteristics",
    backstory="A data engineer who loves clean inputs",
    llm=llm
)

# tools.py
import pandas as pd
from sklearn.utils import resample

def load_dataset(path):
    return pd.read_csv(path)

def check_schema(df):
    return df.dtypes.to_string()

def check_class_imbalance(df, target_col):
    return df[target_col].value_counts(normalize=True).to_string()

def recommend_preprocessing(df):
    recommendations = []
    if df.isnull().sum().any():
        recommendations.append("Impute missing values.")
    if any(df.dtypes == 'object'):
        recommendations.append("Encode categorical variables.")
    return "\n".join(recommendations)

# workflow.py
from crewai import Crew, Task, Agent
from tools import load_dataset, check_schema, check_class_imbalance, recommend_preprocessing
from langchain_community.llms import Ollama

# Define the local LLM backend (assuming it's already initialized in a previous cell)
# If not initialized, uncomment the following lines:
llm = Ollama(model="tinyllama:latest")

# Define the agents
schema_agent = Agent(
    role="Schema Validator",
    goal="Identify schema issues in tabular data",
    backstory="An expert in data quality assurance",
    llm=llm
)

imbalance_agent = Agent(
    role="Class Imbalance Detector",
    goal="Detect and summarize class imbalance issues",
    backstory="A statistical detective for unbalanced datasets",
    llm=llm
)

preprocess_agent = Agent(
    role="Preprocessing Advisor",
    goal="Recommend preprocessing steps based on input data characteristics",
    backstory="A data engineer who loves clean inputs",
    llm=llm
)


# Define tasks using the agents and tools
schema_check_task = Task(
    description="Load the dataset from {dataset_path} and check its schema.",
    expected_output="A string representation of the dataset's schema (data types of columns).",
    agent=schema_agent,
    tools=[load_dataset, check_schema]
)

imbalance_check_task = Task(
    description="Load the dataset from {dataset_path} and check for class imbalance in the 'ocean_proximity' column. The target column is 'ocean_proximity'.",
    expected_output="A string representation of the value counts and their normalized distribution for the 'ocean_proximity' column.",
    agent=imbalance_agent,
    tools=[load_dataset, check_class_imbalance],
    context=[schema_check_task] # This task depends on the schema check
)

preprocessing_recommendation_task = Task(
    description="Load the dataset from {dataset_path} and recommend preprocessing steps based on missing values and categorical features.",
    expected_output="A list of recommended preprocessing steps, such as imputation for missing values and encoding for categorical variables.",
    agent=preprocess_agent,
    tools=[load_dataset, recommend_preprocessing],
    context=[schema_check_task] # This task depends on the schema check
)


crew = Crew(
    agents=[schema_agent, imbalance_agent, preprocess_agent],
    tasks=[schema_check_task, imbalance_check_task, preprocessing_recommendation_task],
    verbose=2 # Add verbose to see the execution process
)
crew_result = crew.kickoff(inputs={"dataset_path": "/content/sample_data/california_housing_test.csv"})
print(crew_result)

# Commented out IPython magic to ensure Python compatibility.
# # Save the content of cell Mf0jRy6DbAUZ to tools.py
# %%writefile tools.py
# import pandas as pd
# from sklearn.utils import resample
# from crewai import tool
# 
# @tool
# def load_dataset(path):
#     """Loads a dataset from a given path."""
#     print(f"Loading dataset from: {path}")
#     return pd.read_csv(path)
# 
# @tool
# def check_schema(df):
#     """Checks the schema (data types) of a pandas DataFrame."""
#     print("Checking schema...")
#     return df.dtypes.to_string()
# 
# @tool
# def check_class_imbalance(df: pd.DataFrame, target_col: str):
#     """Checks for class imbalance in a specified target column of a pandas DataFrame."""
#     print(f"Checking class imbalance for column: {target_col}")
#     if target_col not in df.columns:
#         return f"Error: Target column '{target_col}' not found in the dataset."
#     return df[target_col].value_counts(normalize=True).to_string()
# 
# @tool
# def recommend_preprocessing(df):
#     """Recommends preprocessing steps for a pandas DataFrame based on missing values and categorical features."""
#     print("Recommending preprocessing steps...")
#     recommendations = []
#     if df.isnull().sum().any():
#         recommendations.append("Impute missing values.")
#     if any(df.dtypes == 'object'):
#         recommendations.append("Encode categorical variables.")
#     return "\n".join(recommendations)

# Commented out IPython magic to ensure Python compatibility.
# # Save the content of cell BiG7KmG4atXZ to agents.py
# %%writefile agents.py
# from crewai import Agent
# 
# schema_agent = Agent(
#     role="Schema Validator",
#     goal="Identify schema issues in tabular data",
#     backstory="An expert in data quality assurance",
#     llm=llm
# )
# 
# imbalance_agent = Agent(
#     role="Class Imbalance Detector",
#     goal="Detect and summarize class imbalance issues",
#     backstory="A statistical detective for unbalanced datasets",
#     llm=llm
# )
# 
# preprocess_agent = Agent(
#     role="Preprocessing Advisor",
#     goal="Recommend preprocessing steps based on input data characteristics",
#     backstory="A data engineer who loves clean inputs",
#     llm=llm
# )

# streamlit_app.py
import streamlit as st
import pandas as pd
from workflow import run_workflow  # Assume this triggers the crew

st.title("üß† Dataset Auditor (Local LLM Powered)")

uploaded_file = st.file_uploader("Upload your CSV", type="csv")
if uploaded_file:
    with open("/content/sample_data/california_housing_test.csv", "wb") as f:
        f.write(uploaded_file.getbuffer())
    output = run_workflow("data/input.csv")
    st.markdown("### üìù Audit Report")
    st.text(output)



!pip install streamlit

from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from PyPDF2 import PdfReader
import re

!pip install langchain-openai

from langchain_community.llms import Ollama

model = Ollama(model="tinyllama:latest")

!pip install pypdf2

# Tool for loading and reading a PDF locally
from crewai.tools import tool
from PyPDF2 import PdfReader
import re

@tool
def fetch_pdf_content(pdf_path: str):
    """
    Reads a local PDF and returns the content
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())

        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

"""https://pub.towardsai.net/build-your-first-ai-agent-in-5-easy-steps-100-local-2fb771438a8f"""

from crewai import Agent
from langchain_openai import ChatOpenAI # Assuming ChatOpenAI is used for the model

# Assuming 'model' (ChatOpenAI instance) is defined in a previous cell

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF located in current local directory',
    backstory='Specializes in handling and interpreting PDF documents',
    verbose=True,
    tools=[fetch_pdf_content], # Now fetch_pdf_content is a crewai tool
    allow_delegation=False,
    llm=model
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article',
    backstory='Expert in creating informative and engaging articles',
    verbose=True,
    allow_delegation=False,
    llm=model
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling title for the article',
    backstory='Skilled in crafting engaging and relevant titles',
    verbose=True,
    allow_delegation=False,
    llm=model
)

def pdf_reading_task(pdf):
    return Task(
        description=f"Read and preprocess the PDF at this local path: {{pdf}}", # Use the 'pdf' argument
        agent=pdf_reader,
        expected_output="Extracted and preprocessed text from a PDF",
    )

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content.",
    agent=article_writer,
    expected_output="8-10 paragraphs describing the key points of the PDF",
    tools=[] # Add an empty tools list
)

task_title_generation = Task(
    description="Generate an engaging and relevant title for the article.",
    agent=title_creator,
    expected_output="A Title of About 5-7 Words",
    tools=[] # Add an empty tools list
)

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[pdf_reading_task(pdf="/content/Understanding_Climate_Change.pdf"), # Call the function with the actual PDF path
    task_article_drafting,
    task_title_generation],
    verbose=True # Change verbose to True
)

# Let's start!
result = crew.kickoff()





















from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from PyPDF2 import PdfReader
import re

from langchain_community.llms import Ollama

model = Ollama(model="tinyllama:latest")

# Tool for loading and reading a PDF locally
from crewai.tools import tool
from PyPDF2 import PdfReader
import re

@tool
def fetch_pdf_content(pdf_path: str):
    """
    Reads a local PDF and returns the content
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())

        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

from crewai import Agent
from langchain_openai import ChatOpenAI # Assuming ChatOpenAI is used for the model

# Assuming 'model' (ChatOpenAI instance) is defined in a previous cell

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF located in current local directory',
    backstory='Specializes in handling and interpreting PDF documents',
    verbose=True,
    tools=[fetch_pdf_content], # Now fetch_pdf_content is a crewai tool
    allow_delegation=False,
    llm=model
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article',
    backstory='Expert in creating informative and engaging articles',
    verbose=True,
    allow_delegation=False,
    llm=model
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling title for the article',
    backstory='Skilled in crafting engaging and relevant titles',
    verbose=True,
    allow_delegation=False,
    llm=model
)

def pdf_reading_task(pdf):
    return Task(
        description=f"Read and preprocess the PDF at this local path: {{pdf}}", # Use the 'pdf' argument
        agent=pdf_reader,
        expected_output="Extracted and preprocessed text from a PDF",
    )

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content.",
    agent=article_writer,
    expected_output="8-10 paragraphs describing the key points of the PDF",
    tools=[] # Add an empty tools list
)

task_title_generation = Task(
    description="Generate an engaging and relevant title for the article.",
    agent=title_creator,
    expected_output="A Title of About 5-7 Words",
    tools=[] # Add an empty tools list
)

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[pdf_reading_task(pdf="/content/Understanding_Climate_Change.pdf"), # Call the function with the actual PDF path
    task_article_drafting,
    task_title_generation],
    verbose=True # Change verbose to True
)

# Let's start!
result = crew.kickoff()











import re
from crewai import Agent, Task, Crew, Process
from langchain_community.chat_models import ChatOllama
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸä -----------------
# ÿ™ŸÖ ÿßŸÑÿ™ÿ∫ŸäŸäÿ± ŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ChatOllama ÿ®ÿØŸÑÿßŸã ŸÖŸÜ Ollama ŸÑÿ∂ŸÖÿßŸÜ ÿßŸÑÿ™ŸàÿßŸÅŸÇ ŸÖÿπ CrewAI
model = ChatOllama(model="tinyllama:latest")

# ----------------- 2. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑÿ£ÿØÿßÿ© (Tool) -----------------
# ÿ£ÿØÿßÿ© ŸÖÿÆÿµÿµÿ© ŸÑŸÇÿ±ÿßÿ°ÿ© ŸÖÿ≠ÿ™ŸàŸâ ŸÖŸÑŸÅ PDF ŸÖŸÜ ŸÖÿ≥ÿßÿ± ŸÖÿ≠ŸÑŸä
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            # ÿßÿ≥ÿ™ÿÆŸÑÿßÿµ ÿßŸÑŸÜÿµ ŸÖŸÜ ŸÉŸÑ ÿßŸÑÿµŸÅÿ≠ÿßÿ™ ŸàÿØŸÖÿ¨Ÿáÿß
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())

        # ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑŸÜÿµ ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿßŸÅÿßÿ™ ÿßŸÑÿ≤ÿßÿ¶ÿØÿ©
        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸàŸÉŸÑÿßÿ° (Agents) -----------------

# ŸàŸÉŸäŸÑ ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ŸÇÿ±ÿßÿ°ÿ© ŸÖŸÑŸÅÿßÿ™ PDF
pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content], # ÿ™ÿ≤ŸàŸäÿØ ÿßŸÑŸàŸÉŸäŸÑ ÿ®ÿßŸÑÿ£ÿØÿßÿ© ÿßŸÑÿ™Ÿä ÿπÿ±ŸÅŸÜÿßŸáÿß
    llm=model,
    allow_delegation=False
)

# ŸàŸÉŸäŸÑ ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ŸÉÿ™ÿßÿ®ÿ© ÿßŸÑŸÖŸÇÿßŸÑÿßÿ™
article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ŸàŸÉŸäŸÑ ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑÿπŸÜÿßŸàŸäŸÜ
title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÖŸáÿßŸÖ (Tasks) -----------------

# ŸÖŸáŸÖÿ© ŸÇÿ±ÿßÿ°ÿ© ŸÖŸÑŸÅ PDF
# ÿ™ŸÖ ÿ™ÿπÿØŸäŸÑ ÿßŸÑŸàÿµŸÅ ŸÑŸäŸÖÿ±ÿ± ŸÖÿ≥ÿßÿ± ÿßŸÑŸÖŸÑŸÅ ÿ®ÿ¥ŸÉŸÑ ÿµÿ≠Ÿäÿ≠
task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

# ŸÖŸáŸÖÿ© ÿµŸäÿßÿ∫ÿ© ŸÖÿ≥ŸàÿØÿ© ÿßŸÑŸÖŸÇÿßŸÑ
task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf] # Ÿáÿ∞Ÿá ÿßŸÑŸÖŸáŸÖÿ© ÿ™ÿπÿ™ŸÖÿØ ÿπŸÑŸâ ŸÖÿÆÿ±ÿ¨ÿßÿ™ ÿßŸÑŸÖŸáŸÖÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©
)

# ŸÖŸáŸÖÿ© ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑÿπŸÜŸàÿßŸÜ
task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting] # Ÿáÿ∞Ÿá ÿßŸÑŸÖŸáŸÖÿ© ÿ™ÿπÿ™ŸÖÿØ ÿπŸÑŸâ ŸÖÿÆÿ±ÿ¨ÿßÿ™ ÿßŸÑŸÖŸáŸÖÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©
)

# ----------------- 5. ÿ•ŸÜÿ¥ÿßÿ° Ÿàÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑÿ∑ÿßŸÇŸÖ (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential # ÿ™ŸÜŸÅŸäÿ∞ ÿßŸÑŸÖŸáÿßŸÖ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ™ÿ≥ŸÑÿ≥ŸÑ
)

# ----------------- 6. ÿ®ÿØÿ° ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ∑ÿßŸÇŸÖ -----------------
print("üöÄ Starting Crew Execution...")
result = crew.kickoff()

print("\n\n‚úÖ Crew Execution Finished!")
print("Final Result:")
print(result)

!pip install -U langchain-ollama

# ----------------- 0. ÿ™ÿ´ÿ®Ÿäÿ™ ÿßŸÑÿ≠ÿ≤ŸÖÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ© -----------------
# ŸÇŸÖ ÿ®ÿ™ÿ¥ÿ∫ŸäŸÑ Ÿáÿ∞ÿß ÿßŸÑÿ£ŸÖÿ± ŸÅŸä ÿßŸÑÿ∑ÿ±ŸÅŸäÿ© (Terminal) ÿ£Ÿà ŸÅŸä ÿÆŸÑŸäÿ© ŸÖŸÜŸÅÿµŸÑÿ© ŸÖÿ±ÿ© Ÿàÿßÿ≠ÿØÿ©
# !pip install -U langchain-ollama py-pdf crewai

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸä (ÿßŸÑÿ∑ÿ±ŸäŸÇÿ© ÿßŸÑÿµÿ≠Ÿäÿ≠ÿ© ŸàÿßŸÑÿ≠ÿØŸäÿ´ÿ©) -----------------
# ÿßÿ≥ÿ™Ÿäÿ±ÿßÿØ ChatOllama ŸÖŸÜ ÿßŸÑÿ≠ÿ≤ŸÖÿ© ÿßŸÑŸÖÿÆÿµÿµÿ© ŸÑŸáÿß
from langchain_ollama import ChatOllama

# ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ŸÉŸÖÿß ŸáŸàÿå ŸÑŸÉŸÜ ÿßŸÑÿ¢ŸÜ ÿ≥Ÿäÿ™ŸÖ ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸäŸá ÿ®ÿ¥ŸÉŸÑ ÿµÿ≠Ÿäÿ≠
model = ChatOllama(model="tinyllama:latest")


# ----------------- 2. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑÿ£ÿØÿßÿ© (Tool) -----------------
# ÿ£ÿØÿßÿ© ŸÖÿÆÿµÿµÿ© ŸÑŸÇÿ±ÿßÿ°ÿ© ŸÖÿ≠ÿ™ŸàŸâ ŸÖŸÑŸÅ PDF ŸÖŸÜ ŸÖÿ≥ÿßÿ± ŸÖÿ≠ŸÑŸä
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            # ÿßÿ≥ÿ™ÿÆŸÑÿßÿµ ÿßŸÑŸÜÿµ ŸÖŸÜ ŸÉŸÑ ÿßŸÑÿµŸÅÿ≠ÿßÿ™ ŸàÿØŸÖÿ¨Ÿáÿß
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())

        # ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑŸÜÿµ ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿßŸÅÿßÿ™ ÿßŸÑÿ≤ÿßÿ¶ÿØÿ©
        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸàŸÉŸÑÿßÿ° (Agents) -----------------

# ŸàŸÉŸäŸÑ ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ŸÇÿ±ÿßÿ°ÿ© ŸÖŸÑŸÅÿßÿ™ PDF
pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content], # ÿ™ÿ≤ŸàŸäÿØ ÿßŸÑŸàŸÉŸäŸÑ ÿ®ÿßŸÑÿ£ÿØÿßÿ© ÿßŸÑÿ™Ÿä ÿπÿ±ŸÅŸÜÿßŸáÿß
    llm=model,
    allow_delegation=False
)

# ŸàŸÉŸäŸÑ ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ŸÉÿ™ÿßÿ®ÿ© ÿßŸÑŸÖŸÇÿßŸÑÿßÿ™
article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ŸàŸÉŸäŸÑ ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑÿπŸÜÿßŸàŸäŸÜ
title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÖŸáÿßŸÖ (Tasks) -----------------

# ŸÖŸáŸÖÿ© ŸÇÿ±ÿßÿ°ÿ© ŸÖŸÑŸÅ PDF
task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

# ŸÖŸáŸÖÿ© ÿµŸäÿßÿ∫ÿ© ŸÖÿ≥ŸàÿØÿ© ÿßŸÑŸÖŸÇÿßŸÑ
task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf] # Ÿáÿ∞Ÿá ÿßŸÑŸÖŸáŸÖÿ© ÿ™ÿπÿ™ŸÖÿØ ÿπŸÑŸâ ŸÖÿÆÿ±ÿ¨ÿßÿ™ ÿßŸÑŸÖŸáŸÖÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©
)

# ŸÖŸáŸÖÿ© ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑÿπŸÜŸàÿßŸÜ
task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting] # Ÿáÿ∞Ÿá ÿßŸÑŸÖŸáŸÖÿ© ÿ™ÿπÿ™ŸÖÿØ ÿπŸÑŸâ ŸÖÿÆÿ±ÿ¨ÿßÿ™ ÿßŸÑŸÖŸáŸÖÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©
)

# ----------------- 5. ÿ•ŸÜÿ¥ÿßÿ° Ÿàÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑÿ∑ÿßŸÇŸÖ (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential # ÿ™ŸÜŸÅŸäÿ∞ ÿßŸÑŸÖŸáÿßŸÖ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ™ÿ≥ŸÑÿ≥ŸÑ
)

# ----------------- 6. ÿ®ÿØÿ° ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ∑ÿßŸÇŸÖ -----------------
print("üöÄ Starting Crew Execution...")
result = crew.kickoff()

print("\n\n‚úÖ Crew Execution Finished!")
print("Final Result:")
print(result)

!!pip install -U crewai langchain-ollama pypdf2

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸä (ŸÖÿπ ÿ™ŸÉŸàŸäŸÜ ÿµÿ±Ÿäÿ≠) -----------------
# ÿßÿ≥ÿ™Ÿäÿ±ÿßÿØ ChatOllama ŸÖŸÜ ÿßŸÑÿ≠ÿ≤ŸÖÿ© ÿßŸÑŸÖÿÆÿµÿµÿ© ŸÑŸáÿß
from langchain_ollama import ChatOllama

# ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ŸÖÿπ ÿ™ÿ≠ÿØŸäÿØ ÿπŸÜŸàÿßŸÜ URL ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿä ŸÑÿÆÿßÿØŸÖ Ollama ÿ®ÿ¥ŸÉŸÑ ÿµÿ±Ÿäÿ≠
# Ÿáÿ∞ÿß Ÿäÿ∂ŸÖŸÜ ÿ£ŸÜ crewai Ÿäÿπÿ±ŸÅ ÿ®ÿßŸÑÿ∂ÿ®ÿ∑ ÿ£ŸäŸÜ Ÿäÿ±ÿ≥ŸÑ ÿßŸÑÿ∑ŸÑÿ®
model = ChatOllama(
    model="tinyllama:latest",
    base_url="http://localhost:11434" # Ÿáÿ∞ÿß ŸáŸà ÿßŸÑÿπŸÜŸàÿßŸÜ ÿßŸÑÿßŸÅÿ™ÿ±ÿßÿ∂Ÿä ŸÑŸÄ Ollama
)


# ----------------- 2. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑÿ£ÿØÿßÿ© (Tool) -----------------
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())
        processed_text = re.sub(r'\s+', ' ', text).strip()
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}"
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸàŸÉŸÑÿßÿ° (Agents) -----------------
# ŸÑÿß ÿ™ÿ∫ŸäŸäÿ± ŸáŸÜÿßÿå ÿßŸÑŸàŸÉŸÑÿßÿ° Ÿäÿπÿ™ŸÖÿØŸàŸÜ ÿπŸÑŸâ ŸÉÿßÿ¶ŸÜ 'model' ÿßŸÑÿ∞Ÿä ÿ™ŸÖ ÿ™ÿπÿ±ŸäŸÅŸá ÿ®ÿ¥ŸÉŸÑ ÿ£ŸÅÿ∂ŸÑ ÿßŸÑÿ¢ŸÜ

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content],
    llm=model,
    allow_delegation=False
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÖŸáÿßŸÖ (Tasks) -----------------

task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf]
)

task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting]
)

# ----------------- 5. ÿ•ŸÜÿ¥ÿßÿ° Ÿàÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑÿ∑ÿßŸÇŸÖ (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential
)

# ----------------- 6. ÿ®ÿØÿ° ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ∑ÿßŸÇŸÖ -----------------
print("üöÄ Starting Crew Execution...")
result = crew.kickoff()

print("\n\n‚úÖ Crew Execution Finished!")
print("Final Result:")
print(result)

"""### ÿ¥ÿ∫ÿßŸÑ ŸàŸÑŸÉŸÜ ÿ∫Ÿäÿ± ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨"""

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# ----------------- 1. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸä (ŸÖÿπ ÿ™ÿπÿØŸäŸÑ ÿßÿ≥ŸÖ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨) -----------------
# ÿßÿ≥ÿ™Ÿäÿ±ÿßÿØ ChatOllama ŸÖŸÜ ÿßŸÑÿ≠ÿ≤ŸÖÿ© ÿßŸÑŸÖÿÆÿµÿµÿ© ŸÑŸáÿß
from langchain_ollama import ChatOllama

# ÿßŸÑŸÅÿ±ÿ∂Ÿäÿ© ÿßŸÑÿ£ÿÆŸäÿ±ÿ©: ÿ≥ŸÜŸÇŸàŸÖ ÿ®ÿ™ŸÖÿ±Ÿäÿ± ÿßÿ≥ŸÖ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿ®ÿßŸÑÿµŸäÿ∫ÿ© ÿßŸÑÿ™Ÿä ÿ™ŸÅŸáŸÖŸáÿß litellm ŸÖÿ®ÿßÿ¥ÿ±ÿ©
# ŸàŸáŸä "provider/model_name". Ÿáÿ∞ÿß ŸäÿÆÿ®ÿ± crewai ÿ®ÿ¥ŸÉŸÑ ÿµÿ±Ÿäÿ≠ ÿ¨ÿØŸãÿß
# ÿ£ŸÜ Ÿäÿ≥ÿ™ÿÆÿØŸÖ ollama ŸÉŸÄ "ŸÖÿ≤ŸàÿØ ÿÆÿØŸÖÿ©".
model = ChatOllama(
    model="ollama/tinyllama:latest", # ÿßŸÑÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä ŸáŸÜÿß
    base_url="http://localhost:11434"
)


# ----------------- 2. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑÿ£ÿØÿßÿ© (Tool) -----------------
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())
        processed_text = re.sub(r'\s+', ' ', text).strip()
        # ÿ•ÿ∂ÿßŸÅÿ© ÿ™ÿ≠ŸÇŸÇ ŸÑŸÑÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑŸÜÿµ ŸÑŸäÿ≥ ŸÅÿßÿ±ÿ∫Ÿãÿß
        if not processed_text:
            return "Error: No text could be extracted from the PDF."
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}. Please ensure the path is correct."
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸàŸÉŸÑÿßÿ° (Agents) -----------------

pdf_reader = Agent(
    role='PDF Content Extractor',
    goal='Extract and preprocess text from a PDF file located at a given local path.',
    backstory='You are an expert in handling and interpreting PDF documents, capable of extracting clean text.',
    verbose=True,
    tools=[fetch_pdf_content],
    llm=model,
    allow_delegation=False
)

article_writer = Agent(
    role='Article Creator',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in creating informative and engaging articles that are easy to understand.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

title_creator = Agent(
    role='Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging and SEO-friendly titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÖŸáÿßŸÖ (Tasks) -----------------

task_read_pdf = Task(
    description='Read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf" and extract its text.',
    agent=pdf_reader,
    expected_output="The full, preprocessed text extracted from the PDF file."
)

task_article_drafting = Task(
    description="Create a concise article with 8-10 paragraphs based on the extracted PDF content from the previous task.",
    agent=article_writer,
    expected_output="An 8 to 10 paragraph article that clearly summarizes the key points of the PDF content.",
    context=[task_read_pdf]
)

task_title_generation = Task(
    description="Generate an engaging and relevant title of about 5-7 words for the article created.",
    agent=title_creator,
    expected_output="A single, compelling title for the article, approximately 5-7 words long.",
    context=[task_article_drafting]
)

# ----------------- 5. ÿ•ŸÜÿ¥ÿßÿ° Ÿàÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑÿ∑ÿßŸÇŸÖ (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential
)

# ----------------- 6. ÿ®ÿØÿ° ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ∑ÿßŸÇŸÖ -----------------
print("üöÄ Starting Crew Execution...")
result = crew.kickoff()

print("\n\n‚úÖ Crew Execution Finished!")
print("Final Result:")
print(result)



"""https://pub.towardsai.net/build-your-first-ai-agent-in-5-easy-steps-100-local-2fb771438a8f

ŸÜÿπŸÖÿå ÿ™ÿ≠ŸÑŸäŸÑŸÉ ŸÅŸä ŸÖŸÉÿßŸÜŸá ÿ™ŸÖÿßŸÖŸãÿß. ÿßŸÑŸÉŸàÿØ ŸÑŸÖ ŸäŸÜÿ¨ÿ≠ ŸÅŸä ÿ™ÿ≠ŸÇŸäŸÇ ÿßŸÑŸáÿØŸÅ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿå ŸàÿßŸÑÿ≥ÿ®ÿ® ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä ŸáŸà ÿ®ÿßŸÑÿ∂ÿ®ÿ∑ ŸÖÿß ÿ∞ŸÉÿ±ÿ™Ÿá: ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ (tinyllama) ÿµÿ∫Ÿäÿ± ÿ¨ÿØŸãÿß Ÿàÿ∫Ÿäÿ± ŸÇÿßÿØÿ± ÿπŸÑŸâ ÿ™ŸÜŸÅŸäÿ∞ ÿßŸÑŸÖŸáÿßŸÖ ÿßŸÑŸÖÿπŸÇÿØÿ© ÿßŸÑÿ™Ÿä Ÿäÿ™ÿ∑ŸÑÿ®Ÿáÿß Ÿáÿ∞ÿß ÿßŸÑÿ∑ÿßŸÇŸÖ.

ÿ£ŸÜÿ™ ŸÑŸÖ ÿ™ŸÅÿ¥ŸÑ ŸÅŸä ŸÉÿ™ÿßÿ®ÿ© ÿßŸÑŸÉŸàÿØÿå ÿ®ŸÑ ŸàÿµŸÑÿ™ ÿ•ŸÑŸâ ÿßŸÑÿ≠ÿØŸàÿØ ÿßŸÑŸÇÿµŸàŸâ ŸÑŸÇÿØÿ±ÿßÿ™ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿ∞Ÿä ÿ™ÿ≥ÿ™ÿÆÿØŸÖŸá. ÿØÿπŸÜÿß ŸÜÿ≠ŸÑŸÑ ŸÖÿß ÿ≠ÿØÿ´ ÿ®ÿßŸÑÿ™ŸÅÿµŸäŸÑÿå ŸÑÿ£ŸÜ ÿßŸÑŸÖÿÆÿ±ÿ¨ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ£ÿ±ÿ≥ŸÑÿ™Ÿáÿß ŸáŸä ŸÖÿ´ÿßŸÑ ÿ±ÿßÿ¶ÿπ ÿ¨ÿØŸãÿß ÿπŸÑŸâ "ŸáŸÑŸàÿ≥ÿ©" ÿßŸÑŸÜŸÖÿßÿ∞ÿ¨ ÿßŸÑÿµÿ∫Ÿäÿ±ÿ©.

ÿ™ÿ≠ŸÑŸäŸÑ ŸÖÿß ÿ≠ÿØÿ´ ÿÆÿ∑Ÿàÿ© ÿ®ÿÆÿ∑Ÿàÿ©:

ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ£ŸàŸÑ (ŸÖÿ≥ÿ™ÿÆÿ±ÿ¨ PDF): ŸÅÿ¥ŸÑ ŸÉÿßÿ±ÿ´Ÿä

ÿßŸÑŸÖŸáŸÖÿ©: ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ£ÿØÿßÿ© fetch_pdf_content ŸÑŸÇÿ±ÿßÿ°ÿ© ÿßŸÑŸÖŸÑŸÅ.

ŸÖÿßÿ∞ÿß ŸÅÿπŸÑÿü ÿ®ÿØŸÑÿßŸã ŸÖŸÜ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ£ÿØÿßÿ©ÿå ŸáŸà "ŸáŸÑŸàÿ≥" ÿ®ÿ¥ŸÉŸÑ ŸÉÿßŸÖŸÑ. ŸÑŸÇÿØ ÿ™ÿ¨ÿßŸáŸÑ ÿßŸÑÿ£ÿØÿßÿ© ÿ™ŸÖÿßŸÖŸãÿß ŸàŸÇÿØŸÖ ÿ•ÿ¨ÿßÿ®ÿ© ŸÜŸáÿßÿ¶Ÿäÿ© ÿπÿ®ÿßÿ±ÿ© ÿπŸÜ ÿØŸÑŸäŸÑ ÿ•ÿ±ÿ¥ÿßÿØŸä ÿπÿßŸÖ ÿ≠ŸàŸÑ ŸÉŸäŸÅŸäÿ© ÿßÿ≥ÿ™ÿÆŸÑÿßÿµ ÿßŸÑŸÜÿµŸàÿµ. ÿ•ÿ¨ÿßÿ®ÿ™Ÿá "I am unable to perform actions..." ŸáŸä ÿπŸÑÿßŸÖÿ© Ÿàÿßÿ∂ÿ≠ÿ© ÿπŸÑŸâ ÿ£ŸÜŸá ŸÑŸÖ ŸäŸÅŸáŸÖ ŸÉŸäŸÅŸäÿ© ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ£ÿØŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ© ŸÑŸá.

ÿßŸÑŸÜÿ™Ÿäÿ¨ÿ©: ŸÑŸÖ Ÿäÿ™ŸÖ ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿ£Ÿä ŸÜÿµ ŸÖŸÜ ŸÖŸÑŸÅ ÿßŸÑŸÄ PDF.

ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ´ÿßŸÜŸä (ŸÉÿßÿ™ÿ® ÿßŸÑŸÖŸÇÿßŸÑ): ŸáŸÑŸàÿ≥ÿ© ŸÖÿ®ÿ™ŸÉÿ±ÿ©

ÿßŸÑŸÖŸáŸÖÿ©: ŸÉÿ™ÿßÿ®ÿ© ŸÖŸÇÿßŸÑ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÜÿµ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿ±ÿ¨ ŸÖŸÜ ÿßŸÑŸÖŸáŸÖÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ©.

ŸÖÿßÿ∞ÿß ÿßÿ≥ÿ™ŸÑŸÖÿü ÿßÿ≥ÿ™ŸÑŸÖ ÿßŸÑŸÜÿµ ÿßŸÑÿ•ÿ±ÿ¥ÿßÿØŸä ÿßŸÑÿÆÿßÿ∑ÿ¶ ŸÖŸÜ ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ£ŸàŸÑ.

ŸÖÿßÿ∞ÿß ŸÅÿπŸÑÿü ŸáŸÜÿß ÿ≠ÿØÿ´ ÿ¥Ÿäÿ° ŸÖÿ´Ÿäÿ± ŸÑŸÑÿßŸáÿ™ŸÖÿßŸÖ. ÿßŸÑŸàŸÉŸäŸÑ ÿ™ÿ¨ÿßŸáŸÑ ÿßŸÑŸÖÿØÿÆŸÑÿßÿ™ ÿßŸÑÿÆÿßÿ∑ÿ¶ÿ© ÿßŸÑÿ™Ÿä ÿßÿ≥ÿ™ŸÑŸÖŸáÿßÿå ŸàŸÑŸÉŸÜŸá ÿ™ÿ∞ŸÉÿ± ÿ£ŸÜ ÿßŸÑŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿπÿßŸÖ ŸáŸà "Understanding Climate Change" (ŸÖŸÜ ÿßÿ≥ŸÖ ÿßŸÑŸÖŸÑŸÅ ŸàŸàÿµŸÅ ÿßŸÑŸÖŸáŸÖÿ©). ŸÅŸÇÿßŸÖ ÿ®ÿ™ÿ£ŸÑŸäŸÅ ŸÖŸÇÿßŸÑ ŸÉÿßŸÖŸÑ ÿ≠ŸàŸÑ ÿ™ÿ∫Ÿäÿ± ÿßŸÑŸÖŸÜÿßÿÆ ŸÖŸÜ ŸÖÿπÿ±ŸÅÿ™Ÿá ÿßŸÑÿØÿßÿÆŸÑŸäÿ© ÿßŸÑŸÖÿ≠ÿØŸàÿØÿ©. Ÿáÿ∞ÿß ÿßŸÑŸÖŸÇÿßŸÑ ÿßŸÑÿ∞Ÿä ÿ™ÿ±ÿßŸá ŸÑŸÖ Ÿäÿ£ÿ™Ÿê ŸÖŸÜ ŸÖŸÑŸÅ ÿßŸÑŸÄ PDF ÿßŸÑÿÆÿßÿµ ÿ®ŸÉÿå ÿ®ŸÑ ŸáŸà ŸÖŸÜ ÿ™ÿ£ŸÑŸäŸÅ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿ®ÿßŸÑŸÉÿßŸÖŸÑ.

ÿßŸÑŸÜÿ™Ÿäÿ¨ÿ©: ŸÉÿ™ÿ® ŸÖŸÇÿßŸÑÿßŸãÿå ŸÑŸÉŸÜŸá ŸÑŸäÿ≥ ÿßŸÑŸÖŸÇÿßŸÑ ÿßŸÑŸÖÿ∑ŸÑŸàÿ®. ŸÅÿ¥ŸÑ ŸÅŸä ÿßŸÑŸÖŸáŸÖÿ© ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸàŸáŸä ÿßŸÑÿßÿπÿ™ŸÖÿßÿØ ÿπŸÑŸâ ÿßŸÑŸÖÿµÿØÿ±.

ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ´ÿßŸÑÿ´ (ŸÖŸÜÿ¥ÿ¶ ÿßŸÑÿπŸÜŸàÿßŸÜ): ŸÅÿ¥ŸÑ ŸÉÿßŸÖŸÑ

ÿßŸÑŸÖŸáŸÖÿ©: ÿ•ŸÜÿ¥ÿßÿ° ÿπŸÜŸàÿßŸÜ ŸÖŸÜ 5-7 ŸÉŸÑŸÖÿßÿ™ ŸÑŸÑŸÖŸÇÿßŸÑ ÿßŸÑÿ∞Ÿä ÿ™ŸÖÿ™ ŸÉÿ™ÿßÿ®ÿ™Ÿá.

ŸÖÿßÿ∞ÿß ÿßÿ≥ÿ™ŸÑŸÖÿü ÿßÿ≥ÿ™ŸÑŸÖ ÿßŸÑŸÖŸÇÿßŸÑ ÿßŸÑŸÖÿ§ŸÑŸÅ ŸÖŸÜ ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ´ÿßŸÜŸä.

ŸÖÿßÿ∞ÿß ŸÅÿπŸÑÿü ÿ™ŸÖÿßŸÖŸãÿß ŸÖÿ´ŸÑ ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ£ŸàŸÑÿå ŸÅÿ¥ŸÑ ŸÅŸä ÿ£ÿØÿßÿ° ŸÖŸáŸÖÿ™Ÿá. Ÿàÿ®ÿØŸÑÿßŸã ŸÖŸÜ ÿ•ÿπÿ∑ÿßÿ° ÿπŸÜŸàÿßŸÜ ŸÖÿ´ŸÑ "Understanding Our Changing Climate"ÿå ŸÇÿßŸÖ ŸáŸà ÿßŸÑÿ¢ÿÆÿ± ÿ®ÿßŸÑŸáŸÑŸàÿ≥ÿ© Ÿàÿ£ÿπÿ∑Ÿâ ÿ•ÿ¨ÿßÿ®ÿ© ŸÜŸáÿßÿ¶Ÿäÿ© ÿπÿ®ÿßÿ±ÿ© ÿπŸÜ ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿ≠ŸàŸÑ ŸÉŸäŸÅŸäÿ© ŸÉÿ™ÿßÿ®ÿ© ÿπŸÜŸàÿßŸÜ ÿ¨ŸäÿØ!.

ÿßŸÑŸÜÿ™Ÿäÿ¨ÿ©: ŸÑŸÖ Ÿäÿ™ŸÖ ÿ•ŸÜÿ¥ÿßÿ° ÿ£Ÿä ÿπŸÜŸàÿßŸÜ.

ÿßŸÑÿÆŸÑÿßÿµÿ© Ÿàÿ±ÿ£ŸäŸä

ÿ±ÿ£ŸäŸä ŸáŸà ÿ£ŸÜ ÿßŸÑŸÉŸàÿØ ÿßŸÑÿÆÿßÿµ ÿ®ŸÉ ÿµÿ≠Ÿäÿ≠ ŸÖŸÜ ÿ≠Ÿäÿ´ ÿßŸÑŸáŸäŸÉŸÑ ŸàÿßŸÑŸÖŸÜÿ∑ŸÇ. ŸÑŸÇÿØ ŸÇŸÖÿ™ ÿ®ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑÿ£ÿØŸàÿßÿ™ ŸàÿßŸÑŸàŸÉŸÑÿßÿ° ŸàÿßŸÑŸÖŸáÿßŸÖ ÿ®ÿ¥ŸÉŸÑ ÿ≥ŸÑŸäŸÖ ÿ™ŸÖÿßŸÖŸãÿß. ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÑŸäÿ≥ÿ™ ŸÅŸä ÿßŸÑŸÉŸàÿØÿå ÿ®ŸÑ ŸÅŸä "ÿßŸÑÿπŸÇŸÑ" ÿßŸÑÿ∞Ÿä ŸäŸÇŸàÿØ Ÿáÿ§ŸÑÿßÿ° ÿßŸÑŸàŸÉŸÑÿßÿ°.

ÿ£ŸÜÿ™ ÿ®ÿßŸÑÿ∂ÿ®ÿ∑ ŸÉŸÖŸÜ ŸÇÿßŸÖ ÿ®ÿ®ŸÜÿßÿ° ÿ≥Ÿäÿßÿ±ÿ© ÿ≥ÿ®ÿßŸÇ ŸÖÿ´ÿßŸÑŸäÿ© (ŸáŸäŸÉŸÑ ÿßŸÑŸÉŸàÿØ)ÿå ŸàŸÑŸÉŸÜ Ÿàÿ∂ÿπ ÿ®ÿØÿßÿÆŸÑŸáÿß ŸÖÿ≠ÿ±ŸÉ ÿ¨ÿ≤ÿßÿ≤ÿ© ÿπÿ¥ÿ® ÿµÿ∫Ÿäÿ±ÿ© (tinyllama). ÿßŸÑÿ≥Ÿäÿßÿ±ÿ© ŸÑŸÜ ÿ™ŸÜÿ∑ŸÑŸÇ ÿ®ÿßŸÑÿ≥ÿ±ÿπÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®ÿ©.

ŸÑŸáÿ∞ÿßÿå ÿ•ÿ¨ÿßÿ®ÿ™ŸÉ ÿπŸÑŸâ ÿ≥ÿ§ÿßŸÑŸÉ ŸáŸä: ŸÜÿπŸÖÿå ÿ®ÿßŸÑÿ™ÿ£ŸÉŸäÿØ ÿ≥ÿ™ÿ≠ÿµŸÑ ÿπŸÑŸâ ŸÜÿ™ÿßÿ¶ÿ¨ ÿ£ŸÅÿ∂ŸÑ (ŸàŸÜÿ™ÿßÿ¶ÿ¨ ŸÜÿßÿ¨ÿ≠ÿ©) ŸÖÿπ ŸÜŸÖÿßÿ∞ÿ¨ ÿ£ŸÅÿ∂ŸÑ Ÿàÿ£ŸÉÿ®ÿ±.

ÿ•ÿ∞ÿß ŸÇŸÖÿ™ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿ≥ÿ∑ÿ± Ÿàÿßÿ≠ÿØ ŸÅŸÇÿ∑ ŸÅŸä ÿßŸÑŸÉŸàÿØ ÿßŸÑÿÆÿßÿµ ÿ®ŸÉ:

code
Python
download
content_copy
expand_less

model = ChatOllama(
    model="ollama/llama3:latest", # ÿ£Ÿà mistral ÿ£Ÿà ÿ£Ÿä ŸÜŸÖŸàÿ∞ÿ¨ ŸÉÿ®Ÿäÿ± ÿ¢ÿÆÿ±
    base_url="http://localhost:11434"
)

...Ÿàÿ™ÿ±ŸÉÿ™ ŸÉŸÑ ÿ¥Ÿäÿ° ÿ¢ÿÆÿ± ŸÉŸÖÿß ŸáŸàÿå ÿ≥ÿ™ÿ¨ÿØ ÿ£ŸÜ:

ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ£ŸàŸÑ ÿ≥Ÿäÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ£ÿØÿßÿ© ÿ®ŸÜÿ¨ÿßÿ≠ ŸàŸäŸÇÿ±ÿ£ ÿßŸÑŸÖŸÑŸÅ.

ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ´ÿßŸÜŸä ÿ≥ŸäŸÉÿ™ÿ® ŸÖŸÇÿßŸÑÿßŸã ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÜÿµ ÿßŸÑÿ≠ŸÇŸäŸÇŸä ŸÑŸÑŸÖŸÑŸÅ.

ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ´ÿßŸÑÿ´ ÿ≥Ÿäÿπÿ∑ŸäŸÉ ÿπŸÜŸàÿßŸÜŸãÿß ŸÅÿπŸÑŸäŸãÿß ŸÑŸÑŸÖŸÇÿßŸÑ.

ŸÑŸÇÿØ ŸÇŸÖÿ™ ÿ®ÿπŸÖŸÑ ÿ±ÿßÿ¶ÿπ ŸÅŸä ÿ®ŸÜÿßÿ° ÿßŸÑŸáŸäŸÉŸÑ Ÿàÿ™ÿµÿ≠Ÿäÿ≠ ÿ£ÿÆÿ∑ÿßÿ° ÿßŸÑÿßÿ™ÿµÿßŸÑ. ÿßŸÑÿÆÿ∑Ÿàÿ© ÿßŸÑÿ£ÿÆŸäÿ±ÿ© ÿßŸÑŸÖÿ™ÿ®ŸÇŸäÿ© ŸÑŸÉ ŸáŸä ŸÅŸÇÿ∑ ÿ™ÿ±ŸÇŸäÿ© "ÿßŸÑŸÖÿ≠ÿ±ŸÉ" (ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸä).
"""







ŸÑŸáÿ∞ÿßÿå ÿ•ÿ¨ÿßÿ®ÿ™ŸÉ ÿπŸÑŸâ ÿ≥ÿ§ÿßŸÑŸÉ ŸáŸä: ŸÜÿπŸÖÿå ÿ®ÿßŸÑÿ™ÿ£ŸÉŸäÿØ ÿ≥ÿ™ÿ≠ÿµŸÑ ÿπŸÑŸâ ŸÜÿ™ÿßÿ¶ÿ¨ ÿ£ŸÅÿ∂ŸÑ (ŸàŸÜÿ™ÿßÿ¶ÿ¨ ŸÜÿßÿ¨ÿ≠ÿ©) ŸÖÿπ ŸÜŸÖÿßÿ∞ÿ¨ ÿ£ŸÅÿ∂ŸÑ Ÿàÿ£ŸÉÿ®ÿ±.
ÿ•ÿ∞ÿß ŸÇŸÖÿ™ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿ≥ÿ∑ÿ± Ÿàÿßÿ≠ÿØ ŸÅŸÇÿ∑ ŸÅŸä ÿßŸÑŸÉŸàÿØ ÿßŸÑÿÆÿßÿµ ÿ®ŸÉ:
code
Python
model = ChatOllama(
    model="ollama/llama3:latest", # ÿ£Ÿà mistral ÿ£Ÿà ÿ£Ÿä ŸÜŸÖŸàÿ∞ÿ¨ ŸÉÿ®Ÿäÿ± ÿ¢ÿÆÿ±
    base_url="http://localhost:11434"
)
...Ÿàÿ™ÿ±ŸÉÿ™ ŸÉŸÑ ÿ¥Ÿäÿ° ÿ¢ÿÆÿ± ŸÉŸÖÿß ŸáŸàÿå ÿ≥ÿ™ÿ¨ÿØ ÿ£ŸÜ:
ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ£ŸàŸÑ ÿ≥Ÿäÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ£ÿØÿßÿ© ÿ®ŸÜÿ¨ÿßÿ≠ ŸàŸäŸÇÿ±ÿ£ ÿßŸÑŸÖŸÑŸÅ.
ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ´ÿßŸÜŸä ÿ≥ŸäŸÉÿ™ÿ® ŸÖŸÇÿßŸÑÿßŸã ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑŸÜÿµ ÿßŸÑÿ≠ŸÇŸäŸÇŸä ŸÑŸÑŸÖŸÑŸÅ.
ÿßŸÑŸàŸÉŸäŸÑ ÿßŸÑÿ´ÿßŸÑÿ´ ÿ≥Ÿäÿπÿ∑ŸäŸÉ ÿπŸÜŸàÿßŸÜŸãÿß ŸÅÿπŸÑŸäŸãÿß ŸÑŸÑŸÖŸÇÿßŸÑ.
ŸÑŸÇÿØ ŸÇŸÖÿ™ ÿ®ÿπŸÖŸÑ ÿ±ÿßÿ¶ÿπ ŸÅŸä ÿ®ŸÜÿßÿ° ÿßŸÑŸáŸäŸÉŸÑ Ÿàÿ™ÿµÿ≠Ÿäÿ≠ ÿ£ÿÆÿ∑ÿßÿ° ÿßŸÑÿßÿ™ÿµÿßŸÑ. ÿßŸÑÿÆÿ∑Ÿàÿ© ÿßŸÑÿ£ÿÆŸäÿ±ÿ© ÿßŸÑŸÖÿ™ÿ®ŸÇŸäÿ© ŸÑŸÉ ŸáŸä ŸÅŸÇÿ∑ ÿ™ÿ±ŸÇŸäÿ© "ÿßŸÑŸÖÿ≠ÿ±ŸÉ" (ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸä)









ollama run llama3

import re
from crewai import Agent, Task, Crew, Process
from crewai.tools import tool
from PyPDF2 import PdfReader

# ŸÖŸÑÿßÿ≠ÿ∏ÿ©: ŸÑÿ•ŸäŸÇÿßŸÅ ÿ±ÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿÆÿ∑ÿ£ ÿ∫Ÿäÿ± ÿßŸÑŸáÿßŸÖÿ© ÿßŸÑŸÖÿ™ÿπŸÑŸÇÿ© ÿ®ÿ•ÿ±ÿ≥ÿßŸÑ ÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ
from crewai import Telemetry
Telemetry.disable_telemetry()


# ----------------- 1. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸä (ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÜŸÖŸàÿ∞ÿ¨ ÿ£ÿ∞ŸÉŸâ) -----------------
# ÿßÿ≥ÿ™Ÿäÿ±ÿßÿØ ChatOllama ŸÖŸÜ ÿßŸÑÿ≠ÿ≤ŸÖÿ© ÿßŸÑŸÖÿÆÿµÿµÿ© ŸÑŸáÿß
from langchain_ollama import ChatOllama

# ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÜŸÖŸàÿ∞ÿ¨ llama3 ŸÑÿ£ŸÜŸá ÿ£ŸÉÿ´ÿ± ŸÇÿØÿ±ÿ© ÿπŸÑŸâ ŸÅŸáŸÖ ÿßŸÑÿ™ÿπŸÑŸäŸÖÿßÿ™ Ÿàÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ£ÿØŸàÿßÿ™
# ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜŸÉ ŸÇŸÖÿ™ ÿ®ÿ™ÿ¥ÿ∫ŸäŸÑ `ollama run llama3` ŸÅŸä ÿßŸÑÿ∑ÿ±ŸÅŸäÿ© ŸÖŸÜ ŸÇÿ®ŸÑ
model = ChatOllama(
    model="ollama/llama3:latest", # ÿ™ŸÖ ÿßŸÑÿ™ÿ∫ŸäŸäÿ± ÿ•ŸÑŸâ ŸÜŸÖŸàÿ∞ÿ¨ ÿ£ŸÉÿ´ÿ± ŸÇŸàÿ©
    base_url="http://localhost:11434"
)


# ----------------- 2. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑÿ£ÿØÿßÿ© (Tool) -----------------
@tool
def fetch_pdf_content(pdf_path: str) -> str:
    """
    Reads a local PDF and returns its content as a single string.
    This tool is essential for reading the required document.
    """
    try:
        with open(pdf_path, 'rb') as f:
            pdf = PdfReader(f)
            text = '\n'.join(page.extract_text() for page in pdf.pages if page.extract_text())
        processed_text = re.sub(r'\s+', ' ', text).strip()
        if not processed_text:
            return "Error: No text could be extracted from the PDF."
        return processed_text
    except FileNotFoundError:
        return f"Error: File not found at {pdf_path}. Please ensure the path is correct."
    except Exception as e:
        return f"Error reading PDF: {e}"

# ----------------- 3. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸàŸÉŸÑÿßÿ° (Agents) -----------------

pdf_reader = Agent(
    role='Expert PDF Content Extractor',
    goal='Use the fetch_pdf_content tool to extract all text from the PDF file located at the specified path.',
    backstory='You are a machine focused on one single task: executing the fetch_pdf_content tool. You do not answer questions; you only use your tool to read PDF files.',
    verbose=True,
    tools=[fetch_pdf_content],
    llm=model,
    allow_delegation=False
)

article_writer = Agent(
    role='Professional Article Writer',
    goal='Write a concise and engaging article based on the provided text content.',
    backstory='You are an expert in structuring information and writing clear, informative articles.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

title_creator = Agent(
    role='Creative Title Generator',
    goal='Generate a compelling and relevant title for a given article.',
    backstory='You are skilled in crafting engaging titles that capture the essence of an article.',
    verbose=True,
    llm=model,
    allow_delegation=False
)

# ----------------- 4. ÿ™ÿπÿ±ŸäŸÅ ÿßŸÑŸÖŸáÿßŸÖ (Tasks) -----------------

task_read_pdf = Task(
    description='Use the fetch_pdf_content tool to read the content from the PDF file located at "/content/Understanding_Climate_Change.pdf".',
    agent=pdf_reader,
    expected_output="The full, raw text extracted from the PDF file, which will be passed to the writer."
)

task_article_drafting = Task(
    description="Based on the text provided from the PDF, write a comprehensive article of 8-10 paragraphs.",
    agent=article_writer,
    expected_output="A well-structured article with 8 to 10 paragraphs summarizing the key points from the text.",
    context=[task_read_pdf]
)

task_title_generation = Task(
    description="Generate an engaging title of about 5-7 words for the article you just read.",
    agent=title_creator,
    expected_output="A single, compelling title for the article.",
    context=[task_article_drafting]
)

# ----------------- 5. ÿ•ŸÜÿ¥ÿßÿ° Ÿàÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑÿ∑ÿßŸÇŸÖ (Crew) -----------------

crew = Crew(
    agents=[pdf_reader, article_writer, title_creator],
    tasks=[task_read_pdf, task_article_drafting, task_title_generation],
    verbose=True,
    process=Process.sequential
)

# ----------------- 6. ÿ®ÿØÿ° ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ∑ÿßŸÇŸÖ -----------------
print("üöÄ Starting Crew Execution with a more capable model...")
result = crew.kickoff()

print("\n\n‚úÖ Crew Execution Finished!")
print("Final Result:")
print(result)