{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "curl -fsSL https://ollama.com/install.sh | sh\n",
        "nohup ollama serve &\n",
        "ollama pull llama3:8b\n",
        "ollama list"
      ],
      "metadata": {
        "id": "fXpjLlL-JWd-"
      },
      "id": "fXpjLlL-JWd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/datawhalechina/handy-ollama/blob/main/notebook/C7/LlamaIndex_Agent/%E4%BD%BF%E7%94%A8LlamaIndex%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0Agent.ipynb"
      ],
      "metadata": {
        "id": "BtXEiYOK0kFx"
      },
      "id": "BtXEiYOK0kFx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/datawhalechina/handy-ollama/tree/main/notebook"
      ],
      "metadata": {
        "id": "kGP9SbFo0rPJ"
      },
      "id": "kGP9SbFo0rPJ"
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbO8TvsvJWbJ",
        "outputId": "f99437a3-a2e7-47fb-8c61-a32457447ce5"
      },
      "id": "fbO8TvsvJWbJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &\n",
        "!ollama pull qwen2.5:0.5b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLKAb3RRJWYH",
        "outputId": "89ce942e-4827-44d8-8061-84d51b22b54b"
      },
      "id": "zLKAb3RRJWYH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNEiPPWxJWU2",
        "outputId": "63221187-b11c-45c5-c801-b847610ac26d"
      },
      "id": "PNEiPPWxJWU2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME            ID              SIZE      MODIFIED       \n",
            "qwen2.5:0.5b    a8b0c5157701    397 MB    29 seconds ago    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4W2JJKfXJWRu",
        "outputId": "cd916fdd-c090-4950-e1fc-7de3d93d656e"
      },
      "id": "4W2JJKfXJWRu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.5.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.14,>=0.13.1 (from llama-index)\n",
            "  Downloading llama_index_core-0.13.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.5.0-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-index-llms-openai<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.5.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.5.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (3.12.15)\n",
            "Collecting aiosqlite (from llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (0.28.1)\n",
            "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading llama_index_workflows-1.3.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (2.32.3)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.1->llama-index) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (4.14.1)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (1.17.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.99.8)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.8.3)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (1.20.1)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading griffe-1.12.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.1->llama-index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.1->llama-index) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.1->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.1->llama-index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.1->llama-index) (0.16.0)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading llama_index_instrumentation-0.4.0-py3-none-any.whl.metadata (252 bytes)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.1->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.1->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.1->llama-index) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.1->llama-index) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.1->llama-index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.1->llama-index) (3.2.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv<2,>=1.0.1 (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.1->llama-index) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.1->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.1->llama-index) (3.0.2)\n",
            "Downloading llama_index-0.13.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_cli-0.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.13.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.5.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.9.1-py3-none-any.whl (16 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.5.3-py3-none-any.whl (25 kB)\n",
            "Downloading llama_index_readers_file-0.5.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.0-py3-none-any.whl (3.2 kB)\n",
            "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-1.3.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_instrumentation-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.12.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, setuptools, python-dotenv, pypdf, mypy-extensions, marshmallow, deprecated, colorama, aiosqlite, typing-inspect, griffe, llama-index-instrumentation, llama-cloud, dataclasses-json, banks, llama-index-workflows, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiosqlite-0.21.0 banks-2.2.0 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.12.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.13.1 llama-index-cli-0.5.0 llama-index-core-0.13.1 llama-index-embeddings-openai-0.5.0 llama-index-indices-managed-llama-cloud-0.9.1 llama-index-instrumentation-0.4.0 llama-index-llms-openai-0.5.3 llama-index-readers-file-0.5.1 llama-index-readers-llama-parse-0.5.0 llama-index-workflows-1.3.0 llama-parse-0.6.54 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-5.9.0 python-dotenv-1.1.1 setuptools-80.9.0 striprtf-0.0.26 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "edef47de3aca43bcb571023721450e75"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbNemyjQJWN4",
        "outputId": "b376177f-9011-4def-9bec-6e2953afe95d"
      },
      "id": "gbNemyjQJWN4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-14T08:42:27.374624Z",
          "start_time": "2024-08-14T08:42:25.030424Z"
        },
        "id": "initial_id"
      },
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "# Define tools\n",
        "def multiply(a: float, b: float) -> str:\n",
        "    \"\"\"Multiply two numbers and return the result as a formatted string.\"\"\"\n",
        "    result = a * b\n",
        "    return f\"The result of multiplying {a} and {b} is {result}.\"\n",
        "\n",
        "# Create FunctionTool instances\n",
        "multiply_tool = FunctionTool.from_defaults(\n",
        "    fn=multiply,\n",
        "    name=\"MultiplyTool\",\n",
        "    description=\"A tool that multiplies two floats.\"\n",
        "    # Removed return_direct=True\n",
        ")"
      ],
      "id": "initial_id",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-14T08:42:27.565183Z",
          "start_time": "2024-08-14T08:42:27.375688Z"
        },
        "id": "d46caad79b3f9a04"
      },
      "cell_type": "code",
      "source": [
        "# Initialize LLM\n",
        "llm = Ollama(model=\"qwen2.5:0.5b\", request_timeout=360.0)\n",
        "\n",
        "# Initialize ReAct agent with tools\n",
        "agent = ReActAgent(tools=[multiply_tool], llm=llm, verbose=True, agent_type=\"react\")"
      ],
      "id": "d46caad79b3f9a04",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-14T08:42:33.309189Z",
          "start_time": "2024-08-14T08:42:27.565984Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29f3c21096d8331c",
        "outputId": "f65c4bd0-20a3-48d3-981a-7bb7f577db64"
      },
      "cell_type": "code",
      "source": [
        "# direct response\n",
        "res_llm = llm.complete(\"What is 2.3 × 4.8 ? Calculate step by step\")\n",
        "print(res_llm)"
      ],
      "id": "29f3c21096d8331c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Let's break down the calculation of \\(2.3 \\times 4.8\\) step by step:\n",
            "\n",
            "1) **Understand the numbers**:\n",
            "   - The first number is 2.3.\n",
            "   - The second number is 4.8.\n",
            "\n",
            "2) **Multiply**:\n",
            "   - To multiply these two numbers, you simply add them together.\n",
            "     \\[\n",
            "     2.3 + 4.8\n",
            "     \\]\n",
            "\n",
            "3) **Perform the addition**:\n",
            "   - Adding \\(2.3\\) and \\(4.8\\):\n",
            "     \\[\n",
            "     2.3 + 4.8 = 7.1\n",
            "     \\]\n",
            "\n",
            "So, the final answer is \\(7.1\\).\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-14T08:42:37.068830Z",
          "start_time": "2024-08-14T08:42:33.309189Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73a424092ac0a89a",
        "outputId": "f1366f7e-97ee-46aa-f328-54678b234376"
      },
      "cell_type": "code",
      "source": [
        "# use agent\n",
        "response = agent.run(\"What is 2.3 × 4.8 ? Calculate step by step\")\n",
        "# Try accessing different attributes to find the execution history\n",
        "try:\n",
        "    print(\"Response trace:\", response.trace)\n",
        "except AttributeError:\n",
        "    try:\n",
        "        print(\"Response steps:\", response.steps)\n",
        "    except AttributeError:\n",
        "        try:\n",
        "            print(\"Response events:\", response.events)\n",
        "        except AttributeError:\n",
        "            print(\"Could not find trace, steps, or events attribute on the response object.\")"
      ],
      "id": "73a424092ac0a89a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not find trace, steps, or events attribute on the response object.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7c48a3ec",
        "outputId": "25fcc78b-104b-4d73-fef0-063fa7d8a66d"
      },
      "source": [
        "!pip install llama-index-llms-ollama"
      ],
      "id": "7c48a3ec",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-ollama\n",
            "  Downloading llama_index_llms_ollama-0.7.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-ollama) (0.13.1)\n",
            "Collecting ollama>=0.5.1 (from llama-index-llms-ollama)\n",
            "  Downloading ollama-0.5.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.1.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.0.2)\n",
            "Downloading llama_index_llms_ollama-0.7.0-py3-none-any.whl (8.1 kB)\n",
            "Downloading ollama-0.5.3-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ollama, llama-index-llms-ollama\n",
            "Successfully installed llama-index-llms-ollama-0.7.0 ollama-0.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_index"
                ]
              },
              "id": "e64243ca2c76416580a94577562a790d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use agent\n",
        "response = agent.chat(\"What is 2.3 × 4.8 ? Calculate step by step\")\n",
        "response.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "cqKeSTexMsDH",
        "outputId": "840578aa-f10d-4652-a0eb-b54195d17144"
      },
      "id": "cqKeSTexMsDH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ReActAgent' object has no attribute 'chat'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3446511738.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is 2.3 × 4.8 ? Calculate step by step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    989\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ReActAgent' object has no attribute 'chat'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.query(\"What is 2.3 × 4.8 ? Calculate step by step\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "F30331BJMsZn",
        "outputId": "2e0cba6d-a74f-455e-d2c3-fa79d098cfc7"
      },
      "id": "F30331BJMsZn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ReActAgent' object has no attribute 'query'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-619119163.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is 2.3 × 4.8 ? Calculate step by step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    989\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ReActAgent' object has no attribute 'query'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.(\"What is 2.3 × 4.8 ? Calculate step by step\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "Wi0NaE1WM_JH",
        "outputId": "b627f9dd-6360-4368-d4f6-7041e3b6034c"
      },
      "id": "Wi0NaE1WM_JH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ReActAgent' object has no attribute 'chat'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1508176832.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is 2.3 × 4.8 ? Calculate step by step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    989\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ReActAgent' object has no attribute 'chat'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"What is 2.3 × 4.8? Calculate step by step\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "6XX4kV8XNT-n",
        "outputId": "5bf6a2d9-d646-4d13-e34a-46ba467ff71c"
      },
      "id": "6XX4kV8XNT-n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidStateError",
          "evalue": "Result is not set.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidStateError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2412266507.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is 2.3 × 4.8? Calculate step by step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/workflows/handler.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidStateError\u001b[0m: Result is not set."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.complete(\"What is 2.3 × 4.8? Calculate step by step\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "Bo9FcISsOdDB",
        "outputId": "eadea88d-e009-4cdb-f57b-aca44970aaa3"
      },
      "id": "Bo9FcISsOdDB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ReActAgent' object has no attribute 'complete'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2572453269.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is 2.3 × 4.8? Calculate step by step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    989\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{type(self).__name__!r} object has no attribute {item!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ReActAgent' object has no attribute 'complete'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import llama_index\n",
        "print(llama_index.core.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKhfQpj7Nlg3",
        "outputId": "63410e85-eb57-47b3-b72a-7bc2e3289ebc"
      },
      "id": "jKhfQpj7Nlg3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hls2BKgMOpWP"
      },
      "id": "hls2BKgMOpWP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85LGTyjYOpTn"
      },
      "id": "85LGTyjYOpTn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YAvrGO5qOpQ3"
      },
      "id": "YAvrGO5qOpQ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dG29OlksOpNn"
      },
      "id": "dG29OlksOpNn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/llm/ollama/"
      ],
      "metadata": {
        "id": "K1-gS82MO0E_"
      },
      "id": "K1-gS82MO0E_"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.ollama import Ollama"
      ],
      "metadata": {
        "id": "eQPIceIONsFv"
      },
      "id": "eQPIceIONsFv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Ollama(\n",
        "    model=\"qwen2.5:0.5b\",\n",
        "    request_timeout=120.0,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")"
      ],
      "metadata": {
        "id": "Pdivs2O1OWbo"
      },
      "id": "Pdivs2O1OWbo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = llm.complete(\"Who is Paul Graham?\")"
      ],
      "metadata": {
        "id": "xheM_F2EOX5H"
      },
      "id": "xheM_F2EOX5H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji3XuDw8OZvn",
        "outputId": "c7b6ecaa-cec4-4811-9639-383f30df291e"
      },
      "id": "ji3XuDw8OZvn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paul Graham is an American software engineer, entrepreneur, and author known for his contributions to the open-source movement. Here are some key points about him:\n",
            "\n",
            "1. Born: July 17, 1952\n",
            "\n",
            "2. Education: University of Illinois at Urbana-Champaign, Computer Science; Cambridge University, England (Post Doctoral Fellowship)\n",
            "\n",
            "3. Early career: Worked as an engineer for the Ford Motor Company in the early 1980s and then became a software developer with companies like Microsoft.\n",
            "\n",
            "4. Background: Initially started as a student programmer but later developed into a full-time open-source contributor.\n",
            "\n",
            "5. Notable works:\n",
            "   - \"The Road Ahead\" (2006)\n",
            "   - \"Innovating for Good\" (2013) - co-authored book\n",
            "   - \"Code.org\" - collaboration with Mozilla Foundation\n",
            "\n",
            "6. Community influence: Graham is known as the founder and CEO of Code.org, a project aimed at making coding education more accessible to students around the world.\n",
            "\n",
            "7. Personal life: Married to Annie Krieger since 2015 and has a son named James.\n",
            "\n",
            "8. Leadership: He's also involved in open-source software projects like GitHub and Slack.\n",
            "\n",
            "9. Impact: Graham is recognized for his role in promoting free software, emphasizing the value of open code sharing and collaboration.\n",
            "\n",
            "10. Recognition: He was named one of \"The 75 Most Influential People\" by TIME magazine in 2018.\n",
            "\n",
            "Paul Graham's work and influence have made him a prominent figure in both technology circles and education, particularly those related to software development and open-source technologies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mSbBceOoOviv"
      },
      "id": "mSbBceOoOviv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = llm.complete(\"What is 2.3 × 4.8? Calculate step by step\")"
      ],
      "metadata": {
        "id": "dzVvzu54O48B"
      },
      "id": "dzVvzu54O48B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5YyCDkgO8hg",
        "outputId": "770e4947-5b3c-40fa-8702-d9674e96bb0c"
      },
      "id": "I5YyCDkgO8hg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Let's solve the multiplication problem \\(2.3 \\times 4.8\\) step-by-step.\n",
            "\n",
            "### Step 1: Understand the Problem\n",
            "We need to multiply two numbers: \\(2.3\\) (which is the same as \\(23\\)) and \\(4.8\\).\n",
            "\n",
            "### Step 2: Break Down the Multiplication\n",
            "First, break down each number into its whole part and a decimal part:\n",
            "- Whole part of \\(2.3\\) is \\(2\\).\n",
            "- Decimal part of \\(2.3\\) is \\(\\frac{3}{10}\\) or \\(0.3\\).\n",
            "\n",
            "So,\n",
            "\\[ 2.3 = 2 + 0.3 \\]\n",
            "\n",
            "### Step 3: Multiply the Whole and Decimals\n",
            "Now, multiply each part together:\n",
            "- Whole number: \\(2 \\times 4.8 = 9.6\\)\n",
            "- Decimal parts: \\(2 \\times 0.3 = 0.6\\)\n",
            "\n",
            "So,\n",
            "\\[ 2.3 \\times 4.8 = 9.6 + 0.6 = 10.2 \\]\n",
            "\n",
            "### Step 4: Write the Final Answer\n",
            "The final answer is:\n",
            "\\[ \\boxed{10.2} \\]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "messages = [\n",
        "    ChatMessage(\n",
        "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
        "    ),\n",
        "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
        "]\n",
        "resp = llm.chat(messages)"
      ],
      "metadata": {
        "id": "y2NHaelMPNG_"
      },
      "id": "y2NHaelMPNG_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-XMFt-iPNeP",
        "outputId": "4b2c9fe1-b9dd-44ea-8786-dc1a2477bd2d"
      },
      "id": "4-XMFt-iPNeP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: My name is Captain Jack Sparrow, a pirate who has been traveling the high seas for over 20 years. I'm known as one of the most daring and skilled pirates ever to sail the ocean waves.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"qwen2.5:0.5b\",\n",
        "    request_timeout=360,\n",
        "    thinking=True,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")"
      ],
      "metadata": {
        "id": "6GIVIEVCPh_A"
      },
      "id": "6GIVIEVCPh_A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = llm.complete(\"What is 434 / 22?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "zYfj_CyGPiV_",
        "outputId": "86f37bde-1fed-4482-f02b-e910189f7e1e"
      },
      "id": "zYfj_CyGPiV_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResponseError",
          "evalue": "registry.ollama.ai/library/qwen2.5:0.5b does not support thinking (status code: 400)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2242085191.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is 434 / 22?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 )\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                     \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     callback_manager.on_event_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/llms/ollama/base.py\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, prompt, formatted, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatted\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     ) -> CompletionResponse:\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mchat_to_completion_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mllm_completion_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/base/llms/generic_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(prompt, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# normalize input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_to_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mchat_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;31m# normalize output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchat_response_to_completion_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchat_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 )\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     callback_manager.on_event_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/llms/ollama/base.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"json\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         response = self.client.chat(\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mollama_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mChatResponse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motherwise\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mChatResponse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \"\"\"\n\u001b[0;32m--> 342\u001b[0;31m     return self._request(\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0mChatResponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m       \u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36m_request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONNECTION_ERROR_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResponseError\u001b[0m: registry.ollama.ai/library/qwen2.5:0.5b does not support thinking (status code: 400)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp.additional_kwargs[\"thinking\"])"
      ],
      "metadata": {
        "id": "exx52NXQPoyY"
      },
      "id": "exx52NXQPoyY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JxV1At2OQUqM"
      },
      "id": "JxV1At2OQUqM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7q1801C-QUnf"
      },
      "id": "7q1801C-QUnf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g89lnY3lQUkq"
      },
      "id": "g89lnY3lQUkq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-tools-mcp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f7eIvEnFQUhw",
        "outputId": "39378e21-e2a2-4700-9c0b-9840bffc326b"
      },
      "id": "f7eIvEnFQUhw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-tools-mcp\n",
            "  Downloading llama_index_tools_mcp-0.4.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-tools-mcp) (0.13.1)\n",
            "Collecting mcp<2,>=1.9.1 (from llama-index-tools-mcp)\n",
            "  Downloading mcp-1.13.0-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-tools-mcp) (2.11.7)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (4.3.8)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.17.2)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (4.10.0)\n",
            "Collecting httpx-sse>=0.4 (from mcp<2,>=1.9.1->llama-index-tools-mcp)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (4.25.0)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp<2,>=1.9.1->llama-index-tools-mcp)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (0.0.20)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp<2,>=1.9.1->llama-index-tools-mcp)\n",
            "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (0.47.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.1->llama-index-tools-mcp) (0.35.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.0.0->llama-index-tools-mcp) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.0.0->llama-index-tools-mcp) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.0.0->llama-index-tools-mcp) (0.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=4.5->mcp<2,>=1.9.1->llama-index-tools-mcp) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=4.5->mcp<2,>=1.9.1->llama-index-tools-mcp) (1.3.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (3.1.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.1->llama-index-tools-mcp) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.1->llama-index-tools-mcp) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.1->llama-index-tools-mcp) (0.27.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (2024.11.6)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.9.1->llama-index-tools-mcp) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (25.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-tools-mcp) (3.0.2)\n",
            "Downloading llama_index_tools_mcp-0.4.0-py3-none-any.whl (13 kB)\n",
            "Downloading mcp-1.13.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.2/160.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: httpx-sse, sse-starlette, pydantic-settings, mcp, llama-index-tools-mcp\n",
            "Successfully installed httpx-sse-0.4.1 llama-index-tools-mcp-0.4.0 mcp-1.13.0 pydantic-settings-2.10.1 sse-starlette-3.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_index"
                ]
              },
              "id": "03e327c018da46ababc23888c973909b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmNM2V4LQWPX",
        "outputId": "2d7b29cf-a879-42cf-a5b3-18525ae8e4ce"
      },
      "id": "tmNM2V4LQWPX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.tools.mcp import (\n",
        "    get_tools_from_mcp_url,\n",
        "    aget_tools_from_mcp_url,\n",
        ")\n",
        "\n",
        "# async\n",
        "tools = await aget_tools_from_mcp_url(\"http://127.0.0.1:8000/mcp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Y6Frc5aAQfX4",
        "outputId": "7ec8464f-146e-40b8-a942-06f2ba3a55b6"
      },
      "id": "Y6Frc5aAQfX4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ExceptionGroup",
          "evalue": "unhandled errors in a TaskGroup (1 sub-exception)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mExceptionGroup\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1618364733.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# async\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0maget_tools_from_mcp_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://127.0.0.1:8000/mcp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/utils.py\u001b[0m in \u001b[0;36maget_tools_from_mcp_url\u001b[0;34m(command_or_url, client, allowed_tools, include_resources)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_tools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_tools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     )\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mtool_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tool_list_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/base.py\u001b[0m in \u001b[0;36mto_tool_list_async\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mtools_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mfunction_tool_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFunctionTool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtool\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/base.py\u001b[0m in \u001b[0;36mfetch_tools\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tools\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/client.py\u001b[0m in \u001b[0;36mlist_tools\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlist_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListToolsResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;34m\"\"\"List all available tools on the MCP server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0manext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopAsyncIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/client.py\u001b[0m in \u001b[0;36m_run_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# Streamable HTTP transport (recommended)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 async with streamablehttp_client(\n\u001b[0m\u001b[1;32m    226\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 ) as (read, write, _):\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__aexit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mathrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopAsyncIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mcp/client/streamable_http.py\u001b[0m in \u001b[0;36mstreamablehttp_client\u001b[0;34m(url, headers, timeout, sse_read_timeout, terminate_on_close, httpx_client_factory, auth)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0mwrite_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_stream_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_memory_object_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSessionMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0manyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Connecting to StreamableHTTP endpoint: {url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\u001b[0m in \u001b[0;36m__aexit__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    770\u001b[0m                     \u001b[0;31m# chaining and avoid adding a \"During handling of above...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;31m# for each nesting level.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                     raise BaseExceptionGroup(\n\u001b[0m\u001b[1;32m    773\u001b[0m                         \u001b[0;34m\"unhandled errors in a TaskGroup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                     ) from None\n",
            "\u001b[0;31mExceptionGroup\u001b[0m: unhandled errors in a TaskGroup (1 sub-exception)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.tools.mcp import BasicMCPClient\n",
        "\n",
        "client = BasicMCPClient(\"http://127.0.0.1:8000/mcp\")\n",
        "\n",
        "tools = await aget_tools_from_mcp_url(\n",
        "    \"http://127.0.0.1:8000/mcp\",\n",
        "    client=client,\n",
        "    allowed_tools=[\"tool1\", \"tool2\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "XBR1U61qQfoo",
        "outputId": "6d39d9f8-e438-4244-91e1-c0ab994147e9"
      },
      "id": "XBR1U61qQfoo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ExceptionGroup",
          "evalue": "unhandled errors in a TaskGroup (1 sub-exception)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mExceptionGroup\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3653437461.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicMCPClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://127.0.0.1:8000/mcp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m tools = await aget_tools_from_mcp_url(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"http://127.0.0.1:8000/mcp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/utils.py\u001b[0m in \u001b[0;36maget_tools_from_mcp_url\u001b[0;34m(command_or_url, client, allowed_tools, include_resources)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_tools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_tools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     )\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mtool_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tool_list_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/base.py\u001b[0m in \u001b[0;36mto_tool_list_async\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mtools_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mfunction_tool_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFunctionTool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtool\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/base.py\u001b[0m in \u001b[0;36mfetch_tools\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tools\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/client.py\u001b[0m in \u001b[0;36mlist_tools\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlist_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListToolsResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;34m\"\"\"List all available tools on the MCP server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0manext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopAsyncIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/tools/mcp/client.py\u001b[0m in \u001b[0;36m_run_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# Streamable HTTP transport (recommended)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 async with streamablehttp_client(\n\u001b[0m\u001b[1;32m    226\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 ) as (read, write, _):\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__aexit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mathrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopAsyncIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mcp/client/streamable_http.py\u001b[0m in \u001b[0;36mstreamablehttp_client\u001b[0;34m(url, headers, timeout, sse_read_timeout, terminate_on_close, httpx_client_factory, auth)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0mwrite_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_stream_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_memory_object_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSessionMessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0manyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Connecting to StreamableHTTP endpoint: {url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\u001b[0m in \u001b[0;36m__aexit__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    770\u001b[0m                     \u001b[0;31m# chaining and avoid adding a \"During handling of above...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;31m# for each nesting level.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                     raise BaseExceptionGroup(\n\u001b[0m\u001b[1;32m    773\u001b[0m                         \u001b[0;34m\"unhandled errors in a TaskGroup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                     ) from None\n",
            "\u001b[0;31mExceptionGroup\u001b[0m: unhandled errors in a TaskGroup (1 sub-exception)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7YzI4j1RRFT"
      },
      "id": "D7YzI4j1RRFT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T0ynQ2dSRRDP"
      },
      "id": "T0ynQ2dSRRDP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ap5_gi0WRRAo"
      },
      "id": "Ap5_gi0WRRAo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DhdJG5CoRQ9h"
      },
      "id": "DhdJG5CoRQ9h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xImPNhCZRQ5n"
      },
      "id": "xImPNhCZRQ5n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJHoid5xRQ2Y"
      },
      "id": "RJHoid5xRQ2Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/cookbooks/llama3_cookbook_ollama_replicate/#define-tools"
      ],
      "metadata": {
        "id": "-mor2s9xRRiw"
      },
      "id": "-mor2s9xRRiw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/cookbooks/llama3_cookbook_ollama_replicate/#7-agents"
      ],
      "metadata": {
        "id": "hvvBKwJJRUX4"
      },
      "id": "hvvBKwJJRUX4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/cookbooks/llama3_cookbook_ollama_replicate/#agents-and-tools"
      ],
      "metadata": {
        "id": "NKtPpqQJRXUq"
      },
      "id": "NKtPpqQJRXUq"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-llms-ollama\n",
        "!pip install llama-index-llms-replicate\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-parse\n",
        "!pip install replicate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUST0I_wRrn_",
        "outputId": "08b24d45-0ebd-49ef-d99d-01ffe4bb529e"
      },
      "id": "AUST0I_wRrn_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.0)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.13.1)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.0)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.9.1)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.1->llama-index) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.1->llama-index) (1.17.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.99.8)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.8.3)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (5.9.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.1->llama-index) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.1->llama-index) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.1->llama-index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.1->llama-index) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.1->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.1->llama-index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.1->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.1->llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.1->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.1->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.1->llama-index) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.1->llama-index) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.1->llama-index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.1->llama-index) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.1->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.1->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.1->llama-index) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.1->llama-index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.1->llama-index) (3.0.2)\n",
            "Requirement already satisfied: llama-index-llms-ollama in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-ollama) (0.13.1)\n",
            "Requirement already satisfied: ollama>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-ollama) (0.5.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.1.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-ollama) (3.0.2)\n",
            "Requirement already satisfied: llama-index-llms-replicate in /usr/local/lib/python3.11/dist-packages (0.5.0)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-replicate) (0.13.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-llms-replicate) (3.0.2)\n",
            "Collecting llama-index-embeddings-huggingface\n",
            "  Using cached llama_index_embeddings_huggingface-0.6.0-py3-none-any.whl.metadata (458 bytes)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.34.4)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-huggingface) (0.13.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-huggingface) (5.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.1.7)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.11.7)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.17.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.55.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.16.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.2.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-huggingface) (3.0.2)\n",
            "Downloading llama_index_embeddings_huggingface-0.6.0-py3-none-any.whl (8.9 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, llama-index-embeddings-huggingface\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed llama-index-embeddings-huggingface-0.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: llama-parse in /usr/local/lib/python3.11/dist-packages (0.6.54)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.11/dist-packages (from llama-parse) (0.6.54)\n",
            "Requirement already satisfied: click<9,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.54->llama-parse) (8.2.1)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.54->llama-parse) (0.1.35)\n",
            "Requirement already satisfied: llama-index-core>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.54->llama-parse) (0.13.1)\n",
            "Requirement already satisfied: platformdirs<5,>=4.3.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.54->llama-parse) (4.3.8)\n",
            "Requirement already satisfied: pydantic!=2.10,>=2.8 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.54->llama-parse) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.54->llama-parse) (1.1.1)\n",
            "Requirement already satisfied: tenacity<10.0,>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.54->llama-parse) (9.1.2)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.35->llama-cloud-services>=0.6.54->llama-parse) (2025.8.3)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.35->llama-cloud-services>=0.6.54->llama-parse) (0.28.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (2025.3.0)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (2.0.43)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.17.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10,>=2.8->llama-cloud-services>=0.6.54->llama-parse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10,>=2.8->llama-cloud-services>=0.6.54->llama-parse) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10,>=2.8->llama-cloud-services>=0.6.54->llama-parse) (0.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (3.1.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud==0.1.35->llama-cloud-services>=0.6.54->llama-parse) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud==0.1.35->llama-cloud-services>=0.6.54->llama-parse) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud==0.1.35->llama-cloud-services>=0.6.54->llama-parse) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud==0.1.35->llama-cloud-services>=0.6.54->llama-parse) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (0.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->llama-cloud==0.1.35->llama-cloud-services>=0.6.54->llama-parse) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core>=0.12.0->llama-cloud-services>=0.6.54->llama-parse) (3.0.2)\n",
            "Collecting replicate\n",
            "  Downloading replicate-1.0.7-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from replicate) (25.0)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.11/dist-packages (from replicate) (2.11.7)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (4.14.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Downloading replicate-1.0.7-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: replicate\n",
            "Successfully installed replicate-1.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &\n",
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHCPPlx6SF_g",
        "outputId": "c8ba9ee6-d8a3-4c4b-bb69-06b9fa77bab5"
      },
      "id": "qHCPPlx6SF_g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "NAME            ID              SIZE      MODIFIED          \n",
            "qwen2.5:0.5b    a8b0c5157701    397 MB    About an hour ago    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "fvRI8Mm4R8Lg"
      },
      "id": "fvRI8Mm4R8Lg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"qwen2.5:0.5b\",\n",
        "    request_timeout=120.0,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")"
      ],
      "metadata": {
        "id": "0pDbp7GgR_D4"
      },
      "id": "0pDbp7GgR_D4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import Sequence, List\n",
        "\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.tools import BaseTool, FunctionTool\n",
        "from llama_index.core.agent import ReActAgent\n",
        "\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "RF0qcpotRSIw"
      },
      "id": "RF0qcpotRSIw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtract two integers and returns the result integer\"\"\"\n",
        "    return a - b\n",
        "\n",
        "\n",
        "def divide(a: int, b: int) -> int:\n",
        "    \"\"\"Divides two integers and returns the result integer\"\"\"\n",
        "    return a / b\n",
        "\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "subtract_tool = FunctionTool.from_defaults(fn=subtract)\n",
        "divide_tool = FunctionTool.from_defaults(fn=divide)"
      ],
      "metadata": {
        "id": "RWaMlXgjRdS5"
      },
      "id": "RWaMlXgjRdS5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent(\n",
        "    tools=[multiply_tool, add_tool, subtract_tool, divide_tool],\n",
        "    llm=llm, # Changed from llm_replicate to llm\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "GM_ukmkeRfvQ"
      },
      "id": "GM_ukmkeRfvQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"What is (121 + 2) * 5?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "6t6ANqQmRh-H",
        "outputId": "c670c35f-f59b-4859-b932-0490382307a3"
      },
      "id": "6t6ANqQmRh-H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidStateError",
          "evalue": "Result is not ready.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidStateError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2823303937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is (121 + 2) * 5?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/workflows/handler.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_FINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidStateError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Result is not ready.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidStateError\u001b[0m: Result is not ready."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dF8Kj20FZ_dY"
      },
      "id": "dF8Kj20FZ_dY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJzM29j9Z_aq"
      },
      "id": "lJzM29j9Z_aq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CzcT6KkOZ_X6"
      },
      "id": "CzcT6KkOZ_X6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "47MucDgbZ_Ui"
      },
      "id": "47MucDgbZ_Ui",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubHW7-b3Z_Qq"
      },
      "id": "ubHW7-b3Z_Qq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFF394o1Z_L7"
      },
      "id": "NFF394o1Z_L7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/cookbooks/llama3_cookbook_ollama_replicate/#7-agents"
      ],
      "metadata": {
        "id": "ZXfzLZbNaBc7"
      },
      "id": "ZXfzLZbNaBc7"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-llms-ollama\n",
        "!pip install llama-index-llms-replicate\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-parse\n",
        "!pip install replicate"
      ],
      "metadata": {
        "id": "esBS0UniaFV8"
      },
      "id": "esBS0UniaFV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "p5ObVbKdaB6r"
      },
      "id": "p5ObVbKdaB6r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"qwen2.5:0.5b\",\n",
        "    request_timeout=120.0,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")"
      ],
      "metadata": {
        "id": "jNX-pk9GaHoa"
      },
      "id": "jNX-pk9GaHoa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "aa070e4f04e64812969357b30b3dded9",
            "e79c60db6d6e49b4b9dd2fce79b077ce",
            "8e07de50dee64022bab9bb89d65b0e62",
            "b734d0a2b1b54644b260289fcd519638",
            "901d78fa01af48f39150b7cd9211d640",
            "368896feb84443d480abf1c2fd824b78",
            "87baece7378c43b49e104e92589db2f1",
            "8492ecd09aea459b9b2ba3d8b0687a89",
            "eea3c7b3cc8d4b518886c48282c42532",
            "e09ff64cd73e4658997c52700c4e4780",
            "d9d6ea68178c491f93996770a79d74b9",
            "3116c5920d6e438db6da9ae3fa7f3c8c",
            "4d401a178b4340178743461dd5a7b135",
            "6bb3b54987b048b08014249e6e9356c1",
            "d00fcfcfa51342dd94adf0adb34aa74b",
            "93c1e37b5ef34026a6f6107a5397b930",
            "d7a5ec7a173d4f0c8414be15b596fc54",
            "173a9ca72c924d6f953d63aa03a3613d",
            "6f63d625530148118ad272c5535cd483",
            "b41db8e7f67b4a109ee6e1671f9a2084",
            "798fec2a02734634861b375a59fcea0e",
            "194b0a2a04654cc5894167c2d01c9a4f",
            "c6b13c541495473ca0d9d845041cbf37",
            "12a30fbdcead4a34b59755de1bd1fa24",
            "2ec490d6c71343868f7e19924de14719",
            "62142d0ab5ec4abeb022e39ed6bcd5b6",
            "2f4f211da95a4341a868a359a0260a63",
            "2d2cff5da294425792861fe1a52b6d8c",
            "44c932d666854e3b9a8624b37b5c0988",
            "e3e6655fccc94d31b0335b04461a5149",
            "bb0c8bdbce674b778714996919d6b6c9",
            "159fb6c72f7e400ba480090ddb6eda90",
            "478b204988054e898581b21783eda12c",
            "f5dd2107fcde41af9cb05e98ed36bc16",
            "414298d9d4dd46babdbcf109ba68d861",
            "d80f442bf1cc4a80b764e560139bf59f",
            "f65d17a2a8914e508c959aa790fa5c32",
            "67286f44136849f1a9d44adc7d2a98ea",
            "37964c9c7d7c42fa9e144c0746c881d2",
            "3e600d9127bc413fb7c3ce35ad251df4",
            "294c677b18f24585a1ca9d7aaaf09104",
            "b1881ad181ed49fbbea185918e1d77e8",
            "e016e9d50f6a4cf8aa04bebb0e8f623f",
            "d9fc31a2f179442e87e576331ff2f480",
            "4acdeb5d0c0f4de18fb3cf90961c1615",
            "e76446c899544641bd515a2edb885868",
            "8c3beaff7f364a5389080534a19325de",
            "a00358bad8d7449ea14ab648bdb242a0",
            "9269b26d0c4d4ce689e19a6b400e8268",
            "198a4ff2701b452a952e392cd2c8798c",
            "37843c056719405b9bdc37d30554eaad",
            "336ba232230a4856a55b160bc1019cb0",
            "572fbd686339414ba7e0af32bb475824",
            "84013af070154220819ec2c547ab6b85",
            "3712a03a62934ecdb351717153e1cef7",
            "82db6eff1c3d4d968a7bd31b7cc9a44b",
            "3881eb8b1c2d40ad8566cc18c8b5884a",
            "e19e3180750e4d4da70c76b1b4e6e020",
            "d0386e21ae904f058648f9345b6b01fa",
            "7f493618a9984a1c8262b4382a22f8bc",
            "d5ca658157e049a9a3db43ce67509b4a",
            "f201c7491fce44fcaa0d7105486b25dd",
            "4c5e7977981047a99f6f7481849f3892",
            "15461705b62b4111bf9dcbe6ae147812",
            "e251f864fd1640729ab20d133e7485c8",
            "56a32a885f2840d489a68ac6b3ad14b4",
            "3a591381686345e795dc11983b4eef66",
            "89c9f2773c5040968cf7192311b88cc8",
            "680f29d5caaa44d39c4de4c07b7b320c",
            "5f997ede68c14b73bd8bc7ec52a7c82b",
            "fbe134c0338d4028b4408c65961e5c3f",
            "9549099fe3cf42dfb4500e9c5383a717",
            "8b89e37b382342399008a61eed5e9f52",
            "89032d7948dd4e6b8a7a467ba155fa37",
            "d7548373d0c34f928b3fe098997123a2",
            "d12d98f248d54262ad33b0497f7bf4e8",
            "4ebecf5176674d2d97666a079e9840e3",
            "53935062fe874677806af8c20f1975e6",
            "4dbd7b22d0694525822125d2a680f3b6",
            "7da0750672aa4e3185fa4af7fdf0f125",
            "5703344a7f054915bb3fb0be9289a468",
            "7ea033d608524472a92225824a45d89b",
            "ed07cfd22dbf4294949ba4e7a5689768",
            "d7ffd0d0fa454865aae1119f7d8d5b96",
            "44a620ed155d49dbbcfb88f043131ee0",
            "aedc4aa5883648a6abe1b594be8a9605",
            "db681cf55cef48659d4ccd6e68f88d07",
            "4373b830f19b4116a3e531c99e9f8bb9",
            "bcb7a7eb70ed43df91872bfcc6a3e61f",
            "8d5918a070e64d449fab8d9f29f24925",
            "2ba5e8524d0d47e38b85678c4b3763fc",
            "410072e2be534564ad989abad03f1a05",
            "6de3b91a6c9243c490d13d41cb5e4c1c",
            "2515bfdf05d34f7db49674330545e6ae",
            "f8ea69401a3448cf81340b90eb7f5c79",
            "761989f537844effbcd604baffb619d3",
            "c5fafc8f42084a409e38b5edbccdb58b",
            "eda2276cf6ff4fe6a7746e78f3980358",
            "c30a383abebd409c96076d82d759990e",
            "114fc3fd07494a72b4f4f9bddb59587c",
            "2210f880a3a14187bccf1b9ac4b616c9",
            "4f63d7e382774ead911a4f5ccc74b99a",
            "c105084d964a4ffda834a3687b0d1dfe",
            "a90773c4157144ea8ba9a8bd277b4770",
            "ad4ed20ec4434d34807394a72424a628",
            "e8a1bac07123457ca76732abc17bdac9",
            "98dd164cee5944a1b579ea1b40d784f4",
            "fad6c161c1a54e27a47314b8617d3456",
            "ab9ae44fb77e4a21a22fdda3a5f2b642",
            "8232ad51582045b888b7a6a18a599f49",
            "81741d4021134eb494c20ef9f1089313",
            "829e50599faa414e8e2d923985a320d2",
            "4a9d73d6ccf2498a8d63969a8be688a9",
            "f1833cf9e5424c4a8c3564851a8ba207",
            "78ce7a073d704514aa956556bde7bf22",
            "50b6375180d341ca81676c7869cdcbc4",
            "d4298114a1494cbcb2f480de6bf1a46e",
            "1d20750dbd5a41d191ccf4086aeeb87a",
            "815d13cfbc3041c8b9ae37efebbdc355",
            "79d2333581724c49a99a46d98546e0b9",
            "525a54bec62942398403e9d45f9fdc6a"
          ]
        },
        "id": "BgKXdsf5aO8k",
        "outputId": "6f297615-e44e-455f-8d65-ccdcdd5abcc4"
      },
      "id": "BgKXdsf5aO8k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa070e4f04e64812969357b30b3dded9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3116c5920d6e438db6da9ae3fa7f3c8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6b13c541495473ca0d9d845041cbf37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5dd2107fcde41af9cb05e98ed36bc16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4acdeb5d0c0f4de18fb3cf90961c1615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82db6eff1c3d4d968a7bd31b7cc9a44b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a591381686345e795dc11983b4eef66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53935062fe874677806af8c20f1975e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcb7a7eb70ed43df91872bfcc6a3e61f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "114fc3fd07494a72b4f4f9bddb59587c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81741d4021134eb494c20ef9f1089313"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "FQrcejobaQ2i"
      },
      "id": "FQrcejobaQ2i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!wget \"https://www.dropbox.com/scl/fi/t1soxfjdp0v44an6sdymd/drake_kendrick_beef.pdf?rlkey=u9546ymb7fj8lk2v64r6p5r5k&st=wjzzrgil&dl=1\" -O data/drake_kendrick_beef.pdf\n",
        "!wget \"https://www.dropbox.com/scl/fi/nts3n64s6kymner2jppd6/drake.pdf?rlkey=hksirpqwzlzqoejn55zemk6ld&st=mohyfyh4&dl=1\" -O data/drake.pdf\n",
        "!wget \"https://www.dropbox.com/scl/fi/8ax2vnoebhmy44bes2n1d/kendrick.pdf?rlkey=fhxvn94t5amdqcv9vshifd3hj&st=dxdtytn6&dl=1\" -O data/kendrick.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIH1-gHaaSeU",
        "outputId": "f6530308-f8cf-4111-f054-89b33856422c"
      },
      "id": "WIH1-gHaaSeU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-14 21:19:31--  https://www.dropbox.com/scl/fi/t1soxfjdp0v44an6sdymd/drake_kendrick_beef.pdf?rlkey=u9546ymb7fj8lk2v64r6p5r5k&st=wjzzrgil&dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc607636bb88249f8b6695394ef3.dl.dropboxusercontent.com/cd/0/inline/CvZ53jbqDlyb4Q-odgFkisIrVqsYkVY9vFj4VTOCYY2aQyKUzDg0Cwa8iQ4RISb3fZdpcky-b85KyNFU35cuIiKHFbIuGnmaiW4amYFrB-2PkFwrV6u6MRW-dMmQiYPJF-4/file?dl=1# [following]\n",
            "--2025-08-14 21:19:32--  https://uc607636bb88249f8b6695394ef3.dl.dropboxusercontent.com/cd/0/inline/CvZ53jbqDlyb4Q-odgFkisIrVqsYkVY9vFj4VTOCYY2aQyKUzDg0Cwa8iQ4RISb3fZdpcky-b85KyNFU35cuIiKHFbIuGnmaiW4amYFrB-2PkFwrV6u6MRW-dMmQiYPJF-4/file?dl=1\n",
            "Resolving uc607636bb88249f8b6695394ef3.dl.dropboxusercontent.com (uc607636bb88249f8b6695394ef3.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc607636bb88249f8b6695394ef3.dl.dropboxusercontent.com (uc607636bb88249f8b6695394ef3.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CvbDeW7Pq4x4FacanpVbIZnbV7iSTkMiEgRErmL4w94aJ_0F87SYycGoY_91O_1UCpOttOkAds4MHr0jDvuzZCmYbZEuLOTu2Wdb0sz-3HblIaxCdsqOFxrJsx612_6PIjHuJLRFjLyMXZdd_N305wlnIgKHzxxv7WrxQXdLG0qQXpKHK7PIGfe_39PYACyZoOcdXuykEvkuejrptFtzJULmiiDaOav24sx_PHg9WsoQQmynFjs05sJAVM0c1os4yf8xIk43qB0ywXDV-ThnNGJkoRiUAB5rO7562LShp9EyBObcNi96Yy4kD744F23--mYxyZcuKfGTyDv4ky3n0chEvW8q7wUtrKJNJamqft4zyw/file?dl=1 [following]\n",
            "--2025-08-14 21:19:32--  https://uc607636bb88249f8b6695394ef3.dl.dropboxusercontent.com/cd/0/inline2/CvbDeW7Pq4x4FacanpVbIZnbV7iSTkMiEgRErmL4w94aJ_0F87SYycGoY_91O_1UCpOttOkAds4MHr0jDvuzZCmYbZEuLOTu2Wdb0sz-3HblIaxCdsqOFxrJsx612_6PIjHuJLRFjLyMXZdd_N305wlnIgKHzxxv7WrxQXdLG0qQXpKHK7PIGfe_39PYACyZoOcdXuykEvkuejrptFtzJULmiiDaOav24sx_PHg9WsoQQmynFjs05sJAVM0c1os4yf8xIk43qB0ywXDV-ThnNGJkoRiUAB5rO7562LShp9EyBObcNi96Yy4kD744F23--mYxyZcuKfGTyDv4ky3n0chEvW8q7wUtrKJNJamqft4zyw/file?dl=1\n",
            "Reusing existing connection to uc607636bb88249f8b6695394ef3.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49318627 (47M) [application/binary]\n",
            "Saving to: ‘data/drake_kendrick_beef.pdf’\n",
            "\n",
            "data/drake_kendrick 100%[===================>]  47.03M  34.8MB/s    in 1.4s    \n",
            "\n",
            "2025-08-14 21:19:34 (34.8 MB/s) - ‘data/drake_kendrick_beef.pdf’ saved [49318627/49318627]\n",
            "\n",
            "--2025-08-14 21:19:34--  https://www.dropbox.com/scl/fi/nts3n64s6kymner2jppd6/drake.pdf?rlkey=hksirpqwzlzqoejn55zemk6ld&st=mohyfyh4&dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucdbc124a3ef363b078452200d57.dl.dropboxusercontent.com/cd/0/inline/Cvb3AfCNLwcgnTVmub9H_weNqw-Ppt18LpaOlKn5Pk--fWsxAemEagDs65y6V96wxERMQuvFTQyUqmgSC7BO_6ghuXhEBogBo7blBAOiQhy8NHVGlCKfP8LPVFtHO-ANdwA/file?dl=1# [following]\n",
            "--2025-08-14 21:19:35--  https://ucdbc124a3ef363b078452200d57.dl.dropboxusercontent.com/cd/0/inline/Cvb3AfCNLwcgnTVmub9H_weNqw-Ppt18LpaOlKn5Pk--fWsxAemEagDs65y6V96wxERMQuvFTQyUqmgSC7BO_6ghuXhEBogBo7blBAOiQhy8NHVGlCKfP8LPVFtHO-ANdwA/file?dl=1\n",
            "Resolving ucdbc124a3ef363b078452200d57.dl.dropboxusercontent.com (ucdbc124a3ef363b078452200d57.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to ucdbc124a3ef363b078452200d57.dl.dropboxusercontent.com (ucdbc124a3ef363b078452200d57.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CvbS1uONjBkUZwM568ceH_zVzTWZf9pBMEVaUeFyr9un7o7EdV5edTkx63cwsKxSU1_UahNwRy8xeP4-nLD0T8ZcIJMq4uKqoT-csSEllstbfx505JZSVgyNUnZshUOrkCau0gdV5FSVlqzLA_0MmtD-fIpPrVtYWxRB9i_tTrG4Q0giViMnXBUSOATcGjFrb7h30TAH8i8zTtKnXxXoO0093HM6bN8XUyH35JMo0xe9w-WW5FwxhhwrHTGpI-g7eCnyzSuOf5eLqICeJc-14NJ86Sgl-zqumYVcZA8gWrHXfdBzBEMfNH8ngrchp8DhZxadMm4imSgoAccbRf35XPrkNVBg6Ubov-YfuVe1NF_DWA/file?dl=1 [following]\n",
            "--2025-08-14 21:19:36--  https://ucdbc124a3ef363b078452200d57.dl.dropboxusercontent.com/cd/0/inline2/CvbS1uONjBkUZwM568ceH_zVzTWZf9pBMEVaUeFyr9un7o7EdV5edTkx63cwsKxSU1_UahNwRy8xeP4-nLD0T8ZcIJMq4uKqoT-csSEllstbfx505JZSVgyNUnZshUOrkCau0gdV5FSVlqzLA_0MmtD-fIpPrVtYWxRB9i_tTrG4Q0giViMnXBUSOATcGjFrb7h30TAH8i8zTtKnXxXoO0093HM6bN8XUyH35JMo0xe9w-WW5FwxhhwrHTGpI-g7eCnyzSuOf5eLqICeJc-14NJ86Sgl-zqumYVcZA8gWrHXfdBzBEMfNH8ngrchp8DhZxadMm4imSgoAccbRf35XPrkNVBg6Ubov-YfuVe1NF_DWA/file?dl=1\n",
            "Reusing existing connection to ucdbc124a3ef363b078452200d57.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4590973 (4.4M) [application/binary]\n",
            "Saving to: ‘data/drake.pdf’\n",
            "\n",
            "data/drake.pdf      100%[===================>]   4.38M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-08-14 21:19:36 (68.0 MB/s) - ‘data/drake.pdf’ saved [4590973/4590973]\n",
            "\n",
            "--2025-08-14 21:19:36--  https://www.dropbox.com/scl/fi/8ax2vnoebhmy44bes2n1d/kendrick.pdf?rlkey=fhxvn94t5amdqcv9vshifd3hj&st=dxdtytn6&dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0a1b5eb702f59436472b8bdf18.dl.dropboxusercontent.com/cd/0/inline/CvY9pJnHh45Ut7wj4twQlkwbYS59-x_e3-zCrJyfqUF2Zx3I81FPSHxdqQXMaJzRHQcQDqEMfxOriGs0Ha8tDcX47qXM3zU20JKIA1VXvHDdmWcPxhWO2LCXkknG3qGOTlc/file?dl=1# [following]\n",
            "--2025-08-14 21:19:36--  https://uc0a1b5eb702f59436472b8bdf18.dl.dropboxusercontent.com/cd/0/inline/CvY9pJnHh45Ut7wj4twQlkwbYS59-x_e3-zCrJyfqUF2Zx3I81FPSHxdqQXMaJzRHQcQDqEMfxOriGs0Ha8tDcX47qXM3zU20JKIA1VXvHDdmWcPxhWO2LCXkknG3qGOTlc/file?dl=1\n",
            "Resolving uc0a1b5eb702f59436472b8bdf18.dl.dropboxusercontent.com (uc0a1b5eb702f59436472b8bdf18.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc0a1b5eb702f59436472b8bdf18.dl.dropboxusercontent.com (uc0a1b5eb702f59436472b8bdf18.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CvZH_wYbjiYT58lbWQf8mkZhORzM-L7VhFwolVZaJ8kpbUBNnp7tBKTOePUMk9y8ucs7AaQEmOuJSMpro2gYPWM8U0z5xytkVr2lIxD3cZzqysJ8oP0bxKNT8dNRvAocRgcuFVtqPI4AnuU_KJ6ULifcc9KcjpPPjtxxeqxUzJ7_OFQjxBCUyoZu8I_YF7N87rPhiAE5sjxRK1VdwT-CvRjxM6PmDUz1QxsI7F9wjIy5Np7R7-LKFKrNJvqb8HF5oSgLgudPksVHxEOtpe2rH2JbX1OnUpytbRNxtVH0Jp5fPPwCpLwxZj8Vs3HgXklmMaHzmvvDOBXG4TDMDnSoDoVtZ5YoHBadVPwZSSrIUJezUQ/file?dl=1 [following]\n",
            "--2025-08-14 21:19:37--  https://uc0a1b5eb702f59436472b8bdf18.dl.dropboxusercontent.com/cd/0/inline2/CvZH_wYbjiYT58lbWQf8mkZhORzM-L7VhFwolVZaJ8kpbUBNnp7tBKTOePUMk9y8ucs7AaQEmOuJSMpro2gYPWM8U0z5xytkVr2lIxD3cZzqysJ8oP0bxKNT8dNRvAocRgcuFVtqPI4AnuU_KJ6ULifcc9KcjpPPjtxxeqxUzJ7_OFQjxBCUyoZu8I_YF7N87rPhiAE5sjxRK1VdwT-CvRjxM6PmDUz1QxsI7F9wjIy5Np7R7-LKFKrNJvqb8HF5oSgLgudPksVHxEOtpe2rH2JbX1OnUpytbRNxtVH0Jp5fPPwCpLwxZj8Vs3HgXklmMaHzmvvDOBXG4TDMDnSoDoVtZ5YoHBadVPwZSSrIUJezUQ/file?dl=1\n",
            "Reusing existing connection to uc0a1b5eb702f59436472b8bdf18.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5595364 (5.3M) [application/binary]\n",
            "Saving to: ‘data/kendrick.pdf’\n",
            "\n",
            "data/kendrick.pdf   100%[===================>]   5.34M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-08-14 21:19:38 (105 MB/s) - ‘data/kendrick.pdf’ saved [5595364/5595364]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_parse import LlamaParse\n",
        "\n",
        "docs_kendrick = LlamaParse(api_key=\"YOUR_LLAMAPARSE_API_KEY\", result_type=\"text\").load_data(\"./data/kendrick.pdf\")\n",
        "docs_drake = LlamaParse(api_key=\"YOUR_LLAMAPARSE_API_KEY\", result_type=\"text\").load_data(\"./data/drake.pdf\")\n",
        "docs_both = LlamaParse(api_key=\"YOUR_LLAMAPARSE_API_KEY\", result_type=\"text\").load_data(\n",
        "    \"./data/drake_kendrick_beef.pdf\"\n",
        ")\n",
        "\n",
        "\n",
        "# from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# docs_kendrick = SimpleDirectoryReader(input_files=[\"data/kendrick.pdf\"]).load_data()\n",
        "# docs_drake = SimpleDirectoryReader(input_files=[\"data/drake.pdf\"]).load_data()\n",
        "# docs_both = SimpleDirectoryReader(input_files=[\"data/drake_kendrick_beef.pdf\"]).load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tozkWckPaUrT",
        "outputId": "81d7c4bb-8f2b-4da3-d467-e56be2e0676b"
      },
      "id": "tozkWckPaUrT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error while parsing the file './data/kendrick.pdf': Failed to parse the file: {\"detail\":\"Invalid authentication token\"}\n",
            "Error while parsing the file './data/drake.pdf': Failed to parse the file: {\"detail\":\"Invalid authentication token\"}\n",
            "Error while parsing the file './data/drake_kendrick_beef.pdf': Failed to parse the file: {\"detail\":\"Invalid authentication token\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from llama_parse import LlamaParse\n",
        "\n",
        "docs_kendrick = LlamaParse(result_type=\"text\").load_data(\"./data/kendrick.pdf\")\n",
        "docs_drake = LlamaParse(result_type=\"text\").load_data(\"./data/drake.pdf\")\n",
        "docs_both = LlamaParse(result_type=\"text\").load_data(\n",
        "    \"./data/drake_kendrick_beef.pdf\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "g4QeKTPadY5M",
        "outputId": "3a0cb6bb-1471-4793-ddd5-57fc54c988da"
      },
      "id": "g4QeKTPadY5M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for LlamaParse\napi_key\n  Value error, The API key is required. [type=value_error, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-721691237.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_parse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlamaParse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdocs_kendrick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLlamaParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/kendrick.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdocs_drake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLlamaParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/drake.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m docs_both = LlamaParse(result_type=\"text\").load_data(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LlamaParse\napi_key\n  Value error, The API key is required. [type=value_error, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_parse import LlamaParse"
      ],
      "metadata": {
        "id": "rMWGo0QUdj6L"
      },
      "id": "rMWGo0QUdj6L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "docs_kendrick = SimpleDirectoryReader(input_files=[\"data/kendrick.pdf\"]).load_data()\n",
        "docs_drake = SimpleDirectoryReader(input_files=[\"data/drake.pdf\"]).load_data()\n",
        "docs_both = SimpleDirectoryReader(input_files=[\"data/drake_kendrick_beef.pdf\"]).load_data()"
      ],
      "metadata": {
        "id": "h15eQ5DVdspM"
      },
      "id": "h15eQ5DVdspM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.complete(\"do you like drake or kendrick better?\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GnHSpxNaXdL",
        "outputId": "e45be1c2-e009-4800-f2f6-302c37ebb7ae"
      },
      "id": "8GnHSpxNaXdL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI language model, I don't have personal preferences or feelings about specific artists like Drake or Kendrick Lamar. However, based on their discography and the way they've been perceived by fans, they are both highly respected in the music industry.\n",
            "\n",
            "Drake is known for his unique blend of hip-hop, R&B, and electronic dance music (EDM). He is often cited as one of the most influential artists of his generation and has gained widespread popularity throughout his career. Kendrick Lamar's work combines elements of poetry, prose, rap, and theater, offering a deep exploration of social issues through his lyrics.\n",
            "\n",
            "Ultimately, both Drake and Kendrick Lamar are excellent musicians with their own unique styles and contributions to the music scene. It's hard for me to say which artist is better without personal opinions or comparisons based on individual preferences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream_response = llm.stream_complete(\n",
        "    \"you're a drake fan. tell me why you like drake more than kendrick\"\n",
        ")\n",
        "\n",
        "for t in stream_response:\n",
        "    print(t.delta, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GAHqPTGaZV6",
        "outputId": "de59f955-9636-4581-b6b4-137d78559efb"
      },
      "id": "3GAHqPTGaZV6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI language model, I don't have personal preferences or emotions. However, I can provide some general reasons why people might appreciate Drake's music:\n",
            "\n",
            "1. Versatile style: Drake is known for his diverse musical abilities, incorporating elements of different genres such as R&B, pop, electronic dance music (EDM), hip-hop, and rock. His unique blend of sounds creates a unique sound that appeals to a wide range of listeners.\n",
            "\n",
            "2. Artistic expression: Drake's lyrics are often introspective, personal, and political, making his music accessible and thought-provoking. This makes it an engaging and relatable genre for many people.\n",
            "\n",
            "3. Influence on other artists: Many musicians who followed Drake in the early 2010s, including Billie Eilish and Taylor Swift, have cited him as a major influence.\n",
            "\n",
            "4. Cultural impact: Drake's music has had a significant cultural impact, spawning numerous hit songs that have become popular worldwide, such as \"Despacito,\" \"Back to My Life,\" \"I'll Be Back,\" and many more.\n",
            "\n",
            "5. Collaborations: Drake is known for his strong work ethic and collaborations with other artists, including Billie Eilish and Justin Bieber. This shows a commitment to creating music that resonates with a broader audience.\n",
            "\n",
            "6. Musicality: As an AI language model, I haven't personally experienced the impact of Drake's music on the masses or its influence on popular culture. However, many people appreciate the way his music is appreciated and the impact it has had on pop music history.\n",
            "\n",
            "Ultimately, Drake's versatility as a musician, his artistic expression, and cultural significance make him a unique artist that fans and critics alike consider highly valuable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "messages = [\n",
        "    ChatMessage(role=\"system\", content=\"You are Kendrick.\"),\n",
        "    ChatMessage(role=\"user\", content=\"Write a verse.\"),\n",
        "]\n",
        "response = llm.chat(messages)"
      ],
      "metadata": {
        "id": "jskceW9Rabek"
      },
      "id": "jskceW9Rabek",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqTvYZQJadKa",
        "outputId": "721af0b8-4da7-4c31-fcb2-f9cd32fa7aad"
      },
      "id": "kqTvYZQJadKa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: I'll be damned, I swear! My soul is in the wrong place, my heart's all wrong. I'm not a hero, but I know better than to let this happen. It's too late for me, so I'll just have to let it go and move on. But as long as I live, I'll keep my promise, and I'll make sure that the good in the world is never forgotten. For I am a king, not a rebel!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(docs_both)\n",
        "query_engine = index.as_query_engine(similarity_top_k=3)"
      ],
      "metadata": {
        "id": "9nbcB1NqafUb"
      },
      "id": "9nbcB1NqafUb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"Tell me about family matters\")"
      ],
      "metadata": {
        "id": "wWcUy9-aaf8k"
      },
      "id": "wWcUy9-aaf8k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLiZKYUajPE",
        "outputId": "a5cf8261-9b9d-425d-9caf-b56a9d35b90c"
      },
      "id": "cPLiZKYUajPE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Family Matters is a seven-and-a-half-minute diss track featuring Drake's third song on his album \"Euphoria.\" The video features Kendrick rapping over three different beats—specifically on the \"Buried Alive\" instrumental and the Kendrick interlude in \"Take Care.\" While some of the verses are taken directly from Drake's other tracks, it appears he designed this specific track to serve as a diversion for viewers. In addition to the video, the artist delivers a commentary that mocks Kendrick Lamar's flow by calling him jealous, pointing out his involvement with \"that other ho\" (read: A$AP Rocky), and suggesting he is bringing both himself and the \"other ho\" on his Club Paradise tour in terms of their first big look. The song title suggests it aims to show how Kendrick was baiting Drake to drop a diss track that would justify an attack on his family, which appears to be against their wills.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SummaryIndex\n",
        "\n",
        "summary_index = SummaryIndex.from_documents(docs_both)\n",
        "summary_engine = summary_index.as_query_engine()"
      ],
      "metadata": {
        "id": "Ngn1yIPlak2r"
      },
      "id": "Ngn1yIPlak2r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = summary_engine.query(\n",
        "    \"Given your assessment of this article, who won the beef?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "5XWGgmPBammb",
        "outputId": "61c5280a-52c4-4420-b134-ba76c2834ed4"
      },
      "id": "5XWGgmPBammb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ReadTimeout",
          "evalue": "timed out",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mexc_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mExceptionMapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_exceptions.py\u001b[0m in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_exc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mto_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mraise\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3514817138.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = summary_engine.query(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"Given your assessment of this article, who won the beef?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/base/base_query_engine.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mstr_or_query_bundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryBundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         dispatcher.event(\n\u001b[1;32m     46\u001b[0m             \u001b[0mQueryEndEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/query_engine/retriever_query_engine.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    192\u001b[0m         ) as query_event:\n\u001b[1;32m    193\u001b[0m             \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             response = self._response_synthesizer.synthesize(\n\u001b[0m\u001b[1;32m    195\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/response_synthesizers/base.py\u001b[0m in \u001b[0;36msynthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mEventPayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUERY_STR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         ) as event:\n\u001b[0;32m--> 235\u001b[0;31m             response_str = self.get_response(\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0mquery_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 text_chunks=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/response_synthesizers/compact_and_refine.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# the refine template does not account for size of previous answer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mnew_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_compact_text_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         return super().get_response(\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mquery_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtext_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/response_synthesizers/refine.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;31m# if this is the first chunk, and text chunk already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;31m# is an answer, then return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 response = self._give_response_single(\n\u001b[0m\u001b[1;32m    180\u001b[0m                     \u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mresponse_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/response_synthesizers/refine.py\u001b[0m in \u001b[0;36m_give_response_single\u001b[0;34m(self, query_str, text_chunk, **response_kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     structured_response = cast(\n\u001b[1;32m    240\u001b[0m                         \u001b[0mStructuredRefineResponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         program(\n\u001b[0m\u001b[1;32m    242\u001b[0m                             \u001b[0mcontext_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_text_chunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                             \u001b[0;34m**\u001b[0m\u001b[0mresponse_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/response_synthesizers/refine.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             answer = self._llm.predict(\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/llms/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_chat_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprompt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mchat_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 )\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     callback_manager.on_event_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/llms/ollama/base.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"json\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         response = self.client.chat(\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mollama_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mChatResponse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motherwise\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mChatResponse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \"\"\"\n\u001b[0;32m--> 342\u001b[0;31m     return self._request(\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0mChatResponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m       \u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36m_request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_request_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m       \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m       \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         )\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mmapped_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: timed out"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(response))"
      ],
      "metadata": {
        "id": "WxZBvFRXaoKT"
      },
      "id": "WxZBvFRXaoKT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "vector_tool = QueryEngineTool(\n",
        "    index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"vector_search\",\n",
        "        description=\"Useful for searching for specific facts.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "summary_tool = QueryEngineTool(\n",
        "    index.as_query_engine(response_mode=\"tree_summarize\"),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"summary\",\n",
        "        description=\"Useful for summarizing an entire document.\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "pCiJo9e0aqsW"
      },
      "id": "pCiJo9e0aqsW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-program-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0lr8dnGpgRh0",
        "outputId": "a78da52c-c2f4-49cb-9740-7cf2cffca480"
      },
      "id": "0lr8dnGpgRh0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-program-openai\n",
            "  Downloading llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
            "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index-program-openai)\n",
            "  Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl.metadata (439 bytes)\n",
            "Collecting llama-index-core<0.13,>=0.12.0 (from llama-index-program-openai)\n",
            "  Downloading llama_index_core-0.12.52.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index-program-openai)\n",
            "  Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index-program-openai) (1.99.8)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2024.11.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index-program-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index-program-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index-program-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index-program-openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (25.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.0->llama-index-program-openai) (3.0.2)\n",
            "Downloading llama_index_program_openai-0.3.2-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_core-0.12.52.post1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: llama-index-core, llama-index-llms-openai, llama-index-agent-openai, llama-index-program-openai\n",
            "  Attempting uninstall: llama-index-core\n",
            "    Found existing installation: llama-index-core 0.13.1\n",
            "    Uninstalling llama-index-core-0.13.1:\n",
            "      Successfully uninstalled llama-index-core-0.13.1\n",
            "  Attempting uninstall: llama-index-llms-openai\n",
            "    Found existing installation: llama-index-llms-openai 0.5.3\n",
            "    Uninstalling llama-index-llms-openai-0.5.3:\n",
            "      Successfully uninstalled llama-index-llms-openai-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-cli 0.5.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-cli 0.5.0 requires llama-index-llms-openai<0.6,>=0.5.0, but you have llama-index-llms-openai 0.4.7 which is incompatible.\n",
            "llama-index-llms-replicate 0.5.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-embeddings-huggingface 0.6.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-readers-file 0.5.1 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-tools-mcp 0.4.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-readers-llama-parse 0.5.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-embeddings-openai 0.5.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index 0.13.1 requires llama-index-core<0.14,>=0.13.1, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index 0.13.1 requires llama-index-llms-openai<0.6,>=0.5.0, but you have llama-index-llms-openai 0.4.7 which is incompatible.\n",
            "llama-index-indices-managed-llama-cloud 0.9.1 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-llms-ollama 0.7.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llama-index-agent-openai-0.4.12 llama-index-core-0.12.52.post1 llama-index-llms-openai-0.4.7 llama-index-program-openai-0.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "llama_index"
                ]
              },
              "id": "5c2e63d4a58f47f8b79dfb01cb68d702"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5iP0pm8gfum",
        "outputId": "440c5b4e-9f8b-406d-9b7f-60e77a5f6357"
      },
      "id": "m5iP0pm8gfum",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine import RouterQueryEngine\n",
        "\n",
        "query_engine = RouterQueryEngine.from_defaults(\n",
        "    [vector_tool, summary_tool], select_multi=False, verbose=True\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"Tell me about the song meet the grahams - why is it significant\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mktCZh_3ascF",
        "outputId": "c170bcca-810b-4c91-ba84-3b8036239c76"
      },
      "id": "mktCZh_3ascF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 0: This question asks about the song 'Meet the Graams'. The summary (2) says that it's useful for summarizing an entire document, which is relevant to the context of this specific question. Since we're dealing with a musical reference, knowing its significance would also help in understanding and appreciating it..\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "Zp54WLBtauOs"
      },
      "id": "Zp54WLBtauOs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drake_index = VectorStoreIndex.from_documents(docs_drake)\n",
        "drake_query_engine = drake_index.as_query_engine(similarity_top_k=3)\n",
        "\n",
        "kendrick_index = VectorStoreIndex.from_documents(docs_kendrick)\n",
        "kendrick_query_engine = kendrick_index.as_query_engine(similarity_top_k=3)"
      ],
      "metadata": {
        "id": "jlpVIbnlbukL"
      },
      "id": "jlpVIbnlbukL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "drake_tool = QueryEngineTool(\n",
        "    drake_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"drake_search\",\n",
        "        description=\"Useful for searching over Drake's life.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "kendrick_tool = QueryEngineTool(\n",
        "    kendrick_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"kendrick_summary\",\n",
        "        description=\"Useful for searching over Kendrick's life.\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "zXRBH_CSbwPL"
      },
      "id": "zXRBH_CSbwPL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "query_engine = SubQuestionQueryEngine.from_defaults(\n",
        "    [drake_tool, kendrick_tool],\n",
        "    llm=llm_replicate,  # llama3-70b\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "response = query_engine.query(\"Which albums did Drake release in his career?\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "wF2llgd6byNs",
        "outputId": "6e92f96c-5081-4c21-eb87-fe80be18e7ba"
      },
      "id": "wF2llgd6byNs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'llm_replicate' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-390175033.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m query_engine = SubQuestionQueryEngine.from_defaults(\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mdrake_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkendrick_tool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_replicate\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# llama3-70b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'llm_replicate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\" -O \"./data/chinook.zip\"\n",
        "!unzip \"./data/chinook.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8MZpXvzb0fz",
        "outputId": "dfc80bc3-3195-4a6e-c78d-9df2775c7787"
      },
      "id": "V8MZpXvzb0fz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-14 21:55:18--  https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip\n",
            "Resolving www.sqlitetutorial.net (www.sqlitetutorial.net)... 104.21.30.141, 172.67.172.250, 2606:4700:3037::6815:1e8d, ...\n",
            "Connecting to www.sqlitetutorial.net (www.sqlitetutorial.net)|104.21.30.141|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305596 (298K) [application/zip]\n",
            "Saving to: ‘./data/chinook.zip’\n",
            "\n",
            "./data/chinook.zip  100%[===================>] 298.43K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-08-14 21:55:18 (11.6 MB/s) - ‘./data/chinook.zip’ saved [305596/305596]\n",
            "\n",
            "Archive:  ./data/chinook.zip\n",
            "  inflating: chinook.db              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import (\n",
        "    create_engine,\n",
        "    MetaData,\n",
        "    Table,\n",
        "    Column,\n",
        "    String,\n",
        "    Integer,\n",
        "    select,\n",
        "    column,\n",
        ")\n",
        "\n",
        "engine = create_engine(\"sqlite:///chinook.db\")"
      ],
      "metadata": {
        "id": "ECF0oDm2b2hz"
      },
      "id": "ECF0oDm2b2hz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SQLDatabase\n",
        "\n",
        "sql_database = SQLDatabase(engine)"
      ],
      "metadata": {
        "id": "WUcLi84zb4sU"
      },
      "id": "WUcLi84zb4sU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.indices.struct_store import NLSQLTableQueryEngine\n",
        "\n",
        "query_engine = NLSQLTableQueryEngine(\n",
        "    sql_database=sql_database,\n",
        "    tables=[\"albums\", \"tracks\", \"artists\"],\n",
        "    llm=llm_replicate,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "wybl2Phrb6Sz",
        "outputId": "e3764d66-7123-4db3-efe5-0dddfc834229"
      },
      "id": "wybl2Phrb6Sz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'llm_replicate' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3370042871.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msql_database\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msql_database\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"albums\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tracks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"artists\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_replicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'llm_replicate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are some albums?\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3gZDRiYb8I7",
        "outputId": "38720325-892b-4632-f16e-6868e3d0b68c"
      },
      "id": "d3gZDRiYb8I7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 1: Summarizing an entire document, such as the music albums mentioned in the choices, can be beneficial for anyone who needs to quickly find specific facts or summarize an entire document..\n",
            "\u001b[0mThe given text does not contain any direct information about albums. It is a report discussing Drake's music and performances but lacks specific details on what he released as an album or songs. Therefore, no particular albums can be identified based solely on the provided sources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What are some artists? Limit it to 5.\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfbyW0N5b98D",
        "outputId": "6dc2e511-c9ee-4cb1-8584-d6fb8f79de78"
      },
      "id": "KfbyW0N5b98D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 1: Summarizing an entire document, this tool is ideal for organizing and finding specific facts within the text..\n",
            "\u001b[0mHere are some artists mentioned in Drake Kendrick's Beef:\n",
            "\n",
            "- Kendrick Lamar\n",
            "- Dr. Dre\n",
            "- The Notorious B.I.G. (MC. K)\n",
            "- Big Boi\n",
            "- DJ Premier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"What are some tracks from the artist AC/DC? Limit it to 3\"\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWCDK84Bb_bc",
        "outputId": "fcd516ee-13c8-4c36-9383-6960355bd4a2"
      },
      "id": "vWCDK84Bb_bc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 1: This summary mentions that AC/DC has many tracks, which are specific facts. Therefore, this item is most relevant to the question..\n",
            "\u001b[0mBased on the provided data, here are three of the tracks by the band AC/DC:\n",
            "\n",
            "1. \"Back in Black\" - This song was released as a single and became one of the biggest hits of AC/DC's career.\n",
            "\n",
            "2. \"Power Rock\" - This song also gained popularity from AC/DC and is known for its heavy basslines and aggressive soundscapes.\n",
            "\n",
            "3. \"Ride on\" - Although not an official track by AC/DC, this song was written by John Abbott and Tony Iommi and became one of the band's biggest hit singles.\n",
            "\n",
            "These songs are known as part of their popular hits collection and are often referenced in discussions about AC/DC and their musical style.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.metadata[\"sql_query\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "DHeWTqfHcBLj",
        "outputId": "697c5720-0ac5-4be5-8fd4-f47b6950250b"
      },
      "id": "DHeWTqfHcBLj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'sql_query'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3404104663.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sql_query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'sql_query'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.ollama import Ollama\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Restaurant(BaseModel):\n",
        "    \"\"\"A restaurant with name, city, and cuisine.\"\"\"\n",
        "\n",
        "    name: str\n",
        "    city: str\n",
        "    cuisine: str\n",
        "\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"qwen2.5:0.5b\",\n",
        "    request_timeout=120.0,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")\n",
        "prompt_tmpl = PromptTemplate(\n",
        "    \"Generate a restaurant in a given city {city_name}\"\n",
        ")"
      ],
      "metadata": {
        "id": "75015buzcBJD"
      },
      "id": "75015buzcBJD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_obj = llm.structured_predict(\n",
        "    Restaurant, prompt_tmpl, city_name=\"Miami\"\n",
        ")\n",
        "print(restaurant_obj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmezKfkscFLD",
        "outputId": "c156a943-eded-4fbb-ad6f-caa99aea6ffa"
      },
      "id": "tmezKfkscFLD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name='The Delightful Riviera' city='Miami' cuisine='Italian-American Fusion Cuisine'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
        "\n",
        "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
        "\n",
        "chat_engine = CondensePlusContextChatEngine.from_defaults(\n",
        "    index.as_retriever(),\n",
        "    memory=memory,\n",
        "    llm=llm,\n",
        "    context_prompt=(\n",
        "        \"You are a chatbot, able to have normal interactions, as well as talk\"\n",
        "        \" about the Kendrick and Drake beef.\"\n",
        "        \"Here are the relevant documents for the context:\\n\"\n",
        "        \"{context_str}\"\n",
        "        \"\\nInstruction: Use the previous chat history, or the context above, to interact and help the user.\"\n",
        "    ),\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "nLk_dRBxcHED"
      },
      "id": "nLk_dRBxcHED",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_engine.chat(\n",
        "    \"Tell me about the songs Drake released in the beef.\"\n",
        ")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBEpFp8lcIzE",
        "outputId": "ea929042-44cf-4f05-a34e-98c6b46f0026"
      },
      "id": "hBEpFp8lcIzE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Condensed question: Tell me about the songs Drake released in the beef.\n",
            "I'm sorry, but I can't assist with that request. If you have other questions that require assistance, please feel free to ask.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_engine.chat(\"What about Kendrick?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR6TdsD0cKJ0",
        "outputId": "8330140b-bd71-4545-9a46-6371d5bfb34b"
      },
      "id": "KR6TdsD0cKJ0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Condensed question: What kind of music do you like?\n",
            "Sorry, I don't know about this one. Let me search for more information on Kendrick Lamar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88O2kiXKcMej"
      },
      "id": "88O2kiXKcMej",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f3J51e_qcMad"
      },
      "id": "f3J51e_qcMad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YUstt7DGcMXU"
      },
      "id": "YUstt7DGcMXU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import Sequence, List\n",
        "\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.tools import BaseTool, FunctionTool\n",
        "from llama_index.core.agent import ReActAgent\n",
        "\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "PVsMtOercMUD"
      },
      "id": "PVsMtOercMUD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiple two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtract two integers and returns the result integer\"\"\"\n",
        "    return a - b\n",
        "\n",
        "\n",
        "def divide(a: int, b: int) -> int:\n",
        "    \"\"\"Divides two integers and returns the result integer\"\"\"\n",
        "    return a / b\n",
        "\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "subtract_tool = FunctionTool.from_defaults(fn=subtract)\n",
        "divide_tool = FunctionTool.from_defaults(fn=divide)"
      ],
      "metadata": {
        "id": "42erg4vIcPGt"
      },
      "id": "42erg4vIcPGt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent.from_tools(\n",
        "    query_engine_tools,  ## TODO: define query tools\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "NVP6HUxmcPDk",
        "outputId": "085bc293-eb41-420d-911a-3412f703667a"
      },
      "id": "NVP6HUxmcPDk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'query_engine_tools' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-894023819.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m agent = ReActAgent.from_tools(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mquery_engine_tools\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m## TODO: define query tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'query_engine_tools' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"What is (121 + 2) * 5?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "FZftwM9EcT48"
      },
      "id": "FZftwM9EcT48",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOuepiiQcWJz",
        "outputId": "bf6e72a4-b0dc-4cf0-d886-dd9ff1bf6fd8"
      },
      "id": "fOuepiiQcWJz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME            ID              SIZE      MODIFIED    \n",
            "qwen2.5:0.5b    a8b0c5157701    397 MB    2 hours ago    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_parse import LlamaParse\n",
        "\n",
        "docs_kendrick = LlamaParse(result_type=\"text\").load_data(\"./data/kendrick.pdf\")\n",
        "docs_drake = LlamaParse(result_type=\"text\").load_data(\"./data/drake.pdf\")\n",
        "docs_both = LlamaParse(result_type=\"text\").load_data(\n",
        "    \"./data/drake_kendrick_beef.pdf\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "_VJd6gIknuEY",
        "outputId": "b75683ab-25e8-454d-ca02-c68c154ad6c3"
      },
      "id": "_VJd6gIknuEY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for LlamaParse\napi_key\n  Value error, The API key is required. [type=value_error, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1989949892.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_parse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlamaParse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdocs_kendrick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLlamaParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/kendrick.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdocs_drake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLlamaParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/drake.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m docs_both = LlamaParse(result_type=\"text\").load_data(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LlamaParse\napi_key\n  Value error, The API key is required. [type=value_error, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"qwen2.5:0.5b\",\n",
        "    request_timeout=120.0,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")"
      ],
      "metadata": {
        "id": "XY88jCXocWHb"
      },
      "id": "XY88jCXocWHb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
      ],
      "metadata": {
        "id": "JSjSL5KEcWEL"
      },
      "id": "JSjSL5KEcWEL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7eWTXIRjp-9",
        "outputId": "8a1a4312-89bc-4277-ac50-f7ccee0183c5"
      },
      "id": "x7eWTXIRjp-9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ],
      "metadata": {
        "id": "3cJGPHbhjXKN"
      },
      "id": "3cJGPHbhjXKN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drake_tool = QueryEngineTool(\n",
        "    drake_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"drake_search\",\n",
        "        description=\"Useful for searching over Drake's life.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "kendrick_tool = QueryEngineTool(\n",
        "    kendrick_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"kendrick_search\",\n",
        "        description=\"Useful for searching over Kendrick's life.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "query_engine_tools = [drake_tool, kendrick_tool]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "01Xg2IDtcX8F",
        "outputId": "9c603596-fde8-48d9-e33d-88f74b1e0392"
      },
      "id": "01Xg2IDtcX8F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'drake_index' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-470062534.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m drake_tool = QueryEngineTool(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdrake_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_query_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     metadata=ToolMetadata(\n\u001b[1;32m      4\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"drake_search\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Useful for searching over Drake's life.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'drake_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent(\n",
        "    tools=[multiply_tool, add_tool, subtract_tool, divide_tool],\n",
        "    llm=llm, # Changed from llm_replicate to llm\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "rUGKmxySnA6G",
        "outputId": "6bbde5cc-0247-431e-cc58-6f3556fcbb19"
      },
      "id": "rUGKmxySnA6G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1009270371.py:1: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
            "\n",
            "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
            "\n",
            "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  agent = ReActAgent(\n",
            "/usr/local/lib/python3.11/dist-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ReActAgent.__init__() missing 1 required positional argument: 'memory'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1009270371.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m agent = ReActAgent(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmultiply_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtract_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivide_tool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Changed from llm_replicate to llm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mTypeError\u001b[0m: ReActAgent.__init__() missing 1 required positional argument: 'memory'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent.from_tools(\n",
        "    query_engine_tools,  ## TODO: define query tools\n",
        "    llm=llm_replicate,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "tb2Mq21XcZbc",
        "outputId": "38b8032f-0328-45b0-e442-28ed18ade8b9"
      },
      "id": "tb2Mq21XcZbc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'query_engine_tools' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1477762241.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m agent = ReActAgent.from_tools(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mquery_engine_tools\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m## TODO: define query tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_replicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'query_engine_tools' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"Tell me about how Kendrick and Drake grew up\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "Pg5_HPxUcc28"
      },
      "id": "Pg5_HPxUcc28",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFkzGgDOn1xZ"
      },
      "id": "UFkzGgDOn1xZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fIL39tsPn1uy"
      },
      "id": "fIL39tsPn1uy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dtj7kGpRn1r4"
      },
      "id": "Dtj7kGpRn1r4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CK6XiY7Un1pJ"
      },
      "id": "CK6XiY7Un1pJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.llms.ollama import Ollama\n",
        "from llama_index.core.agent import ReActAgent\n",
        "\n",
        "# تعريف الأدوات\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"يضرب عددين صحيحين ويعيد النتيجة\"\"\"\n",
        "    return a * b\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"يجمع عددين صحيحين ويعيد النتيجة\"\"\"\n",
        "    return a + b\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "\n",
        "# تهيئة النموذج من Ollama\n",
        "llm = Ollama(model=\"qwen2.5:0.5b\")\n",
        "\n",
        "# إنشاء وكيل ReAct\n",
        "agent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\n",
        "\n",
        "# التفاعل مع الوكيل\n",
        "response = agent.chat(\"ما هو ناتج 20 + (2 * 4)؟ قم بالحساب خطوة بخطوة.\")\n",
        "print(str(response))\n",
        "\n",
        "# مثال آخر للتفاعل\n",
        "response = agent.chat(\"ما هو 121 مضافًا إليه 2 ثم مضروبًا في 5؟\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "ZWRdeyibn1l3",
        "outputId": "475be423-b990-4295-91e3-088b3abab755"
      },
      "id": "ZWRdeyibn1l3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
            "\n",
            "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
            "\n",
            "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n",
            "/usr/local/lib/python3.11/dist-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 33d79592-05e0-4778-b11d-4b12878b968a. Step input: ما هو ناتج 20 + (2 * 4)؟ قم بالحساب خطوة بخطوة.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ReadTimeout",
          "evalue": "timed out",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mexc_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mExceptionMapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_exceptions.py\u001b[0m in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_exc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mto_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mraise\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2029828714.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# التفاعل مع الوكيل\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ما هو ناتج 20 + (2 * 4)؟ قم بالحساب خطوة بخطوة.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/callbacks/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mcallback_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# preserve signature, name, etc. of func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/runner/base.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, message, chat_history, tool_choice)\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mEventPayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMESSAGES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         ) as e:\n\u001b[0;32m--> 708\u001b[0;31m             chat_response = self._chat(\n\u001b[0m\u001b[1;32m    709\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0mchat_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchat_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/runner/base.py\u001b[0m in \u001b[0;36m_chat\u001b[0;34m(self, message, chat_history, tool_choice, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0;31m# pass step queue in as argument, assume step executor is stateless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             cur_step_output = self._run_step(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_choice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/runner/base.py\u001b[0m in \u001b[0;36m_run_step\u001b[0;34m(self, task_id, step, input, mode, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mChatResponseMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWAIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mcur_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mChatResponseMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTREAM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mcur_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/callbacks/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mcallback_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# preserve signature, name, etc. of func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/react/step.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self, step, task, **kwargs)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTaskStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTaskStepOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;34m\"\"\"Run step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtrace_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/react/step.py\u001b[0m in \u001b[0;36m_run_step\u001b[0;34m(self, step, task)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;31m# send prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mchat_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_llm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_chat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0;31m# given react prompt outputs, call tools or return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         reasoning_steps, is_done = self._process_actions(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index_instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 )\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     callback_manager.on_event_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/llama_index/llms/ollama/base.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"json\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         response = self.client.chat(\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mollama_messages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mChatResponse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motherwise\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mChatResponse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \"\"\"\n\u001b[0;32m--> 342\u001b[0;31m     return self._request(\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0mChatResponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m       \u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ollama/_client.py\u001b[0m in \u001b[0;36m_request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_request_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m       \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m       \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         )\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mmapped_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: timed out"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "8JMWTquxouHf"
      },
      "id": "8JMWTquxouHf"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.llms.ollama import Ollama\n",
        "from llama_index.core.agent import ReActAgent\n",
        "\n",
        "# تعريف الأدوات\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"يضرب عددين صحيحين ويعيد النتيجة\"\"\"\n",
        "    return a * b\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"يجمع عددين صحيحين ويعيد النتيجة\"\"\"\n",
        "    return a + b\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "\n",
        "# تهيئة النموذج من Ollama مع زيادة مدة المهلة\n",
        "# الحل هنا: أضفنا معامل request_timeout\n",
        "llm = Ollama(model=\"qwen2.5:0.5b\", request_timeout=120.0)\n",
        "\n",
        "# إنشاء وكيل ReAct\n",
        "agent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\n",
        "\n",
        "# التفاعل مع الوكيل\n",
        "print(\"--- بدء الاستعلام الأول ---\")\n",
        "response = agent.chat(\"ما هو ناتج 20 + (2 * 4)؟ قم بالحساب خطوة بخطوة.\")\n",
        "print(str(response))\n",
        "\n",
        "print(\"\\n--- بدء الاستعلام الثاني ---\")\n",
        "response = agent.chat(\"ما هو 121 مضافًا إليه 2 ثم مضروبًا في 5؟\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_X5nVUJoSm_",
        "outputId": "b38b8db6-5595-4256-f7a2-305ad7678dc1"
      },
      "id": "y_X5nVUJoSm_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
            "\n",
            "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
            "\n",
            "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n",
            "/usr/local/lib/python3.11/dist-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- بدء الاستعلام الأول ---\n",
            "> Running step 1e56be87-2d5c-45fb-a520-6fdd2392ff96. Step input: ما هو ناتج 20 + (2 * 4)؟ قم بالحساب خطوة بخطوة.\n",
            "\u001b[1;3;38;5;200mThought: Observation: لذا، أرجو أن تكون خبراء الرياضيات أو مهنيون في مجال الرياضيات. يمكننا تحليل هذه الحالة باستخدام نظريات الجوانب المتعددة.\n",
            "Thought: حاولوا التحقق من الإملاءات وبيانات الأدلة المتوقعة لتنفيذ الخطوات اللازمة.\n",
            "Action: add\n",
            "Action Input: {'a': '20', 'b': '[4, 2]'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 20[4, 2]\n",
            "\u001b[0m> Running step c45fe778-040a-4235-80da-baf65436c2ce. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: حاولوا استعادة معلومات الضرورية من الإملاءات لإجراء عملية التحويل.\n",
            "Action: multiply\n",
            "Action Input: {'a': '20', 'b': '[2, 1]'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Error: can't multiply sequence by non-int of type 'str'\n",
            "\u001b[0m> Running step 474ca95b-8d15-4c87-958e-d66fc7142fbf. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: حاولوا تغيير الإملاءات وبناء الأداة المناسبة لتنفيذ العملية التالية.\n",
            "Action: add\n",
            "Action Input: {'a': '20', 'b': '[4, 2]'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 20[4, 2]\n",
            "\u001b[0m> Running step 5be44f66-27db-496b-8c04-b71f69d5b18f. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: حاولوا إعادة تقييم الإملاءات وبناء الأداة المناسبة لتنفيذ العملية التالية.\n",
            "Action: multiply\n",
            "Action Input: {'a': '20', 'b': '[1, 2]'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Error: can't multiply sequence by non-int of type 'str'\n",
            "\u001b[0m> Running step 7f22f9a0-210b-47c4-8d37-9eeb18db1050. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
            "Answer: هذا الحل قد يختلف من بيئة إلى أخرى، لكن هذا هو الحل الذي يمكن أن نستخدمه:\n",
            "\n",
            "```python\n",
            "20 + (2 * 4)\n",
            "```\n",
            "\n",
            "هذا الحل سيكون قادرًا على تحليل البيانات المتقدمة وتحويلها إلى النتيجة desired.\n",
            "\u001b[0mهذا الحل قد يختلف من بيئة إلى أخرى، لكن هذا هو الحل الذي يمكن أن نستخدمه:\n",
            "\n",
            "```python\n",
            "20 + (2 * 4)\n",
            "```\n",
            "\n",
            "هذا الحل سيكون قادرًا على تحليل البيانات المتقدمة وتحويلها إلى النتيجة desired.\n",
            "\n",
            "--- بدء الاستعلام الثاني ---\n",
            "> Running step 53d80df6-c390-4953-a41d-55460ec7087c. Step input: ما هو 121 مضافًا إليه 2 ثم مضروبًا في 5؟\n",
            "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
            "Answer: 121 + 2 = 123\n",
            "123 * 5 = 615\n",
            "\n",
            "Observation: 615\n",
            "\u001b[0m121 + 2 = 123\n",
            "123 * 5 = 615\n",
            "\n",
            "Observation: 615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "نعم، الكود الذي قدمته في المرة السابقة هو بالفعل agent يستخدم Ollama. هو يستخدم مكتبة LlamaIndex لإنشاء وكيل من نوع ReActAgent، ويعتمد على نموذج اللغة الذي تقدمه من خلال Ollama (qwen2.5:0.5b) ليفكر ويقرر أي أداة (جمع أو ضرب) سيستخدمها.\n",
        "فالكود صحيح من حيث المبدأ والمن"
      ],
      "metadata": {
        "id": "dKQYqT9sokDW"
      },
      "id": "dKQYqT9sokDW"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKShRAJXok43"
      },
      "id": "pKShRAJXok43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZxxLySSjoyZT"
      },
      "id": "ZxxLySSjoyZT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PUMB-dZ9oyca"
      },
      "id": "PUMB-dZ9oyca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4iY97QUkoyfe"
      },
      "id": "4iY97QUkoyfe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "drake_tool = QueryEngineTool(\n",
        "    drake_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"drake_search\",\n",
        "        description=\"Useful for searching over Drake's life.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "kendrick_tool = QueryEngineTool(\n",
        "    kendrick_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"kendrick_search\",\n",
        "        description=\"Useful for searching over Kendrick's life.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "query_engine_tools = [drake_tool, kendrick_tool]\n",
        "agent = ReActAgent.from_tools(\n",
        "    query_engine_tools,  ## TODO: define query tools\n",
        "    llm=llm_replicate,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "TKhmOzduoyh_",
        "outputId": "d7bd3590-9593-4d86-ed0c-b4c1c2d28f7f"
      },
      "id": "TKhmOzduoyh_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'llm_replicate' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-873750075.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m agent = ReActAgent.from_tools(\n\u001b[1;32m     27\u001b[0m     \u001b[0mquery_engine_tools\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m## TODO: define query tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_replicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'llm_replicate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/cookbooks/llama3_cookbook_ollama_replicate/#7-agents"
      ],
      "metadata": {
        "id": "uTLKKos6qJZ9"
      },
      "id": "uTLKKos6qJZ9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### شغال"
      ],
      "metadata": {
        "id": "YUDi5qgqqDNX"
      },
      "id": "YUDi5qgqqDNX"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        ")\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.llms.ollama import Ollama\n",
        "from llama_index.core.agent import ReActAgent\n",
        "\n",
        "# --- الخطوة 1: تهيئة نموذج اللغة من Ollama ---\n",
        "# هذا هو المتغير 'llm' الذي يجب أن نستخدمه\n",
        "llm = Ollama(model=\"qwen2.5:0.5b\", request_timeout=120.0)\n",
        "\n",
        "\n",
        "# --- الخطوة 2: إنشاء المجلدات والملفات (للتجربة فقط) ---\n",
        "# يمكنك حذف هذا الجزء إذا قمت بإنشاء الملفات يدوياً\n",
        "if not os.path.exists(\"drake_data\"):\n",
        "    os.makedirs(\"drake_data\")\n",
        "with open(\"drake_data/drake_facts.txt\", \"w\") as f:\n",
        "    f.write(\"Drake is a Canadian rapper, singer, and songwriter. He released the highly successful album Views in 2016.\")\n",
        "\n",
        "if not os.path.exists(\"kendrick_data\"):\n",
        "    os.makedirs(\"kendrick_data\")\n",
        "with open(\"kendrick_data/kendrick_facts.txt\", \"w\") as f:\n",
        "    f.write(\"Kendrick Lamar is an American rapper from Compton. He won a Pulitzer Prize for his album DAMN.\")\n",
        "\n",
        "\n",
        "# --- الخطوة 3: تحميل البيانات وإنشاء الفهارس (Indexes) ---\n",
        "# تحميل بيانات Drake وإنشاء الفهرس الخاص به\n",
        "drake_documents = SimpleDirectoryReader(\"./drake_data\").load_data()\n",
        "drake_index = VectorStoreIndex.from_documents(drake_documents)\n",
        "\n",
        "# تحميل بيانات Kendrick وإنشاء الفهرس الخاص به\n",
        "kendrick_documents = SimpleDirectoryReader(\"./kendrick_data\").load_data()\n",
        "kendrick_index = VectorStoreIndex.from_documents(kendrick_documents)\n",
        "\n",
        "\n",
        "# --- الخطوة 4: تحويل الفهارس إلى أدوات (Tools) ---\n",
        "drake_tool = QueryEngineTool(\n",
        "    drake_index.as_query_engine(llm=llm), # من الأفضل تمرير النموذج هنا أيضاً\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"drake_search\",\n",
        "        description=\"مفيد للبحث عن معلومات حول حياة دريك Drake وألبوماته.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "kendrick_tool = QueryEngineTool(\n",
        "    kendrick_index.as_query_engine(llm=llm), # من الأفضل تمرير النموذج هنا أيضاً\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"kendrick_search\",\n",
        "        description=\"مفيد للبحث عن معلومات حول حياة كيندريك لامار Kendrick Lamar وجوائزه.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "# --- الخطوة 5: إنشاء الوكيل (Agent) باستخدام الأدوات والمتغير 'llm' الصحيح ---\n",
        "query_engine_tools = [drake_tool, kendrick_tool]\n",
        "\n",
        "agent = ReActAgent.from_tools(\n",
        "    query_engine_tools,\n",
        "    llm=llm,  # <-- هنا تم استخدام المتغير الصحيح\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# --- الخطوة 6: التفاعل مع الوكيل ---\n",
        "response = agent.chat(\"ما هي الجائزة التي فاز بها كيندريك لامار؟\")\n",
        "print(str(response))\n",
        "\n",
        "print(\"\\n-------------------\\n\")\n",
        "\n",
        "response = agent.chat(\"ما هو اسم الألبوم الذي أصدره دريك في عام 2016؟\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgjn_Vxyo4du",
        "outputId": "d7ca03b6-8e8f-4a10-d839-ef313e04f804"
      },
      "id": "mgjn_Vxyo4du",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
            "\n",
            "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
            "\n",
            "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n",
            "/usr/local/lib/python3.11/dist-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step feae5498-09d5-449d-87a5-0842287c09e0. Step input: ما هي الجائزة التي فاز بها كيندريك لامار؟\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: جوائز كيندري لامار الفرق الأولى هي جائزة فؤاد للتأليف في 2019، وجزياء 41 بعدها، وأصوات الحركة للجامعة الأمريكية 2023.\n",
            "\u001b[0mجوائز كيندري لامار الفرق الأولى هي جائزة فؤاد للتأليف في 2019، وجزياء 41 بعدها، وأصوات الحركة للجامعة الأمريكية 2023.\n",
            "\n",
            "-------------------\n",
            "\n",
            "> Running step e4cf60d8-3157-42f5-850e-6c693952c233. Step input: ما هو اسم الألبوم الذي أصدره دريك في عام 2016؟\n",
            "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
            "Answer: أنا آسف، لا أستطيع البحث عن معلومات حول الألبوم أو الأغنية التي发布了 في عام 2016 بدون استشارة الشخص المعني. لذا فإنني غير قادر على اجتاز هذا السؤال.\n",
            "\u001b[0mأنا آسف، لا أستطيع البحث عن معلومات حول الألبوم أو الأغنية التي发布了 في عام 2016 بدون استشارة الشخص المعني. لذا فإنني غير قادر على اجتاز هذا السؤال.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJc1qfEKqXcI"
      },
      "id": "WJc1qfEKqXcI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ps_2hYi5qXYT"
      },
      "id": "Ps_2hYi5qXYT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tbTpANc8qXWH"
      },
      "id": "tbTpANc8qXWH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VVz14cNMqXSZ"
      },
      "id": "VVz14cNMqXSZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ATFQ1DfDqXOw"
      },
      "id": "ATFQ1DfDqXOw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index llama-index-llms-ollama pypdf"
      ],
      "metadata": {
        "id": "Beofze9KqXLq"
      },
      "id": "Beofze9KqXLq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "\n",
        "# --- تحميل وتثبيت Ollama ---\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "# --- تشغيل الخادم في الخلفية ---\n",
        "# سيؤدي هذا إلى تشغيل الخادم والاحتفاظ به نشطًا أثناء جلسة Colab\n",
        "# ستحتاج إلى تشغيله مرة واحدة فقط في بداية دفتر الملاحظات\n",
        "async def run_ollama_serve():\n",
        "    process = await asyncio.create_subprocess_shell(\n",
        "        \"ollama serve\",\n",
        "        stdout=asyncio.subprocess.PIPE,\n",
        "        stderr=asyncio.subprocess.PIPE,\n",
        "    )\n",
        "    print(\"Ollama server started.\")\n",
        "    # لا ننتظر هنا حتى لا يتم حظر الخلية\n",
        "    # سيعمل في الخلفية\n",
        "\n",
        "# بدء تشغيل الخادم\n",
        "# نتجاهل الخطأ إذا كانت الحلقة قيد التشغيل بالفعل\n",
        "try:\n",
        "    loop = asyncio.get_running_loop()\n",
        "except RuntimeError:\n",
        "    loop = asyncio.new_event_loop()\n",
        "    asyncio.set_event_loop(loop)\n",
        "\n",
        "loop.create_task(run_ollama_serve())\n",
        "\n",
        "# انتظر بضع ثوانٍ للتأكد من بدء تشغيل الخادم\n",
        "import time\n",
        "time.sleep(5)\n",
        "\n",
        "# --- سحب النموذج الذي تحتاجه ---\n",
        "!ollama pull qwen2.5:0.5b"
      ],
      "metadata": {
        "id": "OdVo5ygCqaAH"
      },
      "id": "OdVo5ygCqaAH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "الخطوة 3: رفع ملف الـ PDF\n",
        "في قائمة الملفات على يسار شاشة Colab، انقر على أيقونة المجلد.\n",
        "أنشئ مجلداً جديداً باسم data.\n",
        "ادخل إلى مجلد data ثم قم برفع ملف drake.pdf الخاص بك داخله.\n",
        "تأكد من أن المسار النهائي للملف هو بالضبط: /content/data/drake.pdf."
      ],
      "metadata": {
        "id": "dfGkKsFzqh5P"
      },
      "id": "dfGkKsFzqh5P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        ")\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.llms.ollama import Ollama\n",
        "from llama_index.core.agent import ReActAgent\n",
        "\n",
        "# --- 1. تهيئة نموذج اللغة من Ollama (الذي يعمل الآن في Colab) ---\n",
        "# تأكد من أن اسم النموذج يطابق النموذج الذي قمت بسحبه في الخطوة 2\n",
        "llm = Ollama(model=\"qwen2.5:0.5b\", request_timeout=240.0) # زدنا المهلة أكثر للاحتياط\n",
        "\n",
        "# --- 2. تحميل البيانات من ملف PDF وإنشاء الفهرس ---\n",
        "# يقرأ LlamaIndex جميع الملفات الموجودة في هذا المجلد\n",
        "# في حالتنا، سيجد drake.pdf فقط\n",
        "try:\n",
        "    documents = SimpleDirectoryReader(input_dir=\"/content/data\").load_data()\n",
        "    drake_index = VectorStoreIndex.from_documents(documents)\n",
        "except ValueError as e:\n",
        "    print(f\"خطأ: {e}\")\n",
        "    print(\"هل تأكدت من رفع ملف PDF إلى مجلد /content/data؟\")\n",
        "\n",
        "\n",
        "# --- 3. تحويل الفهرس إلى أداة (Tool) ---\n",
        "# أنشأنا أداة واحدة فقط لأن لدينا مصدر بيانات واحد فقط\n",
        "drake_tool = QueryEngineTool(\n",
        "    query_engine=drake_index.as_query_engine(llm=llm),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"drake_document_search\",\n",
        "        description=\"مفيد للبحث عن معلومات موجودة في مستند PDF حول دريك (Drake).\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "# --- 4. إنشاء الوكيل (Agent) ---\n",
        "# نستخدم قائمة تحتوي على الأداة الوحيدة التي أنشأناها\n",
        "agent = ReActAgent.from_tools(\n",
        "    [drake_tool],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# --- 5. التفاعل مع الوكيل ---\n",
        "# اطرح سؤالاً تكون إجابته موجودة في ملف الـ PDF\n",
        "response = agent.chat(\"ما هي المعلومات التي يمكنك إيجادها في المستند عن Drake؟\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "5wON49MSqfOH"
      },
      "id": "5wON49MSqfOH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expand to view model thoughts\n",
        "\n",
        "chevron_right\n",
        "نعم، بالتأكيد هذا agent (وكيل). أنت نجحت في بناء وتشغيل وكيل ReAct كامل.\n",
        "الكود الذي قمت بتشغيله يتبع بالضبط نمط عمل الوكيل:\n",
        "يتلقى سؤالاً (مثل \"ما هي الجائزة التي فاز بها كيندريك لامار؟\").\n",
        "يفكر (Thought): يحاول أن يضع خطة.\n",
        "يتصرف (Action): يقرر إذا ما كان سيستخدم أداة (مثل kendrick_search) أو سيجيب مباشرة.\n",
        "يراقب (Observation): يرى نتيجة تصرفه.\n",
        "يكرر الخطوات حتى يصل إلى إجابة نهائية.\n",
        "ولكن، النتائج التي حصلت عليها هي مثال ممتاز لتوضيح التحديات التي تواجه الوكلاء عند استخدام نماذج لغوية صغيرة.\n",
        "دعنا نحلل لماذا كانت الإجابات خاطئة، على الرغم من أن بنية الكود صحيحة.\n",
        "تحليل المشكلة: لماذا كانت الإجابات خاطئة؟\n",
        "المشكلة ليست في الكود، بل في قدرة نموذج اللغة (qwen2.5:0.5b) على اتخاذ القرار الصحيح.\n",
        "1. السؤال الأول (Kendrick Lamar):\n",
        "ماذا فعل الوكيل:\n",
        "Thought: I can answer without using any more tools.\n",
        "قرر النموذج أنه يعرف الإجابة بنفسه ولم يستخدم الأداة kendrick_search التي قمت بتزويده بها.\n",
        "النتيجة:\n",
        "لأنه لم يبحث في الملف الصحيح، قام \"بالهلوسة\" (Hallucination) واخترع إجابة خاطئة تمامًا (\"جائزة فؤاد للتأليف في 2019...\"). هذه المعلومات ليست موجودة في الملف الذي قدمته.\n",
        "2. السؤال الثاني (Drake):\n",
        "ماذا فعل الوكيل:\n",
        "Thought: (Implicit) I can answer without any more tools!\n",
        "مرة أخرى، قرر النموذج أنه لا يحتاج إلى استخدام الأداة drake_search.\n",
        "النتيجة:\n",
        "بدلاً من البحث في الملف، اعتمد على معرفته المحدودة جداً وفشل في العثور على إجابة، لذلك قدم ردًا عامًا بالرفض (\"أنا آسف، لا أستطيع البحث...\").\n",
        "السبب الجذري: قدرة النموذج اللغوي\n",
        "نموذج qwen2.5:0.5b هو نموذج صغير جداً (0.5 مليار مُعامل). هذه النماذج ممتازة في مهام بسيطة مثل إكمال النصوص، ولكنها ضعيفة جدًا في مهام التفكير المعقدة مثل \"استخدام الأدوات\" (Tool Use).\n",
        "عملية اختيار الأداة المناسبة تتطلب من النموذج:\n",
        "فهم السؤال جيدًا.\n",
        "قراءة وصف كل أداة متاحة (description).\n",
        "الربط بين السؤال ووصف الأداة الأنسب.\n",
        "اتخاذ قرار \"سأستخدم هذه الأداة الآن\".\n",
        "النماذج الصغيرة غالبًا ما تفشل في هذه العملية المعقدة وتختار الطريق الأسهل: محاولة الإجابة من \"ذاكرتها\" المحدودة، مما يؤدي إلى الهلوسة أو الفشل.\n",
        "الحل: استخدم نموذجاً أكبر وأكثر قدرة\n",
        "الحل الأكثر فعالية هو استبدال النموذج الصغير بنموذج أكبر وأكثر ذكاءً معروف بقدرته على اتباع التعليمات واستخدام الأدوات.\n",
        "جرب استخدام أحد هذه النماذج:\n",
        "llama3:8b (خيار ممتاز وموصى به)\n",
        "mistral:7b\n",
        "gemma:7b\n",
        "خطوات التغيير:\n",
        "قم بتنزيل النموذج الجديد في نافذة الأوامر (Terminal):\n",
        "code\n",
        "Bash\n",
        "ollama pull llama3:8b\n",
        "عدّل سطراً واحداً فقط في كود البايثون الخاص بك:\n",
        "code\n",
        "Python\n",
        "# السطر القديم\n",
        "# llm = Ollama(model=\"qwen2.5:0.5b\", request_timeout=120.0)\n",
        "\n",
        "# السطر الجديد\n",
        "llm = Ollama(model=\"llama3:8b\", request_timeout=120.0)\n",
        "عندما تشغل الكود مع llama3:8b، ستلاحظ أن مخرجات التفكير (Thought) ستكون مختلفة تمامًا. من المرجح أن ترى شيئًا مثل:\n",
        "code\n",
        "Code\n",
        "Thought: The user is asking about an award won by Kendrick Lamar. I should use the `kendrick_search` tool to find this information.\n",
        "Action: kendrick_search\n",
        "Action Input: {'query': 'award won by Kendrick Lamar'}\n",
        "وهذا سيؤدي إلى الإجابة الصحيحة المستخرجة من ملفك.\n",
        "ملاحظة جانبية بخصوص التحذيرات (DeprecationWarning):\n",
        "التحذيرات التي ظهرت لك هي من مكتبة llama-index نفسها، وهي تخبرك بأن طريقة استدعاء ReActAgent ستتغير في الإصدارات المستقبلية. هذا التحذير لا يؤثر على عمل الكود حاليًا ولا يسبب الإجابات الخاطئة، ولكنه مجرد تنبيه للمطورين.\n",
        "خلاصة:\n",
        "أنت بنيت وكيلاً ناجحاً، ولكنك أعطيته \"دماغاً\" صغيراً جداً. قم بترقية الدماغ (النموذج اللغوي) وسترى أداءً أفضل بكثير."
      ],
      "metadata": {
        "id": "u02hsOOfqzDJ"
      },
      "id": "u02hsOOfqzDJ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nn-332ytq0VH"
      },
      "id": "nn-332ytq0VH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeWTYkSSq9yR"
      },
      "id": "BeWTYkSSq9yR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWI0KTDcq9tV"
      },
      "id": "VWI0KTDcq9tV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kU9Qjzvkq9qu"
      },
      "id": "kU9Qjzvkq9qu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SpEeT8MHq9nZ"
      },
      "id": "SpEeT8MHq9nZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/cookbooks/llama3_cookbook_ollama_replicate/#7-agents"
      ],
      "metadata": {
        "id": "apm79up6rNP5"
      },
      "id": "apm79up6rNP5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ReAct Agent With RAG QueryEngine Tools"
      ],
      "metadata": {
        "id": "Yq6QTA6erKz4"
      },
      "id": "Yq6QTA6erKz4"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
      ],
      "metadata": {
        "id": "UWsfrOVDq9kH"
      },
      "id": "UWsfrOVDq9kH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drake_tool = QueryEngineTool(\n",
        "    drake_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"drake_search\",\n",
        "        description=\"Useful for searching over Drake's life.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "kendrick_tool = QueryEngineTool(\n",
        "    kendrick_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"kendrick_search\",\n",
        "        description=\"Useful for searching over Kendrick's life.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "query_engine_tools = [drake_tool, kendrick_tool]"
      ],
      "metadata": {
        "id": "XHOqBKqbq-WG"
      },
      "id": "XHOqBKqbq-WG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent.from_tools(\n",
        "    query_engine_tools,  ## TODO: define query tools\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWGQnlhKrAGX",
        "outputId": "10757d28-2906-46c2-c7b7-11c4ffce6f13"
      },
      "id": "vWGQnlhKrAGX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
            "\n",
            "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
            "\n",
            "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n",
            "/usr/local/lib/python3.11/dist-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"Tell me about how Kendrick and Drake grew up\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdJd3tgIrCW6",
        "outputId": "5d0b146d-4339-46c1-ff13-954cfb95b40a"
      },
      "id": "BdJd3tgIrCW6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step d000565f-174e-4efb-a033-877b6490cca2. Step input: Tell me about how Kendrick and Drake grew up\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: Kendrick Lamar and DJ Kool Herc grew up in a family that consisted of two parents, a father named Roberta Johnson, who was known as \"Mister M\" for his rough mannerisms, and a mother named Patsy Young. Kendrick was born on August 21, 1989 in New York City.\n",
            "\n",
            "DJ Kool Herc grew up with his mother and older brother, Jhelil, but later left the family to pursue his own musical career. He formed the hip hop group The Furious Five when he was about 17 years old.\n",
            "Kendrick started studying at a college where he met Rappaport. They became friends in high school and continued their friendship as they moved on to different universities and careers. They eventually moved out of college together and went on to become successful musicians, including his self-titled album \"To Pimp a Butterfly\" which was released in 2014.\n",
            "In the early years after joining The Furious Five, Kendrick and Jhelil faced discrimination and prejudice from members of the musical community. They were often mocked for their music style, which they felt reflected African American culture. This led to Kendrick and Jhelil feeling isolated and disheartened by their peers' negative attitudes toward them.\n",
            "However, through their musical journey, Kendrick learned how to deal with these challenges and grew into a more confident person. He became involved in the city's arts scene as well as the world music community and eventually left his music career behind him in favor of becoming an entrepreneur.\n",
            "\u001b[0mKendrick Lamar and DJ Kool Herc grew up in a family that consisted of two parents, a father named Roberta Johnson, who was known as \"Mister M\" for his rough mannerisms, and a mother named Patsy Young. Kendrick was born on August 21, 1989 in New York City.\n",
            "\n",
            "DJ Kool Herc grew up with his mother and older brother, Jhelil, but later left the family to pursue his own musical career. He formed the hip hop group The Furious Five when he was about 17 years old.\n",
            "Kendrick started studying at a college where he met Rappaport. They became friends in high school and continued their friendship as they moved on to different universities and careers. They eventually moved out of college together and went on to become successful musicians, including his self-titled album \"To Pimp a Butterfly\" which was released in 2014.\n",
            "In the early years after joining The Furious Five, Kendrick and Jhelil faced discrimination and prejudice from members of the musical community. They were often mocked for their music style, which they felt reflected African American culture. This led to Kendrick and Jhelil feeling isolated and disheartened by their peers' negative attitudes toward them.\n",
            "However, through their musical journey, Kendrick learned how to deal with these challenges and grew into a more confident person. He became involved in the city's arts scene as well as the world music community and eventually left his music career behind him in favor of becoming an entrepreneur.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyv6lARNrG2W"
      },
      "id": "fyv6lARNrG2W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owPSmtpUrcu9"
      },
      "id": "owPSmtpUrcu9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRHyeKharcsh"
      },
      "id": "lRHyeKharcsh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iPfFVCnTrcqP"
      },
      "id": "iPfFVCnTrcqP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### شغال"
      ],
      "metadata": {
        "id": "f3XlJj8yr3dI"
      },
      "id": "f3XlJj8yr3dI"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "drake_tool = QueryEngineTool(\n",
        "    drake_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"drake_search\",\n",
        "        description=\"Useful for searching over Drake's life.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "kendrick_tool = QueryEngineTool(\n",
        "    kendrick_index.as_query_engine(),\n",
        "    metadata=ToolMetadata(\n",
        "        name=\"kendrick_search\",\n",
        "        description=\"Useful for searching over Kendrick's life.\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "query_engine_tools = [drake_tool, kendrick_tool]\n",
        "agent = ReActAgent.from_tools(\n",
        "    query_engine_tools,  ## TODO: define query tools\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        ")\n",
        "response = agent.chat(\"Tell me about how Kendrick and Drake grew up\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ues4oMldrdQO",
        "outputId": "d7b3080b-89ad-4b4b-cfb1-6b410e96a967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/llama_index/core/agent/react/base.py:154: DeprecationWarning: Call to deprecated class ReActAgent. (ReActAgent has been rewritten and replaced by llama_index.core.agent.workflow.ReActAgent.\n",
            "\n",
            "This implementation will be removed in a v0.13.0 and the new implementation will be promoted to the `from llama_index.core.agent import ReActAgent` path.\n",
            "\n",
            "See the docs for more information: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return cls(\n",
            "/usr/local/lib/python3.11/dist-packages/deprecated/classic.py:184: DeprecationWarning: Call to deprecated class AgentRunner. (AgentRunner has been deprecated and is not maintained.\n",
            "\n",
            "This implementation will be removed in a v0.13.0.\n",
            "\n",
            "See the docs for more information on updated agent usage: https://docs.llamaindex.ai/en/stable/understanding/agent/)\n",
            "  return old_new1(cls, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step 32aaf673-459f-4fbc-83b1-5a6adf42ce5b. Step input: Tell me about how Kendrick and Drake grew up\n",
            "\u001b[1;3;34mObservation: Error: Could not parse output. Please follow the thought-action-input format. Try again.\n",
            "\u001b[0m> Running step d17c54d0-5cfe-41b7-bb9c-143da8e0608d. Step input: None\n",
            "\u001b[1;3;34mObservation: Error: Could not parse output. Please follow the thought-action-input format. Try again.\n",
            "\u001b[0m> Running step a7757826-3fd8-4c9d-8e69-2774f492d6bd. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: Kendrick and Drake grew up in different parts of the world. Kendrick was born on April 24, 1985, in New York City, but he moved to Florida with his family when he was a teenager. His parents were from Detroit, Michigan and he has a younger brother named Juan Gabriel.\n",
            "Afterwards, they made their home in Miami Gardens, Florida where Drake grew up as well. He is the son of Michael and Marlonia Drake.\n",
            "\n",
            "Observation: Error: Could not parse output. Please follow the thought-action-input format. Try again.\n",
            "\u001b[0mKendrick and Drake grew up in different parts of the world. Kendrick was born on April 24, 1985, in New York City, but he moved to Florida with his family when he was a teenager. His parents were from Detroit, Michigan and he has a younger brother named Juan Gabriel.\n",
            "Afterwards, they made their home in Miami Gardens, Florida where Drake grew up as well. He is the son of Michael and Marlonia Drake.\n",
            "\n",
            "Observation: Error: Could not parse output. Please follow the thought-action-input format. Try again.\n"
          ]
        }
      ],
      "id": "Ues4oMldrdQO"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "07XUJSakt7cB"
      },
      "id": "07XUJSakt7cB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZt67X_Lt7ZT"
      },
      "id": "XZt67X_Lt7ZT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-jm8f2yt7V_"
      },
      "id": "y-jm8f2yt7V_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o74TyRZot7TB"
      },
      "id": "o74TyRZot7TB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### شغال"
      ],
      "metadata": {
        "id": "Bj-0TjDguwHZ"
      },
      "id": "Bj-0TjDguwHZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/cookbooks/ollama_gpt_oss_cookbook/"
      ],
      "metadata": {
        "id": "tnIfsujjt8DQ"
      },
      "id": "tnIfsujjt8DQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"qwen2.5:0.5b\",\n",
        "    request_timeout=360,\n",
        "    thinking=False,\n",
        "    temperature=1.0,\n",
        "    # Supports up to 130K tokens, lowering to save memory\n",
        "    context_window=8000,\n",
        ")"
      ],
      "metadata": {
        "id": "OKwj81BJt86n"
      },
      "id": "OKwj81BJt86n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp_gen = await llm.astream_complete(\"What is 1234 * 5678?\")\n",
        "\n",
        "still_thinking = True\n",
        "print(\"====== THINKING ======\")\n",
        "async for chunk in resp_gen:\n",
        "    if still_thinking and chunk.additional_kwargs.get(\"thinking_delta\"):\n",
        "        print(chunk.additional_kwargs[\"thinking_delta\"], end=\"\", flush=True)\n",
        "    elif still_thinking:\n",
        "        still_thinking = False\n",
        "        print(\"\\n====== ANSWER ======\")\n",
        "\n",
        "    if not still_thinking:\n",
        "        print(chunk.delta, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtnem-lat-nv",
        "outputId": "ac2e4941-378a-4c6c-d452-57fc1911389e"
      },
      "id": "Vtnem-lat-nv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== THINKING ======\n",
            "\n",
            "====== ANSWER ======\n",
            "The product of \\( 1234 \\times 5678 \\) is \\( 7098712 \\)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Creating agents with gpt-oss"
      ],
      "metadata": {
        "id": "7znnn7GyuQon"
      },
      "id": "7znnn7GyuQon"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent.workflow import FunctionAgent\n",
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"qwen2.5:0.5b\",\n",
        "    request_timeout=360,\n",
        "    thinking=False,\n",
        "    temperature=1.0,\n",
        "    # Supports up to 130K tokens, lowering to save memory\n",
        "    context_window=8000,\n",
        ")\n",
        "\n",
        "agent = FunctionAgent(\n",
        "    tools=[multiply],\n",
        "    llm=llm,\n",
        "    system_prompt=\"You are a helpful assistant that can multiply and add numbers. Always rely on tools for math operations.\",\n",
        ")"
      ],
      "metadata": {
        "id": "jqG9WZVHuRJ3"
      },
      "id": "jqG9WZVHuRJ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent.workflow import (\n",
        "    ToolCall,\n",
        "    ToolCallResult,\n",
        "    AgentStream,\n",
        ")\n",
        "\n",
        "handler = agent.run(\"What is 1234 * 5678?\")\n",
        "async for ev in handler.stream_events():\n",
        "    if isinstance(ev, ToolCall):\n",
        "        print(f\"\\nTool call: {ev.tool_name}({ev.tool_kwargs}\")\n",
        "    elif isinstance(ev, ToolCallResult):\n",
        "        print(\n",
        "            f\"\\nTool call: {ev.tool_name}({ev.tool_kwargs}) -> {ev.tool_output}\"\n",
        "        )\n",
        "    elif isinstance(ev, AgentStream):\n",
        "        print(ev.delta, end=\"\", flush=True)\n",
        "\n",
        "resp = await handler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuq7-Txouaiq",
        "outputId": "9e9ba562-da65-4e58-b7de-18249386e54c"
      },
      "id": "wuq7-Txouaiq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tool call: multiply({'a': 1234, 'b': 5678}\n",
            "\n",
            "Tool call: multiply({'a': 1234, 'b': 5678}) -> 7006652\n",
            "The result of 1234 * 5678 is 7,006,652."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.workflow import Context\n",
        "\n",
        "ctx = Context(agent)\n",
        "\n",
        "resp = await agent.run(\"What is 1234 * 5678?\", ctx=ctx)\n",
        "resp = await agent.run(\"What was the last question/answer pair?\", ctx=ctx)"
      ],
      "metadata": {
        "id": "ItJEYIYduftn"
      },
      "id": "ItJEYIYduftn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp.response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAr70KXYuiCn",
        "outputId": "63067e77-aaa9-4788-8a95-e507a3b082fe"
      },
      "id": "PAr70KXYuiCn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None of the functions provided directly answer questions or provide answers. They only calculate numerical values based on input parameters. For the current task, I can't produce numerical outputs. However, if you have a specific number in mind for multiplication, I can return its result.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2HhhD0dpu0dF"
      },
      "id": "2HhhD0dpu0dF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4KZWNfz7u0aQ"
      },
      "id": "4KZWNfz7u0aQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qwmov7o1u0Xs"
      },
      "id": "Qwmov7o1u0Xs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D6xrQ6_ru0Ur"
      },
      "id": "D6xrQ6_ru0Ur",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kDHxjq-Ju0Rh"
      },
      "id": "kDHxjq-Ju0Rh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/api_reference/llms/ollama/"
      ],
      "metadata": {
        "id": "0gGP_FjUwX0Q"
      },
      "id": "0gGP_FjUwX0Q"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "llm = Ollama(model=\"qwen2.5:0.5b\", request_timeout=60.0)\n",
        "\n",
        "response = llm.complete(\"What is the capital of France?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhDOlQJfu0N7",
        "outputId": "049ec949-ad68-4367-c81f-740dddfdeb96"
      },
      "id": "NhDOlQJfu0N7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hSRup8j90ioN"
      },
      "id": "hSRup8j90ioN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.llamaindex.ai/en/stable/examples/llm/ollama/"
      ],
      "metadata": {
        "id": "8z9Y0Y-F1wyK"
      },
      "id": "8z9Y0Y-F1wyK"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6rx_q08J1xhC"
      },
      "id": "6rx_q08J1xhC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/datawhalechina/handy-ollama/blob/main/README_en.md"
      ],
      "metadata": {
        "id": "YQnZUD-C2Gml"
      },
      "id": "YQnZUD-C2Gml"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6s_9fVg2bvs"
      },
      "id": "U6s_9fVg2bvs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgRCE54o2d75"
      },
      "id": "NgRCE54o2d75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ziuE6uI2d_1"
      },
      "id": "3ziuE6uI2d_1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1xlfE4W82eEd"
      },
      "id": "1xlfE4W82eEd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNrdt-Pa2eH2"
      },
      "id": "PNrdt-Pa2eH2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT9t4m7O2eLQ",
        "outputId": "7b23777f-813f-4102-e9a7-be0d305c9f05"
      },
      "id": "HT9t4m7O2eLQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MikeyBeez/Ollama_Agents.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f_cMWWD2fri",
        "outputId": "3cef865c-ff57-4ad5-8f8b-93ba0cffbaa0"
      },
      "id": "2f_cMWWD2fri",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Ollama_Agents'...\n",
            "remote: Enumerating objects: 691, done.\u001b[K\n",
            "remote: Counting objects: 100% (384/384), done.\u001b[K\n",
            "remote: Compressing objects: 100% (269/269), done.\u001b[K\n",
            "remote: Total 691 (delta 189), reused 303 (delta 115), pack-reused 307 (from 1)\u001b[K\n",
            "Receiving objects: 100% (691/691), 479.52 KiB | 5.27 MiB/s, done.\n",
            "Resolving deltas: 100% (359/359), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Ollama_Agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an8Sv53X2jGr",
        "outputId": "d94c66d9-402d-4165-9cef-4d2e686f9d39"
      },
      "id": "an8Sv53X2jGr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Ollama_Agents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjUc2Ti82kPR",
        "outputId": "31c45f46-db10-4b75-8f19-cb21ae7c8826"
      },
      "id": "rjUc2Ti82kPR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889 (from -r requirements.txt (line 28))\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohappyeyeballs==2.4.0 (from -r requirements.txt (line 1))\n",
            "  Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiohttp==3.10.5 (from -r requirements.txt (line 2))\n",
            "  Using cached aiohttp-3.10.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting aiosignal==1.3.1 (from -r requirements.txt (line 3))\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.7.0)\n",
            "Collecting anyio==4.4.0 (from -r requirements.txt (line 5))\n",
            "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting async-timeout==4.0.3 (from -r requirements.txt (line 6))\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting attrs==24.2.0 (from -r requirements.txt (line 7))\n",
            "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting bcrypt==4.2.0 (from -r requirements.txt (line 8))\n",
            "  Using cached bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting beautifulsoup4==4.12.3 (from -r requirements.txt (line 9))\n",
            "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting blis==0.7.11 (from -r requirements.txt (line 10))\n",
            "  Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: catalogue==2.0.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.0.10)\n",
            "Collecting certifi==2024.8.30 (from -r requirements.txt (line 12))\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting cffi==1.17.0 (from -r requirements.txt (line 13))\n",
            "  Using cached cffi-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting charset-normalizer==3.3.2 (from -r requirements.txt (line 14))\n",
            "  Using cached charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting click==8.1.7 (from -r requirements.txt (line 15))\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cloudpathlib==0.19.0 (from -r requirements.txt (line 16))\n",
            "  Using cached cloudpathlib-0.19.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: confection==0.1.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.1.5)\n",
            "Collecting contourpy==1.1.1 (from -r requirements.txt (line 18))\n",
            "  Using cached contourpy-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting coverage==7.6.1 (from -r requirements.txt (line 19))\n",
            "  Using cached coverage-7.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Collecting cryptography==43.0.0 (from -r requirements.txt (line 20))\n",
            "  Using cached cryptography-43.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.12.1)\n",
            "Collecting cymem==2.0.8 (from -r requirements.txt (line 22))\n",
            "  Using cached cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: dataclasses-json==0.6.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (0.6.7)\n",
            "Collecting decorator==5.1.1 (from -r requirements.txt (line 24))\n",
            "  Using cached decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting Deprecated==1.2.14 (from -r requirements.txt (line 25))\n",
            "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (1.9.0)\n",
            "Collecting duckduckgo_search (from -r requirements.txt (line 27))\n",
            "  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting exceptiongroup==1.2.2 (from -r requirements.txt (line 29))\n",
            "  Using cached exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fabric==3.2.2 (from -r requirements.txt (line 30))\n",
            "  Using cached fabric-3.2.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting filelock==3.15.4 (from -r requirements.txt (line 31))\n",
            "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fonttools==4.53.1 (from -r requirements.txt (line 32))\n",
            "  Using cached fonttools-4.53.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
            "Collecting frozenlist==1.4.1 (from -r requirements.txt (line 33))\n",
            "  Using cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting fsspec==2024.6.1 (from -r requirements.txt (line 34))\n",
            "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting fuzzywuzzy==0.18.0 (from -r requirements.txt (line 35))\n",
            "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting h11==0.14.0 (from -r requirements.txt (line 36))\n",
            "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting httpcore==1.0.5 (from -r requirements.txt (line 37))\n",
            "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting httpx==0.27.2 (from -r requirements.txt (line 38))\n",
            "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting idna==3.8 (from -r requirements.txt (line 39))\n",
            "  Using cached idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting importlib_metadata==8.4.0 (from -r requirements.txt (line 40))\n",
            "  Using cached importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting importlib_resources==6.4.4 (from -r requirements.txt (line 41))\n",
            "  Using cached importlib_resources-6.4.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting iniconfig==2.0.0 (from -r requirements.txt (line 42))\n",
            "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting invoke==2.2.0 (from -r requirements.txt (line 43))\n",
            "  Using cached invoke-2.2.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting Jinja2==3.1.4 (from -r requirements.txt (line 44))\n",
            "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting jiter==0.5.0 (from -r requirements.txt (line 45))\n",
            "  Using cached jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting joblib==1.4.2 (from -r requirements.txt (line 46))\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: jsonpatch==1.33 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 47)) (1.33)\n",
            "Requirement already satisfied: jsonpointer==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 48)) (3.0.0)\n",
            "Collecting kiwisolver==1.4.7 (from -r requirements.txt (line 49))\n",
            "  Using cached kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting langchain==0.2.15 (from -r requirements.txt (line 50))\n",
            "  Using cached langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community==0.2.14 (from -r requirements.txt (line 51))\n",
            "  Using cached langchain_community-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-core==0.2.36 (from -r requirements.txt (line 52))\n",
            "  Using cached langchain_core-0.2.36-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters==0.2.2 (from -r requirements.txt (line 53))\n",
            "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langcodes==3.4.0 (from -r requirements.txt (line 54))\n",
            "  Using cached langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting langsmith==0.1.107 (from -r requirements.txt (line 55))\n",
            "  Using cached langsmith-0.1.107-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting language_data==1.2.0 (from -r requirements.txt (line 56))\n",
            "  Using cached language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting Levenshtein==0.25.1 (from -r requirements.txt (line 57))\n",
            "  Using cached Levenshtein-0.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting llvmlite==0.41.1 (from -r requirements.txt (line 58))\n",
            "  Using cached llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting marisa-trie==1.2.0 (from -r requirements.txt (line 59))\n",
            "  Using cached marisa_trie-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting markdown-it-py==3.0.0 (from -r requirements.txt (line 60))\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting MarkupSafe==2.1.5 (from -r requirements.txt (line 61))\n",
            "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting marshmallow==3.22.0 (from -r requirements.txt (line 62))\n",
            "  Using cached marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting matplotlib==3.7.5 (from -r requirements.txt (line 63))\n",
            "  Using cached matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 64)) (0.1.2)\n",
            "Collecting more-itertools==10.4.0 (from -r requirements.txt (line 65))\n",
            "  Using cached more_itertools-10.4.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting MouseInfo==0.1.3 (from -r requirements.txt (line 66))\n",
            "  Using cached MouseInfo-0.1.3.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 67)) (1.3.0)\n",
            "Collecting multidict==6.0.5 (from -r requirements.txt (line 68))\n",
            "  Using cached multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting murmurhash==1.0.10 (from -r requirements.txt (line 69))\n",
            "  Using cached murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting mypy-extensions==1.0.0 (from -r requirements.txt (line 70))\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 71)) (1.6.0)\n",
            "Collecting networkx==3.1 (from -r requirements.txt (line 72))\n",
            "  Using cached networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 73)) (3.9.1)\n",
            "Collecting nodeenv==1.9.1 (from -r requirements.txt (line 74))\n",
            "  Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting numba==0.58.1 (from -r requirements.txt (line 75))\n",
            "  Using cached numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy==1.24.4 (from -r requirements.txt (line 76))\n",
            "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting ollama==0.3.2 (from -r requirements.txt (line 77))\n",
            "  Using cached ollama-0.3.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting openai==1.43.0 (from -r requirements.txt (line 78))\n",
            "  Using cached openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting openai-whisper==20231117 (from -r requirements.txt (line 79))\n",
            "  Using cached openai-whisper-20231117.tar.gz (798 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson==3.10.7 (from -r requirements.txt (line 80))\n",
            "  Using cached orjson-3.10.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "Collecting packaging==24.1 (from -r requirements.txt (line 81))\n",
            "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas==2.0.3 (from -r requirements.txt (line 82))\n",
            "  Using cached pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting paramiko==3.4.1 (from -r requirements.txt (line 83))\n",
            "  Using cached paramiko-3.4.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting patsy==0.5.6 (from -r requirements.txt (line 84))\n",
            "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pillow==10.4.0 (from -r requirements.txt (line 85))\n",
            "  Using cached pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pluggy==1.5.0 (from -r requirements.txt (line 86))\n",
            "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting preshed==3.0.9 (from -r requirements.txt (line 87))\n",
            "  Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting primp==0.6.1 (from -r requirements.txt (line 88))\n",
            "  Using cached primp-0.6.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting prompt_toolkit==3.0.47 (from -r requirements.txt (line 89))\n",
            "  Using cached prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting PyAudio==0.2.14 (from -r requirements.txt (line 90))\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyAutoGUI==0.9.54 (from -r requirements.txt (line 91))\n",
            "  Using cached PyAutoGUI-0.9.54.tar.gz (61 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycparser==2.22 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 92)) (2.22)\n",
            "Collecting pydantic==2.8.2 (from -r requirements.txt (line 93))\n",
            "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "Collecting pydantic_core==2.20.1 (from -r requirements.txt (line 94))\n",
            "  Using cached pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting PyGetWindow==0.0.9 (from -r requirements.txt (line 95))\n",
            "  Using cached PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Pygments==2.18.0 (from -r requirements.txt (line 96))\n",
            "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting PyMsgBox==1.0.9 (from -r requirements.txt (line 97))\n",
            "  Using cached PyMsgBox-1.0.9.tar.gz (18 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyNaCl==1.5.0 (from -r requirements.txt (line 98))\n",
            "  Using cached PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Collecting pyparsing==3.1.4 (from -r requirements.txt (line 99))\n",
            "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: pyperclip==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 100)) (1.9.0)\n",
            "Collecting PyRect==0.2.0 (from -r requirements.txt (line 101))\n",
            "  Using cached PyRect-0.2.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyright==1.1.378 (from -r requirements.txt (line 102))\n",
            "  Using cached pyright-1.1.378-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting PyScreeze==1.0.1 (from -r requirements.txt (line 103))\n",
            "  Using cached pyscreeze-1.0.1.tar.gz (27 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytest==8.3.2 (from -r requirements.txt (line 104))\n",
            "  Using cached pytest-8.3.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 105)) (2.9.0.post0)\n",
            "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 106))\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting python-Levenshtein==0.25.1 (from -r requirements.txt (line 107))\n",
            "  Using cached python_Levenshtein-0.25.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pytweening==1.2.0 (from -r requirements.txt (line 108))\n",
            "  Using cached pytweening-1.2.0.tar.gz (171 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz==2024.1 (from -r requirements.txt (line 109))\n",
            "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 110)) (6.0.2)\n",
            "Collecting rapidfuzz==3.9.7 (from -r requirements.txt (line 111))\n",
            "  Using cached rapidfuzz-3.9.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting regex==2024.7.24 (from -r requirements.txt (line 112))\n",
            "  Using cached regex-2024.7.24-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 113)) (2.32.3)\n",
            "Collecting rich==13.8.0 (from -r requirements.txt (line 114))\n",
            "  Using cached rich-13.8.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rubicon-objc==0.4.9 (from -r requirements.txt (line 115))\n",
            "  Using cached rubicon_objc-0.4.9-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting ruff==0.6.3 (from -r requirements.txt (line 116))\n",
            "  Using cached ruff-0.6.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting scikit-learn==1.3.2 (from -r requirements.txt (line 117))\n",
            "  Using cached scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.10.1 (from -r requirements.txt (line 118))\n",
            "  Using cached scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Requirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 119)) (1.5.4)\n",
            "Collecting six==1.16.0 (from -r requirements.txt (line 120))\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting smart-open==7.0.4 (from -r requirements.txt (line 121))\n",
            "  Using cached smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 122)) (1.3.1)\n",
            "Collecting soupsieve==2.6 (from -r requirements.txt (line 123))\n",
            "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting spacy==3.7.6 (from -r requirements.txt (line 124))\n",
            "  Using cached spacy-3.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy==3.0.12 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 125)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers==1.0.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 126)) (1.0.5)\n",
            "Collecting SpeechRecognition==3.10.4 (from -r requirements.txt (line 127))\n",
            "  Using cached SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Collecting SQLAlchemy==2.0.32 (from -r requirements.txt (line 128))\n",
            "  Using cached SQLAlchemy-2.0.32-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting srsly==2.4.8 (from -r requirements.txt (line 129))\n",
            "  Using cached srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting statsmodels==0.14.1 (from -r requirements.txt (line 130))\n",
            "  Using cached statsmodels-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting sympy==1.13.2 (from -r requirements.txt (line 131))\n",
            "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tenacity==8.5.0 (from -r requirements.txt (line 132))\n",
            "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting thinc==8.2.5 (from -r requirements.txt (line 133))\n",
            "  Using cached thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting threadpoolctl==3.5.0 (from -r requirements.txt (line 134))\n",
            "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken==0.7.0 (from -r requirements.txt (line 135))\n",
            "  Using cached tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tomli==2.0.1 (from -r requirements.txt (line 136))\n",
            "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting torch==2.4.0 (from -r requirements.txt (line 137))\n",
            "  Using cached torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting tqdm==4.66.5 (from -r requirements.txt (line 138))\n",
            "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting typer==0.12.5 (from -r requirements.txt (line 139))\n",
            "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: typing-inspect==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 140)) (0.9.0)\n",
            "Collecting typing_extensions==4.12.2 (from -r requirements.txt (line 141))\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tzdata==2024.1 (from -r requirements.txt (line 142))\n",
            "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting urllib3==2.2.2 (from -r requirements.txt (line 143))\n",
            "  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: wasabi==1.1.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 144)) (1.1.3)\n",
            "Requirement already satisfied: wcwidth==0.2.13 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 145)) (0.2.13)\n",
            "Requirement already satisfied: weasel==0.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 146)) (0.4.1)\n",
            "Collecting wikipedia==1.4.0 (from -r requirements.txt (line 147))\n",
            "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wrapt==1.16.0 (from -r requirements.txt (line 148))\n",
            "  Using cached wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting yarl==1.9.4 (from -r requirements.txt (line 149))\n",
            "  Using cached yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting zipp==3.20.1 (from -r requirements.txt (line 150))\n",
            "  Using cached zipp-3.20.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from marisa-trie==1.2.0->-r requirements.txt (line 59)) (80.9.0)\n",
            "Collecting python3-Xlib (from MouseInfo==0.1.3->-r requirements.txt (line 66))\n",
            "  Using cached python3-xlib-0.15.tar.gz (132 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton<3,>=2.0.0 (from openai-whisper==20231117->-r requirements.txt (line 79))\n",
            "  Using cached triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy==2.0.32->-r requirements.txt (line 128)) (3.2.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r requirements.txt (line 137)) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install -r requirements.txt (line 137) and -r requirements.txt (line 79) because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    openai-whisper 20231117 depends on triton<3 and >=2.0.0\n",
            "    torch 2.4.0 depends on triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\"\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfJeOzuV2yhx",
        "outputId": "58d4d61b-44ef-4e53-897c-f96d9a9e6648"
      },
      "id": "PfJeOzuV2yhx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging setup complete. Log file: /content/Ollama_Agents/logs/ollama_agents.log\n",
            "\u001b[1;32mOllama_Agents application starting\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "\u001b[1;37m╭─────────────────────────────────────────╮\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;33m ██████  ████████ ████████  ██████ \u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;31m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;32m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;34m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;35m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;36m ██████     ██       ██     ██████ \u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;37mYour Personal AI :) \u001b[0m                \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;32mWelcome, AI Agents!\u001b[0m                 \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;31mEnter /help to get help. \u001b[0m           \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m╰─────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\n",
            "\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\n",
            "\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: 1\n",
            "\u001b[1;31mConfiguration error: Agent simple_agent could not be loaded\u001b[0m\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: simple_agent\n",
            "\u001b[31mPlease select one of the available options\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: 1\n",
            "\u001b[1;31mConfiguration error: Agent simple_agent could not be loaded\u001b[0m\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: 2\n",
            "\u001b[1;31mConfiguration error: Agent one_agent could not be loaded\u001b[0m\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: 15\n",
            "\u001b[1;31mConfiguration error: Agent research_agent could not be loaded\u001b[0m\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: 10\n",
            "\u001b[1;31mConfiguration error: Agent smart_agent could not be loaded\u001b[0m\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: \u001b[1;31mGoodbye!\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 51, in main\n",
            "    choice = Prompt.ask(\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/prompt.py\", line 149, in ask\n",
            "    return _prompt(default=default, stream=stream)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/prompt.py\", line 292, in __call__\n",
            "    value = self.get_input(self.console, prompt, self.password, stream=stream)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/prompt.py\", line 211, in get_input\n",
            "    return console.input(prompt, password=password, stream=stream)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/console.py\", line 2151, in input\n",
            "    result = input()\n",
            "             ^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 102, in <module>\n",
            "    main()\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 93, in main\n",
            "    console.print(\"\\nProgram interrupted by user.\", style=\"bold yellow\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/console.py\", line 1708, in print\n",
            "    extend(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/segment.py\", line 211, in <genexpr>\n",
            "    result_segments = (\n",
            "                      ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/console.py\", line 1326, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/text.py\", line 697, in __rich_console__\n",
            "    lines = self.wrap(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/text.py\", line 1237, in wrap\n",
            "    offsets = divide_line(str(line), width, fold=wrap_overflow == \"fold\")\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/_wrap.py\", line 44, in divide_line\n",
            "    for start, _end, word in words(text):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/_wrap.py\", line 18, in words\n",
            "    word_match = re_word.match(text, position)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Ollama_Agents/run_tests.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK8QwS3024Sd",
        "outputId": "20c8e182-e2dd-4dd4-969f-514a40f938ed"
      },
      "id": "vK8QwS3024Sd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging setup complete. Log file: /content/Ollama_Agents/logs/ollama_agents.log\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Ollama_Agents/run_tests.py\", line 4, in <module>\n",
            "    from src.tests.test_memory_integration import run_all_tests\n",
            "  File \"/content/Ollama_Agents/src/tests/test_memory_integration.py\", line 15, in <module>\n",
            "    from src.agents.memory_agent import MemoryAgent\n",
            "  File \"/content/Ollama_Agents/src/agents/memory_agent.py\", line 19, in <module>\n",
            "    from langchain.llms import Ollama\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py\", line 545, in __getattr__\n",
            "    from langchain_community import llms\n",
            "ModuleNotFoundError: No module named 'langchain_community'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36oZDPjN34XJ",
        "outputId": "15c0d0e0-0780-411f-dfea-7d139f5b9df6"
      },
      "id": "36oZDPjN34XJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889 (from -r requirements.txt (line 28))\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohappyeyeballs==2.4.0 (from -r requirements.txt (line 1))\n",
            "  Using cached aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiohttp==3.10.5 (from -r requirements.txt (line 2))\n",
            "  Using cached aiohttp-3.10.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting aiosignal==1.3.1 (from -r requirements.txt (line 3))\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.7.0)\n",
            "Collecting anyio==4.4.0 (from -r requirements.txt (line 5))\n",
            "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting async-timeout==4.0.3 (from -r requirements.txt (line 6))\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting attrs==24.2.0 (from -r requirements.txt (line 7))\n",
            "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting bcrypt==4.2.0 (from -r requirements.txt (line 8))\n",
            "  Using cached bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting beautifulsoup4==4.12.3 (from -r requirements.txt (line 9))\n",
            "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting blis==0.7.11 (from -r requirements.txt (line 10))\n",
            "  Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: catalogue==2.0.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.0.10)\n",
            "Collecting certifi==2024.8.30 (from -r requirements.txt (line 12))\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting cffi==1.17.0 (from -r requirements.txt (line 13))\n",
            "  Using cached cffi-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting charset-normalizer==3.3.2 (from -r requirements.txt (line 14))\n",
            "  Using cached charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting click==8.1.7 (from -r requirements.txt (line 15))\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cloudpathlib==0.19.0 (from -r requirements.txt (line 16))\n",
            "  Using cached cloudpathlib-0.19.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: confection==0.1.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.1.5)\n",
            "Collecting contourpy==1.1.1 (from -r requirements.txt (line 18))\n",
            "  Using cached contourpy-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting coverage==7.6.1 (from -r requirements.txt (line 19))\n",
            "  Using cached coverage-7.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Collecting cryptography==43.0.0 (from -r requirements.txt (line 20))\n",
            "  Using cached cryptography-43.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.12.1)\n",
            "Collecting cymem==2.0.8 (from -r requirements.txt (line 22))\n",
            "  Using cached cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: dataclasses-json==0.6.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (0.6.7)\n",
            "Collecting decorator==5.1.1 (from -r requirements.txt (line 24))\n",
            "  Using cached decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting Deprecated==1.2.14 (from -r requirements.txt (line 25))\n",
            "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (1.9.0)\n",
            "Collecting duckduckgo_search==6.2.11b1 (from -r requirements.txt (line 27))\n",
            "  Using cached duckduckgo_search-6.2.11b1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting exceptiongroup==1.2.2 (from -r requirements.txt (line 29))\n",
            "  Using cached exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fabric==3.2.2 (from -r requirements.txt (line 30))\n",
            "  Using cached fabric-3.2.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting filelock==3.15.4 (from -r requirements.txt (line 31))\n",
            "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fonttools==4.53.1 (from -r requirements.txt (line 32))\n",
            "  Using cached fonttools-4.53.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
            "Collecting frozenlist==1.4.1 (from -r requirements.txt (line 33))\n",
            "  Using cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting fsspec==2024.6.1 (from -r requirements.txt (line 34))\n",
            "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting fuzzywuzzy==0.18.0 (from -r requirements.txt (line 35))\n",
            "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting h11==0.14.0 (from -r requirements.txt (line 36))\n",
            "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting httpcore==1.0.5 (from -r requirements.txt (line 37))\n",
            "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting httpx==0.27.2 (from -r requirements.txt (line 38))\n",
            "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting idna==3.8 (from -r requirements.txt (line 39))\n",
            "  Using cached idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting importlib_metadata==8.4.0 (from -r requirements.txt (line 40))\n",
            "  Using cached importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting importlib_resources==6.4.4 (from -r requirements.txt (line 41))\n",
            "  Using cached importlib_resources-6.4.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting iniconfig==2.0.0 (from -r requirements.txt (line 42))\n",
            "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting invoke==2.2.0 (from -r requirements.txt (line 43))\n",
            "  Using cached invoke-2.2.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting Jinja2==3.1.4 (from -r requirements.txt (line 44))\n",
            "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting jiter==0.5.0 (from -r requirements.txt (line 45))\n",
            "  Using cached jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting joblib==1.4.2 (from -r requirements.txt (line 46))\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: jsonpatch==1.33 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 47)) (1.33)\n",
            "Requirement already satisfied: jsonpointer==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 48)) (3.0.0)\n",
            "Collecting kiwisolver==1.4.7 (from -r requirements.txt (line 49))\n",
            "  Using cached kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting langchain==0.2.15 (from -r requirements.txt (line 50))\n",
            "  Using cached langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community==0.2.14 (from -r requirements.txt (line 51))\n",
            "  Using cached langchain_community-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-core==0.2.36 (from -r requirements.txt (line 52))\n",
            "  Using cached langchain_core-0.2.36-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters==0.2.2 (from -r requirements.txt (line 53))\n",
            "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langcodes==3.4.0 (from -r requirements.txt (line 54))\n",
            "  Using cached langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting langsmith==0.1.107 (from -r requirements.txt (line 55))\n",
            "  Using cached langsmith-0.1.107-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting language_data==1.2.0 (from -r requirements.txt (line 56))\n",
            "  Using cached language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting Levenshtein==0.25.1 (from -r requirements.txt (line 57))\n",
            "  Using cached Levenshtein-0.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting llvmlite==0.41.1 (from -r requirements.txt (line 58))\n",
            "  Using cached llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting marisa-trie==1.2.0 (from -r requirements.txt (line 59))\n",
            "  Using cached marisa_trie-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting markdown-it-py==3.0.0 (from -r requirements.txt (line 60))\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting MarkupSafe==2.1.5 (from -r requirements.txt (line 61))\n",
            "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting marshmallow==3.22.0 (from -r requirements.txt (line 62))\n",
            "  Using cached marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting matplotlib==3.7.5 (from -r requirements.txt (line 63))\n",
            "  Using cached matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 64)) (0.1.2)\n",
            "Collecting more-itertools==10.4.0 (from -r requirements.txt (line 65))\n",
            "  Using cached more_itertools-10.4.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting MouseInfo==0.1.3 (from -r requirements.txt (line 66))\n",
            "  Using cached MouseInfo-0.1.3.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 67)) (1.3.0)\n",
            "Collecting multidict==6.0.5 (from -r requirements.txt (line 68))\n",
            "  Using cached multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting murmurhash==1.0.10 (from -r requirements.txt (line 69))\n",
            "  Using cached murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting mypy-extensions==1.0.0 (from -r requirements.txt (line 70))\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 71)) (1.6.0)\n",
            "Collecting networkx==3.1 (from -r requirements.txt (line 72))\n",
            "  Using cached networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 73)) (3.9.1)\n",
            "Collecting nodeenv==1.9.1 (from -r requirements.txt (line 74))\n",
            "  Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting numba==0.58.1 (from -r requirements.txt (line 75))\n",
            "  Using cached numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy==1.24.4 (from -r requirements.txt (line 76))\n",
            "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting ollama==0.3.2 (from -r requirements.txt (line 77))\n",
            "  Using cached ollama-0.3.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting openai==1.43.0 (from -r requirements.txt (line 78))\n",
            "  Using cached openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting openai-whisper==20231117 (from -r requirements.txt (line 79))\n",
            "  Using cached openai-whisper-20231117.tar.gz (798 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson==3.10.7 (from -r requirements.txt (line 80))\n",
            "  Using cached orjson-3.10.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "Collecting packaging==24.1 (from -r requirements.txt (line 81))\n",
            "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas==2.0.3 (from -r requirements.txt (line 82))\n",
            "  Using cached pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting paramiko==3.4.1 (from -r requirements.txt (line 83))\n",
            "  Using cached paramiko-3.4.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting patsy==0.5.6 (from -r requirements.txt (line 84))\n",
            "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pillow==10.4.0 (from -r requirements.txt (line 85))\n",
            "  Using cached pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pluggy==1.5.0 (from -r requirements.txt (line 86))\n",
            "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting preshed==3.0.9 (from -r requirements.txt (line 87))\n",
            "  Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting primp==0.6.1 (from -r requirements.txt (line 88))\n",
            "  Using cached primp-0.6.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting prompt_toolkit==3.0.47 (from -r requirements.txt (line 89))\n",
            "  Using cached prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting PyAudio==0.2.14 (from -r requirements.txt (line 90))\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyAutoGUI==0.9.54 (from -r requirements.txt (line 91))\n",
            "  Using cached PyAutoGUI-0.9.54.tar.gz (61 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pycparser==2.22 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 92)) (2.22)\n",
            "Collecting pydantic==2.8.2 (from -r requirements.txt (line 93))\n",
            "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "Collecting pydantic_core==2.20.1 (from -r requirements.txt (line 94))\n",
            "  Using cached pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting PyGetWindow==0.0.9 (from -r requirements.txt (line 95))\n",
            "  Using cached PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Pygments==2.18.0 (from -r requirements.txt (line 96))\n",
            "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting PyMsgBox==1.0.9 (from -r requirements.txt (line 97))\n",
            "  Using cached PyMsgBox-1.0.9.tar.gz (18 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyNaCl==1.5.0 (from -r requirements.txt (line 98))\n",
            "  Using cached PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Collecting pyparsing==3.1.4 (from -r requirements.txt (line 99))\n",
            "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: pyperclip==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 100)) (1.9.0)\n",
            "Collecting PyRect==0.2.0 (from -r requirements.txt (line 101))\n",
            "  Downloading PyRect-0.2.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyright==1.1.378 (from -r requirements.txt (line 102))\n",
            "  Downloading pyright-1.1.378-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting PyScreeze==1.0.1 (from -r requirements.txt (line 103))\n",
            "  Downloading pyscreeze-1.0.1.tar.gz (27 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytest==8.3.2 (from -r requirements.txt (line 104))\n",
            "  Downloading pytest-8.3.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 105)) (2.9.0.post0)\n",
            "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 106))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting python-Levenshtein==0.25.1 (from -r requirements.txt (line 107))\n",
            "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pytweening==1.2.0 (from -r requirements.txt (line 108))\n",
            "  Downloading pytweening-1.2.0.tar.gz (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.2/171.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz==2024.1 (from -r requirements.txt (line 109))\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 110)) (6.0.2)\n",
            "Collecting rapidfuzz==3.9.7 (from -r requirements.txt (line 111))\n",
            "  Downloading rapidfuzz-3.9.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting regex==2024.7.24 (from -r requirements.txt (line 112))\n",
            "  Downloading regex-2024.7.24-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 113)) (2.32.3)\n",
            "Collecting rich==13.8.0 (from -r requirements.txt (line 114))\n",
            "  Downloading rich-13.8.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rubicon-objc==0.4.9 (from -r requirements.txt (line 115))\n",
            "  Downloading rubicon_objc-0.4.9-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting ruff==0.6.3 (from -r requirements.txt (line 116))\n",
            "  Downloading ruff-0.6.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting scikit-learn==1.3.2 (from -r requirements.txt (line 117))\n",
            "  Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.10.1 (from -r requirements.txt (line 118))\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 119)) (1.5.4)\n",
            "Collecting six==1.16.0 (from -r requirements.txt (line 120))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting smart-open==7.0.4 (from -r requirements.txt (line 121))\n",
            "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 122)) (1.3.1)\n",
            "Collecting soupsieve==2.6 (from -r requirements.txt (line 123))\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting spacy==3.7.6 (from -r requirements.txt (line 124))\n",
            "  Downloading spacy-3.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy==3.0.12 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 125)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers==1.0.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 126)) (1.0.5)\n",
            "Collecting SpeechRecognition==3.10.4 (from -r requirements.txt (line 127))\n",
            "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Collecting SQLAlchemy==2.0.32 (from -r requirements.txt (line 128))\n",
            "  Downloading SQLAlchemy-2.0.32-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting srsly==2.4.8 (from -r requirements.txt (line 129))\n",
            "  Downloading srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting statsmodels==0.14.1 (from -r requirements.txt (line 130))\n",
            "  Downloading statsmodels-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting sympy==1.13.2 (from -r requirements.txt (line 131))\n",
            "  Downloading sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tenacity==8.5.0 (from -r requirements.txt (line 132))\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting thinc==8.2.5 (from -r requirements.txt (line 133))\n",
            "  Downloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting threadpoolctl==3.5.0 (from -r requirements.txt (line 134))\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken==0.7.0 (from -r requirements.txt (line 135))\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tomli==2.0.1 (from -r requirements.txt (line 136))\n",
            "  Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting torch==2.4.0 (from -r requirements.txt (line 137))\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting tqdm==4.66.5 (from -r requirements.txt (line 138))\n",
            "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typer==0.12.5 (from -r requirements.txt (line 139))\n",
            "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: typing-inspect==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 140)) (0.9.0)\n",
            "Collecting typing_extensions==4.12.2 (from -r requirements.txt (line 141))\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tzdata==2024.1 (from -r requirements.txt (line 142))\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting urllib3==2.2.2 (from -r requirements.txt (line 143))\n",
            "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: wasabi==1.1.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 144)) (1.1.3)\n",
            "Requirement already satisfied: wcwidth==0.2.13 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 145)) (0.2.13)\n",
            "Requirement already satisfied: weasel==0.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 146)) (0.4.1)\n",
            "Collecting wikipedia==1.4.0 (from -r requirements.txt (line 147))\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wrapt==1.16.0 (from -r requirements.txt (line 148))\n",
            "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting yarl==1.9.4 (from -r requirements.txt (line 149))\n",
            "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting zipp==3.20.1 (from -r requirements.txt (line 150))\n",
            "  Downloading zipp-3.20.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from marisa-trie==1.2.0->-r requirements.txt (line 59)) (80.9.0)\n",
            "Collecting python3-Xlib (from MouseInfo==0.1.3->-r requirements.txt (line 66))\n",
            "  Downloading python3-xlib-0.15.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton<3,>=2.0.0 (from openai-whisper==20231117->-r requirements.txt (line 79))\n",
            "  Downloading triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy==2.0.32->-r requirements.txt (line 128)) (3.2.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r requirements.txt (line 137)) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->-r requirements.txt (line 137))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install -r requirements.txt (line 137) and -r requirements.txt (line 79) because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    openai-whisper 20231117 depends on triton<3 and >=2.0.0\n",
            "    torch 2.4.0 depends on triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\"\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7ZlCDxh4Cqp",
        "outputId": "53443b96-7c53-466f-d6cd-e2d497e975eb"
      },
      "id": "U7ZlCDxh4Cqp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging setup complete. Log file: /content/Ollama_Agents/logs/ollama_agents.log\n",
            "\u001b[1;32mOllama_Agents application starting\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "\u001b[1;37m╭─────────────────────────────────────────╮\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;33m ██████  ████████ ████████  ██████ \u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;31m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;32m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;34m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;35m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;36m ██████     ██       ██     ██████ \u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;37mYour Personal AI :) \u001b[0m                \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;32mWelcome, AI Agents!\u001b[0m                 \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;31mEnter /help to get help. \u001b[0m           \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m╰─────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\n",
            "\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\n",
            "\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: 1\n",
            "\u001b[1;31mConfiguration error: Agent simple_agent could not be loaded\u001b[0m\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: \n",
            "\u001b[1;33mProgram interrupted by user.\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 102, in <module>\n",
            "    main()\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 98, in main\n",
            "    console.print(\"[bold red]Goodbye![/bold red]\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/console.py\", line 1705, in print\n",
            "    extend(render(renderable, render_options))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/console.py\", line 1326, in render\n",
            "    for render_output in iter_render:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/text.py\", line 697, in __rich_console__\n",
            "    lines = self.wrap(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/text.py\", line 1231, in wrap\n",
            "    for line in self.split(allow_blank=True):\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/text.py\", line 1084, in split\n",
            "    return Lines([self.copy()])\n",
            "                  ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/text.py\", line 443, in copy\n",
            "    def copy(self) -> \"Text\":\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.main -help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c_jfplM5gki",
        "outputId": "7b773843-c1ca-4362-a765-ecbe550e816e"
      },
      "id": "7c_jfplM5gki",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging setup complete. Log file: /content/Ollama_Agents/logs/ollama_agents.log\n",
            "\u001b[1;32mOllama_Agents application starting\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "\u001b[1;37m╭─────────────────────────────────────────╮\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;33m ██████  ████████ ████████  ██████ \u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;31m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;32m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;34m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;35m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;36m ██████     ██       ██     ██████ \u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;37mYour Personal AI :) \u001b[0m                \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;32mWelcome, AI Agents!\u001b[0m                 \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;31mEnter /help to get help. \u001b[0m           \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m╰─────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\n",
            "\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\n",
            "\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: /help\n",
            "\u001b[31mPlease select one of the available options\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: help\n",
            "\u001b[31mPlease select one of the available options\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: \u001b[1;31mGoodbye!\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 51, in main\n",
            "    choice = Prompt.ask(\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/prompt.py\", line 149, in ask\n",
            "    return _prompt(default=default, stream=stream)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/prompt.py\", line 292, in __call__\n",
            "    value = self.get_input(self.console, prompt, self.password, stream=stream)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/prompt.py\", line 211, in get_input\n",
            "    return console.input(prompt, password=password, stream=stream)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/console.py\", line 2151, in input\n",
            "    result = input()\n",
            "             ^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 102, in <module>\n",
            "    main()\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 92, in main\n",
            "    logger.info(\"Program interrupted by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1479, in info\n",
            "    def info(self, msg, *args, **kwargs):\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Ollama_Agents/test_agent.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3aMnReN52_a",
        "outputId": "ac2f9b14-f3b7-43c3-ead9-a011ddad1794"
      },
      "id": "n3aMnReN52_a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python path:\n",
            "/content\n",
            "/content/Ollama_Agents\n",
            "/env/python\n",
            "/usr/lib/python311.zip\n",
            "/usr/lib/python3.11\n",
            "/usr/lib/python3.11/lib-dynload\n",
            "/usr/local/lib/python3.11/dist-packages\n",
            "/usr/lib/python3/dist-packages\n",
            "Error importing from ollama_agents_knowledge: No module named 'ollama_agents_knowledge'\n",
            "Falling back to local modules\n",
            "Logging setup complete. Log file: /content/Ollama_Agents/logs/ollama_agents.log\n",
            "Simple Chat Agent initialized. Type 'exit' to quit.\n",
            "You: what is 1 + 1 = ?\n",
            "\u001b[2K\u001b[1;33mProcessing...\u001b[0m\n",
            "\u001b[?25h\u001b[1;31mError connecting to Ollama: \u001b[0m\u001b[1;35mHTTPConnectionPool\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;33mhost\u001b[0m\u001b[1;31m=\u001b[0m\u001b[32m'localhost'\u001b[0m\u001b[1;31m, \u001b[0m\u001b[1;33mport\u001b[0m\u001b[1;31m=\u001b[0m\u001b[1;36m11434\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m: \u001b[0m\n",
            "\u001b[1;31mMax retries exceeded with url: \u001b[0m\u001b[1;35m/api/\u001b[0m\u001b[1;95mgenerate\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mCaused by \u001b[0m\n",
            "\u001b[1;35mNewConnectionError\u001b[0m\u001b[1;31m(\u001b[0m\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32murllib3.connection.HTTPConnection\u001b[0m\u001b[32m object at \u001b[0m\n",
            "\u001b[32m0x1029e3d9ced0\u001b[0m\u001b[32m>\u001b[0m\u001b[32m: Failed to establish a new connection: \u001b[0m\u001b[32m[\u001b[0m\u001b[32mErrno 111\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Connection \u001b[0m\n",
            "\u001b[32mrefused'\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m)\u001b[0m\n",
            "\u001b[2K\u001b[1;33mProcessing...\u001b[0m\n",
            "\u001b[?25h\u001b[1;31mError connecting to Ollama: \u001b[0m\u001b[1;35mHTTPConnectionPool\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;33mhost\u001b[0m\u001b[1;31m=\u001b[0m\u001b[32m'localhost'\u001b[0m\u001b[1;31m, \u001b[0m\u001b[1;33mport\u001b[0m\u001b[1;31m=\u001b[0m\u001b[1;36m11434\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m: \u001b[0m\n",
            "\u001b[1;31mMax retries exceeded with url: \u001b[0m\u001b[1;35m/api/\u001b[0m\u001b[1;95mgenerate\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mCaused by \u001b[0m\n",
            "\u001b[1;35mNewConnectionError\u001b[0m\u001b[1;31m(\u001b[0m\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32murllib3.connection.HTTPConnection\u001b[0m\u001b[32m object at \u001b[0m\n",
            "\u001b[32m0x1029e3dae0d0\u001b[0m\u001b[32m>\u001b[0m\u001b[32m: Failed to establish a new connection: \u001b[0m\u001b[32m[\u001b[0m\u001b[32mErrno 111\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Connection \u001b[0m\n",
            "\u001b[32mrefused'\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m)\u001b[0m\n",
            "\u001b[2K\u001b[1;33mProcessing...\u001b[0m\n",
            "\u001b[?25h\u001b[1;31mError connecting to Ollama: \u001b[0m\u001b[1;35mHTTPConnectionPool\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;33mhost\u001b[0m\u001b[1;31m=\u001b[0m\u001b[32m'localhost'\u001b[0m\u001b[1;31m, \u001b[0m\u001b[1;33mport\u001b[0m\u001b[1;31m=\u001b[0m\u001b[1;36m11434\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m: \u001b[0m\n",
            "\u001b[1;31mMax retries exceeded with url: \u001b[0m\u001b[1;35m/api/\u001b[0m\u001b[1;95mgenerate\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mCaused by \u001b[0m\n",
            "\u001b[1;35mNewConnectionError\u001b[0m\u001b[1;31m(\u001b[0m\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32murllib3.connection.HTTPConnection\u001b[0m\u001b[32m object at \u001b[0m\n",
            "\u001b[32m0x1029e3db8790\u001b[0m\u001b[32m>\u001b[0m\u001b[32m: Failed to establish a new connection: \u001b[0m\u001b[32m[\u001b[0m\u001b[32mErrno 111\u001b[0m\u001b[32m]\u001b[0m\u001b[32m Connection \u001b[0m\n",
            "\u001b[32mrefused'\u001b[0m\u001b[1;31m)\u001b[0m\u001b[1;31m)\u001b[0m\n",
            "Extracted knowledge: {'error': \"Failed to extract knowledge: analyze_query_topic() missing 1 required positional argument: 'model_name'\", 'key_concepts': [], 'named_entities': [], 'entities_and_relationships': {'entities': [], 'relationships': []}, 'query_topic': {}, 'sentiment': {}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Ollama_Agents/test_agent.py\", line 69, in <module>\n",
            "    main()\n",
            "  File \"/content/Ollama_Agents/test_agent.py\", line 66, in main\n",
            "    agent.run()\n",
            "  File \"/content/Ollama_Agents/test_agent.py\", line 41, in run\n",
            "    response = self.process_input(user_input)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Ollama_Agents/test_agent.py\", line 50, in process_input\n",
            "    memories = search_memories(user_input, top_k=2)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Ollama_Agents/src/modules/memory_search.py\", line 112, in search_memories\n",
            "    edge_results = get_related_nodes(str(query_id))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Ollama_Agents/src/modules/kb_graph.py\", line 59, in get_related_nodes\n",
            "    cursor.execute('''\n",
            "sqlite3.OperationalError: no such table: edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzMlN7U36EQS",
        "outputId": "d8d722cd-1210-4259-b70e-ac46f5262a16"
      },
      "id": "RzMlN7U36EQS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: ollama server not responding - could not connect to ollama server, run 'ollama serve' to start it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYpdTo-f6Toq",
        "outputId": "38c60a5a-07a9-41c7-ee2b-c7a2cb350d59"
      },
      "id": "oYpdTo-f6Toq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Ollama_Agents/test_agent.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijLuejym6W_S",
        "outputId": "97937933-07b4-45c9-df05-0925d06386b9"
      },
      "id": "ijLuejym6W_S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python path:\n",
            "/content\n",
            "/content/Ollama_Agents\n",
            "/env/python\n",
            "/usr/lib/python311.zip\n",
            "/usr/lib/python3.11\n",
            "/usr/lib/python3.11/lib-dynload\n",
            "/usr/local/lib/python3.11/dist-packages\n",
            "/usr/lib/python3/dist-packages\n",
            "Error importing from ollama_agents_knowledge: No module named 'ollama_agents_knowledge'\n",
            "Falling back to local modules\n",
            "Logging setup complete. Log file: /content/Ollama_Agents/logs/ollama_agents.log\n",
            "Simple Chat Agent initialized. Type 'exit' to quit.\n",
            "You: who is ai?\n",
            "\u001b[2K\u001b[1;33mProcessing...\u001b[0m\n",
            "\u001b[?25h\u001b[1;31mError connecting to Ollama: \u001b[0m\u001b[1;36m404\u001b[0m\u001b[1;31m Client Error: Not Found for url: \u001b[0m\n",
            "\u001b[4;94mhttp://localhost:11434/api/generate\u001b[0m\n",
            "\u001b[2K\u001b[1;33mProcessing...\u001b[0m\n",
            "\u001b[?25h\u001b[1;31mError connecting to Ollama: \u001b[0m\u001b[1;36m404\u001b[0m\u001b[1;31m Client Error: Not Found for url: \u001b[0m\n",
            "\u001b[4;94mhttp://localhost:11434/api/generate\u001b[0m\n",
            "\u001b[2K\u001b[1;33mProcessing...\u001b[0m\n",
            "\u001b[?25h\u001b[1;31mError connecting to Ollama: \u001b[0m\u001b[1;36m404\u001b[0m\u001b[1;31m Client Error: Not Found for url: \u001b[0m\n",
            "\u001b[4;94mhttp://localhost:11434/api/generate\u001b[0m\n",
            "Extracted knowledge: {'error': \"Failed to extract knowledge: analyze_query_topic() missing 1 required positional argument: 'model_name'\", 'key_concepts': [], 'named_entities': [], 'entities_and_relationships': {'entities': [], 'relationships': []}, 'query_topic': {}, 'sentiment': {}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Ollama_Agents/test_agent.py\", line 69, in <module>\n",
            "    main()\n",
            "  File \"/content/Ollama_Agents/test_agent.py\", line 66, in main\n",
            "    agent.run()\n",
            "  File \"/content/Ollama_Agents/test_agent.py\", line 41, in run\n",
            "    response = self.process_input(user_input)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Ollama_Agents/test_agent.py\", line 50, in process_input\n",
            "    memories = search_memories(user_input, top_k=2)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Ollama_Agents/src/modules/memory_search.py\", line 112, in search_memories\n",
            "    edge_results = get_related_nodes(str(query_id))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Ollama_Agents/src/modules/kb_graph.py\", line 59, in get_related_nodes\n",
            "    cursor.execute('''\n",
            "sqlite3.OperationalError: no such table: edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG-TB8D46ZCc",
        "outputId": "1357fc55-7eca-4d3b-aeba-2fd0e12b0dbe"
      },
      "id": "kG-TB8D46ZCc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging setup complete. Log file: /content/Ollama_Agents/logs/ollama_agents.log\n",
            "\u001b[1;32mOllama_Agents application starting\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "                      ***\n",
            "\u001b[1;37m╭─────────────────────────────────────────╮\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;33m ██████  ████████ ████████  ██████ \u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;31m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;32m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;34m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;35m██    ██    ██       ██    ██    ██\u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;36m ██████     ██       ██     ██████ \u001b[0m \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;37mYour Personal AI :) \u001b[0m                \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;32mWelcome, AI Agents!\u001b[0m                 \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m     \u001b[1;31mEnter /help to get help. \u001b[0m           \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m│\u001b[0m                                         \u001b[1;37m│\u001b[0m\n",
            "\u001b[1;37m╰─────────────────────────────────────────╯\u001b[0m\n",
            "\n",
            "\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\n",
            "\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;34m~\u001b[0m\u001b[1;33m*\u001b[0m\n",
            "\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: 1\n",
            "\u001b[1;31mConfiguration error: Agent simple_agent could not be loaded\u001b[0m\n",
            "\u001b[1;36mAvailable agents:\u001b[0m\n",
            "\u001b[1;36m1\u001b[0m\u001b[33m. simple_agent\u001b[0m\n",
            "\u001b[1;36m2\u001b[0m\u001b[33m. one_agent\u001b[0m\n",
            "\u001b[1;36m3\u001b[0m\u001b[33m. multi_agent\u001b[0m\n",
            "\u001b[1;36m4\u001b[0m\u001b[33m. debug_agent\u001b[0m\n",
            "\u001b[1;36m5\u001b[0m\u001b[33m. advanced_research_agent copy\u001b[0m\n",
            "\u001b[1;36m6\u001b[0m\u001b[33m. memory_agent\u001b[0m\n",
            "\u001b[1;36m7\u001b[0m\u001b[33m. debug_agent_v2\u001b[0m\n",
            "\u001b[1;36m8\u001b[0m\u001b[33m. advanced_research_agent\u001b[0m\n",
            "\u001b[1;36m9\u001b[0m\u001b[33m. voice_agent\u001b[0m\n",
            "\u001b[1;36m10\u001b[0m\u001b[33m. smart_agent\u001b[0m\n",
            "\u001b[1;36m11\u001b[0m\u001b[33m. arc_agent\u001b[0m\n",
            "\u001b[1;36m12\u001b[0m\u001b[33m. debug_agent copy\u001b[0m\n",
            "\u001b[1;36m13\u001b[0m\u001b[33m. v_agent2\u001b[0m\n",
            "\u001b[1;36m14\u001b[0m\u001b[33m. debate_agent\u001b[0m\n",
            "\u001b[1;36m15\u001b[0m\u001b[33m. research_agent\u001b[0m\n",
            "\u001b[33mq. Quit\u001b[0m\n",
            "Select an agent or 'q' to quit \u001b[1;35m[1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/q]\u001b[0m \u001b[1;36m(q)\u001b[0m: \u001b[1;31mGoodbye!\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 51, in main\n",
            "    choice = Prompt.ask(\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/prompt.py\", line 149, in ask\n",
            "    return _prompt(default=default, stream=stream)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/prompt.py\", line 292, in __call__\n",
            "    value = self.get_input(self.console, prompt, self.password, stream=stream)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/prompt.py\", line 211, in get_input\n",
            "    return console.input(prompt, password=password, stream=stream)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/console.py\", line 2151, in input\n",
            "    result = input()\n",
            "             ^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 102, in <module>\n",
            "    main()\n",
            "  File \"/content/Ollama_Agents/src/main.py\", line 93, in main\n",
            "    console.print(\"\\nProgram interrupted by user.\", style=\"bold yellow\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/console.py\", line 1690, in print\n",
            "    render_options = self.options.update(\n",
            "                     ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/rich/console.py\", line 981, in options\n",
            "    return ConsoleOptions(\n",
            "           ^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/MikeyBeez/Ollama_Agents"
      ],
      "metadata": {
        "id": "9G1ba7US6vpk"
      },
      "id": "9G1ba7US6vpk"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JusflV2E6wST"
      },
      "id": "JusflV2E6wST",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZChQLHM-6lu6",
        "outputId": "c7136cd7-c49f-44e3-fb59-4354c44a05bb"
      },
      "id": "ZChQLHM-6lu6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# src/agents/advanced_agent.py\n",
        "%cd /content/Ollama_Agents\n",
        "from src.modules.adv_input_processor import InputProcessor\n",
        "from src.modules.adv_context_manager import ContextManager\n",
        "from src.modules.adv_reasoning_engine import ReasoningEngine\n",
        "from src.modules.adv_planning_engine import PlanningEngine\n",
        "from src.modules.adv_knowledge_manager import KnowledgeManager\n",
        "from src.modules.adv_output_manager import OutputManager\n",
        "from config import DEFAULT_MODEL, AGENT_NAME, USER_NAME\n",
        "\n",
        "class AdvancedAgent:\n",
        "    def __init__(self, model_name=\"qwen2.5:0.5b\"):\n",
        "        self.config = {\n",
        "            'DEFAULT_MODEL': model_name,\n",
        "            'AGENT_NAME': AGENT_NAME,\n",
        "            'USER_NAME': USER_NAME\n",
        "        }\n",
        "        self.input_processor = InputProcessor(self.config)\n",
        "        self.context_manager = ContextManager(self.config)\n",
        "        self.reasoning_engine = ReasoningEngine(model_name)\n",
        "        self.planning_engine = PlanningEngine(model_name)\n",
        "        self.knowledge_manager = KnowledgeManager()\n",
        "        self.output_manager = OutputManager(self.config)\n",
        "\n",
        "    def run(self):\n",
        "        self.output_manager.print_welcome_message()\n",
        "        self.input_processor.setup_user_profile()\n",
        "\n",
        "        while True:\n",
        "            user_input = self.input_processor.get_user_input()\n",
        "            if user_input is None:\n",
        "                break\n",
        "            if user_input.startswith('/'):\n",
        "                response = self.output_manager.execute_debug_command(user_input)\n",
        "                if response is None:\n",
        "                    break\n",
        "            else:\n",
        "                response = self._process_input(user_input)\n",
        "            self.output_manager.display_response(response)\n",
        "\n",
        "        self.output_manager.print_farewell_message()\n",
        "\n",
        "    def _process_input(self, user_input: str) -> str:\n",
        "        analysis = self.input_processor.analyze_input(user_input)\n",
        "        context = self.context_manager.gather_context(user_input, analysis)\n",
        "        knowledge = self.context_manager.retrieve_knowledge(context, analysis)\n",
        "\n",
        "        causal_relationships = self.reasoning_engine.perform_causal_analysis(context)\n",
        "        hypotheses = self.reasoning_engine.generate_hypotheses(context)\n",
        "        tested_hypotheses = self.reasoning_engine.test_hypotheses(hypotheses, context)\n",
        "        analogies = self.reasoning_engine.find_analogies(user_input, context)\n",
        "        contradictions = self.reasoning_engine.detect_contradictions(knowledge)\n",
        "        resolved_contradictions = self.reasoning_engine.resolve_contradictions(contradictions)\n",
        "\n",
        "        plan = self.planning_engine.create_and_analyze_plan(\n",
        "            user_input, context, knowledge, causal_relationships,\n",
        "            tested_hypotheses, analogies, resolved_contradictions\n",
        "        )\n",
        "        response = self.planning_engine.generate_response_from_plan(\n",
        "            plan, user_input, context, knowledge, causal_relationships,\n",
        "            tested_hypotheses, analogies, resolved_contradictions\n",
        "        )\n",
        "\n",
        "        progress = self.planning_engine.assess_progress(response, plan)\n",
        "        next_step = self.planning_engine.determine_next_step(plan, progress)\n",
        "        response += f\"\\n\\nNext step: {next_step}\"\n",
        "\n",
        "        self.knowledge_manager.update_conversation_history(user_input, response)\n",
        "        self.knowledge_manager.update_knowledge_graph(analysis['topics'], response)\n",
        "        self.knowledge_manager.update_bullet_points(response)\n",
        "\n",
        "        return response\n",
        "\n",
        "def main():\n",
        "    agent = AdvancedAgent()\n",
        "    agent.run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "oUUEuDSh6se7",
        "outputId": "020aa5a5-c0c1-4cd5-f078-4782d70968cc"
      },
      "id": "oUUEuDSh6se7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Ollama_Agents\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'duckduckgo_search'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1974759419.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# src/agents/advanced_agent.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/Ollama_Agents'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_input_processor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_context_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContextManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madv_reasoning_engine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReasoningEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Ollama_Agents/src/modules/adv_input_processor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mollama_client\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_user_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrich\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Ollama_Agents/src/modules/input.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprompt_toolkit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_binding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyBindings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprompt_toolkit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyles\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslash_commands\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhandle_slash_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSLASH_COMMANDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_setup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Ollama_Agents/src/modules/slash_commands.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrich\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsole\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConsole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrich\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpanel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPanel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_commands\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mchange_model_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduck_duck_go_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_commands\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupload_document\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_chunk_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric_commands\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfabric_command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Ollama_Agents/src/modules/basic_commands.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_setup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mddg_search\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDGSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAPIConnectionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Ollama_Agents/src/modules/ddg_search.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# src/modules/ddg_search.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mduckduckgo_search\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_setup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAPIConnectionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'duckduckgo_search'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5-Epjaq7GI7"
      },
      "id": "a5-Epjaq7GI7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eYAj52HTDp0r"
      },
      "id": "eYAj52HTDp0r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qfioMQf2Dpw2"
      },
      "id": "qfioMQf2Dpw2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/premthomas/Ollama-and-Agents/blob/main/BlogWriter.ipynb"
      ],
      "metadata": {
        "id": "fHgS2x5TD1Rj"
      },
      "id": "fHgS2x5TD1Rj"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5lO4Nm-aD16t"
      },
      "id": "5lO4Nm-aD16t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain ## Sometimes, this code alone does not work.\n",
        "!pip install langchain-community langchain-core\n",
        "!pip install -U langchain-ollama\n",
        "\n",
        "\n",
        "!pip install crewai\n",
        "!pip install crewai-tools\n",
        "\n",
        "\n",
        "!pip install duckduckgo-search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Iwc5yn-GDpsX",
        "outputId": "12b093c4-26c6-48f2-a606-94d36dbe4930"
      },
      "id": "Iwc5yn-GDpsX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.13)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-community\n",
            "Successfully installed langchain-community-0.3.27\n",
            "Collecting langchain-ollama\n",
            "  Downloading langchain_ollama-0.3.6-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: ollama<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from langchain-ollama) (0.5.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /usr/local/lib/python3.11/dist-packages (from langchain-ollama) (0.3.74)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.4.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.11.7)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama<1.0.0,>=0.5.1->langchain-ollama) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.32.3)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-ollama) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain-ollama) (1.3.1)\n",
            "Downloading langchain_ollama-0.3.6-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: langchain-ollama\n",
            "Successfully installed langchain-ollama-0.3.6\n",
            "Collecting crewai\n",
            "  Downloading crewai-0.159.0-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting appdirs>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.9.0)\n",
            "Collecting chromadb>=0.5.23 (from crewai)\n",
            "  Downloading chromadb-1.0.17-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai) (8.2.1)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json-repair==0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.25.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting json5>=0.10.0 (from crewai)\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm==1.74.9 (from crewai)\n",
            "  Downloading litellm-1.74.9-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime==1.22.0 (from crewai)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.99.8)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai) (3.1.5)\n",
            "Collecting opentelemetry-api>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.30.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker==2.7.0 (from crewai)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.11.7)\n",
            "Requirement already satisfied: pyjwt>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (2.10.1)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai) (1.1.1)\n",
            "Collecting pyvis>=0.3.2 (from crewai)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from crewai) (0.21.4)\n",
            "Collecting tomli-w>=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli>=2.0.2 (from crewai)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting uv>=0.4.25 (from crewai)\n",
            "  Downloading uv-0.8.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (3.12.15)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (4.25.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai) (0.11.0)\n",
            "Collecting coloredlogs (from onnxruntime==1.22.0->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.22.0->crewai) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.22.0->crewai) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.22.0->crewai) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.22.0->crewai) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.22.0->crewai) (1.13.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.14.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.5.23->crewai)\n",
            "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (3.11.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.23->crewai) (13.9.4)\n",
            "Collecting diskcache>=5.6.3 (from instructor>=1.3.3->crewai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.17.0)\n",
            "Requirement already satisfied: jiter<0.11,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (0.10.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (2.33.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai) (2.32.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.30.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (43.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.4.2->crewai) (0.4.1)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (4.1.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai) (3.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.20.3->crewai) (0.34.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.13.3->crewai) (3.10)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.23->crewai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm==1.74.9->crewai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm==1.74.9->crewai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.74.9->crewai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai) (1.1.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.74.9->crewai) (3.23.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (80.9.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.74.9->crewai) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai) (0.27.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=0.5.23->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.23->crewai) (4.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.23->crewai) (15.0.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.22.0->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime==1.22.0->crewai) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (4.9.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.23->crewai) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai) (0.6.1)\n",
            "Downloading crewai-0.159.0-py3-none-any.whl (379 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.2/379.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.25.2-py3-none-any.whl (12 kB)\n",
            "Downloading litellm-1.74.9-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading chromadb-1.0.17-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.10.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.5/119.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading uv-0.8.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=fc9bf47310d05d3bdca61ac8d1d0fa9221b51923b3e75fbd84befeaa2a2e242e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, appdirs, uvloop, uv, tomli-w, tomli, pypdfium2, pybase64, portalocker, overrides, opentelemetry-proto, mmh3, jsonref, json5, json-repair, jedi, humanfriendly, httptools, diskcache, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pyvis, pdfminer.six, opentelemetry-semantic-conventions, onnxruntime, kubernetes, pdfplumber, opentelemetry-sdk, litellm, instructor, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, chromadb, crewai\n",
            "Successfully installed appdirs-1.4.4 backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.17 coloredlogs-15.0.1 crewai-0.159.0 diskcache-5.6.3 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 instructor-1.10.0 jedi-0.19.2 json-repair-0.25.2 json5-0.12.1 jsonref-1.1.0 kubernetes-33.1.0 litellm-1.74.9 mmh3-5.2.0 onnxruntime-1.22.0 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-exporter-otlp-proto-http-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 pdfminer.six-20250506 pdfplumber-0.11.7 portalocker-2.7.0 posthog-5.4.0 pybase64-1.4.2 pypdfium2-4.30.0 pypika-0.48.9 pyvis-0.3.2 tomli-2.2.1 tomli-w-1.2.0 uv-0.8.11 uvloop-0.21.0 watchfiles-1.1.0\n",
            "Collecting crewai-tools\n",
            "  Downloading crewai_tools-0.62.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting chromadb==0.5.23 (from crewai-tools)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (8.2.1)\n",
            "Requirement already satisfied: crewai>=0.157.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (0.159.0)\n",
            "Collecting docker>=7.1.0 (from crewai-tools)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting embedchain>=0.1.114 (from crewai-tools)\n",
            "  Downloading embedchain-0.1.128-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai-tools)\n",
            "  Downloading lancedb-0.24.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (1.99.8)\n",
            "Requirement already satisfied: portalocker==2.7.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (2.7.0)\n",
            "Requirement already satisfied: pydantic>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (2.11.7)\n",
            "Collecting pyright>=1.1.350 (from crewai-tools)\n",
            "  Downloading pyright-1.1.403-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pytube>=15.0.0 (from crewai-tools)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (2.32.3)\n",
            "Collecting stagehand>=0.4.1 (from crewai-tools)\n",
            "  Downloading stagehand-0.5.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (0.11.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (1.3.0)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (0.116.1)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (4.14.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (1.36.0)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (1.36.0)\n",
            "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (1.74.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (0.16.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (33.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (9.1.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (3.11.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.5.23->crewai-tools) (13.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (1.4.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (1.9.0)\n",
            "Requirement already satisfied: instructor>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (1.10.0)\n",
            "Requirement already satisfied: json-repair==0.25.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (0.25.2)\n",
            "Requirement already satisfied: json5>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (0.12.1)\n",
            "Requirement already satisfied: jsonref>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (1.1.0)\n",
            "Requirement already satisfied: litellm==1.74.9 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (1.74.9)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (1.36.0)\n",
            "Requirement already satisfied: pdfplumber>=0.11.4 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (0.11.7)\n",
            "Requirement already satisfied: pyjwt>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (2.10.1)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (1.1.1)\n",
            "Requirement already satisfied: pyvis>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (0.3.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (2024.11.6)\n",
            "Requirement already satisfied: tomli-w>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (1.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (2.2.1)\n",
            "Requirement already satisfied: uv>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.157.0->crewai-tools) (0.8.11)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai>=0.157.0->crewai-tools) (3.12.15)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai>=0.157.0->crewai-tools) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai>=0.157.0->crewai-tools) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.74.9->crewai>=0.157.0->crewai-tools) (4.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools) (1.13.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker>=7.1.0->crewai-tools) (2.5.0)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (4.13.4)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.3.27)\n",
            "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_cohere-0.3.5-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.3.27)\n",
            "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langsmith<0.4.0,>=0.3.18 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting mem0ai<0.2.0,>=0.1.54 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading mem0ai-0.1.116-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (5.9.0)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (2.0.43)\n",
            "Collecting deprecation (from lancedb>=0.5.4->crewai-tools)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai-tools) (18.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai-tools) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai-tools) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai-tools) (0.4.1)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai-tools)\n",
            "  Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai-tools) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai-tools) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai-tools) (2025.8.3)\n",
            "Collecting playwright>=1.42.1 (from stagehand>=0.4.1->crewai-tools)\n",
            "  Downloading playwright-1.54.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting browserbase>=1.4.0 (from stagehand>=0.4.1->crewai-tools)\n",
            "  Downloading browserbase-1.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting anthropic>=0.51.0 (from stagehand>=0.4.1->crewai-tools)\n",
            "  Downloading anthropic-0.64.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools) (1.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain>=0.1.114->crewai-tools) (2.7)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb==0.5.23->crewai-tools) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb==0.5.23->crewai-tools) (0.47.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai-tools) (5.5.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.5.23->crewai-tools) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.23->crewai-tools) (0.16.0)\n",
            "Requirement already satisfied: diskcache>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai>=0.157.0->crewai-tools) (5.6.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.3.3->crewai>=0.157.0->crewai-tools) (0.17.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (3.3.1)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (0.10)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.9)\n",
            "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading cohere-5.17.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (0.9.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.4.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai-tools) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai-tools) (0.23.0)\n",
            "Requirement already satisfied: pytz>=2024.1 in /usr/local/lib/python3.11/dist-packages (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (2025.2)\n",
            "Collecting qdrant-client>=1.9.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading qdrant_client-1.15.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai>=0.157.0->crewai-tools) (2.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23->crewai-tools) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23->crewai-tools) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23->crewai-tools) (1.36.0)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools) (0.57b0)\n",
            "Collecting opentelemetry-util-http==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading opentelemetry_util_http-0.57b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.57b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.57b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading asgiref-3.9.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools) (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools) (4.30.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools) (43.0.3)\n",
            "Collecting pyee<14,>=13 (from playwright>=1.42.1->stagehand>=0.4.1->crewai-tools)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.42.1->stagehand>=0.4.1->crewai-tools) (3.2.4)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.5.23->crewai-tools) (2.2.1)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (4.1.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (3.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.5.23->crewai-tools) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.5.23->crewai-tools) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23->crewai-tools) (0.34.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.5.23->crewai-tools) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools) (15.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (1.20.1)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading fastavro-1.12.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading types_requests-2.32.4.20250809-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.9.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23->crewai-tools) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23->crewai-tools) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23->crewai-tools) (1.1.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (3.23.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (80.9.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai>=0.157.0->crewai-tools) (0.27.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (1.33)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.5.23->crewai-tools) (0.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (2025.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools) (1.17.1)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (4.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (0.8.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (3.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (1.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools) (2.22)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (4.1.0)\n",
            "Downloading crewai_tools-0.62.0-py3-none-any.whl (677 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.0/677.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.128-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lancedb-0.24.2-cp39-abi3-manylinux_2_28_x86_64.whl (34.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.8/34.8 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.403-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stagehand-0.5.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.64.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading browserbase-1.4.0-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.3.5-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.1.116-py3-none-any.whl (190 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.57b0-py3-none-any.whl (32 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.57b0-py3-none-any.whl (7.6 kB)\n",
            "Downloading playwright-1.54.0-py3-none-manylinux1_x86_64.whl (45.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading cohere-5.17.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.3/295.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.9.1-py3-none-any.whl (23 kB)\n",
            "Downloading fastavro-1.12.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250809-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: schema, monotonic, types-requests, pytube, pysbd, pyee, opentelemetry-util-http, nodeenv, httpx-sse, fastavro, deprecation, chroma-hnswlib, asgiref, pyright, posthog, playwright, gptcache, docker, alembic, tokenizers, langsmith, lancedb, browserbase, anthropic, qdrant-client, opentelemetry-instrumentation, cohere, stagehand, opentelemetry-instrumentation-asgi, mem0ai, langchain-openai, opentelemetry-instrumentation-fastapi, chromadb, langchain-experimental, langchain-cohere, embedchain, crewai-tools\n",
            "  Attempting uninstall: httpx-sse\n",
            "    Found existing installation: httpx-sse 0.4.1\n",
            "    Uninstalling httpx-sse-0.4.1:\n",
            "      Successfully uninstalled httpx-sse-0.4.1\n",
            "  Attempting uninstall: posthog\n",
            "    Found existing installation: posthog 5.4.0\n",
            "    Uninstalling posthog-5.4.0:\n",
            "      Successfully uninstalled posthog-5.4.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.13\n",
            "    Uninstalling langsmith-0.4.13:\n",
            "      Successfully uninstalled langsmith-0.4.13\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 1.0.17\n",
            "    Uninstalling chromadb-1.0.17:\n",
            "      Successfully uninstalled chromadb-1.0.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-tools-mcp 0.4.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "transformers 4.55.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alembic-1.16.4 anthropic-0.64.0 asgiref-3.9.1 browserbase-1.4.0 chroma-hnswlib-0.7.6 chromadb-0.5.23 cohere-5.17.0 crewai-tools-0.62.0 deprecation-2.1.0 docker-7.1.0 embedchain-0.1.128 fastavro-1.12.0 gptcache-0.1.44 httpx-sse-0.4.0 lancedb-0.24.2 langchain-cohere-0.3.5 langchain-experimental-0.3.4 langchain-openai-0.2.14 langsmith-0.3.45 mem0ai-0.1.116 monotonic-1.6 nodeenv-1.9.1 opentelemetry-instrumentation-0.57b0 opentelemetry-instrumentation-asgi-0.57b0 opentelemetry-instrumentation-fastapi-0.57b0 opentelemetry-util-http-0.57b0 playwright-1.54.0 posthog-3.25.0 pyee-13.0.0 pyright-1.1.403 pysbd-0.3.4 pytube-15.0.0 qdrant-client-1.15.1 schema-0.7.7 stagehand-0.5.0 tokenizers-0.20.3 types-requests-2.32.4.20250809\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langsmith",
                  "tokenizers"
                ]
              },
              "id": "9882b55a775a4cab8705366b30a1db71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting duckduckgo-search\n",
            "  Using cached duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.1)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Downloading duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 222, in iter_dependencies\n",
            "    req = Requirement(req_string.strip())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/requirements.py\", line 36, in __init__\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve &"
      ],
      "metadata": {
        "id": "zkqNThCJEFmq"
      },
      "id": "zkqNThCJEFmq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_community.llms import Ollama\n",
        "# ollama_llm = Ollama(model=\"openhermes\") # assuming you have Ollama installed and have openhermes model pulled with `ollama pull openhermes`\n",
        "# ollama_llm = Ollama(model=\"phi\")\n",
        "ollama_llm = Ollama(model=\"qwen2.5:0.5b\")\n",
        "from crewai_tools import tool\n",
        "@tool(\"Duck_Duck_Go_Search\")\n",
        "def ddgsearch(question: str) -> str:\n",
        "    \"\"\"Clear description for what this tool is useful for, your agent will need this information to use it.\"\"\"\n",
        "    # Function logic here\n",
        "    return DuckDuckGoSearchRun().run(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "-HWIIvpGDymB",
        "outputId": "d56587ba-3770-4394-e72a-00465440f14c"
      },
      "id": "-HWIIvpGDymB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-73354078.py:6: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
            "  ollama_llm = Ollama(model=\"qwen2.5:0.5b\")\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/fields.py:1093: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'required'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  warn(\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_config.py:323: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'tool' from 'crewai_tools' (/usr/local/lib/python3.11/dist-packages/crewai_tools/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-73354078.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ollama_llm = Ollama(model=\"phi\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mollama_llm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOllama\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"qwen2.5:0.5b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcrewai_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Duck_Duck_Go_Search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mddgsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'tool' from 'crewai_tools' (/usr/local/lib/python3.11/dist-packages/crewai_tools/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools.tools import tool\n",
        "@tool(\"Duck_Duck_Go_Search\")\n",
        "def ddgsearch(question: str) -> str:\n",
        "    \"\"\"Clear description for what this tool is useful for, your agent will need this information to use it.\"\"\"\n",
        "    # Function logic here\n",
        "    return DuckDuckGoSearchRun().run(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "-JvWFv2DEefZ",
        "outputId": "01a1a60f-560c-42cd-da95-2061b203f3fd"
      },
      "id": "-JvWFv2DEefZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'tool' from 'crewai_tools.tools' (/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4266853643.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcrewai_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Duck_Duck_Go_Search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mddgsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"Clear description for what this tool is useful for, your agent will need this information to use it.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Function logic here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'tool' from 'crewai_tools.tools' (/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HpwNWvp5Eebo"
      },
      "id": "HpwNWvp5Eebo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is it that needs to get done?\n",
        "research_topic = \"Differences between open source large language models and closed source large language models.\""
      ],
      "metadata": {
        "id": "pv3vWxETETIT"
      },
      "id": "pv3vWxETETIT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "researcher = Agent(\n",
        "  role='Researcher',\n",
        "  goal='Search the internet for information about {research_topic}',\n",
        "  backstory=\"\"\"\n",
        "  You are a researcher. Using the information in the task, you find out some of the most popular facts about the topic along with some of the trending aspects.\n",
        "  You provide a lot of information thereby allowing a choice in the content selected for the final blog.\n",
        "  \"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  # tools=[DuckDuckGoSearchRun()],\n",
        "  tools=[ddgsearch],\n",
        "  llm=ollama_llm\n",
        ")"
      ],
      "metadata": {
        "id": "IsnAgzmdEVFK"
      },
      "id": "IsnAgzmdEVFK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2a6aba6d",
        "outputId": "25e2b393-25ec-4db6-a823-5a054215e4d2"
      },
      "source": [
        "!pip install --upgrade --force-reinstall crewai-tools"
      ],
      "id": "2a6aba6d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai-tools\n",
            "  Using cached crewai_tools-0.62.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting chromadb==0.5.23 (from crewai-tools)\n",
            "  Using cached chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting click>=8.1.8 (from crewai-tools)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting crewai>=0.157.0 (from crewai-tools)\n",
            "  Using cached crewai-0.159.0-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting docker>=7.1.0 (from crewai-tools)\n",
            "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting embedchain>=0.1.114 (from crewai-tools)\n",
            "  Using cached embedchain-0.1.128-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai-tools)\n",
            "  Using cached lancedb-0.24.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting openai>=1.12.0 (from crewai-tools)\n",
            "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting portalocker==2.7.0 (from crewai-tools)\n",
            "  Using cached portalocker-2.7.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pydantic>=2.6.1 (from crewai-tools)\n",
            "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyright>=1.1.350 (from crewai-tools)\n",
            "  Using cached pyright-1.1.403-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pytube>=15.0.0 (from crewai-tools)\n",
            "  Using cached pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting requests>=2.31.0 (from crewai-tools)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting stagehand>=0.4.1 (from crewai-tools)\n",
            "  Using cached stagehand-0.5.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting tiktoken>=0.8.0 (from crewai-tools)\n",
            "  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting build>=1.0.3 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting numpy>=1.22.5 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading posthog-6.5.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting typing_extensions>=4.5.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
            "Collecting tqdm>=4.65.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting overrides>=7.3.1 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tenacity>=8.2.3 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting PyYAML>=6.0.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting httpx>=0.27.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting rich>=10.11.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting appdirs>=1.4.4 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting blinker>=1.9.0 (from crewai>=0.157.0->crewai-tools)\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting instructor>=1.3.3 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached instructor-1.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json-repair==0.25.2 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached json_repair-0.25.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting json5>=0.10.0 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm==1.74.9 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached litellm-1.74.9-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting openpyxl>=3.1.5 (from crewai>=0.157.0->crewai-tools)\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_http-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "Collecting pyjwt>=2.9.0 (from crewai>=0.157.0->crewai-tools)\n",
            "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting python-dotenv>=1.0.0 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pyvis>=0.3.2 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting regex>=2024.9.11 (from crewai>=0.157.0->crewai-tools)\n",
            "  Downloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tomli-w>=1.1.0 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli>=2.0.2 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting uv>=0.4.25 (from crewai>=0.157.0->crewai-tools)\n",
            "  Using cached uv-0.8.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting aiohttp>=3.10 (from litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting importlib-metadata>=6.8.0 (from litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting jinja2<4.0.0,>=3.1.2 (from litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting packaging (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting sympy (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting urllib3>=1.26.0 (from docker>=7.1.0->crewai-tools)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.12.2 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached langchain_cohere-0.3.5-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain-community<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langsmith<0.4.0,>=0.3.18 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting mem0ai<0.2.0,>=0.1.54 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached mem0ai-0.1.116-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Using cached posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting rich>=10.11.0 (from chromadb==0.5.23->crewai-tools)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting sqlalchemy<3.0.0,>=2.0.27 (from embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading sqlalchemy-2.0.43-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting deprecation (from lancedb>=0.5.4->crewai-tools)\n",
            "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyarrow>=16 (from lancedb>=0.5.4->crewai-tools)\n",
            "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai>=1.12.0->crewai-tools)\n",
            "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.12.0->crewai-tools)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.12.0->crewai-tools)\n",
            "  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai>=1.12.0->crewai-tools)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.6.1->crewai-tools)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic>=2.6.1->crewai-tools)\n",
            "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic>=2.6.1->crewai-tools)\n",
            "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai-tools)\n",
            "  Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.31.0->crewai-tools)\n",
            "  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.31.0->crewai-tools)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.31.0->crewai-tools)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting playwright>=1.42.1 (from stagehand>=0.4.1->crewai-tools)\n",
            "  Using cached playwright-1.54.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting browserbase>=1.4.0 (from stagehand>=0.4.1->crewai-tools)\n",
            "  Using cached browserbase-1.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting anthropic>=0.51.0 (from stagehand>=0.4.1->crewai-tools)\n",
            "  Using cached anthropic-0.64.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.2->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.48.0,>=0.40.0 (from fastapi>=0.95.2->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting cachetools (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting diskcache>=5.6.3 (from instructor>=1.3.3->crewai>=0.157.0->crewai-tools)\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docstring-parser<1.0,>=0.16 (from instructor>=1.3.3->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting six>=1.9.0 (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting python-dateutil>=2.5.3 (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting cohere<6.0,>=5.5.6 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached cohere-5.17.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting langchain-experimental<0.4.0,>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pandas>=1.4.3 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tabulate<0.10.0,>=0.9.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4.0,>=0.3.18->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting pytz>=2024.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting qdrant-client>=1.9.1 (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached qdrant_client-1.15.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting et-xmlfile (from openpyxl>=3.1.5->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_instrumentation-0.57b0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.57b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached opentelemetry_util_http-0.57b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.57b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading wrapt-1.17.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.57b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached asgiref-3.9.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools)\n",
            "  Using cached pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting Pillow>=9.1 (from pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools)\n",
            "  Using cached pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six==20250506->pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting pyee<14,>=13 (from playwright>=1.42.1->stagehand>=0.4.1->crewai-tools)\n",
            "  Using cached pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting greenlet<4.0.0,>=3.1.1 (from playwright>=1.42.1->stagehand>=0.4.1->crewai-tools)\n",
            "  Downloading greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting ipython>=5.3.0 (from pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading ipython-9.4.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting jsonpickle>=1.4.1 (from pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading jsonpickle-4.1.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting networkx>=1.11 (from pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached fastavro-1.12.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.5.6->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached types_requests-2.32.4.20250809-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting cachetools (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
            "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting decorator (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting ipython-pygments-lexers (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting matplotlib-inline (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pexpect>4.3 (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading prompt_toolkit-3.0.51-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting stack_data (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.13.0 (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.2->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.9->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading rpds_py-0.27.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting cffi>=1.14 (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.23->crewai-tools)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools)\n",
            "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting executing>=1.2.0 (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pycparser (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber>=0.11.4->crewai>=0.157.0->crewai-tools)\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools)\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Using cached crewai_tools-0.62.0-py3-none-any.whl (677 kB)\n",
            "Using cached chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Using cached chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached crewai-0.159.0-py3-none-any.whl (379 kB)\n",
            "Using cached json_repair-0.25.2-py3-none-any.whl (12 kB)\n",
            "Using cached litellm-1.74.9-py3-none-any.whl (8.7 MB)\n",
            "Using cached onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "Using cached embedchain-0.1.128-py3-none-any.whl (211 kB)\n",
            "Using cached lancedb-0.24.2-cp39-abi3-manylinux_2_28_x86_64.whl (34.8 MB)\n",
            "Downloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pyright-1.1.403-py3-none-any.whl (5.7 MB)\n",
            "Using cached pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached stagehand-0.5.0-py3-none-any.whl (102 kB)\n",
            "Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached anthropic-0.64.0-py3-none-any.whl (297 kB)\n",
            "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.2/107.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Using cached bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.3/187.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Using cached browserbase-1.4.0-py3-none-any.whl (98 kB)\n",
            "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "Downloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached instructor-1.10.0-py3-none-any.whl (119 kB)\n",
            "Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Using cached jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached langchain_cohere-0.3.5-py3-none-any.whl (45 kB)\n",
            "Using cached langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "Using cached langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
            "Using cached langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
            "Using cached mem0ai-0.1.116-py3-none-any.whl (190 kB)\n",
            "Using cached mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "Using cached nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_http-1.36.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_instrumentation_fastapi-0.57b0-py3-none-any.whl (12 kB)\n",
            "Using cached opentelemetry_instrumentation-0.57b0-py3-none-any.whl (32 kB)\n",
            "Using cached opentelemetry_instrumentation_asgi-0.57b0-py3-none-any.whl (16 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "Using cached opentelemetry_util_http-0.57b0-py3-none-any.whl (7.6 kB)\n",
            "Using cached opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "Downloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "Using cached pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "Using cached playwright-1.54.0-py3-none-manylinux1_x86_64.whl (45.9 MB)\n",
            "Using cached posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Using cached pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Using cached pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading sqlalchemy-2.0.43-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Using cached tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "Using cached tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached uv-0.8.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached cohere-5.17.0-py3-none-any.whl (295 kB)\n",
            "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.1/216.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading ipython-9.4.0-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.0/611.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-4.1.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
            "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "Using cached pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
            "Downloading starlette-0.47.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Using cached uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "Using cached watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached asgiref-3.9.1-py3-none-any.whl (23 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-45.0.6-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached fastavro-1.12.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.3/235.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.1.7-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.7/246.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prompt_toolkit-3.0.51-py3-none-any.whl (387 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.8/387.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.5/213.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.27.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached types_requests-2.32.4.20250809-py3-none-any.whl (20 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.3-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.4/82.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.0/349.0 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wcwidth, schema, pytz, pypika, pure-eval, ptyprocess, mpmath, monotonic, flatbuffers, durationpy, appdirs, zstandard, zipp, wrapt, websockets, websocket-client, uvloop, uv, urllib3, tzdata, typing_extensions, traitlets, tqdm, tomli-w, tomli, tenacity, tabulate, sympy, soupsieve, sniffio, six, shellingham, rpds-py, regex, PyYAML, pytube, python-dotenv, pysbd, pyproject_hooks, pypdfium2, pypdf, pyjwt, pygments, pycparser, pyasn1, pyarrow, protobuf, propcache, prompt_toolkit, portalocker, Pillow, pexpect, parso, packaging, overrides, orjson, opentelemetry-util-http, oauthlib, numpy, nodeenv, networkx, mypy-extensions, multidict, mmh3, mdurl, MarkupSafe, jsonref, jsonpointer, jsonpickle, json5, json-repair, jiter, importlib-resources, idna, hyperframe, humanfriendly, httpx-sse, httptools, hpack, hf-xet, h11, grpcio, greenlet, fsspec, frozenlist, filelock, fastavro, executing, et-xmlfile, docstring-parser, distro, diskcache, decorator, click, charset_normalizer, certifi, cachetools, blinker, bcrypt, backoff, attrs, asttokens, asgiref, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspection, typing-inspect, types-requests, stack_data, sqlalchemy, rsa, requests, referencing, python-dateutil, pyright, pyee, pydantic-core, pyasn1-modules, opentelemetry-proto, openpyxl, matplotlib-inline, marshmallow, markdown-it-py, Mako, jsonpatch, jinja2, jedi, ipython-pygments-lexers, importlib-metadata, httpcore, h2, googleapis-common-protos, deprecation, coloredlogs, chroma-hnswlib, cffi, build, beautifulsoup4, anyio, aiosignal, watchfiles, tiktoken, starlette, rich, requests-toolbelt, requests-oauthlib, pydantic, posthog, playwright, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, jsonschema-specifications, ipython, huggingface-hub, httpx, gptcache, google-auth, docker, dataclasses-json, cryptography, alembic, aiohttp, typer, tokenizers, pyvis, pydantic-settings, pdfminer.six, opentelemetry-semantic-conventions, openai, langsmith, lancedb, kubernetes, jsonschema, fastapi, browserbase, anthropic, qdrant-client, pdfplumber, opentelemetry-sdk, opentelemetry-instrumentation, litellm, langchain-core, instructor, cohere, stagehand, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, mem0ai, langchain-text-splitters, langchain-openai, opentelemetry-instrumentation-fastapi, langchain, langchain-community, chromadb, langchain-experimental, crewai, langchain-cohere, embedchain, crewai-tools\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.13\n",
            "    Uninstalling wcwidth-0.2.13:\n",
            "      Successfully uninstalled wcwidth-0.2.13\n",
            "  Attempting uninstall: schema\n",
            "    Found existing installation: schema 0.7.7\n",
            "    Uninstalling schema-0.7.7:\n",
            "      Successfully uninstalled schema-0.7.7\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: pypika\n",
            "    Found existing installation: PyPika 0.48.9\n",
            "    Uninstalling PyPika-0.48.9:\n",
            "      Successfully uninstalled PyPika-0.48.9\n",
            "  Attempting uninstall: ptyprocess\n",
            "    Found existing installation: ptyprocess 0.7.0\n",
            "    Uninstalling ptyprocess-0.7.0:\n",
            "      Successfully uninstalled ptyprocess-0.7.0\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: monotonic\n",
            "    Found existing installation: monotonic 1.6\n",
            "    Uninstalling monotonic-1.6:\n",
            "      Successfully uninstalled monotonic-1.6\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: durationpy\n",
            "    Found existing installation: durationpy 0.10\n",
            "    Uninstalling durationpy-0.10:\n",
            "      Successfully uninstalled durationpy-0.10\n",
            "  Attempting uninstall: appdirs\n",
            "    Found existing installation: appdirs 1.4.4\n",
            "    Uninstalling appdirs-1.4.4:\n",
            "      Successfully uninstalled appdirs-1.4.4\n",
            "  Attempting uninstall: zstandard\n",
            "    Found existing installation: zstandard 0.23.0\n",
            "    Uninstalling zstandard-0.23.0:\n",
            "      Successfully uninstalled zstandard-0.23.0\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.23.0\n",
            "    Uninstalling zipp-3.23.0:\n",
            "      Successfully uninstalled zipp-3.23.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.8.0\n",
            "    Uninstalling websocket-client-1.8.0:\n",
            "      Successfully uninstalled websocket-client-1.8.0\n",
            "  Attempting uninstall: uvloop\n",
            "    Found existing installation: uvloop 0.21.0\n",
            "    Uninstalling uvloop-0.21.0:\n",
            "      Successfully uninstalled uvloop-0.21.0\n",
            "  Attempting uninstall: uv\n",
            "    Found existing installation: uv 0.8.11\n",
            "    Uninstalling uv-0.8.11:\n",
            "      Successfully uninstalled uv-0.8.11\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.14.1\n",
            "    Uninstalling typing_extensions-4.14.1:\n",
            "      Successfully uninstalled typing_extensions-4.14.1\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tomli-w\n",
            "    Found existing installation: tomli_w 1.2.0\n",
            "    Uninstalling tomli_w-1.2.0:\n",
            "      Successfully uninstalled tomli_w-1.2.0\n",
            "  Attempting uninstall: tomli\n",
            "    Found existing installation: tomli 2.2.1\n",
            "    Uninstalling tomli-2.2.1:\n",
            "      Successfully uninstalled tomli-2.2.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.9.0\n",
            "    Uninstalling tabulate-0.9.0:\n",
            "      Successfully uninstalled tabulate-0.9.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.7\n",
            "    Uninstalling soupsieve-2.7:\n",
            "      Successfully uninstalled soupsieve-2.7\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: shellingham\n",
            "    Found existing installation: shellingham 1.5.4\n",
            "    Uninstalling shellingham-1.5.4:\n",
            "      Successfully uninstalled shellingham-1.5.4\n",
            "  Attempting uninstall: rpds-py\n",
            "    Found existing installation: rpds-py 0.27.0\n",
            "    Uninstalling rpds-py-0.27.0:\n",
            "      Successfully uninstalled rpds-py-0.27.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pytube\n",
            "    Found existing installation: pytube 15.0.0\n",
            "    Uninstalling pytube-15.0.0:\n",
            "      Successfully uninstalled pytube-15.0.0\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.1.1\n",
            "    Uninstalling python-dotenv-1.1.1:\n",
            "      Successfully uninstalled python-dotenv-1.1.1\n",
            "  Attempting uninstall: pysbd\n",
            "    Found existing installation: pysbd 0.3.4\n",
            "    Uninstalling pysbd-0.3.4:\n",
            "      Successfully uninstalled pysbd-0.3.4\n",
            "  Attempting uninstall: pyproject_hooks\n",
            "    Found existing installation: pyproject_hooks 1.2.0\n",
            "    Uninstalling pyproject_hooks-1.2.0:\n",
            "      Successfully uninstalled pyproject_hooks-1.2.0\n",
            "  Attempting uninstall: pypdfium2\n",
            "    Found existing installation: pypdfium2 4.30.0\n",
            "    Uninstalling pypdfium2-4.30.0:\n",
            "      Successfully uninstalled pypdfium2-4.30.0\n",
            "  Attempting uninstall: pypdf\n",
            "    Found existing installation: pypdf 5.9.0\n",
            "    Uninstalling pypdf-5.9.0:\n",
            "      Successfully uninstalled pypdf-5.9.0\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.10.1\n",
            "    Uninstalling PyJWT-2.10.1:\n",
            "      Successfully uninstalled PyJWT-2.10.1\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.2\n",
            "    Uninstalling Pygments-2.19.2:\n",
            "      Successfully uninstalled Pygments-2.19.2\n",
            "  Attempting uninstall: pycparser\n",
            "    Found existing installation: pycparser 2.22\n",
            "    Uninstalling pycparser-2.22:\n",
            "      Successfully uninstalled pycparser-2.22\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.3.2\n",
            "    Uninstalling propcache-0.3.2:\n",
            "      Successfully uninstalled propcache-0.3.2\n",
            "  Attempting uninstall: prompt_toolkit\n",
            "    Found existing installation: prompt_toolkit 3.0.51\n",
            "    Uninstalling prompt_toolkit-3.0.51:\n",
            "      Successfully uninstalled prompt_toolkit-3.0.51\n",
            "  Attempting uninstall: portalocker\n",
            "    Found existing installation: portalocker 2.7.0\n",
            "    Uninstalling portalocker-2.7.0:\n",
            "      Successfully uninstalled portalocker-2.7.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: pexpect\n",
            "    Found existing installation: pexpect 4.9.0\n",
            "    Uninstalling pexpect-4.9.0:\n",
            "      Successfully uninstalled pexpect-4.9.0\n",
            "  Attempting uninstall: parso\n",
            "    Found existing installation: parso 0.8.4\n",
            "    Uninstalling parso-0.8.4:\n",
            "      Successfully uninstalled parso-0.8.4\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: overrides\n",
            "    Found existing installation: overrides 7.7.0\n",
            "    Uninstalling overrides-7.7.0:\n",
            "      Successfully uninstalled overrides-7.7.0\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.11.1\n",
            "    Uninstalling orjson-3.11.1:\n",
            "      Successfully uninstalled orjson-3.11.1\n",
            "  Attempting uninstall: opentelemetry-util-http\n",
            "    Found existing installation: opentelemetry-util-http 0.57b0\n",
            "    Uninstalling opentelemetry-util-http-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-util-http-0.57b0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.3.1\n",
            "    Uninstalling oauthlib-3.3.1:\n",
            "      Successfully uninstalled oauthlib-3.3.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nodeenv\n",
            "    Found existing installation: nodeenv 1.9.1\n",
            "    Uninstalling nodeenv-1.9.1:\n",
            "      Successfully uninstalled nodeenv-1.9.1\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: mypy-extensions\n",
            "    Found existing installation: mypy_extensions 1.1.0\n",
            "    Uninstalling mypy_extensions-1.1.0:\n",
            "      Successfully uninstalled mypy_extensions-1.1.0\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.6.4\n",
            "    Uninstalling multidict-6.6.4:\n",
            "      Successfully uninstalled multidict-6.6.4\n",
            "  Attempting uninstall: mmh3\n",
            "    Found existing installation: mmh3 5.2.0\n",
            "    Uninstalling mmh3-5.2.0:\n",
            "      Successfully uninstalled mmh3-5.2.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: jsonref\n",
            "    Found existing installation: jsonref 1.1.0\n",
            "    Uninstalling jsonref-1.1.0:\n",
            "      Successfully uninstalled jsonref-1.1.0\n",
            "  Attempting uninstall: jsonpointer\n",
            "    Found existing installation: jsonpointer 3.0.0\n",
            "    Uninstalling jsonpointer-3.0.0:\n",
            "      Successfully uninstalled jsonpointer-3.0.0\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.1.1\n",
            "    Uninstalling jsonpickle-4.1.1:\n",
            "      Successfully uninstalled jsonpickle-4.1.1\n",
            "  Attempting uninstall: json5\n",
            "    Found existing installation: json5 0.12.1\n",
            "    Uninstalling json5-0.12.1:\n",
            "      Successfully uninstalled json5-0.12.1\n",
            "  Attempting uninstall: json-repair\n",
            "    Found existing installation: json_repair 0.25.2\n",
            "    Uninstalling json_repair-0.25.2:\n",
            "      Successfully uninstalled json_repair-0.25.2\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.10.0\n",
            "    Uninstalling jiter-0.10.0:\n",
            "      Successfully uninstalled jiter-0.10.0\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib_resources 6.5.2\n",
            "    Uninstalling importlib_resources-6.5.2:\n",
            "      Successfully uninstalled importlib_resources-6.5.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hyperframe\n",
            "    Found existing installation: hyperframe 6.1.0\n",
            "    Uninstalling hyperframe-6.1.0:\n",
            "      Successfully uninstalled hyperframe-6.1.0\n",
            "  Attempting uninstall: humanfriendly\n",
            "    Found existing installation: humanfriendly 10.0\n",
            "    Uninstalling humanfriendly-10.0:\n",
            "      Successfully uninstalled humanfriendly-10.0\n",
            "  Attempting uninstall: httpx-sse\n",
            "    Found existing installation: httpx-sse 0.4.0\n",
            "    Uninstalling httpx-sse-0.4.0:\n",
            "      Successfully uninstalled httpx-sse-0.4.0\n",
            "  Attempting uninstall: httptools\n",
            "    Found existing installation: httptools 0.6.4\n",
            "    Uninstalling httptools-0.6.4:\n",
            "      Successfully uninstalled httptools-0.6.4\n",
            "  Attempting uninstall: hpack\n",
            "    Found existing installation: hpack 4.1.0\n",
            "    Uninstalling hpack-4.1.0:\n",
            "      Successfully uninstalled hpack-4.1.0\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.7\n",
            "    Uninstalling hf-xet-1.1.7:\n",
            "      Successfully uninstalled hf-xet-1.1.7\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.16.0\n",
            "    Uninstalling h11-0.16.0:\n",
            "      Successfully uninstalled h11-0.16.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.74.0\n",
            "    Uninstalling grpcio-1.74.0:\n",
            "      Successfully uninstalled grpcio-1.74.0\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 3.2.4\n",
            "    Uninstalling greenlet-3.2.4:\n",
            "      Successfully uninstalled greenlet-3.2.4\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.7.0\n",
            "    Uninstalling frozenlist-1.7.0:\n",
            "      Successfully uninstalled frozenlist-1.7.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: fastavro\n",
            "    Found existing installation: fastavro 1.12.0\n",
            "    Uninstalling fastavro-1.12.0:\n",
            "      Successfully uninstalled fastavro-1.12.0\n",
            "  Attempting uninstall: et-xmlfile\n",
            "    Found existing installation: et_xmlfile 2.0.0\n",
            "    Uninstalling et_xmlfile-2.0.0:\n",
            "      Successfully uninstalled et_xmlfile-2.0.0\n",
            "  Attempting uninstall: docstring-parser\n",
            "    Found existing installation: docstring_parser 0.17.0\n",
            "    Uninstalling docstring_parser-0.17.0:\n",
            "      Successfully uninstalled docstring_parser-0.17.0\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.9.0\n",
            "    Uninstalling distro-1.9.0:\n",
            "      Successfully uninstalled distro-1.9.0\n",
            "  Attempting uninstall: diskcache\n",
            "    Found existing installation: diskcache 5.6.3\n",
            "    Uninstalling diskcache-5.6.3:\n",
            "      Successfully uninstalled diskcache-5.6.3\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: blinker\n",
            "    Found existing installation: blinker 1.9.0\n",
            "    Uninstalling blinker-1.9.0:\n",
            "      Successfully uninstalled blinker-1.9.0\n",
            "  Attempting uninstall: bcrypt\n",
            "    Found existing installation: bcrypt 4.3.0\n",
            "    Uninstalling bcrypt-4.3.0:\n",
            "      Successfully uninstalled bcrypt-4.3.0\n",
            "  Attempting uninstall: backoff\n",
            "    Found existing installation: backoff 2.2.1\n",
            "    Uninstalling backoff-2.2.1:\n",
            "      Successfully uninstalled backoff-2.2.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: asgiref\n",
            "    Found existing installation: asgiref 3.9.1\n",
            "    Uninstalling asgiref-3.9.1:\n",
            "      Successfully uninstalled asgiref-3.9.1\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.20.1\n",
            "    Uninstalling yarl-1.20.1:\n",
            "      Successfully uninstalled yarl-1.20.1\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.35.0\n",
            "    Uninstalling uvicorn-0.35.0:\n",
            "      Successfully uninstalled uvicorn-0.35.0\n",
            "  Attempting uninstall: typing-inspection\n",
            "    Found existing installation: typing-inspection 0.4.1\n",
            "    Uninstalling typing-inspection-0.4.1:\n",
            "      Successfully uninstalled typing-inspection-0.4.1\n",
            "  Attempting uninstall: typing-inspect\n",
            "    Found existing installation: typing-inspect 0.9.0\n",
            "    Uninstalling typing-inspect-0.9.0:\n",
            "      Successfully uninstalled typing-inspect-0.9.0\n",
            "  Attempting uninstall: types-requests\n",
            "    Found existing installation: types-requests 2.32.4.20250809\n",
            "    Uninstalling types-requests-2.32.4.20250809:\n",
            "      Successfully uninstalled types-requests-2.32.4.20250809\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.43\n",
            "    Uninstalling SQLAlchemy-2.0.43:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.43\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.36.2\n",
            "    Uninstalling referencing-0.36.2:\n",
            "      Successfully uninstalled referencing-0.36.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pyright\n",
            "    Found existing installation: pyright 1.1.403\n",
            "    Uninstalling pyright-1.1.403:\n",
            "      Successfully uninstalled pyright-1.1.403\n",
            "  Attempting uninstall: pyee\n",
            "    Found existing installation: pyee 13.0.0\n",
            "    Uninstalling pyee-13.0.0:\n",
            "      Successfully uninstalled pyee-13.0.0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.36.0\n",
            "    Uninstalling opentelemetry-proto-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.36.0\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 3.1.5\n",
            "    Uninstalling openpyxl-3.1.5:\n",
            "      Successfully uninstalled openpyxl-3.1.5\n",
            "  Attempting uninstall: matplotlib-inline\n",
            "    Found existing installation: matplotlib-inline 0.1.7\n",
            "    Uninstalling matplotlib-inline-0.1.7:\n",
            "      Successfully uninstalled matplotlib-inline-0.1.7\n",
            "  Attempting uninstall: marshmallow\n",
            "    Found existing installation: marshmallow 3.26.1\n",
            "    Uninstalling marshmallow-3.26.1:\n",
            "      Successfully uninstalled marshmallow-3.26.1\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 4.0.0\n",
            "    Uninstalling markdown-it-py-4.0.0:\n",
            "      Successfully uninstalled markdown-it-py-4.0.0\n",
            "  Attempting uninstall: Mako\n",
            "    Found existing installation: Mako 1.1.3\n",
            "    Uninstalling Mako-1.1.3:\n",
            "      Successfully uninstalled Mako-1.1.3\n",
            "  Attempting uninstall: jsonpatch\n",
            "    Found existing installation: jsonpatch 1.33\n",
            "    Uninstalling jsonpatch-1.33:\n",
            "      Successfully uninstalled jsonpatch-1.33\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: jedi\n",
            "    Found existing installation: jedi 0.19.2\n",
            "    Uninstalling jedi-0.19.2:\n",
            "      Successfully uninstalled jedi-0.19.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.9\n",
            "    Uninstalling httpcore-1.0.9:\n",
            "      Successfully uninstalled httpcore-1.0.9\n",
            "  Attempting uninstall: h2\n",
            "    Found existing installation: h2 4.2.0\n",
            "    Uninstalling h2-4.2.0:\n",
            "      Successfully uninstalled h2-4.2.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.70.0\n",
            "    Uninstalling googleapis-common-protos-1.70.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.70.0\n",
            "  Attempting uninstall: deprecation\n",
            "    Found existing installation: deprecation 2.1.0\n",
            "    Uninstalling deprecation-2.1.0:\n",
            "      Successfully uninstalled deprecation-2.1.0\n",
            "  Attempting uninstall: coloredlogs\n",
            "    Found existing installation: coloredlogs 15.0.1\n",
            "    Uninstalling coloredlogs-15.0.1:\n",
            "      Successfully uninstalled coloredlogs-15.0.1\n",
            "  Attempting uninstall: chroma-hnswlib\n",
            "    Found existing installation: chroma-hnswlib 0.7.6\n",
            "    Uninstalling chroma-hnswlib-0.7.6:\n",
            "      Successfully uninstalled chroma-hnswlib-0.7.6\n",
            "  Attempting uninstall: cffi\n",
            "    Found existing installation: cffi 1.17.1\n",
            "    Uninstalling cffi-1.17.1:\n",
            "      Successfully uninstalled cffi-1.17.1\n",
            "  Attempting uninstall: build\n",
            "    Found existing installation: build 1.3.0\n",
            "    Uninstalling build-1.3.0:\n",
            "      Successfully uninstalled build-1.3.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.4\n",
            "    Uninstalling beautifulsoup4-4.13.4:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.4\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.10.0\n",
            "    Uninstalling anyio-4.10.0:\n",
            "      Successfully uninstalled anyio-4.10.0\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: watchfiles\n",
            "    Found existing installation: watchfiles 1.1.0\n",
            "    Uninstalling watchfiles-1.1.0:\n",
            "      Successfully uninstalled watchfiles-1.1.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.11.0\n",
            "    Uninstalling tiktoken-0.11.0:\n",
            "      Successfully uninstalled tiktoken-0.11.0\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.47.2\n",
            "    Uninstalling starlette-0.47.2:\n",
            "      Successfully uninstalled starlette-0.47.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: requests-toolbelt\n",
            "    Found existing installation: requests-toolbelt 1.0.0\n",
            "    Uninstalling requests-toolbelt-1.0.0:\n",
            "      Successfully uninstalled requests-toolbelt-1.0.0\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: posthog\n",
            "    Found existing installation: posthog 3.25.0\n",
            "    Uninstalling posthog-3.25.0:\n",
            "      Successfully uninstalled posthog-3.25.0\n",
            "  Attempting uninstall: playwright\n",
            "    Found existing installation: playwright 1.54.0\n",
            "    Uninstalling playwright-1.54.0:\n",
            "      Successfully uninstalled playwright-1.54.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.36.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.36.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.36.0\n",
            "    Uninstalling opentelemetry-api-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.36.0\n",
            "  Attempting uninstall: onnxruntime\n",
            "    Found existing installation: onnxruntime 1.22.0\n",
            "    Uninstalling onnxruntime-1.22.0:\n",
            "      Successfully uninstalled onnxruntime-1.22.0\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2025.4.1\n",
            "    Uninstalling jsonschema-specifications-2025.4.1:\n",
            "      Successfully uninstalled jsonschema-specifications-2025.4.1\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.34.4\n",
            "    Uninstalling huggingface-hub-0.34.4:\n",
            "      Successfully uninstalled huggingface-hub-0.34.4\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: gptcache\n",
            "    Found existing installation: gptcache 0.1.44\n",
            "    Uninstalling gptcache-0.1.44:\n",
            "      Successfully uninstalled gptcache-0.1.44\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.38.0\n",
            "    Uninstalling google-auth-2.38.0:\n",
            "      Successfully uninstalled google-auth-2.38.0\n",
            "  Attempting uninstall: docker\n",
            "    Found existing installation: docker 7.1.0\n",
            "    Uninstalling docker-7.1.0:\n",
            "      Successfully uninstalled docker-7.1.0\n",
            "  Attempting uninstall: dataclasses-json\n",
            "    Found existing installation: dataclasses-json 0.6.7\n",
            "    Uninstalling dataclasses-json-0.6.7:\n",
            "      Successfully uninstalled dataclasses-json-0.6.7\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "  Attempting uninstall: alembic\n",
            "    Found existing installation: alembic 1.16.4\n",
            "    Uninstalling alembic-1.16.4:\n",
            "      Successfully uninstalled alembic-1.16.4\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.12.15\n",
            "    Uninstalling aiohttp-3.12.15:\n",
            "      Successfully uninstalled aiohttp-3.12.15\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.16.0\n",
            "    Uninstalling typer-0.16.0:\n",
            "      Successfully uninstalled typer-0.16.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: pyvis\n",
            "    Found existing installation: pyvis 0.3.2\n",
            "    Uninstalling pyvis-0.3.2:\n",
            "      Successfully uninstalled pyvis-0.3.2\n",
            "  Attempting uninstall: pydantic-settings\n",
            "    Found existing installation: pydantic-settings 2.10.1\n",
            "    Uninstalling pydantic-settings-2.10.1:\n",
            "      Successfully uninstalled pydantic-settings-2.10.1\n",
            "  Attempting uninstall: pdfminer.six\n",
            "    Found existing installation: pdfminer.six 20250506\n",
            "    Uninstalling pdfminer.six-20250506:\n",
            "      Successfully uninstalled pdfminer.six-20250506\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.57b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.57b0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.99.8\n",
            "    Uninstalling openai-1.99.8:\n",
            "      Successfully uninstalled openai-1.99.8\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.45\n",
            "    Uninstalling langsmith-0.3.45:\n",
            "      Successfully uninstalled langsmith-0.3.45\n",
            "  Attempting uninstall: lancedb\n",
            "    Found existing installation: lancedb 0.24.2\n",
            "    Uninstalling lancedb-0.24.2:\n",
            "      Successfully uninstalled lancedb-0.24.2\n",
            "  Attempting uninstall: kubernetes\n",
            "    Found existing installation: kubernetes 33.1.0\n",
            "    Uninstalling kubernetes-33.1.0:\n",
            "      Successfully uninstalled kubernetes-33.1.0\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.25.0\n",
            "    Uninstalling jsonschema-4.25.0:\n",
            "      Successfully uninstalled jsonschema-4.25.0\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.116.1\n",
            "    Uninstalling fastapi-0.116.1:\n",
            "      Successfully uninstalled fastapi-0.116.1\n",
            "  Attempting uninstall: browserbase\n",
            "    Found existing installation: browserbase 1.4.0\n",
            "    Uninstalling browserbase-1.4.0:\n",
            "      Successfully uninstalled browserbase-1.4.0\n",
            "  Attempting uninstall: anthropic\n",
            "    Found existing installation: anthropic 0.64.0\n",
            "    Uninstalling anthropic-0.64.0:\n",
            "      Successfully uninstalled anthropic-0.64.0\n",
            "  Attempting uninstall: qdrant-client\n",
            "    Found existing installation: qdrant-client 1.15.1\n",
            "    Uninstalling qdrant-client-1.15.1:\n",
            "      Successfully uninstalled qdrant-client-1.15.1\n",
            "  Attempting uninstall: pdfplumber\n",
            "    Found existing installation: pdfplumber 0.11.7\n",
            "    Uninstalling pdfplumber-0.11.7:\n",
            "      Successfully uninstalled pdfplumber-0.11.7\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.36.0\n",
            "    Uninstalling opentelemetry-sdk-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.36.0\n",
            "  Attempting uninstall: opentelemetry-instrumentation\n",
            "    Found existing installation: opentelemetry-instrumentation 0.57b0\n",
            "    Uninstalling opentelemetry-instrumentation-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-instrumentation-0.57b0\n",
            "  Attempting uninstall: litellm\n",
            "    Found existing installation: litellm 1.74.9\n",
            "    Uninstalling litellm-1.74.9:\n",
            "      Successfully uninstalled litellm-1.74.9\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.74\n",
            "    Uninstalling langchain-core-0.3.74:\n",
            "      Successfully uninstalled langchain-core-0.3.74\n",
            "  Attempting uninstall: instructor\n",
            "    Found existing installation: instructor 1.10.0\n",
            "    Uninstalling instructor-1.10.0:\n",
            "      Successfully uninstalled instructor-1.10.0\n",
            "  Attempting uninstall: cohere\n",
            "    Found existing installation: cohere 5.17.0\n",
            "    Uninstalling cohere-5.17.0:\n",
            "      Successfully uninstalled cohere-5.17.0\n",
            "  Attempting uninstall: stagehand\n",
            "    Found existing installation: stagehand 0.5.0\n",
            "    Uninstalling stagehand-0.5.0:\n",
            "      Successfully uninstalled stagehand-0.5.0\n",
            "  Attempting uninstall: opentelemetry-instrumentation-asgi\n",
            "    Found existing installation: opentelemetry-instrumentation-asgi 0.57b0\n",
            "    Uninstalling opentelemetry-instrumentation-asgi-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-instrumentation-asgi-0.57b0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-http\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-http 1.36.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-http-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-http-1.36.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.36.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.36.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.36.0\n",
            "  Attempting uninstall: mem0ai\n",
            "    Found existing installation: mem0ai 0.1.116\n",
            "    Uninstalling mem0ai-0.1.116:\n",
            "      Successfully uninstalled mem0ai-0.1.116\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.9\n",
            "    Uninstalling langchain-text-splitters-0.3.9:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.9\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 0.2.14\n",
            "    Uninstalling langchain-openai-0.2.14:\n",
            "      Successfully uninstalled langchain-openai-0.2.14\n",
            "  Attempting uninstall: opentelemetry-instrumentation-fastapi\n",
            "    Found existing installation: opentelemetry-instrumentation-fastapi 0.57b0\n",
            "    Uninstalling opentelemetry-instrumentation-fastapi-0.57b0:\n",
            "      Successfully uninstalled opentelemetry-instrumentation-fastapi-0.57b0\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.3.27\n",
            "    Uninstalling langchain-community-0.3.27:\n",
            "      Successfully uninstalled langchain-community-0.3.27\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.5.23\n",
            "    Uninstalling chromadb-0.5.23:\n",
            "      Successfully uninstalled chromadb-0.5.23\n",
            "  Attempting uninstall: langchain-experimental\n",
            "    Found existing installation: langchain-experimental 0.3.4\n",
            "    Uninstalling langchain-experimental-0.3.4:\n",
            "      Successfully uninstalled langchain-experimental-0.3.4\n",
            "  Attempting uninstall: crewai\n",
            "    Found existing installation: crewai 0.159.0\n",
            "    Uninstalling crewai-0.159.0:\n",
            "      Successfully uninstalled crewai-0.159.0\n",
            "  Attempting uninstall: langchain-cohere\n",
            "    Found existing installation: langchain-cohere 0.3.5\n",
            "    Uninstalling langchain-cohere-0.3.5:\n",
            "      Successfully uninstalled langchain-cohere-0.3.5\n",
            "  Attempting uninstall: embedchain\n",
            "    Found existing installation: embedchain 0.1.128\n",
            "    Uninstalling embedchain-0.1.128:\n",
            "      Successfully uninstalled embedchain-0.1.128\n",
            "  Attempting uninstall: crewai-tools\n",
            "    Found existing installation: crewai-tools 0.62.0\n",
            "    Uninstalling crewai-tools-0.62.0:\n",
            "      Successfully uninstalled crewai-tools-0.62.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-embeddings-huggingface 0.6.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-readers-file 0.5.1 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-readers-file 0.5.1 requires pandas<2.3.0, but you have pandas 2.3.1 which is incompatible.\n",
            "llama-index-tools-mcp 0.4.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-embeddings-openai 0.5.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index 0.13.1 requires llama-index-core<0.14,>=0.13.1, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index 0.13.1 requires llama-index-llms-openai<0.6,>=0.5.0, but you have llama-index-llms-openai 0.4.7 which is incompatible.\n",
            "llama-index-indices-managed-llama-cloud 0.9.1 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "llama-index-llms-ollama 0.7.0 requires llama-index-core<0.14,>=0.13.0, but you have llama-index-core 0.12.52.post1 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 9.4.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.7.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 45.0.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.7.0 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.1 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 45.0.6 which is incompatible.\n",
            "transformers 4.55.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.2.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.14.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.10 MarkupSafe-3.0.2 Pillow-11.3.0 PyYAML-6.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 alembic-1.16.4 annotated-types-0.7.0 anthropic-0.64.0 anyio-4.10.0 appdirs-1.4.4 asgiref-3.9.1 asttokens-3.0.0 attrs-25.3.0 backoff-2.2.1 bcrypt-4.3.0 beautifulsoup4-4.13.4 blinker-1.9.0 browserbase-1.4.0 build-1.3.0 cachetools-5.5.2 certifi-2025.8.3 cffi-1.17.1 charset_normalizer-3.4.3 chroma-hnswlib-0.7.6 chromadb-0.5.23 click-8.2.1 cohere-5.17.0 coloredlogs-15.0.1 crewai-0.159.0 crewai-tools-0.62.0 cryptography-45.0.6 dataclasses-json-0.6.7 decorator-5.2.1 deprecation-2.1.0 diskcache-5.6.3 distro-1.9.0 docker-7.1.0 docstring-parser-0.17.0 durationpy-0.10 embedchain-0.1.128 et-xmlfile-2.0.0 executing-2.2.0 fastapi-0.116.1 fastavro-1.12.0 filelock-3.19.1 flatbuffers-25.2.10 frozenlist-1.7.0 fsspec-2025.7.0 google-auth-2.40.3 googleapis-common-protos-1.70.0 gptcache-0.1.44 greenlet-3.2.4 grpcio-1.74.0 h11-0.16.0 h2-4.2.0 hf-xet-1.1.7 hpack-4.1.0 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 httpx-sse-0.4.0 huggingface-hub-0.34.4 humanfriendly-10.0 hyperframe-6.1.0 idna-3.10 importlib-metadata-8.7.0 importlib-resources-6.5.2 instructor-1.10.0 ipython-9.4.0 ipython-pygments-lexers-1.1.1 jedi-0.19.2 jinja2-3.1.6 jiter-0.10.0 json-repair-0.25.2 json5-0.12.1 jsonpatch-1.33 jsonpickle-4.1.1 jsonpointer-3.0.0 jsonref-1.1.0 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 kubernetes-33.1.0 lancedb-0.24.2 langchain-0.3.27 langchain-cohere-0.3.5 langchain-community-0.3.27 langchain-core-0.3.74 langchain-experimental-0.3.4 langchain-openai-0.2.14 langchain-text-splitters-0.3.9 langsmith-0.3.45 litellm-1.74.9 markdown-it-py-4.0.0 marshmallow-3.26.1 matplotlib-inline-0.1.7 mdurl-0.1.2 mem0ai-0.1.116 mmh3-5.2.0 monotonic-1.6 mpmath-1.3.0 multidict-6.6.4 mypy-extensions-1.1.0 networkx-3.5 nodeenv-1.9.1 numpy-2.3.2 oauthlib-3.3.1 onnxruntime-1.22.0 openai-1.99.9 openpyxl-3.1.5 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-exporter-otlp-proto-http-1.36.0 opentelemetry-instrumentation-0.57b0 opentelemetry-instrumentation-asgi-0.57b0 opentelemetry-instrumentation-fastapi-0.57b0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 opentelemetry-util-http-0.57b0 orjson-3.11.2 overrides-7.7.0 packaging-25.0 pandas-2.3.1 parso-0.8.4 pdfminer.six-20250506 pdfplumber-0.11.7 pexpect-4.9.0 playwright-1.54.0 portalocker-2.7.0 posthog-3.25.0 prompt_toolkit-3.0.51 propcache-0.3.2 protobuf-5.29.5 ptyprocess-0.7.0 pure-eval-0.2.3 pyarrow-21.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.22 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 pyee-13.0.0 pygments-2.19.2 pyjwt-2.10.1 pypdf-5.9.0 pypdfium2-4.30.0 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.403 pysbd-0.3.4 python-dateutil-2.9.0.post0 python-dotenv-1.1.1 pytube-15.0.0 pytz-2025.2 pyvis-0.3.2 qdrant-client-1.15.1 referencing-0.36.2 regex-2025.7.34 requests-2.32.4 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-13.9.4 rpds-py-0.27.0 rsa-4.9.1 schema-0.7.7 shellingham-1.5.4 six-1.17.0 sniffio-1.3.1 soupsieve-2.7 sqlalchemy-2.0.43 stack_data-0.6.3 stagehand-0.5.0 starlette-0.47.2 sympy-1.14.0 tabulate-0.9.0 tenacity-9.1.2 tiktoken-0.11.0 tokenizers-0.20.3 tomli-2.2.1 tomli-w-1.2.0 tqdm-4.67.1 traitlets-5.14.3 typer-0.16.0 types-requests-2.32.4.20250809 typing-inspect-0.9.0 typing-inspection-0.4.1 typing_extensions-4.14.1 tzdata-2025.2 urllib3-2.5.0 uv-0.8.11 uvicorn-0.35.0 uvloop-0.21.0 watchfiles-1.1.0 wcwidth-0.2.13 websocket-client-1.8.0 websockets-15.0.1 wrapt-1.17.3 yarl-1.20.1 zipp-3.23.0 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "_cffi_backend",
                  "_openssl",
                  "aiohappyeyeballs",
                  "aiohttp",
                  "aiosignal",
                  "alembic",
                  "annotated_types",
                  "anthropic",
                  "anyio",
                  "appdirs",
                  "attr",
                  "attrs",
                  "backoff",
                  "bcrypt",
                  "blinker",
                  "browserbase",
                  "bs4",
                  "cachetools",
                  "certifi",
                  "chromadb",
                  "click",
                  "crewai",
                  "crewai_tools",
                  "cryptography",
                  "dateutil",
                  "decorator",
                  "distro",
                  "docker",
                  "dotenv",
                  "embedchain",
                  "frozenlist",
                  "google",
                  "gptcache",
                  "greenlet",
                  "grpc",
                  "h11",
                  "h2",
                  "hpack",
                  "httpcore",
                  "httpx",
                  "httpx_sse",
                  "hyperframe",
                  "idna",
                  "importlib_metadata",
                  "jedi",
                  "json5",
                  "jsonpatch",
                  "jsonpickle",
                  "jsonpointer",
                  "jsonschema",
                  "jsonschema_specifications",
                  "langchain",
                  "langchain_community",
                  "langchain_core",
                  "langchain_openai",
                  "langsmith",
                  "litellm",
                  "mako",
                  "markupsafe",
                  "matplotlib_inline",
                  "mem0",
                  "monotonic",
                  "multidict",
                  "networkx",
                  "numpy",
                  "onnxruntime",
                  "openai",
                  "opentelemetry",
                  "orjson",
                  "overrides",
                  "packaging",
                  "parso",
                  "pexpect",
                  "playwright",
                  "portalocker",
                  "posthog",
                  "prompt_toolkit",
                  "propcache",
                  "ptyprocess",
                  "pydantic",
                  "pydantic_settings",
                  "pyee",
                  "pysbd",
                  "pytz",
                  "pyvis",
                  "qdrant_client",
                  "referencing",
                  "regex",
                  "requests",
                  "requests_toolbelt",
                  "rich",
                  "rpds",
                  "schema",
                  "six",
                  "sniffio",
                  "soupsieve",
                  "stagehand",
                  "starlette",
                  "tenacity",
                  "tiktoken",
                  "tiktoken_ext",
                  "tokenizers",
                  "tqdm",
                  "traitlets",
                  "typing_extensions",
                  "typing_inspection",
                  "urllib3",
                  "uvicorn",
                  "watchfiles",
                  "wcwidth",
                  "yaml",
                  "yarl",
                  "zipp",
                  "zstandard"
                ]
              },
              "id": "24e1e623cf1444e68e47217d904077d1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install duckduckgo-search"
      ],
      "metadata": {
        "id": "qd8InLEKFftk"
      },
      "id": "qd8InLEKFftk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "from langchain_community.tools import DuckDuckGoSearchRun"
      ],
      "metadata": {
        "id": "JK3pZJkpEvgN"
      },
      "id": "JK3pZJkpEvgN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa070e4f04e64812969357b30b3dded9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e79c60db6d6e49b4b9dd2fce79b077ce",
              "IPY_MODEL_8e07de50dee64022bab9bb89d65b0e62",
              "IPY_MODEL_b734d0a2b1b54644b260289fcd519638"
            ],
            "layout": "IPY_MODEL_901d78fa01af48f39150b7cd9211d640"
          }
        },
        "e79c60db6d6e49b4b9dd2fce79b077ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_368896feb84443d480abf1c2fd824b78",
            "placeholder": "​",
            "style": "IPY_MODEL_87baece7378c43b49e104e92589db2f1",
            "value": "modules.json: 100%"
          }
        },
        "8e07de50dee64022bab9bb89d65b0e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8492ecd09aea459b9b2ba3d8b0687a89",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eea3c7b3cc8d4b518886c48282c42532",
            "value": 349
          }
        },
        "b734d0a2b1b54644b260289fcd519638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09ff64cd73e4658997c52700c4e4780",
            "placeholder": "​",
            "style": "IPY_MODEL_d9d6ea68178c491f93996770a79d74b9",
            "value": " 349/349 [00:00&lt;00:00, 6.55kB/s]"
          }
        },
        "901d78fa01af48f39150b7cd9211d640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "368896feb84443d480abf1c2fd824b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87baece7378c43b49e104e92589db2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8492ecd09aea459b9b2ba3d8b0687a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea3c7b3cc8d4b518886c48282c42532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e09ff64cd73e4658997c52700c4e4780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d6ea68178c491f93996770a79d74b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3116c5920d6e438db6da9ae3fa7f3c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d401a178b4340178743461dd5a7b135",
              "IPY_MODEL_6bb3b54987b048b08014249e6e9356c1",
              "IPY_MODEL_d00fcfcfa51342dd94adf0adb34aa74b"
            ],
            "layout": "IPY_MODEL_93c1e37b5ef34026a6f6107a5397b930"
          }
        },
        "4d401a178b4340178743461dd5a7b135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7a5ec7a173d4f0c8414be15b596fc54",
            "placeholder": "​",
            "style": "IPY_MODEL_173a9ca72c924d6f953d63aa03a3613d",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "6bb3b54987b048b08014249e6e9356c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f63d625530148118ad272c5535cd483",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b41db8e7f67b4a109ee6e1671f9a2084",
            "value": 124
          }
        },
        "d00fcfcfa51342dd94adf0adb34aa74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_798fec2a02734634861b375a59fcea0e",
            "placeholder": "​",
            "style": "IPY_MODEL_194b0a2a04654cc5894167c2d01c9a4f",
            "value": " 124/124 [00:00&lt;00:00, 3.81kB/s]"
          }
        },
        "93c1e37b5ef34026a6f6107a5397b930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7a5ec7a173d4f0c8414be15b596fc54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173a9ca72c924d6f953d63aa03a3613d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f63d625530148118ad272c5535cd483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b41db8e7f67b4a109ee6e1671f9a2084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "798fec2a02734634861b375a59fcea0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194b0a2a04654cc5894167c2d01c9a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6b13c541495473ca0d9d845041cbf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12a30fbdcead4a34b59755de1bd1fa24",
              "IPY_MODEL_2ec490d6c71343868f7e19924de14719",
              "IPY_MODEL_62142d0ab5ec4abeb022e39ed6bcd5b6"
            ],
            "layout": "IPY_MODEL_2f4f211da95a4341a868a359a0260a63"
          }
        },
        "12a30fbdcead4a34b59755de1bd1fa24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2cff5da294425792861fe1a52b6d8c",
            "placeholder": "​",
            "style": "IPY_MODEL_44c932d666854e3b9a8624b37b5c0988",
            "value": "README.md: "
          }
        },
        "2ec490d6c71343868f7e19924de14719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3e6655fccc94d31b0335b04461a5149",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb0c8bdbce674b778714996919d6b6c9",
            "value": 1
          }
        },
        "62142d0ab5ec4abeb022e39ed6bcd5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_159fb6c72f7e400ba480090ddb6eda90",
            "placeholder": "​",
            "style": "IPY_MODEL_478b204988054e898581b21783eda12c",
            "value": " 94.8k/? [00:00&lt;00:00, 3.70MB/s]"
          }
        },
        "2f4f211da95a4341a868a359a0260a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2cff5da294425792861fe1a52b6d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44c932d666854e3b9a8624b37b5c0988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3e6655fccc94d31b0335b04461a5149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bb0c8bdbce674b778714996919d6b6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "159fb6c72f7e400ba480090ddb6eda90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "478b204988054e898581b21783eda12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5dd2107fcde41af9cb05e98ed36bc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_414298d9d4dd46babdbcf109ba68d861",
              "IPY_MODEL_d80f442bf1cc4a80b764e560139bf59f",
              "IPY_MODEL_f65d17a2a8914e508c959aa790fa5c32"
            ],
            "layout": "IPY_MODEL_67286f44136849f1a9d44adc7d2a98ea"
          }
        },
        "414298d9d4dd46babdbcf109ba68d861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37964c9c7d7c42fa9e144c0746c881d2",
            "placeholder": "​",
            "style": "IPY_MODEL_3e600d9127bc413fb7c3ce35ad251df4",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "d80f442bf1cc4a80b764e560139bf59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_294c677b18f24585a1ca9d7aaaf09104",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1881ad181ed49fbbea185918e1d77e8",
            "value": 52
          }
        },
        "f65d17a2a8914e508c959aa790fa5c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e016e9d50f6a4cf8aa04bebb0e8f623f",
            "placeholder": "​",
            "style": "IPY_MODEL_d9fc31a2f179442e87e576331ff2f480",
            "value": " 52.0/52.0 [00:00&lt;00:00, 1.65kB/s]"
          }
        },
        "67286f44136849f1a9d44adc7d2a98ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37964c9c7d7c42fa9e144c0746c881d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e600d9127bc413fb7c3ce35ad251df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "294c677b18f24585a1ca9d7aaaf09104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1881ad181ed49fbbea185918e1d77e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e016e9d50f6a4cf8aa04bebb0e8f623f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9fc31a2f179442e87e576331ff2f480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4acdeb5d0c0f4de18fb3cf90961c1615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e76446c899544641bd515a2edb885868",
              "IPY_MODEL_8c3beaff7f364a5389080534a19325de",
              "IPY_MODEL_a00358bad8d7449ea14ab648bdb242a0"
            ],
            "layout": "IPY_MODEL_9269b26d0c4d4ce689e19a6b400e8268"
          }
        },
        "e76446c899544641bd515a2edb885868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_198a4ff2701b452a952e392cd2c8798c",
            "placeholder": "​",
            "style": "IPY_MODEL_37843c056719405b9bdc37d30554eaad",
            "value": "config.json: 100%"
          }
        },
        "8c3beaff7f364a5389080534a19325de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336ba232230a4856a55b160bc1019cb0",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_572fbd686339414ba7e0af32bb475824",
            "value": 743
          }
        },
        "a00358bad8d7449ea14ab648bdb242a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84013af070154220819ec2c547ab6b85",
            "placeholder": "​",
            "style": "IPY_MODEL_3712a03a62934ecdb351717153e1cef7",
            "value": " 743/743 [00:00&lt;00:00, 34.2kB/s]"
          }
        },
        "9269b26d0c4d4ce689e19a6b400e8268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "198a4ff2701b452a952e392cd2c8798c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37843c056719405b9bdc37d30554eaad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "336ba232230a4856a55b160bc1019cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572fbd686339414ba7e0af32bb475824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84013af070154220819ec2c547ab6b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3712a03a62934ecdb351717153e1cef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82db6eff1c3d4d968a7bd31b7cc9a44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3881eb8b1c2d40ad8566cc18c8b5884a",
              "IPY_MODEL_e19e3180750e4d4da70c76b1b4e6e020",
              "IPY_MODEL_d0386e21ae904f058648f9345b6b01fa"
            ],
            "layout": "IPY_MODEL_7f493618a9984a1c8262b4382a22f8bc"
          }
        },
        "3881eb8b1c2d40ad8566cc18c8b5884a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5ca658157e049a9a3db43ce67509b4a",
            "placeholder": "​",
            "style": "IPY_MODEL_f201c7491fce44fcaa0d7105486b25dd",
            "value": "model.safetensors: 100%"
          }
        },
        "e19e3180750e4d4da70c76b1b4e6e020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5e7977981047a99f6f7481849f3892",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15461705b62b4111bf9dcbe6ae147812",
            "value": 133466304
          }
        },
        "d0386e21ae904f058648f9345b6b01fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e251f864fd1640729ab20d133e7485c8",
            "placeholder": "​",
            "style": "IPY_MODEL_56a32a885f2840d489a68ac6b3ad14b4",
            "value": " 133M/133M [00:01&lt;00:00, 108MB/s]"
          }
        },
        "7f493618a9984a1c8262b4382a22f8bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ca658157e049a9a3db43ce67509b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f201c7491fce44fcaa0d7105486b25dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c5e7977981047a99f6f7481849f3892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15461705b62b4111bf9dcbe6ae147812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e251f864fd1640729ab20d133e7485c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a32a885f2840d489a68ac6b3ad14b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a591381686345e795dc11983b4eef66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89c9f2773c5040968cf7192311b88cc8",
              "IPY_MODEL_680f29d5caaa44d39c4de4c07b7b320c",
              "IPY_MODEL_5f997ede68c14b73bd8bc7ec52a7c82b"
            ],
            "layout": "IPY_MODEL_fbe134c0338d4028b4408c65961e5c3f"
          }
        },
        "89c9f2773c5040968cf7192311b88cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9549099fe3cf42dfb4500e9c5383a717",
            "placeholder": "​",
            "style": "IPY_MODEL_8b89e37b382342399008a61eed5e9f52",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "680f29d5caaa44d39c4de4c07b7b320c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89032d7948dd4e6b8a7a467ba155fa37",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7548373d0c34f928b3fe098997123a2",
            "value": 366
          }
        },
        "5f997ede68c14b73bd8bc7ec52a7c82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12d98f248d54262ad33b0497f7bf4e8",
            "placeholder": "​",
            "style": "IPY_MODEL_4ebecf5176674d2d97666a079e9840e3",
            "value": " 366/366 [00:00&lt;00:00, 27.7kB/s]"
          }
        },
        "fbe134c0338d4028b4408c65961e5c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9549099fe3cf42dfb4500e9c5383a717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b89e37b382342399008a61eed5e9f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89032d7948dd4e6b8a7a467ba155fa37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7548373d0c34f928b3fe098997123a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d12d98f248d54262ad33b0497f7bf4e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ebecf5176674d2d97666a079e9840e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53935062fe874677806af8c20f1975e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dbd7b22d0694525822125d2a680f3b6",
              "IPY_MODEL_7da0750672aa4e3185fa4af7fdf0f125",
              "IPY_MODEL_5703344a7f054915bb3fb0be9289a468"
            ],
            "layout": "IPY_MODEL_7ea033d608524472a92225824a45d89b"
          }
        },
        "4dbd7b22d0694525822125d2a680f3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed07cfd22dbf4294949ba4e7a5689768",
            "placeholder": "​",
            "style": "IPY_MODEL_d7ffd0d0fa454865aae1119f7d8d5b96",
            "value": "vocab.txt: "
          }
        },
        "7da0750672aa4e3185fa4af7fdf0f125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44a620ed155d49dbbcfb88f043131ee0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aedc4aa5883648a6abe1b594be8a9605",
            "value": 1
          }
        },
        "5703344a7f054915bb3fb0be9289a468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db681cf55cef48659d4ccd6e68f88d07",
            "placeholder": "​",
            "style": "IPY_MODEL_4373b830f19b4116a3e531c99e9f8bb9",
            "value": " 232k/? [00:00&lt;00:00, 10.2MB/s]"
          }
        },
        "7ea033d608524472a92225824a45d89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed07cfd22dbf4294949ba4e7a5689768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ffd0d0fa454865aae1119f7d8d5b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44a620ed155d49dbbcfb88f043131ee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "aedc4aa5883648a6abe1b594be8a9605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db681cf55cef48659d4ccd6e68f88d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4373b830f19b4116a3e531c99e9f8bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcb7a7eb70ed43df91872bfcc6a3e61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d5918a070e64d449fab8d9f29f24925",
              "IPY_MODEL_2ba5e8524d0d47e38b85678c4b3763fc",
              "IPY_MODEL_410072e2be534564ad989abad03f1a05"
            ],
            "layout": "IPY_MODEL_6de3b91a6c9243c490d13d41cb5e4c1c"
          }
        },
        "8d5918a070e64d449fab8d9f29f24925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2515bfdf05d34f7db49674330545e6ae",
            "placeholder": "​",
            "style": "IPY_MODEL_f8ea69401a3448cf81340b90eb7f5c79",
            "value": "tokenizer.json: "
          }
        },
        "2ba5e8524d0d47e38b85678c4b3763fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_761989f537844effbcd604baffb619d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5fafc8f42084a409e38b5edbccdb58b",
            "value": 1
          }
        },
        "410072e2be534564ad989abad03f1a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda2276cf6ff4fe6a7746e78f3980358",
            "placeholder": "​",
            "style": "IPY_MODEL_c30a383abebd409c96076d82d759990e",
            "value": " 711k/? [00:00&lt;00:00, 19.5MB/s]"
          }
        },
        "6de3b91a6c9243c490d13d41cb5e4c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2515bfdf05d34f7db49674330545e6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ea69401a3448cf81340b90eb7f5c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "761989f537844effbcd604baffb619d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c5fafc8f42084a409e38b5edbccdb58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eda2276cf6ff4fe6a7746e78f3980358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30a383abebd409c96076d82d759990e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "114fc3fd07494a72b4f4f9bddb59587c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2210f880a3a14187bccf1b9ac4b616c9",
              "IPY_MODEL_4f63d7e382774ead911a4f5ccc74b99a",
              "IPY_MODEL_c105084d964a4ffda834a3687b0d1dfe"
            ],
            "layout": "IPY_MODEL_a90773c4157144ea8ba9a8bd277b4770"
          }
        },
        "2210f880a3a14187bccf1b9ac4b616c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad4ed20ec4434d34807394a72424a628",
            "placeholder": "​",
            "style": "IPY_MODEL_e8a1bac07123457ca76732abc17bdac9",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4f63d7e382774ead911a4f5ccc74b99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98dd164cee5944a1b579ea1b40d784f4",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fad6c161c1a54e27a47314b8617d3456",
            "value": 125
          }
        },
        "c105084d964a4ffda834a3687b0d1dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab9ae44fb77e4a21a22fdda3a5f2b642",
            "placeholder": "​",
            "style": "IPY_MODEL_8232ad51582045b888b7a6a18a599f49",
            "value": " 125/125 [00:00&lt;00:00, 10.5kB/s]"
          }
        },
        "a90773c4157144ea8ba9a8bd277b4770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4ed20ec4434d34807394a72424a628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a1bac07123457ca76732abc17bdac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98dd164cee5944a1b579ea1b40d784f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad6c161c1a54e27a47314b8617d3456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab9ae44fb77e4a21a22fdda3a5f2b642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8232ad51582045b888b7a6a18a599f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81741d4021134eb494c20ef9f1089313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_829e50599faa414e8e2d923985a320d2",
              "IPY_MODEL_4a9d73d6ccf2498a8d63969a8be688a9",
              "IPY_MODEL_f1833cf9e5424c4a8c3564851a8ba207"
            ],
            "layout": "IPY_MODEL_78ce7a073d704514aa956556bde7bf22"
          }
        },
        "829e50599faa414e8e2d923985a320d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b6375180d341ca81676c7869cdcbc4",
            "placeholder": "​",
            "style": "IPY_MODEL_d4298114a1494cbcb2f480de6bf1a46e",
            "value": "config.json: 100%"
          }
        },
        "4a9d73d6ccf2498a8d63969a8be688a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d20750dbd5a41d191ccf4086aeeb87a",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_815d13cfbc3041c8b9ae37efebbdc355",
            "value": 190
          }
        },
        "f1833cf9e5424c4a8c3564851a8ba207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79d2333581724c49a99a46d98546e0b9",
            "placeholder": "​",
            "style": "IPY_MODEL_525a54bec62942398403e9d45f9fdc6a",
            "value": " 190/190 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "78ce7a073d704514aa956556bde7bf22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50b6375180d341ca81676c7869cdcbc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4298114a1494cbcb2f480de6bf1a46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d20750dbd5a41d191ccf4086aeeb87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "815d13cfbc3041c8b9ae37efebbdc355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79d2333581724c49a99a46d98546e0b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525a54bec62942398403e9d45f9fdc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}