# -*- coding: utf-8 -*-
"""suc_GLM-4.5-Air-GGUF_parts.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x2ENYjMenZ7LmKVRHM4SEZAV-FX0gE16
"""







!wget https://huggingface.co/unsloth/GLM-4.5-Air-GGUF/resolve/main/Q4_K_M/GLM-4.5-Air-Q4_K_M-00001-of-00002.gguf

!wget https://huggingface.co/unsloth/GLM-4.5-Air-GGUF/resolve/main/Q4_K_M/GLM-4.5-Air-Q4_K_M-00002-of-00002.gguf

!wget https://github.com/ggml-org/llama.cpp/releases/download/b6123/llama-b6123-bin-ubuntu-x64.zip

!unzip llama-b6123-bin-ubuntu-x64.zip

!build/bin/llama-cli -h

!/content/build/bin/llama-gguf-split -h

!/content/build/bin/llama-gguf-split --merge /content/GLM-4.5-Air-Q4_K_M-00001-of-00002.gguf

!/content/build/bin/llama-gguf-split --merge /content/GLM-4.5-Air-Q4_K_M-00001-of-00002.gguf GLM-4.5-Air-Q4_K_M.gguf

!/content/build/bin/llama-gguf-split --split-max-size 10G /content/GLM-4.5-Air-Q4_K_M.gguf /content/GLM-4.5-Air-Q4_K_M-split.gguf

from huggingface_hub import notebook_login
notebook_login()

from huggingface_hub import HfApi

# تهيئة الواجهة البرمجية
api = HfApi()

# تحديد المجلد المحلي واسم المستودع
folder_path = "/content/a"
repo_id = "rakmik/GLM-4.5-Air-GGUF_part5G"

# رفع المجلد
# سيتم رفع محتويات المجلد مباشرة إلى المستودع
api.upload_folder(
    folder_path=folder_path,
    repo_id=repo_id,
    repo_type="model"
)

print(f"تم رفع المجلد بنجاح إلى المستودع: https://huggingface.co/{repo_id}/tree/main")