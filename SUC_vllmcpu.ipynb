{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1db394233fa43899307fad2e46b8934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b16fa795b5714f7a965701d99fa5a6a9",
              "IPY_MODEL_58bdb957986541dfae7c96870683f0e3",
              "IPY_MODEL_e31352de146a4543a9943a4ffe7b7885"
            ],
            "layout": "IPY_MODEL_de1cf4db0965418893affdff728e4657"
          }
        },
        "b16fa795b5714f7a965701d99fa5a6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbc2f64073f241e788b0471c1a819fc4",
            "placeholder": "​",
            "style": "IPY_MODEL_767aff20608c4efab57c067b3c5b39c7",
            "value": "Adding requests: 100%"
          }
        },
        "58bdb957986541dfae7c96870683f0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5dcff209678465cabc3bf3e93ca3110",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_802c4974333d4337981fb0b12b1ceb3f",
            "value": 1
          }
        },
        "e31352de146a4543a9943a4ffe7b7885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efbce2f3117e4b7eb7af101d0c4cae2c",
            "placeholder": "​",
            "style": "IPY_MODEL_b0461e28d9fd408ca24c61176ac56288",
            "value": " 1/1 [00:00&lt;00:00,  9.26it/s]"
          }
        },
        "de1cf4db0965418893affdff728e4657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbc2f64073f241e788b0471c1a819fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "767aff20608c4efab57c067b3c5b39c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5dcff209678465cabc3bf3e93ca3110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "802c4974333d4337981fb0b12b1ceb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efbce2f3117e4b7eb7af101d0c4cae2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0461e28d9fd408ca24c61176ac56288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22fd0008f1464101af99c34b8a45b409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4de452e80eb4dda94d8b4b60914d161",
              "IPY_MODEL_88e684e7311d49c1a3349e81fb5ebea2",
              "IPY_MODEL_d349d312108745eca23204d198667a33"
            ],
            "layout": "IPY_MODEL_65482ce7b6eb4dcf8e5b9759391cb15c"
          }
        },
        "a4de452e80eb4dda94d8b4b60914d161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8227e7243ce64a4288dc5918f11ff8cd",
            "placeholder": "​",
            "style": "IPY_MODEL_207e4474a1e4468da07fc5882a9a3068",
            "value": "Processed prompts: 100%"
          }
        },
        "88e684e7311d49c1a3349e81fb5ebea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5ae18af56a471ebfe85f5768f4bbaa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05ec6172671440fd8c8cdc6d7e52ecf9",
            "value": 1
          }
        },
        "d349d312108745eca23204d198667a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_609cd13afa714ebaaa167fad49af815c",
            "placeholder": "​",
            "style": "IPY_MODEL_458e7f4658254ed09d8384d83933bb44",
            "value": " 1/1 [00:01&lt;00:00,  1.22s/it, est. speed input: 4.91 toks/s, output: 13.10 toks/s]"
          }
        },
        "65482ce7b6eb4dcf8e5b9759391cb15c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8227e7243ce64a4288dc5918f11ff8cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "207e4474a1e4468da07fc5882a9a3068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c5ae18af56a471ebfe85f5768f4bbaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ec6172671440fd8c8cdc6d7e52ecf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "609cd13afa714ebaaa167fad49af815c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458e7f4658254ed09d8384d83933bb44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "160fe0dd4b264d47831c5f554060fa4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5730cbd9f21841aca8f61729349030fc",
              "IPY_MODEL_b6081c134a094923ae1e2a2bcab381de",
              "IPY_MODEL_99a0b8a1ebab484ba5a77f07ddaa5ce3"
            ],
            "layout": "IPY_MODEL_e1f27c991dce47099655d9740e5adf9a"
          }
        },
        "5730cbd9f21841aca8f61729349030fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21d3e513d7834142b0cf433388273ef1",
            "placeholder": "​",
            "style": "IPY_MODEL_3bdad1c10a4a4ca392bcd433c01238ff",
            "value": "Adding requests: 100%"
          }
        },
        "b6081c134a094923ae1e2a2bcab381de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7f2783e1d64f5f81ae9e0f2511a182",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaf9bb6c171741c9867df0cfd5ae08df",
            "value": 4
          }
        },
        "99a0b8a1ebab484ba5a77f07ddaa5ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5497467f238d48b8b113446dd75ace4f",
            "placeholder": "​",
            "style": "IPY_MODEL_c43fe18d4e1b4f44b41367734ee516e6",
            "value": " 4/4 [00:00&lt;00:00, 162.96it/s]"
          }
        },
        "e1f27c991dce47099655d9740e5adf9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d3e513d7834142b0cf433388273ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bdad1c10a4a4ca392bcd433c01238ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e7f2783e1d64f5f81ae9e0f2511a182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf9bb6c171741c9867df0cfd5ae08df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5497467f238d48b8b113446dd75ace4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43fe18d4e1b4f44b41367734ee516e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "652f0cdcbe434d939f1865d97030f793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83ecb9f98f744dc79ace01f5f31bf950",
              "IPY_MODEL_533896b7ee584251aa6182749fbda9c0",
              "IPY_MODEL_51ad4ca0fecd411cac0c4778189027bf"
            ],
            "layout": "IPY_MODEL_e3b9f0b62cb540d69f51c8628c0cb125"
          }
        },
        "83ecb9f98f744dc79ace01f5f31bf950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c2b15e10a5a4300b6bf835986fb5ad0",
            "placeholder": "​",
            "style": "IPY_MODEL_268cad636f6c4d8a99140c22b2d978ad",
            "value": "Processed prompts: 100%"
          }
        },
        "533896b7ee584251aa6182749fbda9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_842d7c0393204c99b7d8f66b57b23c23",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64541266cc1c4a30a4dd505b36e40c49",
            "value": 4
          }
        },
        "51ad4ca0fecd411cac0c4778189027bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb87852fcc6a4884aa1e9a5d039484bd",
            "placeholder": "​",
            "style": "IPY_MODEL_f1d894247278493db9f62fdfc9d9de74",
            "value": " 4/4 [00:02&lt;00:00,  1.24s/it, est. speed input: 8.79 toks/s, output: 21.64 toks/s]"
          }
        },
        "e3b9f0b62cb540d69f51c8628c0cb125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "3c2b15e10a5a4300b6bf835986fb5ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268cad636f6c4d8a99140c22b2d978ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "842d7c0393204c99b7d8f66b57b23c23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64541266cc1c4a30a4dd505b36e40c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb87852fcc6a4884aa1e9a5d039484bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1d894247278493db9f62fdfc9d9de74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb4973Lzt8OH",
        "outputId": "6770a085-44c3-4973-dfc9-7d30153a4721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,918 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 2,307 kB in 3s (873 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libgl1 is already the newest version (1.4.0-1).\n",
            "libnuma-dev is already the newest version (2.0.14-3ubuntu2).\n",
            "libnuma-dev set to manually installed.\n",
            "libsm6 is already the newest version (2:1.2.3-1build2).\n",
            "libtcmalloc-minimal4 is already the newest version (2.9.1-0ubuntu3).\n",
            "libtcmalloc-minimal4 set to manually installed.\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "lsof is already the newest version (4.93.2+dfsg-1.1build2).\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
            "jq is already the newest version (1.6-2.1ubuntu3.1).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  cpp-12 libasan8 libgcc-12-dev libhiredis0.14 libstdc++-12-dev libtsan2\n",
            "Suggested packages:\n",
            "  distcc | icecc gcc-12-locales cpp-12-doc g++-12-multilib gcc-12-doc\n",
            "  gcc-12-multilib libstdc++-12-doc\n",
            "The following NEW packages will be installed:\n",
            "  ccache cpp-12 g++-12 gcc-12 libasan8 libgcc-12-dev libhiredis0.14\n",
            "  libstdc++-12-dev libtsan2\n",
            "0 upgraded, 9 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 55.0 MB of archives.\n",
            "After this operation, 198 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhiredis0.14 amd64 0.14.1-2 [32.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ccache amd64 4.5.1-1 [495 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 cpp-12 amd64 12.3.0-1ubuntu1~22.04 [10.8 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libasan8 amd64 12.3.0-1ubuntu1~22.04 [2,442 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtsan2 amd64 12.3.0-1ubuntu1~22.04 [2,477 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgcc-12-dev amd64 12.3.0-1ubuntu1~22.04 [2,618 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gcc-12 amd64 12.3.0-1ubuntu1~22.04 [21.7 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libstdc++-12-dev amd64 12.3.0-1ubuntu1~22.04 [2,192 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 g++-12 amd64 12.3.0-1ubuntu1~22.04 [12.2 MB]\n",
            "Fetched 55.0 MB in 3s (19.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libhiredis0.14:amd64.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libhiredis0.14_0.14.1-2_amd64.deb ...\n",
            "Unpacking libhiredis0.14:amd64 (0.14.1-2) ...\n",
            "Selecting previously unselected package ccache.\n",
            "Preparing to unpack .../1-ccache_4.5.1-1_amd64.deb ...\n",
            "Unpacking ccache (4.5.1-1) ...\n",
            "Selecting previously unselected package cpp-12.\n",
            "Preparing to unpack .../2-cpp-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libasan8:amd64.\n",
            "Preparing to unpack .../3-libasan8_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libtsan2:amd64.\n",
            "Preparing to unpack .../4-libtsan2_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libgcc-12-dev:amd64.\n",
            "Preparing to unpack .../5-libgcc-12-dev_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package gcc-12.\n",
            "Preparing to unpack .../6-gcc-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package libstdc++-12-dev:amd64.\n",
            "Preparing to unpack .../7-libstdc++-12-dev_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking libstdc++-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package g++-12.\n",
            "Preparing to unpack .../8-g++-12_12.3.0-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking g++-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up cpp-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libasan8:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libtsan2:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libhiredis0.14:amd64 (0.14.1-2) ...\n",
            "Setting up ccache (4.5.1-1) ...\n",
            "Updating symlinks in /usr/lib/ccache ...\n",
            "Setting up libgcc-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up libstdc++-12-dev:amd64 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up gcc-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Setting up g++-12 (12.3.0-1ubuntu1~22.04) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "update-alternatives: using /usr/bin/gcc-12 to provide /usr/bin/gcc (gcc) in auto mode\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update  -y\n",
        "!sudo apt-get install -y --no-install-recommends ccache git curl wget ca-certificates gcc-12 g++-12 libtcmalloc-minimal4 libnuma-dev ffmpeg libsm6 libxext6 libgl1 jq lsof\n",
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update  -y\n",
        "!sudo apt-get install -y --no-install-recommends ccache git curl wget ca-certificates gcc-12 g++-12 libtcmalloc-minimal4 libnuma-dev ffmpeg libsm6 libxext6 libgl1 jq lsof\n",
        "!sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xzBUs1EuWZF",
        "outputId": "d1089d63-5950-4d0b-9b90-776b3abaf0b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libgl1 is already the newest version (1.4.0-1).\n",
            "libnuma-dev is already the newest version (2.0.14-3ubuntu2).\n",
            "libsm6 is already the newest version (2:1.2.3-1build2).\n",
            "libtcmalloc-minimal4 is already the newest version (2.9.1-0ubuntu3).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "lsof is already the newest version (4.93.2+dfsg-1.1build2).\n",
            "ccache is already the newest version (4.5.1-1).\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "gcc-12 is already the newest version (12.3.0-1ubuntu1~22.04).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
            "jq is already the newest version (1.6-2.1ubuntu3.1).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "g++-12 is already the newest version (12.3.0-1ubuntu1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vllm-project/vllm.git vllm_source\n",
        "%cd vllm_source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Qth_Iru1WF",
        "outputId": "45064aff-e044-4916-e584-aee534ffdc77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vllm_source'...\n",
            "remote: Enumerating objects: 98001, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 98001 (delta 77), reused 23 (delta 23), pack-reused 97865 (from 3)\u001b[K\n",
            "Receiving objects: 100% (98001/98001), 69.41 MiB | 23.81 MiB/s, done.\n",
            "Resolving deltas: 100% (77391/77391), done.\n",
            "/content/vllm_source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -r requirements/cpu-build.txt --torch-backend auto\n",
        "!uv pip install -r requirements/cpu.txt --torch-backend auto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7LtJTtzuYAM",
        "outputId": "fc36ceca-93d4-4d7b-eb8d-1adc6c668178"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--torch-backend` setting is experimental and may change without warning. Pass `--preview` to disable this warning.\u001b[0m\n",
            "\u001b[2K  \u001b[31m×\u001b[0m No solution found when resolving dependencies:\n",
            "\u001b[31m  ╰─▶ \u001b[0mBecause only setuptools<=70.2.0 is available and you require\n",
            "\u001b[31m      \u001b[0msetuptools>=77.0.3,<80.0.0, we can conclude that your requirements are\n",
            "\u001b[31m      \u001b[0munsatisfiable.\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m `\u001b[36msetuptools\u001b[39m` was found on \u001b[36mhttps://download.pytorch.org/whl/cpu\u001b[39m,\n",
            "\u001b[31m      \u001b[0mbut not at the requested version (\u001b[36msetuptools>=77.0.3,<80.0.0\u001b[39m). A\n",
            "\u001b[31m      \u001b[0mcompatible version may be available on a subsequent index (e.g.,\n",
            "\u001b[31m      \u001b[0m\u001b[36mhttps://pypi.org/simple\u001b[39m). By default, uv will only consider versions\n",
            "\u001b[31m      \u001b[0mthat are published on the first index that contains a given package, to\n",
            "\u001b[31m      \u001b[0mavoid dependency confusion attacks. If all indexes are equally trusted,\n",
            "\u001b[31m      \u001b[0muse `\u001b[32m--index-strategy unsafe-best-match\u001b[39m` to consider all versions from\n",
            "\u001b[31m      \u001b[0mall indexes, regardless of the order in which they were defined.\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--torch-backend` setting is experimental and may change without warning. Pass `--preview` to disable this warning.\u001b[0m\n",
            "\u001b[2K  \u001b[31m×\u001b[0m No solution found when resolving dependencies:\n",
            "\u001b[31m  ╰─▶ \u001b[0mBecause there is no version of intel-openmp{platform_machine ==\n",
            "\u001b[31m      \u001b[0m'x86_64'}==2024.2.1 and you require intel-openmp{platform_machine\n",
            "\u001b[31m      \u001b[0m== 'x86_64'}==2024.2.1, we can conclude that your requirements are\n",
            "\u001b[31m      \u001b[0munsatisfiable.\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m `\u001b[36mintel-openmp\u001b[39m` was found on \u001b[36mhttps://download.pytorch.org/whl/cpu\u001b[39m,\n",
            "\u001b[31m      \u001b[0mbut not at the requested version (\u001b[36mintel-openmp==2024.2.1\u001b[39m). A\n",
            "\u001b[31m      \u001b[0mcompatible version may be available on a subsequent index (e.g.,\n",
            "\u001b[31m      \u001b[0m\u001b[36mhttps://pypi.org/simple\u001b[39m). By default, uv will only consider versions\n",
            "\u001b[31m      \u001b[0mthat are published on the first index that contains a given package, to\n",
            "\u001b[31m      \u001b[0mavoid dependency confusion attacks. If all indexes are equally trusted,\n",
            "\u001b[31m      \u001b[0muse `\u001b[32m--index-strategy unsafe-best-match\u001b[39m` to consider all versions from\n",
            "\u001b[31m      \u001b[0mall indexes, regardless of the order in which they were defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install cmake>=3.26.1 wheel packaging ninja setuptools-scm>=8 numpy\n",
        "!pip install -v -r requirements/cpu.txt \\\n",
        "    --extra-index-url https://download.pytorch.org/whl/cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MpXjW4a5vbSN",
        "outputId": "a32a746a-bc54-46be-8a13-a3e39c1ff3a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Using pip 25.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu\n",
            "Ignoring importlib_metadata: markers 'python_version < \"3.10\"' don't match your environment\n",
            "Ignoring six: markers 'python_version > \"3.11\"' don't match your environment\n",
            "Ignoring setuptools: markers 'python_version > \"3.11\"' don't match your environment\n",
            "Ignoring numba: markers 'python_version == \"3.9\"' don't match your environment\n",
            "Ignoring torch: markers 'platform_system == \"Darwin\"' don't match your environment\n",
            "Ignoring torch: markers 'platform_machine == \"ppc64le\"' don't match your environment\n",
            "Ignoring torch: markers 'platform_machine == \"aarch64\"' don't match your environment\n",
            "Ignoring torchaudio: markers 'platform_machine == \"ppc64le\"' don't match your environment\n",
            "Ignoring torchvision: markers 'platform_machine == \"ppc64le\"' don't match your environment\n",
            "Ignoring py-cpuinfo: markers 'platform_machine == \"aarch64\"' don't match your environment\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 2)) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 7)) (4.67.1)\n",
            "Collecting blake3 (from -r /content/vllm_source/requirements/common.txt (line 8))\n",
            "  Obtaining dependency information for blake3 from https://files.pythonhosted.org/packages/63/fc/d9a91e69e52f8ddabbad30a68a4185644c30fd26e33605120a185438c458/blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 9)) (9.0.0)\n",
            "Collecting transformers>=4.55.0 (from -r /content/vllm_source/requirements/common.txt (line 10))\n",
            "  Obtaining dependency information for transformers>=4.55.0 from https://files.pythonhosted.org/packages/1c/93/bcb22fb52ed65084c0199270832aa4cdd4b41296d896f3e7ade188bccb68/transformers-4.55.0-py3-none-any.whl.metadata\n",
            "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.33.0->-r /content/vllm_source/requirements/common.txt (line 11)) (0.34.3)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 12)) (0.21.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 13)) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (0.116.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 15)) (3.12.15)\n",
            "Requirement already satisfied: openai>=1.98.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 16)) (1.98.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 17)) (2.11.7)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 18)) (0.22.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 19)) (11.3.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from -r /content/vllm_source/requirements/common.txt (line 20))\n",
            "  Obtaining dependency information for prometheus-fastapi-instrumentator>=7.0.0 from https://files.pythonhosted.org/packages/27/72/0824c18f3bc75810f55dacc2dd933f6ec829771180245ae3cc976195dec0/prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 21)) (0.9.0)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.11 (from -r /content/vllm_source/requirements/common.txt (line 22))\n",
            "  Obtaining dependency information for lm-format-enforcer<0.11,>=0.10.11 from https://files.pythonhosted.org/packages/57/1c/7bb80fe2dff9a9c38b180571ca867f518eb9110f79d4b670ea124e153680/lm_format_enforcer-0.10.12-py3-none-any.whl.metadata\n",
            "  Downloading lm_format_enforcer-0.10.12-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<0.8.0,>=0.7.11 (from -r /content/vllm_source/requirements/common.txt (line 23))\n",
            "  Obtaining dependency information for llguidance<0.8.0,>=0.7.11 from https://files.pythonhosted.org/packages/af/80/5a40b9689f17612434b820854cba9b8cabd5142072c491b5280fe5f7a35e/llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting outlines_core==0.2.10 (from -r /content/vllm_source/requirements/common.txt (line 24))\n",
            "  Obtaining dependency information for outlines_core==0.2.10 from https://files.pythonhosted.org/packages/b5/5f/e3c4589f1814a5d50c3b1b95ef2ff151c9e6e6d5c5ab62e07078410b1c6a/outlines_core-0.2.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading outlines_core-0.2.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting diskcache==5.6.3 (from -r /content/vllm_source/requirements/common.txt (line 26))\n",
            "  Obtaining dependency information for diskcache==5.6.3 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lark==1.2.2 (from -r /content/vllm_source/requirements/common.txt (line 27))\n",
            "  Obtaining dependency information for lark==1.2.2 from https://files.pythonhosted.org/packages/2d/00/d90b10b962b4277f5e64a78b6609968859ff86889f5b898c1a778c06ec00/lark-1.2.2-py3-none-any.whl.metadata\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.21 (from -r /content/vllm_source/requirements/common.txt (line 28))\n",
            "  Obtaining dependency information for xgrammar==0.1.21 from https://files.pythonhosted.org/packages/07/67/e60c49fa74f5a5d86601a26d9938341d5903595fd98cd470d24ac86db2f0/xgrammar-0.1.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading xgrammar-0.1.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 29)) (4.14.1)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 30)) (3.18.0)\n",
            "Collecting partial-json-parser (from -r /content/vllm_source/requirements/common.txt (line 31))\n",
            "  Obtaining dependency information for partial-json-parser from https://files.pythonhosted.org/packages/cb/40/1f922794af3dc7503f19319a8804b398a161a2cd54183cff8b12225b8d85/partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata\n",
            "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 32)) (26.2.1)\n",
            "Collecting msgspec (from -r /content/vllm_source/requirements/common.txt (line 33))\n",
            "  Obtaining dependency information for msgspec from https://files.pythonhosted.org/packages/85/2e/db7e189b57901955239f7689b5dcd6ae9458637a9c66747326726c650523/msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf>=0.13.0 (from -r /content/vllm_source/requirements/common.txt (line 34))\n",
            "  Obtaining dependency information for gguf>=0.13.0 from https://files.pythonhosted.org/packages/fc/31/6a93a887617ee7deeaa602ca3d02d1c12a6cb8a742a695de5d128f5fa46a/gguf-0.17.1-py3-none-any.whl.metadata\n",
            "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36))\n",
            "  Obtaining dependency information for mistral_common>=1.8.2 from https://files.pythonhosted.org/packages/c8/23/bfc9da018375ea1bf31cf94f325d98904003cd6891007ae900d70fc7bcf9/mistral_common-1.8.3-py3-none-any.whl.metadata\n",
            "  Downloading mistral_common-1.8.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 37)) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 38)) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 41)) (0.8.1)\n",
            "Collecting compressed-tensors==0.10.2 (from -r /content/vllm_source/requirements/common.txt (line 42))\n",
            "  Obtaining dependency information for compressed-tensors==0.10.2 from https://files.pythonhosted.org/packages/43/ac/56bb4b6b3150783119479e2f05e32ebfc39ca6ff8e6fcd45eb178743b39e/compressed_tensors-0.10.2-py3-none-any.whl.metadata\n",
            "  Downloading compressed_tensors-0.10.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.19.0 (from -r /content/vllm_source/requirements/common.txt (line 43))\n",
            "  Obtaining dependency information for depyf==0.19.0 from https://files.pythonhosted.org/packages/28/4d/1192acbcdc5e843f5e5d51f6e8788f2b60a9fe0b578ac385ded67a0b0b26/depyf-0.19.0-py3-none-any.whl.metadata\n",
            "  Downloading depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 44)) (3.1.1)\n",
            "Collecting watchfiles (from -r /content/vllm_source/requirements/common.txt (line 45))\n",
            "  Obtaining dependency information for watchfiles from https://files.pythonhosted.org/packages/2b/a1/ec0a606bde4853d6c4a578f9391eeb3684a9aea736a8eb217e3e00aa89a1/watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting python-json-logger (from -r /content/vllm_source/requirements/common.txt (line 46))\n",
            "  Obtaining dependency information for python-json-logger from https://files.pythonhosted.org/packages/08/20/0f2523b9e50a8052bc6a8b732dfc8568abbdc42010aef03a2d750bdab3b2/python_json_logger-3.3.0-py3-none-any.whl.metadata\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 47)) (1.16.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from -r /content/vllm_source/requirements/common.txt (line 48)) (1.11.1.4)\n",
            "Collecting pybase64 (from -r /content/vllm_source/requirements/common.txt (line 49))\n",
            "  Obtaining dependency information for pybase64 from https://files.pythonhosted.org/packages/29/9b/6ed2dd2bc8007f33b8316d6366b0901acbdd5665b419c2893b3dd48708de/pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata\n",
            "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting cbor2 (from -r /content/vllm_source/requirements/common.txt (line 50))\n",
            "  Obtaining dependency information for cbor2 from https://files.pythonhosted.org/packages/e1/84/e177d9bef4749d14f31c513b25e341ac84e403e2ffa2bde562eac9e6184b/cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting setproctitle (from -r /content/vllm_source/requirements/common.txt (line 51))\n",
            "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/cc/41/fbf57ec52f4f0776193bd94334a841f0bc9d17e745f89c7790f336420c65/setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting openai-harmony>=0.0.3 (from -r /content/vllm_source/requirements/common.txt (line 52))\n",
            "  Obtaining dependency information for openai-harmony>=0.0.3 from https://files.pythonhosted.org/packages/20/54/0354d74cdaedc67fe59bd091c30ef5a63768354c439af3bc6eb7a5bfabcb/openai_harmony-0.0.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading openai_harmony-0.0.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.6,<3.9'): https://files.pythonhosted.org/packages/d1/68/d872f91bcb57c00c54835beb950a9d9ceb99e497f167fa333e8eba968ecc/numba-0.52.0rc3.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.9)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.6,<3.9'): https://files.pythonhosted.org/packages/46/e1/cbbc7c7967d9b10e54c852bf5bece0222a63bfb809d3354014c957ef1bda/numba-0.52.0.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.9)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/c8/e6/681c43623f362d6c504eb29944184c0df6357be10ed2fad6071fd1b7e143/numba-0.53.0rc1.post1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/d4/b2/d6e507259f4630b319811b57c2bb3364d2737ae297a972a055cf40df36a5/numba-0.53.0rc2.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/5e/ef/d761365ea63f28b85574069e953664e9fe218d50b85b3f84849ebecf953c/numba-0.53.0rc3.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/b0/6d/bb1204879726d6db6dc92de995bdbd64792369f0be3f8a36710cc2d93f78/numba-0.53.0.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/e3/7d/3d61160836e49f40913741c464f119551c15ed371c1d91ea50308495b93b/numba-0.53.1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.6,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/f2/76/00e4f3443c093f6064044357b8f07abde5ed7a15d6c43988a68c184b62a5/numba-0.54.0rc2.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/ec/74/f6ff055664ac01adac37ad8f5ab5c94d75badfd264fdab209e0f5f1fafef/numba-0.54.0rc3.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/24/66/4720b6f70b42c74f10296a9803f8ba28c284f55cee6839f457bc67588277/numba-0.54.0.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/d3/93/05c88fc9f17655a93428f49646d1086c8b2b98e8531033f13f3fe464fae5/numba-0.54.1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/05/d9/5a3bc6549fe7ea8336f06cd72dac0ad69b18c8089930e560467cf9de359d/numba-0.55.0rc1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.11)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/cf/e2/8213c08fc9392c99b37de9823119a83576469354154eb08ad653b6ab5213/numba-0.55.0.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.11)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/69/df/bd36068b2c1d0d34794f8ac0c222f9c4ad88dc710b400e65dbb3b59ea57e/numba-0.55.1.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.11)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/39/dd/7109030bb584e8f0c4c8796bfd39fc5811cb77368a8c5db335f99c1fec9e/numba-0.55.2.tar.gz (from https://pypi.org/simple/numba/) (requires-python:>=3.7,<3.11)\n",
            "Collecting numba==0.61.2 (from -r requirements/cpu.txt (line 5))\n",
            "  Obtaining dependency information for numba==0.61.2 from https://files.pythonhosted.org/packages/97/c8/8740616c8436c86c1b9a62e72cb891177d2c34c2d24ddcde4c390371bf4c/numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 8)) (25.0)\n",
            "Collecting setuptools<80.0.0,>=77.0.3 (from -r requirements/cpu.txt (line 9))\n",
            "  Obtaining dependency information for setuptools<80.0.0,>=77.0.3 from https://files.pythonhosted.org/packages/0d/6d/b4752b044bf94cb802d88a888dc7d288baaf77d7910b7dedda74b5ceea0c/setuptools-79.0.1-py3-none-any.whl.metadata\n",
            "  Downloading setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting torch==2.6.0+cpu (from -r requirements/cpu.txt (line 11))\n",
            "  Obtaining dependency information for torch==2.6.0+cpu from https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl.metadata\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 17)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 21)) (0.21.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 23)) (4.0.0)\n",
            "Collecting intel-openmp==2024.2.1 (from -r requirements/cpu.txt (line 26))\n",
            "  Obtaining dependency information for intel-openmp==2024.2.1 from https://files.pythonhosted.org/packages/78/2d/64570ae938a8ee2337ed8ba28ae1d85d3555ee6e5faadabea9e8b43a900d/intel_openmp-2024.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading intel_openmp-2024.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting intel_extension_for_pytorch==2.6.0 (from -r requirements/cpu.txt (line 27))\n",
            "  Obtaining dependency information for intel_extension_for_pytorch==2.6.0 from https://files.pythonhosted.org/packages/e4/d3/11fd732ce163b7e8b0ada01973a601d25583176390d70f119789a485ad37/intel_extension_for_pytorch-2.6.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading intel_extension_for_pytorch-2.6.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 28)) (3.2.0)\n",
            "Collecting astor (from depyf==0.19.0->-r /content/vllm_source/requirements/common.txt (line 43))\n",
            "  Obtaining dependency information for astor from https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl.metadata\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->-r /content/vllm_source/requirements/common.txt (line 43)) (0.3.8)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.6,<3.10'): https://files.pythonhosted.org/packages/19/66/6b2c49c7c68da48d17059882fdb9ad9ac9e5ac3f22b00874d7996e3c44a8/llvmlite-0.36.0.tar.gz (from https://pypi.org/simple/llvmlite/) (requires-python:>=3.6,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.10'): https://files.pythonhosted.org/packages/55/21/f7df5d35f3f5d0637d64a89f6b0461f2adf78e22916d6372486f8fc2193d/llvmlite-0.37.0.tar.gz (from https://pypi.org/simple/llvmlite/) (requires-python:>=3.7,<3.10)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/d8/e3/bd329a96549809598acd5daaccd35fd9d0883185cfe7f681a9e3e54beaa0/llvmlite-0.38.0.tar.gz (from https://pypi.org/simple/llvmlite/) (requires-python:>=3.7,<3.11)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/90/fc/313c916fb49495ac7c1f9ab213cd3d3285342691b860a2810a51c6c1a10e/llvmlite-0.38.1.tar.gz (from https://pypi.org/simple/llvmlite/) (requires-python:>=3.7,<3.11)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->-r requirements/cpu.txt (line 5))\n",
            "  Obtaining dependency information for llvmlite<0.45,>=0.44.0dev0 from https://files.pythonhosted.org/packages/99/fe/d030f1849ebb1f394bb3f7adad5e729b634fb100515594aca25c354ffc62/llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (1.13.1)\n",
            "Collecting intel-cmplr-lib-ur==2024.2.1 (from intel-openmp==2024.2.1->-r requirements/cpu.txt (line 26))\n",
            "  Obtaining dependency information for intel-cmplr-lib-ur==2024.2.1 from https://files.pythonhosted.org/packages/d4/d9/bfa66a5060f48d40c0698cfe19f1c803ea9f0e60ac4872463ba4dc96542b/intel_cmplr_lib_ur-2024.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading intel_cmplr_lib_ur-2024.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (1.3.0)\n",
            "Collecting interegular>=0.3.2 (from lm-format-enforcer<0.11,>=0.10.11->-r /content/vllm_source/requirements/common.txt (line 22))\n",
            "  Obtaining dependency information for interegular>=0.3.2 from https://files.pythonhosted.org/packages/c4/01/72d6472f80651673716d1deda2a5bbb633e563ecf94f4479da5519d69d25/interegular-0.3.3-py37-none-any.whl.metadata\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r /content/vllm_source/requirements/common.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r /content/vllm_source/requirements/common.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r /content/vllm_source/requirements/common.txt (line 6)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r /content/vllm_source/requirements/common.txt (line 6)) (2025.7.14)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->-r /content/vllm_source/requirements/common.txt (line 10)) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->-r /content/vllm_source/requirements/common.txt (line 11)) (1.1.5)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (0.47.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->-r /content/vllm_source/requirements/common.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->-r /content/vllm_source/requirements/common.txt (line 17)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->-r /content/vllm_source/requirements/common.txt (line 17)) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/vllm_source/requirements/common.txt (line 15)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/vllm_source/requirements/common.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/vllm_source/requirements/common.txt (line 15)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/vllm_source/requirements/common.txt (line 15)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/vllm_source/requirements/common.txt (line 15)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/vllm_source/requirements/common.txt (line 15)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/vllm_source/requirements/common.txt (line 15)) (1.20.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.98.0->-r /content/vllm_source/requirements/common.txt (line 16)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.98.0->-r /content/vllm_source/requirements/common.txt (line 16)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.98.0->-r /content/vllm_source/requirements/common.txt (line 16)) (0.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.98.0->-r /content/vllm_source/requirements/common.txt (line 16)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.98.0->-r /content/vllm_source/requirements/common.txt (line 16)) (0.16.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36)) (4.25.0)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36))\n",
            "  Obtaining dependency information for pydantic-extra-types>=2.10.5 from https://files.pythonhosted.org/packages/70/1a/5f4fd9e7285f10c44095a4f9fe17d0f358d1702a7c74a9278c794e8a7537/pydantic_extra_types-2.10.5-py3-none-any.whl.metadata\n",
            "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/cpu.txt (line 23)) (18.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/cpu.txt (line 23)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/cpu.txt (line 23)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/cpu.txt (line 23)) (0.70.16)\n",
            "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14))\n",
            "  Obtaining dependency information for fastapi-cli>=0.0.8 from https://files.pythonhosted.org/packages/e0/3f/6ad3103c5f59208baf4c798526daea6a74085bb35d1c161c501863470476/fastapi_cli-0.0.8-py3-none-any.whl.metadata\n",
            "  Downloading fastapi_cli-0.0.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (0.0.20)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14))\n",
            "  Obtaining dependency information for email-validator>=2.0.0 from https://files.pythonhosted.org/packages/d7/ee/bf0adb559ad3c786f12bcbc9296b3f5675f529199bef03e2df281fa1fadb/email_validator-2.2.0-py3-none-any.whl.metadata\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (0.35.0)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14))\n",
            "  Obtaining dependency information for dnspython>=2.0.0 from https://files.pythonhosted.org/packages/68/1b/e0a87d256e40e8c888847551b20a017a6b98139178505dc7ffb96f04e954/dnspython-2.7.0-py3-none-any.whl.metadata\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (0.16.0)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.12'): https://files.pythonhosted.org/packages/c4/54/562d3fd758ae3b8318b6534db56e0fd57c73a0caf9b1186aa069aa20d4af/rich_toolkit-0.1.0-py3-none-any.whl (from https://pypi.org/simple/rich-toolkit/) (requires-python:>=3.12)\n",
            "  Link requires a different Python (3.11.13 not in: '>=3.12'): https://files.pythonhosted.org/packages/70/ba/a15e45b87e6e8597845945e153cef21002607d45d217b389eab9ea0a682c/rich_toolkit-0.1.0.tar.gz (from https://pypi.org/simple/rich-toolkit/) (requires-python:>=3.12)\n",
            "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14))\n",
            "  Obtaining dependency information for rich-toolkit>=0.14.8 from https://files.pythonhosted.org/packages/8b/13/39030884b963a602041e4c0c90bd1a58b068f8ec9d33baddd62216eee56c/rich_toolkit-0.14.9-py3-none-any.whl.metadata\n",
            "  Downloading rich_toolkit-0.14.9-py3-none-any.whl.metadata (999 bytes)\n",
            "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14))\n",
            "  Obtaining dependency information for fastapi-cloud-cli>=0.1.1 from https://files.pythonhosted.org/packages/e5/a6/5aa862489a2918a096166fd98d9fe86b7fd53c607678b3fa9d8c432d88d5/fastapi_cloud_cli-0.1.5-py3-none-any.whl.metadata\n",
            "  Downloading fastapi_cloud_cli-0.1.5-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14))\n",
            "  Obtaining dependency information for rignore>=0.5.1 from https://files.pythonhosted.org/packages/d4/2d/58912efa4137e989616d679a5390b53e93d5150be47217dd686ff60cd4cd/rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (2.34.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36)) (0.26.0)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36))\n",
            "  Obtaining dependency information for pycountry>=23 from https://files.pythonhosted.org/packages/b1/ec/1fb891d8a2660716aadb2143235481d15ed1cbfe3ad669194690b0604492/pycountry-24.6.1-py3-none-any.whl.metadata\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (8.2.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (0.1.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14))\n",
            "  Obtaining dependency information for httptools>=0.6.3 from https://files.pythonhosted.org/packages/b1/2f/205d1f2a190b72da6ffb5f41a3736c26d6fa7871101212b15e9b5cd8f61d/httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14))\n",
            "  Obtaining dependency information for python-dotenv>=0.13 from https://files.pythonhosted.org/packages/5f/ed/539768cf28c661b5b068d66d96a2f155c4971a5d55684a514c1a0e0dec2f/python_dotenv-1.1.1-py3-none-any.whl.metadata\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14))\n",
            "  Obtaining dependency information for uvloop>=0.15.1 from https://files.pythonhosted.org/packages/8a/ca/0864176a649838b838f36d44bf31c451597ab363b60dc9e09c9630619d41/uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/vllm_source/requirements/common.txt (line 14)) (15.0.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36)) (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36)) (2.22)\n",
            "Requirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/vllm_source/requirements/common.txt (line 36)) (0.5.0.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements/cpu.txt (line 23)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements/cpu.txt (line 23)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements/cpu.txt (line 23)) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements/cpu.txt (line 23)) (1.17.0)\n",
            "Downloading outlines_core-0.2.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "Downloading xgrammar-0.1.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.10.2-py3-none-any.whl (169 kB)\n",
            "Downloading depyf-0.19.0-py3-none-any.whl (39 kB)\n",
            "Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl (178.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading intel_openmp-2024.2.1-py2.py3-none-manylinux1_x86_64.whl (29.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.6/29.6 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading intel_extension_for_pytorch-2.6.0-cp311-cp311-manylinux_2_28_x86_64.whl (105.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading intel_cmplr_lib_ur-2024.2.1-py2.py3-none-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.12-py3-none-any.whl (44 kB)\n",
            "Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
            "Downloading transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
            "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
            "Downloading mistral_common-1.8.3-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "Downloading cbor2-5.6.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
            "Downloading setproctitle-1.3.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Downloading openai_harmony-0.0.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "Downloading fastapi_cli-0.0.8-py3-none-any.whl (10 kB)\n",
            "Downloading fastapi_cloud_cli-0.1.5-py3-none-any.whl (18 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich_toolkit-0.14.9-py3-none-any.whl (25 kB)\n",
            "Downloading rignore-0.6.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (950 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.6/950.6 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Installing collected packages: intel-cmplr-lib-ur, blake3, uvloop, setuptools, setproctitle, rignore, python-json-logger, python-dotenv, pycountry, pybase64, partial-json-parser, outlines_core, msgspec, llvmlite, llguidance, lark, interegular, intel-openmp, intel_extension_for_pytorch, httptools, gguf, dnspython, diskcache, cbor2, astor, watchfiles, torch, numba, email-validator, depyf, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, lm-format-enforcer, transformers, fastapi-cloud-cli, fastapi-cli, xgrammar, mistral_common, compressed-tensors\n",
            "\u001b[2K  Attempting uninstall: intel-cmplr-lib-ur\n",
            "\u001b[2K    Found existing installation: intel-cmplr-lib-ur 2025.2.0\n",
            "\u001b[2K    Uninstalling intel-cmplr-lib-ur-2025.2.0:\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libsycl_ur_trace_collector.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_adapter_level_zero.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_adapter_level_zero.so.0\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_adapter_level_zero.so.0.12.0\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_adapter_level_zero_v2.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_adapter_level_zero_v2.so.0\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_adapter_level_zero_v2.so.0.12.0\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_adapter_opencl.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_adapter_opencl.so.0\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_adapter_opencl.so.0.12.0\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_loader.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_loader.so.0\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libur_loader.so.0.12.0\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/intel_cmplr_lib_ur-2025.2.0.dist-info/\n",
            "\u001b[2K      Successfully uninstalled intel-cmplr-lib-ur-2025.2.0\n",
            "\u001b[2K  Attempting uninstall: setuptools\n",
            "\u001b[2K    Found existing installation: setuptools 75.2.0\n",
            "\u001b[2K    Uninstalling setuptools-75.2.0:\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/_distutils_hack/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/distutils-precedence.pth\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/pkg_resources/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/setuptools-75.2.0.dist-info/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/setuptools/\n",
            "\u001b[2K      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[2K  changing mode of /usr/local/bin/dotenv to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/pybase64 to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/json-playground to 755\n",
            "\u001b[2K  Attempting uninstall: llvmlite\n",
            "\u001b[2K    Found existing installation: llvmlite 0.43.0\n",
            "\u001b[2K    Uninstalling llvmlite-0.43.0:\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/llvmlite-0.43.0.dist-info/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/llvmlite/\n",
            "\u001b[2K      Successfully uninstalled llvmlite-0.43.0\n",
            "\u001b[2K  Attempting uninstall: intel-openmp\n",
            "\u001b[2K    Found existing installation: intel-openmp 2025.2.0\n",
            "\u001b[2K    Uninstalling intel-openmp-2025.2.0:\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libarcher.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libarcher_static.a\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libiomp5.a\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libiomp5.dbg\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libiomp5.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libiomp5_db.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libiompstubs5.a\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libiompstubs5.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomp-fallback-cassert.spv\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomp-fallback-cmath-fp64.spv\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomp-fallback-cmath.spv\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomp-fallback-complex-fp64.spv\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomp-fallback-complex.spv\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomp-fallback-cstring.spv\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomp-fallback-imf-fp64.spv\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomp-fallback-imf.spv\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomptarget.rtl.level0.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomptarget.rtl.opencl.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomptarget.rtl.unified_runtime.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomptarget.rtl.x86_64.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomptarget.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/libomptarget.sycl.wrap.so\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/pkgconfig/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/intel_openmp-2025.2.0.dist-info/\n",
            "\u001b[2K      Removing file or directory /usr/local/opt/compiler/include/\n",
            "\u001b[2K      Removing file or directory /usr/local/opt/compiler/lib/\n",
            "\u001b[2K      Removing file or directory /usr/local/share/doc/compiler/licensing/openmp/\n",
            "\u001b[2K      Successfully uninstalled intel-openmp-2025.2.0\n",
            "\u001b[2K  changing mode of /usr/local/bin/ipexrun to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/gguf-convert-endian to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/gguf-dump to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/gguf-editor-gui to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/gguf-new-metadata to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/gguf-set-metadata to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/cbor2 to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/watchfiles to 755\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.6.0+cu124\n",
            "\u001b[2K    Uninstalling torch-2.6.0+cu124:\n",
            "\u001b[2K      Removing file or directory /usr/local/bin/torchfrtrace\n",
            "\u001b[2K      Removing file or directory /usr/local/bin/torchrun\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/functorch/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/torch-2.6.0+cu124.dist-info/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/torch/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/torchgen/\n",
            "\u001b[2K      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[2K  changing mode of /usr/local/bin/torchfrtrace to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/torchrun to 755\n",
            "\u001b[2K  Attempting uninstall: numba\n",
            "\u001b[2K    Found existing installation: numba 0.60.0\n",
            "\u001b[2K    Uninstalling numba-0.60.0:\n",
            "\u001b[2K      Removing file or directory /usr/local/bin/numba\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/numba-0.60.0.dist-info/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/numba/\n",
            "\u001b[2K      Successfully uninstalled numba-0.60.0\n",
            "\u001b[2K  changing mode of /usr/local/bin/email_validator to 755\n",
            "\u001b[2K  Attempting uninstall: transformers\n",
            "\u001b[2K    Found existing installation: transformers 4.54.1\n",
            "\u001b[2K    Uninstalling transformers-4.54.1:\n",
            "\u001b[2K      Removing file or directory /usr/local/bin/transformers\n",
            "\u001b[2K      Removing file or directory /usr/local/bin/transformers-cli\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/transformers-4.54.1.dist-info/\n",
            "\u001b[2K      Removing file or directory /usr/local/lib/python3.11/dist-packages/transformers/\n",
            "\u001b[2K      Successfully uninstalled transformers-4.54.1\n",
            "\u001b[2K  changing mode of /usr/local/bin/transformers to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/transformers-cli to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/fastapi to 755\n",
            "\u001b[2K  changing mode of /usr/local/bin/mistral_common to 755\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41/41\u001b[0m [compressed-tensors]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astor-0.8.1 blake3-1.0.5 cbor2-5.6.5 compressed-tensors-0.10.2 depyf-0.19.0 diskcache-5.6.3 dnspython-2.7.0 email-validator-2.2.0 fastapi-cli-0.0.8 fastapi-cloud-cli-0.1.5 gguf-0.17.1 httptools-0.6.4 intel-cmplr-lib-ur-2024.2.1 intel-openmp-2024.2.1 intel_extension_for_pytorch-2.6.0 interegular-0.3.3 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.10.12 mistral_common-1.8.3 msgspec-0.19.0 numba-0.61.2 openai-harmony-0.0.3 outlines_core-0.2.10 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-extra-types-2.10.5 python-dotenv-1.1.1 python-json-logger-3.3.0 rich-toolkit-0.14.9 rignore-0.6.4 setproctitle-1.3.6 setuptools-79.0.1 torch-2.6.0+cpu transformers-4.55.0 uvloop-0.21.0 watchfiles-1.1.0 xgrammar-0.1.21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "10f4f2f4512942568c54a14feddc5f26"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/vllm_source\n",
        "!VLLM_TARGET_DEVICE=cpu python setup.py install\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly6mvyLOvbkd",
        "outputId": "fd9da2ca-7f24-4dc8-e579-844408bdaf1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vllm_source\n",
            "running install\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:90: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating vllm.egg-info\n",
            "writing vllm.egg-info/PKG-INFO\n",
            "writing dependency_links to vllm.egg-info/dependency_links.txt\n",
            "writing entry points to vllm.egg-info/entry_points.txt\n",
            "writing requirements to vllm.egg-info/requires.txt\n",
            "writing top-level names to vllm.egg-info/top_level.txt\n",
            "writing manifest file 'vllm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'vllm.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/collect_env.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/version.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_custom_ops.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/logits_process.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/sampling_params.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/pooling_params.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_ipex_ops.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_version.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/scripts.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/beam_search.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/connections.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/sequence.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/scalar_type.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/envs.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/tasks.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/outputs.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/config.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/logger.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/jsontree.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/tracing.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/env_override.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/forward_context.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/test_utils.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/ray\n",
            "copying vllm/ray/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/ray\n",
            "copying vllm/ray/lazy_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/ray\n",
            "copying vllm/ray/ray_env.py -> build/lib.linux-x86_64-cpython-311/vllm/ray\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/image.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/video.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/parse.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/audio.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/profiling.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/inputs.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/processing.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/hasher.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/base.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/image.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/video.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/audio.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/base.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/ray_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/uniproc_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/executor_base.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/ray_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/msgspec_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/mp_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/multiproc_worker_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuron_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/pooling_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuron_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/enc_dec_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_neuron_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/model_runner_base.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_neuronx_distributed_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuronx_distributed_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cache_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/communication_op.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/kv_events.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/parallel_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/tpu_distributed_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/plugins\n",
            "copying vllm/plugins/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/plugins\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/preprocess.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/data.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/parse.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/glm4_moe_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/qwen3_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/abs_reasoning_parsers.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/step3_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/gptoss_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/granite_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/hunyuan_a13b_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/deepseek_r1_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/mistral_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "copying vllm/triton_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "copying vllm/triton_utils/importing.py -> build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "copying vllm/device_allocator/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "copying vllm/device_allocator/cumem.py -> build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/parameter.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/pooling_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/custom_op.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/sampling_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/score_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/harmony_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/chat_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/launcher.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/llm.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/api_server.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/ssl.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/logger.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/context.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/tool.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/layer.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/selector.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "copying vllm/usage/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "copying vllm/usage/usage_lib.py -> build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/models.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/request.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/async_llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/async_timeout.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/protocol.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/arg_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/metrics_types.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "copying vllm/third_party/pynvml.py -> build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "copying vllm/third_party/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/logging_utils/dump_input.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/logging_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/logging_utils/formatter.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/tokenizer_group.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/tokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/tokenizer_base.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/detokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/dynamic_module.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/s3_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/detokenizer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/config.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/processor.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/placeholder_block_space_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/block_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/evictor.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/cuda.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/rocm.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/neuron.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/cpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/tpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/xpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/models.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/fully_sharded_layers.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/lora.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/request.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/peft_helper.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/resolver.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/request.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/kv_cache_interface.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/outputs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/serial_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "copying vllm/utils/flashinfer.py -> build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "copying vllm/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "copying vllm/utils/tensor_schema.py -> build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "copying vllm/utils/deep_gemm.py -> build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/layerwise_profile.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/throughput.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/datasets.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/latency.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/compiler_interface.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/decorators.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/counter.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/backends.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/vllm_inductor_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fusion_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fix_functionalization.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/base_piecewise_backend.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/monitor.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/activation_quant_fusion.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/pass_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/sequence_parallelism.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fx_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/collective_fusion.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/inductor_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/torch25_custom_graph_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/noop_elimination.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/cuda_piecewise_backend.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fusion.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/multi_output_match.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/kv_transfer_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "copying vllm/distributed/eplb/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "copying vllm/distributed/eplb/rebalance_execute.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "copying vllm/distributed/eplb/eplb_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "copying vllm/distributed/eplb/rebalance_algo.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/tpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/ray_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cuda_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/all2all.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/base_device_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/neuron_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/custom_all_reduce_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/pynccl_wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/quick_all_reduce.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/xpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/shm_broadcast.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/custom_all_reduce.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/pynccl.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cuda_wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/factory.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers\n",
            "copying vllm/plugins/lora_resolvers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers\n",
            "copying vllm/plugins/lora_resolvers/filesystem_resolver.py -> build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aimv2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_5_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/pixtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interfaces_base.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpm_eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granite.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ernie45.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_vl_01.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/idefics3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bloom.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/fairseq2_llama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/dots1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_j.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/intern_vit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/grok1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mllama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mimo_mtp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpmv.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/voxtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ernie45_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_mtp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_audio.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/stablelm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_onevision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/clip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/adapters.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bailing_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/hunyuan_v1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mimo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/constant_size_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_5_omni_thinker.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4_moe_mtp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/idefics2_vision_model.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bart.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmo2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama_eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bert_with_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/tarsier.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/molmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/teleflm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/module_mapping.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mixtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/zamba2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/telechat2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4_1v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jais.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/exaone4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama_eagle3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/hyperclovax_vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/dbrx.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/step3_text.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_v2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/kimi_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mllama4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/orion.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/whisper.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/opt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/prithvi_geospatial_mae.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jina_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internlm2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/smolvlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3n.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_bigcode.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/baichuan.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpm3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoeshared.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mixtral_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internvl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/arctic.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/blip2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phimoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nvlm_d.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internlm2_ve.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ovis.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/transformers.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/siglip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron_nas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_rm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mpt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/commandr.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4_multimodal.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mlp_speculator.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/plamo2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/chatglm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_next_video.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aya_vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/falcon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/chameleon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_text_01.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ultravox.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interns1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bert.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/arcee.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/starcoder2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/config.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/modernbert.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/blip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granite_speech.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/fuyu.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama4_eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm_audio.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3_mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoehybrid.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/solar.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4flash.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/keye.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/paligemma.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/exaone.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_neox.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/persimmon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mistral3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/skyworkr1v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_oss.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aria.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gritlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_next.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/moonvit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron_h.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/florence2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen3_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/roberta.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interns1_vit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/step3_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/falcon_h1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/h2ovl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/linear.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/pooler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/layernorm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/resampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/lightning_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/activation.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/logits_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/vocab_parallel_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/sharded_state_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/runai_streamer_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/neuron.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/tensorizer_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/tensorizer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/neuronx_distributed.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/dummy_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/gguf_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/weight_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/base_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/tpu.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/bitsandbytes_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/default_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/input_quant_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/schema.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/torchao.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/ipex_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/bitblas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/experts_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/mxfp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gguf.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/aqlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/modelopt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/fbgemm_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/auto_round.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq_triton.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/base_config.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_bitblas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/qqq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/tpu_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/moe_wna16.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/inc.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/kv_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_marlin_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/rtn.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/bitsandbytes.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/ptpc_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/hqq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/deepspeedfp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/neuron_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/deepgemm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/layer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_batched_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/cutlass_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deep_gemm_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_torch_iterative.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/cpu_fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/modular_kernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/config.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_align_block_size.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_marlin_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/mrope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/llama3_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/common.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/base.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_mixer2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_mixer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba2_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/quark.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/quark_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels\n",
            "copying vllm/model_executor/layers/quantization/kernels/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/machete_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/fp8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/w8a8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/int8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/layer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/allspark_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/quant_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/gptq_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/bitblas_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/mxfp4_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/flashinfer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/layernorm_gated.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_state_passing.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_bmm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/causal_conv1d.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/mamba_ssm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_combined.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_responses.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_transcription.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/cli_args.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/speech_to_text.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_chat.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_completion.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_pooling.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/run_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/logits_processors.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/api_server.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_score.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_classification.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_tokenization.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_models.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/protocol.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/collect_env.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/types.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/openai.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/main.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/run_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/throughput.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/main.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/latency.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/base.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flashinfer.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/xformers.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/dual_chunk_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/differential_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/rocm_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/triton_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/placeholder_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/rocm_aiter_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_decode_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_unified_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_merge_attn_states.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_flash_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/prefix_prefill.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/chunked_prefill_paged_decode.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/nki_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/rocm_aiter_paged_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/pallas_kv_cache_update.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/paged_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/rocm_aiter_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/merge_attn_states.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention/utils\n",
            "copying vllm/attention/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/utils\n",
            "copying vllm/attention/utils/fa_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/utils\n",
            "copying vllm/attention/utils/kv_sharing_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "copying vllm/attention/backends/mla/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "copying vllm/attention/backends/mla/common.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/client.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/single_step.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/multi_step.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/stop_checker.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/util.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mllama.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/jais.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nemotron.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mistral.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/kimi_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/arctic.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nvlm_d.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/ovis.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mlp_speculator.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/chatglm.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/falcon.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/ultravox.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nemotron_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/moonvit.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nemotron_h.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/step3_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "copying vllm/transformers_utils/tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "copying vllm/transformers_utils/tokenizers/mistral.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/transformers_utils/processors/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/transformers_utils/processors/ovis.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/transformers_utils/processors/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators\n",
            "copying vllm/transformers_utils/configs/speculators/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators\n",
            "copying vllm/transformers_utils/configs/speculators/algos.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators\n",
            "copying vllm/transformers_utils/configs/speculators/base.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/prefix_caching_block.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/common.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/naive_block.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/block_table.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/cpu_gpu_block_allocator.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_base.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_selector.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_cpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_gpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_tpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_xpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops\n",
            "copying vllm/lora/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_shrink_op.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_kernel_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_expand_op.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/kernel_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops\n",
            "copying vllm/lora/ops/ipex_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops\n",
            "copying vllm/lora/ops/ipex_ops/lora_ops.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops\n",
            "copying vllm/lora/ops/xla_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops\n",
            "copying vllm/lora/ops/xla_ops/lora_ops.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "copying vllm/lora/ops/torch_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "copying vllm/lora/ops/torch_ops/lora_ops.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/ray_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/multiproc_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_guidance.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_xgrammar.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/request.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_outlines.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_types.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/reader.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/loggers.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/stats.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/prometheus.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/ray_wrappers.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/lora_model_runner_mixin.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/xpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/kv_connector_model_runner_mixin.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/cpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/xpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/cpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_input_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/block_table.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_input_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/pool\n",
            "copying vllm/v1/pool/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/pool\n",
            "copying vllm/v1/pool/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/pool\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/rejection_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/logits_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/attention\n",
            "copying vllm/v1/attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/core.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/mm_input_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/core_client.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/detokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/parallel_sampling.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/logprobs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/output_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/exceptions.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/async_llm.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/coordinator.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/ngram_proposer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/block_pool.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_coordinator.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/single_type_kv_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/encoder_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/bad_words.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/topk_topp_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/logprobs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/penalties.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/mamba_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/flashinfer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/xformers.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/triton_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/flex_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/mamba_selectors.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/rocm_aiter_fa.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/tree_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/cpu_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/common.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/triton_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/rocm_aiter_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/cutlass_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/output.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/async_scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/request_queue.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/benchmarks/lib/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/benchmarks/lib/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/benchmarks/lib/ready_checker.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/benchmarks/lib/endpoint_request_func.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/py.typed -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn\n",
            "copying vllm/vllm_flash_attn/.gitkeep -> build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn\n",
            "copying vllm/distributed/kv_transfer/README.md -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/plugins/lora_resolvers/README.md -> build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/README -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/transformers_utils/chat_templates/template_basic.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/template_blip2.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/template_chatml.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/template_deepseek_vl2.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/template_fuyu.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "running build_ext\n",
            "-- The CXX compiler identification is GNU 12.3.0\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Build type: RelWithDebInfo\n",
            "-- Target device: cpu\n",
            "-- Found Python: /usr/bin/python3 (found version \"3.11.13\") found components: Interpreter Development.Module Development.SABIModule\n",
            "-- Found python matching: /usr/bin/python3.\n",
            "\u001b[33mCMake Warning at /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:22 (message):\n",
            "  static library kineto_LIBRARY-NOTFOUND not found.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:121 (append_torchlib_if_found)\n",
            "  CMakeLists.txt:80 (find_package)\n",
            "\n",
            "\u001b[0m\n",
            "-- Found Torch: /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch.so\n",
            "\u001b[33mCMake Warning at cmake/cpu_extension.cmake:143 (message):\n",
            "  vLLM CPU backend using AVX2 ISA\n",
            "Call Stack (most recent call first):\n",
            "  CMakeLists.txt:97 (include)\n",
            "\n",
            "\u001b[0m\n",
            "-- CPU extension compile flags: -mf16c;-fopenmp;-DVLLM_CPU_EXTENSION;-mavx2\n",
            "-- CPU extension source files: csrc/cpu/activation.cpp;csrc/cpu/attention.cpp;csrc/cpu/cache.cpp;csrc/cpu/utils.cpp;csrc/cpu/layernorm.cpp;csrc/cpu/mla_decode.cpp;csrc/cpu/pos_encoding.cpp;csrc/cpu/torch_bindings.cpp\n",
            "-- Enabling C extension.\n",
            "-- Configuring done (3.5s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/vllm_source/build/temp.linux-x86_64-cpython-311\n",
            "[9/9] Linking CXX shared module _C.abi3.so\u001b[K\n",
            "-- Install configuration: \"RelWithDebInfo\"\n",
            "-- Installing: /content/vllm_source/build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so\n",
            "-- Set non-toolchain portion of runtime path of \"/content/vllm_source/build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so\" to \"\"\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/collect_env.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/__init__.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/lazy_utils.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/ray_env.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/version.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/image.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/utils.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/__init__.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/registry.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/video.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/parse.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/audio.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/profiling.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/inputs.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/processing.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/hasher.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/base.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "creating build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/image.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/__init__.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/video.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/audio.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/base.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "creating build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/ray_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/uniproc_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/executor_base.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/ray_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/msgspec_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/mp_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/multiproc_worker_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/__init__.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_custom_ops.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logits_process.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/worker_base.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuron_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/utils.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/__init__.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/pooling_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuron_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/enc_dec_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_neuron_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/model_runner_base.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_neuronx_distributed_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuronx_distributed_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cache_engine.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/README.md -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_transfer_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/factory.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/communication_op.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/rebalance_execute.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/eplb_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/rebalance_algo.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/tpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/ray_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cuda_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/all2all.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/base_device_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/neuron_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/custom_all_reduce_utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/pynccl_wrapper.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/quick_all_reduce.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/xpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/shm_broadcast.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/custom_all_reduce.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/pynccl.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cuda_wrapper.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_events.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/parallel_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/tpu_distributed_utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/plugins\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/__init__.py -> build/bdist.linux-x86_64/egg/vllm/plugins\n",
            "creating build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/README.md -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/filesystem_resolver.py -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/preprocess.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/__init__.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/registry.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/data.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/parse.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/sampling_params.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/glm4_moe_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/qwen3_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/abs_reasoning_parsers.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/step3_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/gptoss_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/__init__.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/granite_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/hunyuan_a13b_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/deepseek_r1_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/mistral_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/pooling_params.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_ipex_ops.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn/.gitkeep -> build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "creating build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/triton_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/triton_utils/importing.py -> build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/device_allocator/__init__.py -> build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/device_allocator/cumem.py -> build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_version.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/scripts.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/parameter.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aimv2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_5_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/pixtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interfaces_base.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granite.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ernie45.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_vl_01.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/idefics3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bloom.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/fairseq2_llama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/dots1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_j.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/intern_vit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/grok1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mllama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mimo_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpmv.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/voxtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ernie45_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_audio.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/stablelm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_onevision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/clip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/medusa.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/adapters.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bailing_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/hunyuan_v1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mimo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/constant_size_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_5_omni_thinker.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_moe_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/idefics2_vision_model.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/registry.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bart.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmo2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bert_with_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/tarsier.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/molmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/teleflm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/module_mapping.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mixtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/zamba2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/telechat2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_1v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jais.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/exaone4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama_eagle3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/hyperclovax_vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/dbrx.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/step3_text.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_v2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/kimi_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mllama4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/orion.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/whisper.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/opt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/prithvi_geospatial_mae.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jina_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internlm2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/smolvlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3n.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_bigcode.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/baichuan.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoeshared.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mixtral_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internvl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/arctic.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/blip2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phimoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nvlm_d.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internlm2_ve.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ovis.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/transformers.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/siglip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_nas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_rm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mpt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/commandr.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4_multimodal.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mlp_speculator.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/plamo2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/chatglm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_next_video.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aya_vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/falcon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/chameleon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_text_01.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ultravox.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interns1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bert.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/arcee.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/starcoder2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/modernbert.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/blip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granite_speech.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/fuyu.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama4_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm_audio.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3_mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoehybrid.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/solar.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4flash.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/keye.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/paligemma.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/exaone.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_neox.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/persimmon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mistral3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/skyworkr1v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_oss.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aria.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gritlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_next.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/moonvit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_h.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/florence2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen3_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/roberta.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interns1_vit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/step3_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/falcon_h1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/h2ovl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/input_quant_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/schema.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/torchao.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/ipex_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/experts_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/quark.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/quark_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/mxfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gguf.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/aqlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/modelopt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/fbgemm_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/auto_round.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq_triton.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/base_config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/qqq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/tpu_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/moe_wna16.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/inc.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kv_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_marlin_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/rtn.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/bitsandbytes.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/ptpc_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/hqq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/machete_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/fp8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/w8a8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/int8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/layer_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/allspark_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/quant_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/gptq_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/bitblas_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/mxfp4_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/flashinfer_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/deepspeedfp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/neuron_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/deepgemm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/linear.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/layer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/README -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_batched_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/cutlass_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_pallas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deep_gemm_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_torch_iterative.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/cpu_fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/modular_kernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_align_block_size.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_marlin_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/mrope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/llama3_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/common.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/base.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/pooler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/layernorm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/resampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/layernorm_gated.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_state_passing.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_bmm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/causal_conv1d.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/mamba_ssm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_combined.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/abstract.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_mixer2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_mixer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba2_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/lightning_attn.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/activation.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/logits_processor.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/vocab_parallel_embedding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/pooling_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/sharded_state_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/runai_streamer_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/neuron.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tensorizer_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tensorizer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/neuronx_distributed.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/dummy_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/gguf_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/weight_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/base_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tpu.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/bitsandbytes_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/default_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/custom_op.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/sampling_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/score_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_engine.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_responses.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_transcription.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/cli_args.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/speech_to_text.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_chat.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_completion.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_pooling.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/run_batch.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/logits_processors.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/api_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_score.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_embedding.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_classification.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_tokenization.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_models.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/protocol.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/harmony_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/chat_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/launcher.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/llm.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/api_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/collect_env.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/types.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/openai.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/main.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/serve.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/run_batch.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/throughput.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/main.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/serve.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/latency.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/base.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/ssl.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/logger.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/context.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/tool.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/beam_search.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/connections.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/layer.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/xformers.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/dual_chunk_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/differential_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/rocm_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/abstract.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/triton_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla/common.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/placeholder_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_decode_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_unified_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_merge_attn_states.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_flash_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/prefix_prefill.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/chunked_prefill_paged_decode.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/nki_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/rocm_aiter_paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/pallas_kv_cache_update.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/merge_attn_states.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/selector.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/fa_utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/kv_sharing_utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/usage\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/usage/__init__.py -> build/bdist.linux-x86_64/egg/vllm/usage\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/usage/usage_lib.py -> build/bdist.linux-x86_64/egg/vllm/usage\n",
            "creating build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/models.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/utils.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/__init__.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/request.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/layers.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/metrics.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/async_llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/async_timeout.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/client.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/engine.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/single_step.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/multi_step.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/stop_checker.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/util.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/protocol.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/arg_utils.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/metrics_types.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/third_party/pynvml.py -> build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/third_party/__init__.py -> build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "creating build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/dump_input.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/formatter.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/sequence.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/scalar_type.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_chatml.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_deepseek_vl2.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/registry.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_blip2.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_fuyu.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_basic.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mllama.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/medusa.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/jais.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mistral.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/kimi_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/arctic.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nvlm_d.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/ovis.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mlp_speculator.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/eagle.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/chatglm.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/algos.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/base.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/falcon.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/ultravox.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/moonvit.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron_h.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/step3_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_base.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/detokenizer.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/dynamic_module.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/s3_utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers/mistral.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/detokenizer_utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/config.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/ovis.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processor.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/envs.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/__init__.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/placeholder_block_space_manager.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block_manager.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/utils.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/__init__.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/prefix_caching_block.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/common.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/naive_block.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/block_table.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/cpu_gpu_block_allocator.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/evictor.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/scheduler.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/cuda.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/rocm.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/__init__.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/neuron.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/interface.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/cpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/tpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/xpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/models.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/fully_sharded_layers.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_base.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_selector.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_cpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_gpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_tpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_xpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/lora.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_shrink_op.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_kernel_metadata.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_expand_op.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/kernel_utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/request.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/peft_helper.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/resolver.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/layers.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/tasks.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/outputs.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/ray_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/multiproc_executor.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/abstract.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_guidance.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_xgrammar.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/request.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_outlines.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_types.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/reader.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/loggers.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/stats.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/prometheus.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/ray_wrappers.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/worker_base.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/lora_model_runner_mixin.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/xpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/kv_connector_model_runner_mixin.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/cpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/xpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/cpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_input_batch.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/block_table.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_input_batch.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/pool/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/pool/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/rejection_sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/bad_words.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/topk_topp_sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/logprobs.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/penalties.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/logits_processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/xformers.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/triton_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flex_attention.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba_selectors.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/common.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/triton_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/cutlass_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/rocm_aiter_fa.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/tree_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/cpu_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/pallas.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/request.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/core.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/mm_input_cache.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/core_client.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/detokenizer.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/parallel_sampling.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/logprobs.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/output_processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/exceptions.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/async_llm.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/coordinator.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/medusa.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/metrics.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/eagle.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/ngram_proposer.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/kv_cache_interface.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/block_pool.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_coordinator.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/single_type_kv_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/encoder_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/interface.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/output.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/async_scheduler.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/scheduler.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/request_queue.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/outputs.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/serial_utils.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/config.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logger.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/tensor_schema.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/deep_gemm.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/jsontree.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/utils.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/__init__.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/layerwise_profile.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/py.typed -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/__init__.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/throughput.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/datasets.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/serve.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/latency.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "creating build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/utils.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/__init__.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/ready_checker.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/endpoint_request_func.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/tracing.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/env_override.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/forward_context.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/test_utils.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/compiler_interface.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/decorators.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/__init__.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/counter.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/wrapper.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/backends.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/vllm_inductor_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fusion_attn.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fix_functionalization.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/base_piecewise_backend.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/monitor.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/activation_quant_fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/pass_manager.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/sequence_parallelism.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fx_utils.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/collective_fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/inductor_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/torch25_custom_graph_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/noop_elimination.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/cuda_piecewise_backend.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/multi_output_match.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/collect_env.py to collect_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/lazy_utils.py to lazy_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/ray_env.py to ray_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/version.py to version.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/image.py to image.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/video.py to video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/parse.py to parse.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/audio.py to audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/profiling.py to profiling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/inputs.py to inputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/processing.py to processing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/hasher.py to hasher.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/image.py to image.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/video.py to video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/audio.py to audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/ray_distributed_executor.py to ray_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/uniproc_executor.py to uniproc_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/executor_base.py to executor_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/ray_utils.py to ray_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/msgspec_utils.py to msgspec_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/mp_distributed_executor.py to mp_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/multiproc_worker_utils.py to multiproc_worker_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_custom_ops.py to _custom_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logits_process.py to logits_process.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/worker_base.py to worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuron_worker.py to neuron_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_model_runner.py to multi_step_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/pooling_model_runner.py to pooling_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuron_model_runner.py to neuron_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/model_runner.py to model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/enc_dec_model_runner.py to enc_dec_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_neuron_model_runner.py to multi_step_neuron_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_worker.py to multi_step_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/model_runner_base.py to model_runner_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_neuronx_distributed_model_runner.py to multi_step_neuronx_distributed_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/worker.py to worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuronx_distributed_model_runner.py to neuronx_distributed_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cache_engine.py to cache_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py to pynccl_pipe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py to mooncake_pipe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py to simple_buffer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py to mooncake_store.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_transfer_state.py to kv_transfer_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/factory.py to factory.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py to shared_storage_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py to nixl_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py to p2p_nccl_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py to p2p_nccl_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py to tensor_memory_pool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py to multi_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py to lmcache_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/communication_op.py to communication_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/rebalance_execute.py to rebalance_execute.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/eplb_state.py to eplb_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/rebalance_algo.py to rebalance_algo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/tpu_communicator.py to tpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/ray_communicator.py to ray_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cpu_communicator.py to cpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cuda_communicator.py to cuda_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/all2all.py to all2all.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/base_device_communicator.py to base_device_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/neuron_communicator.py to neuron_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/custom_all_reduce_utils.py to custom_all_reduce_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/pynccl_wrapper.py to pynccl_wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/quick_all_reduce.py to quick_all_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/xpu_communicator.py to xpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/shm_broadcast.py to shm_broadcast.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/custom_all_reduce.py to custom_all_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/pynccl.py to pynccl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cuda_wrapper.py to cuda_wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_events.py to kv_events.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/parallel_state.py to parallel_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/tpu_distributed_utils.py to tpu_distributed_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers/filesystem_resolver.py to filesystem_resolver.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/preprocess.py to preprocess.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/data.py to data.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/parse.py to parse.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/sampling_params.py to sampling_params.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/glm4_moe_reasoning_parser.py to glm4_moe_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/qwen3_reasoning_parser.py to qwen3_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/abs_reasoning_parsers.py to abs_reasoning_parsers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/step3_reasoning_parser.py to step3_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/gptoss_reasoning_parser.py to gptoss_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/granite_reasoning_parser.py to granite_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/hunyuan_a13b_reasoning_parser.py to hunyuan_a13b_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/deepseek_r1_reasoning_parser.py to deepseek_r1_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/mistral_reasoning_parser.py to mistral_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/pooling_params.py to pooling_params.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_ipex_ops.py to _ipex_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/triton_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/triton_utils/importing.py to importing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/device_allocator/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/device_allocator/cumem.py to cumem.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_version.py to _version.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/scripts.py to scripts.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/parameter.py to parameter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aimv2.py to aimv2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm.py to minicpm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_5_vl.py to qwen2_5_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/pixtral.py to pixtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interfaces_base.py to interfaces_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm_eagle.py to minicpm_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granite.py to granite.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ernie45.py to ernie45.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi.py to phi.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_vl_01.py to minimax_vl_01.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/idefics3.py to idefics3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bloom.py to bloom.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/fairseq2_llama.py to fairseq2_llama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/dots1.py to dots1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_j.py to gpt_j.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/intern_vit.py to intern_vit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/grok1.py to grok1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek.py to deepseek.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mllama.py to mllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mimo_mtp.py to mimo_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpmv.py to minicpmv.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/voxtral.py to voxtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma2.py to gemma2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ernie45_moe.py to ernie45_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_mtp.py to deepseek_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_audio.py to qwen2_audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/stablelm.py to stablelm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/vision.py to vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_onevision.py to llava_onevision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/clip.py to clip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/adapters.py to adapters.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bailing_moe.py to bailing_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/hunyuan_v1.py to hunyuan_v1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mimo.py to mimo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava.py to llava.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/constant_size_cache.py to constant_size_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_5_omni_thinker.py to qwen2_5_omni_thinker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3.py to phi3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_moe_mtp.py to glm4_moe_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/idefics2_vision_model.py to idefics2_vision_model.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bart.py to bart.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma.py to gemma.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmo2.py to olmo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen3.py to qwen3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama_eagle.py to llama_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bert_with_rope.py to bert_with_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/tarsier.py to tarsier.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2.py to qwen2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/molmo.py to molmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/teleflm.py to teleflm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba_cache.py to mamba_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_vl.py to qwen2_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/module_mapping.py to module_mapping.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mixtral.py to mixtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/zamba2.py to zamba2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3v.py to phi3v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/telechat2.py to telechat2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_1v.py to glm4_1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jais.py to jais.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/exaone4.py to exaone4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4.py to glm4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama_eagle3.py to llama_eagle3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_moe.py to qwen2_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/hyperclovax_vision.py to hyperclovax_vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron.py to nemotron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/dbrx.py to dbrx.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/step3_text.py to step3_text.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_v2.py to deepseek_v2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/kimi_vl.py to kimi_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_cache.py to minimax_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mllama4.py to mllama4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/orion.py to orion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/whisper.py to whisper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/opt.py to opt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/prithvi_geospatial_mae.py to prithvi_geospatial_mae.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm_utils.py to phi4mm_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jina_vl.py to jina_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmoe.py to olmoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internlm2.py to internlm2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/smolvlm.py to smolvlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3n.py to gemma3n.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_bigcode.py to gpt_bigcode.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/baichuan.py to baichuan.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm3.py to minicpm3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoeshared.py to granitemoeshared.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm.py to glm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen.py to qwen.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mixtral_quant.py to mixtral_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba2.py to mamba2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internvl.py to internvl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba.py to mamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/arctic.py to arctic.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/blip2.py to blip2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phimoe.py to phimoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama.py to llama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nvlm_d.py to nvlm_d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_moe.py to glm4_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internlm2_ve.py to internlm2_ve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/transformers.py to transformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/siglip.py to siglip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_nas.py to nemotron_nas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_rm.py to qwen2_rm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bamba.py to bamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mpt.py to mpt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/commandr.py to commandr.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt2.py to gpt2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmo.py to olmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4_multimodal.py to phi4_multimodal.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mlp_speculator.py to mlp_speculator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/plamo2.py to plamo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm.py to phi4mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/chatglm.py to chatglm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_next_video.py to llava_next_video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aya_vision.py to aya_vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen_vl.py to qwen_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/falcon.py to falcon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3.py to gemma3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/chameleon.py to chameleon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_text_01.py to minimax_text_01.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ultravox.py to ultravox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interns1.py to interns1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bert.py to bert.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/arcee.py to arcee.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/starcoder2.py to starcoder2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4v.py to glm4v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jamba.py to jamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/modernbert.py to modernbert.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/blip.py to blip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granite_speech.py to granite_speech.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/fuyu.py to fuyu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_vl.py to nemotron_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoe.py to granitemoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama4_eagle.py to llama4_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm_audio.py to phi4mm_audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3_mm.py to gemma3_mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama4.py to llama4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoehybrid.py to granitemoehybrid.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/solar.py to solar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4flash.py to phi4flash.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/keye.py to keye.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/paligemma.py to paligemma.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/exaone.py to exaone.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_neox.py to gpt_neox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/persimmon.py to persimmon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mistral3.py to mistral3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/skyworkr1v.py to skyworkr1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_oss.py to gpt_oss.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aria.py to aria.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gritlm.py to gritlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_next.py to llava_next.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpmo.py to minicpmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/moonvit.py to moonvit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_h.py to nemotron_h.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/florence2.py to florence2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen3_moe.py to qwen3_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/roberta.py to roberta.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interns1_vit.py to interns1_vit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/step3_vl.py to step3_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/falcon_h1.py to falcon_h1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/h2ovl.py to h2ovl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/input_quant_fp8.py to input_quant_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/schema.py to schema.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/torchao.py to torchao.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/marlin.py to marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/fp8.py to fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/ipex_quant.py to ipex_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/bitblas.py to bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/experts_int8.py to experts_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/quark.py to quark.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py to quark_w4a4_mxfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py to quark_w8a8_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py to quark_w8a8_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py to quark_scheme.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/quark_moe.py to quark_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/mxfp4.py to mxfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gguf.py to gguf.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq.py to gptq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq_marlin.py to awq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/aqlm.py to aqlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/modelopt.py to modelopt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py to conch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py to marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py to bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py to exllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py to machete.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py to dynamic_4bit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py to MPLinearKernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py to allspark.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py to aiter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py to cutlass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py to triton.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py to xla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py to ScaledMMLinearKernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq.py to awq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/fbgemm_fp8.py to fbgemm_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py to compressed_tensors_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py to compressed_tensors_wNa16.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py to compressed_tensors_w8a16_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py to compressed_tensors_w4a8_int.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py to compressed_tensors_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py to compressed_tensors_scheme.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py to compressed_tensors_w8a8_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py to compressed_tensors_w4a4_nvfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py to compressed_tensors_w8a8_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py to compressed_tensors_w4a16_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py to compressed_tensors_w4a16_nvfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py to triton_scaled_mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py to compressed_tensors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/auto_round.py to auto_round.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq_triton.py to awq_triton.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/base_config.py to base_config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_bitblas.py to gptq_bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/qqq.py to qqq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/tpu_int8.py to tpu_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/moe_wna16.py to moe_wna16.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/inc.py to inc.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kv_cache.py to kv_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_marlin_24.py to gptq_marlin_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/rtn.py to rtn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/bitsandbytes.py to bitsandbytes.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_marlin.py to gptq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/ptpc_fp8.py to ptpc_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/hqq_marlin.py to hqq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/machete_utils.py to machete_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py to nvfp4_emulation_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py to nvfp4_moe_support.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/fp8_utils.py to fp8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/w8a8_utils.py to w8a8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/int8_utils.py to int8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py to marlin_utils_test_qqq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py to marlin_utils_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test.py to marlin_utils_test.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/layer_utils.py to layer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/allspark_utils.py to allspark_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/quant_utils.py to quant_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py to marlin_utils_test_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils.py to marlin_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/gptq_utils.py to gptq_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/bitblas_utils.py to bitblas_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py to flashinfer_fp4_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py to marlin_utils_fp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/mxfp4_utils.py to mxfp4_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/flashinfer_utils.py to flashinfer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/deepspeedfp.py to deepspeedfp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/neuron_quant.py to neuron_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/deepgemm.py to deepgemm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/linear.py to linear.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/layer.py to layer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deep_gemm_moe.py to deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_moe.py to fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py to flashinfer_cutlass_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_batched_moe.py to fused_batched_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/cutlass_moe.py to cutlass_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py to moe_permute_unpermute.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_pallas.py to moe_pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/prepare_finalize.py to prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py to pplx_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py to deepep_ht_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deep_gemm_utils.py to deep_gemm_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py to flashinfer_cutlass_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py to triton_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_torch_iterative.py to moe_torch_iterative.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py to topk_weight_and_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/cpu_fused_moe.py to cpu_fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/modular_kernel.py to modular_kernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py to batched_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_align_block_size.py to moe_align_block_size.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_marlin_moe.py to fused_marlin_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py to batched_triton_or_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py to deepep_ll_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py to rocm_aiter_fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py to yarn_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/mrope.py to mrope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py to dynamic_ntk_alpha_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/llama3_rope.py to llama3_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py to ntk_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py to deepseek_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py to linear_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py to dual_chunk_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py to dynamic_ntk_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py to phi3_long_rope_scaled_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py to llama4_vision_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/pooler.py to pooler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/layernorm.py to layernorm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/resampler.py to resampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/layernorm_gated.py to layernorm_gated.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_state_passing.py to ssd_state_passing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py to ssd_chunk_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py to ssd_chunk_scan.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_bmm.py to ssd_bmm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/causal_conv1d.py to causal_conv1d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/mamba_ssm.py to mamba_ssm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_combined.py to ssd_combined.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_mixer2.py to mamba_mixer2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_mixer.py to mamba_mixer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba2_metadata.py to mamba2_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_utils.py to mamba_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/lightning_attn.py to lightning_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/activation.py to activation.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/logits_processor.py to logits_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/vocab_parallel_embedding.py to vocab_parallel_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/pooling_metadata.py to pooling_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/sharded_state_loader.py to sharded_state_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/runai_streamer_loader.py to runai_streamer_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/neuron.py to neuron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tensorizer_loader.py to tensorizer_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tensorizer.py to tensorizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/neuronx_distributed.py to neuronx_distributed.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/dummy_loader.py to dummy_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/gguf_loader.py to gguf_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/weight_utils.py to weight_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/base_loader.py to base_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tpu.py to tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/bitsandbytes_loader.py to bitsandbytes_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/default_loader.py to default_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/custom_op.py to custom_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/sampling_metadata.py to sampling_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/score_utils.py to score_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_engine.py to serving_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_responses.py to serving_responses.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_transcription.py to serving_transcription.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/cli_args.py to cli_args.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/speech_to_text.py to speech_to_text.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_chat.py to serving_chat.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_completion.py to serving_completion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_pooling.py to serving_pooling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/run_batch.py to run_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py to minimax_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py to mistral_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py to xlam_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py to phi4mini_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py to hermes_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py to step3_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py to llama_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py to granite_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py to internlm2_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py to deepseekv3_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py to glm4_moe_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py to pythonic_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py to jamba_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py to abstract_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py to granite_20b_fc_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py to kimi_k2_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py to llama4_pythonic_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py to hunyuan_a13b_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py to qwen3coder_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/logits_processors.py to logits_processors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/api_server.py to api_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_score.py to serving_score.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_embedding.py to serving_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_classification.py to serving_classification.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_tokenization.py to serving_tokenization.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_models.py to serving_models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/protocol.py to protocol.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/harmony_utils.py to harmony_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/chat_utils.py to chat_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/launcher.py to launcher.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/llm.py to llm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/api_server.py to api_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/collect_env.py to collect_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/types.py to types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/openai.py to openai.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/main.py to main.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/run_batch.py to run_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/throughput.py to throughput.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/main.py to main.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/latency.py to latency.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/ssl.py to ssl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/logger.py to logger.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/context.py to context.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/tool.py to tool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/beam_search.py to beam_search.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/connections.py to connections.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/layer.py to layer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flash_attn.py to flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/xformers.py to xformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/dual_chunk_flash_attn.py to dual_chunk_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/differential_flash_attn.py to differential_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/rocm_flash_attn.py to rocm_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/triton_mla.py to triton_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/mla/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/mla/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/placeholder_attn.py to placeholder_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_decode_attention.py to triton_decode_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_unified_attention.py to triton_unified_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_merge_attn_states.py to triton_merge_attn_states.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_flash_attention.py to triton_flash_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/prefix_prefill.py to prefix_prefill.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/chunked_prefill_paged_decode.py to chunked_prefill_paged_decode.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/nki_flash_attn.py to nki_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/rocm_aiter_paged_attn.py to rocm_aiter_paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/pallas_kv_cache_update.py to pallas_kv_cache_update.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/paged_attn.py to paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/merge_attn_states.py to merge_attn_states.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/selector.py to selector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/fa_utils.py to fa_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/kv_sharing_utils.py to kv_sharing_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/usage/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/usage/usage_lib.py to usage_lib.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/llm_engine.py to llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/async_llm_engine.py to async_llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/async_timeout.py to async_timeout.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/client.py to client.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/engine.py to engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/single_step.py to single_step.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/multi_step.py to multi_step.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/stop_checker.py to stop_checker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/util.py to util.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/protocol.py to protocol.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/arg_utils.py to arg_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/metrics_types.py to metrics_types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/third_party/pynvml.py to pynvml.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/third_party/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/dump_input.py to dump_input.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/formatter.py to formatter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/sequence.py to sequence.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/scalar_type.py to scalar_type.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group.py to tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer.py to tokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mllama.py to mllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/jais.py to jais.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron.py to nemotron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mistral.py to mistral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/kimi_vl.py to kimi_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/arctic.py to arctic.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nvlm_d.py to nvlm_d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mlp_speculator.py to mlp_speculator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/chatglm.py to chatglm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/algos.py to algos.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/falcon.py to falcon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/ultravox.py to ultravox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron_vl.py to nemotron_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/moonvit.py to moonvit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron_h.py to nemotron_h.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/step3_vl.py to step3_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_base.py to tokenizer_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/detokenizer.py to detokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/dynamic_module.py to dynamic_module.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/s3_utils.py to s3_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers/mistral.py to mistral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/detokenizer_utils.py to detokenizer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processor.py to processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/envs.py to envs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/placeholder_block_space_manager.py to placeholder_block_space_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block_manager.py to block_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/prefix_caching_block.py to prefix_caching_block.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/naive_block.py to naive_block.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/block_table.py to block_table.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/cpu_gpu_block_allocator.py to cpu_gpu_block_allocator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/evictor.py to evictor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/scheduler.py to scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/cuda.py to cuda.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/rocm.py to rocm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/neuron.py to neuron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/cpu.py to cpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/tpu.py to tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/xpu.py to xpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/fully_sharded_layers.py to fully_sharded_layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_base.py to punica_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_selector.py to punica_selector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_cpu.py to punica_cpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_gpu.py to punica_gpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_tpu.py to punica_tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_xpu.py to punica_xpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/lora.py to lora.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_shrink_op.py to lora_shrink_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_kernel_metadata.py to lora_kernel_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_expand_op.py to lora_expand_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/kernel_utils.py to kernel_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/peft_helper.py to peft_helper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/resolver.py to resolver.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/tasks.py to tasks.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/outputs.py to outputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/ray_distributed_executor.py to ray_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/multiproc_executor.py to multiproc_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_guidance.py to backend_guidance.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_xgrammar.py to backend_xgrammar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_outlines.py to backend_outlines.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_types.py to backend_types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/reader.py to reader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/loggers.py to loggers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/stats.py to stats.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/prometheus.py to prometheus.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/ray_wrappers.py to ray_wrappers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/worker_base.py to worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_worker.py to gpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_model_runner.py to gpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_model_runner.py to tpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/lora_model_runner_mixin.py to lora_model_runner_mixin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/xpu_model_runner.py to xpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/kv_connector_model_runner_mixin.py to kv_connector_model_runner_mixin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/cpu_worker.py to cpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/xpu_worker.py to xpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_worker.py to tpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/cpu_model_runner.py to cpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_input_batch.py to tpu_input_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/block_table.py to block_table.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_input_batch.py to gpu_input_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/pool/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/pool/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/rejection_sampler.py to rejection_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/bad_words.py to bad_words.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/topk_topp_sampler.py to topk_topp_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/logprobs.py to logprobs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/penalties.py to penalties.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/logits_processor.py to logits_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba_attn.py to mamba_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flash_attn.py to flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/xformers.py to xformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/triton_attn.py to triton_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flex_attention.py to flex_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba_selectors.py to mamba_selectors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/triton_mla.py to triton_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/cutlass_mla.py to cutlass_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/rocm_aiter_fa.py to rocm_aiter_fa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/tree_attn.py to tree_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/cpu_attn.py to cpu_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/pallas.py to pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/core.py to core.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/mm_input_cache.py to mm_input_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/core_client.py to core_client.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/detokenizer.py to detokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/llm_engine.py to llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/parallel_sampling.py to parallel_sampling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/logprobs.py to logprobs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/output_processor.py to output_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/exceptions.py to exceptions.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/async_llm.py to async_llm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/coordinator.py to coordinator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/processor.py to processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/ngram_proposer.py to ngram_proposer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/kv_cache_interface.py to kv_cache_interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/block_pool.py to block_pool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_coordinator.py to kv_cache_coordinator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/single_type_kv_cache_manager.py to single_type_kv_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_utils.py to kv_cache_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/encoder_cache_manager.py to encoder_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/output.py to output.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/async_scheduler.py to async_scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/scheduler.py to scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/request_queue.py to request_queue.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_manager.py to kv_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/outputs.py to outputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/serial_utils.py to serial_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logger.py to logger.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/tensor_schema.py to tensor_schema.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/deep_gemm.py to deep_gemm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/jsontree.py to jsontree.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/layerwise_profile.py to layerwise_profile.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/throughput.py to throughput.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/datasets.py to datasets.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/latency.py to latency.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/ready_checker.py to ready_checker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/endpoint_request_func.py to endpoint_request_func.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/tracing.py to tracing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/env_override.py to env_override.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/forward_context.py to forward_context.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/test_utils.py to test_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/compiler_interface.py to compiler_interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/decorators.py to decorators.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/counter.py to counter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/wrapper.py to wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/backends.py to backends.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/vllm_inductor_pass.py to vllm_inductor_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fusion_attn.py to fusion_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fix_functionalization.py to fix_functionalization.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/base_piecewise_backend.py to base_piecewise_backend.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/monitor.py to monitor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/activation_quant_fusion.py to activation_quant_fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/pass_manager.py to pass_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/sequence_parallelism.py to sequence_parallelism.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fx_utils.py to fx_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/collective_fusion.py to collective_fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/inductor_pass.py to inductor_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/torch25_custom_graph_pass.py to torch25_custom_graph_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/noop_elimination.py to noop_elimination.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/cuda_piecewise_backend.py to cuda_piecewise_backend.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fusion.py to fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/multi_output_match.py to multi_output_match.cpython-311.pyc\n",
            "creating stub loader for vllm/_C.abi3.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_C.py to _C.cpython-311.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "vllm.__pycache__._C.cpython-311: module references __file__\n",
            "vllm.__pycache__.config.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.__pycache__.logger.cpython-311: module references __file__\n",
            "vllm.compilation.__pycache__.inductor_pass.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.distributed.device_communicators.__pycache__.custom_all_reduce_utils.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.fused_moe.__pycache__.fused_moe.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.quantization.utils.__pycache__.fp8_utils.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.quantization.utils.__pycache__.int8_utils.cpython-311: module references __file__\n",
            "vllm.transformers_utils.chat_templates.__pycache__.registry.cpython-311: module references __file__\n",
            "vllm.utils.__pycache__.__init__.cpython-311: module MAY be using inspect.getsource\n",
            "creating dist\n",
            "creating 'dist/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg\n",
            "Extracting vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg to /usr/local/lib/python3.11/dist-packages\n",
            "Adding vllm 0.10.1.dev405+g31f09c615.cpu to easy-install.pth file\n",
            "Installing vllm script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg\n",
            "Processing dependencies for vllm==0.10.1.dev405+g31f09c615.cpu\n",
            "Searching for numba==0.61.2\n",
            "Best match: numba 0.61.2\n",
            "Adding numba 0.61.2 to easy-install.pth file\n",
            "detected new path './vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg'\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for llguidance==0.7.30\n",
            "Best match: llguidance 0.7.30\n",
            "Adding llguidance 0.7.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for xgrammar==0.1.21\n",
            "Best match: xgrammar 0.1.21\n",
            "Adding xgrammar 0.1.21 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for triton==3.2.0\n",
            "Best match: triton 3.2.0\n",
            "Adding triton 3.2.0 to easy-install.pth file\n",
            "Installing proton script to /usr/local/bin\n",
            "Installing proton-viewer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for intel-extension-for-pytorch==2.6.0\n",
            "Best match: intel-extension-for-pytorch 2.6.0\n",
            "Adding intel-extension-for-pytorch 2.6.0 to easy-install.pth file\n",
            "Installing ipexrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for intel-openmp==2024.2.1\n",
            "Best match: intel-openmp 2024.2.1\n",
            "Adding intel-openmp 2024.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torch==2.6.0+cpu\n",
            "Best match: torch 2.6.0+cpu\n",
            "Adding torch 2.6.0+cpu to easy-install.pth file\n",
            "Installing torchfrtrace script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torchvision==0.21.0+cu124\n",
            "Best match: torchvision 0.21.0+cu124\n",
            "Adding torchvision 0.21.0+cu124 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torchaudio==2.6.0+cu124\n",
            "Best match: torchaudio 2.6.0+cu124\n",
            "Adding torchaudio 2.6.0+cu124 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for datasets==4.0.0\n",
            "Best match: datasets 4.0.0\n",
            "Adding datasets 4.0.0 to easy-install.pth file\n",
            "Installing datasets-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for setuptools==79.0.1\n",
            "Best match: setuptools 79.0.1\n",
            "Adding setuptools 79.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for packaging==25.0\n",
            "Best match: packaging 25.0\n",
            "Adding packaging 25.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for openai-harmony==0.0.3\n",
            "Best match: openai-harmony 0.0.3\n",
            "Adding openai-harmony 0.0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for setproctitle==1.3.6\n",
            "Best match: setproctitle 1.3.6\n",
            "Adding setproctitle 1.3.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cbor2==5.6.5\n",
            "Best match: cbor2 5.6.5\n",
            "Adding cbor2 5.6.5 to easy-install.pth file\n",
            "Installing cbor2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pybase64==1.4.2\n",
            "Best match: pybase64 1.4.2\n",
            "Adding pybase64 1.4.2 to easy-install.pth file\n",
            "Installing pybase64 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for ninja==1.11.1.4\n",
            "Best match: ninja 1.11.1.4\n",
            "Adding ninja 1.11.1.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for scipy==1.16.1\n",
            "Best match: scipy 1.16.1\n",
            "Adding scipy 1.16.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-json-logger==3.3.0\n",
            "Best match: python-json-logger 3.3.0\n",
            "Adding python-json-logger 3.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for watchfiles==1.1.0\n",
            "Best match: watchfiles 1.1.0\n",
            "Adding watchfiles 1.1.0 to easy-install.pth file\n",
            "Installing watchfiles script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cloudpickle==3.1.1\n",
            "Best match: cloudpickle 3.1.1\n",
            "Adding cloudpickle 3.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for depyf==0.19.0\n",
            "Best match: depyf 0.19.0\n",
            "Adding depyf 0.19.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for compressed-tensors==0.10.2\n",
            "Best match: compressed-tensors 0.10.2\n",
            "Adding compressed-tensors 0.10.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for einops==0.8.1\n",
            "Best match: einops 0.8.1\n",
            "Adding einops 0.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for PyYAML==6.0.2\n",
            "Best match: PyYAML 6.0.2\n",
            "Adding PyYAML 6.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opencv-python-headless==4.12.0.88\n",
            "Best match: opencv-python-headless 4.12.0.88\n",
            "Adding opencv-python-headless 4.12.0.88 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mistral-common==1.8.3\n",
            "Best match: mistral-common 1.8.3\n",
            "Adding mistral-common 1.8.3 to easy-install.pth file\n",
            "Installing mistral_common script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for gguf==0.17.1\n",
            "Best match: gguf 0.17.1\n",
            "Adding gguf 0.17.1 to easy-install.pth file\n",
            "Installing gguf-convert-endian script to /usr/local/bin\n",
            "Installing gguf-dump script to /usr/local/bin\n",
            "Installing gguf-editor-gui script to /usr/local/bin\n",
            "Installing gguf-new-metadata script to /usr/local/bin\n",
            "Installing gguf-set-metadata script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for msgspec==0.19.0\n",
            "Best match: msgspec 0.19.0\n",
            "Adding msgspec 0.19.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pyzmq==26.2.1\n",
            "Best match: pyzmq 26.2.1\n",
            "Adding pyzmq 26.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for partial-json-parser==0.2.1.1.post6\n",
            "Best match: partial-json-parser 0.2.1.1.post6\n",
            "Adding partial-json-parser 0.2.1.1.post6 to easy-install.pth file\n",
            "Installing json-playground script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for filelock==3.18.0\n",
            "Best match: filelock 3.18.0\n",
            "Adding filelock 3.18.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typing-extensions==4.14.1\n",
            "Best match: typing-extensions 4.14.1\n",
            "Adding typing-extensions 4.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for lark==1.2.2\n",
            "Best match: lark 1.2.2\n",
            "Adding lark 1.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for diskcache==5.6.3\n",
            "Best match: diskcache 5.6.3\n",
            "Adding diskcache 5.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for outlines-core==0.2.10\n",
            "Best match: outlines-core 0.2.10\n",
            "Adding outlines-core 0.2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for lm-format-enforcer==0.10.12\n",
            "Best match: lm-format-enforcer 0.10.12\n",
            "Adding lm-format-enforcer 0.10.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tiktoken==0.9.0\n",
            "Best match: tiktoken 0.9.0\n",
            "Adding tiktoken 0.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for prometheus-fastapi-instrumentator==7.1.0\n",
            "Best match: prometheus-fastapi-instrumentator 7.1.0\n",
            "Adding prometheus-fastapi-instrumentator 7.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pillow==11.3.0\n",
            "Best match: pillow 11.3.0\n",
            "Adding pillow 11.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for prometheus-client==0.22.1\n",
            "Best match: prometheus-client 0.22.1\n",
            "Adding prometheus-client 0.22.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic==2.11.7\n",
            "Best match: pydantic 2.11.7\n",
            "Adding pydantic 2.11.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for openai==1.98.0\n",
            "Best match: openai 1.98.0\n",
            "Adding openai 1.98.0 to easy-install.pth file\n",
            "Installing openai script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiohttp==3.12.15\n",
            "Best match: aiohttp 3.12.15\n",
            "Adding aiohttp 3.12.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi==0.116.1\n",
            "Best match: fastapi 0.116.1\n",
            "Adding fastapi 0.116.1 to easy-install.pth file\n",
            "Installing fastapi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for protobuf==5.29.5\n",
            "Best match: protobuf 5.29.5\n",
            "Adding protobuf 5.29.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tokenizers==0.21.4\n",
            "Best match: tokenizers 0.21.4\n",
            "Adding tokenizers 0.21.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for huggingface-hub==0.34.3\n",
            "Best match: huggingface-hub 0.34.3\n",
            "Adding huggingface-hub 0.34.3 to easy-install.pth file\n",
            "Installing hf script to /usr/local/bin\n",
            "Installing huggingface-cli script to /usr/local/bin\n",
            "Installing tiny-agents script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for transformers==4.55.0\n",
            "Best match: transformers 4.55.0\n",
            "Adding transformers 4.55.0 to easy-install.pth file\n",
            "Installing transformers script to /usr/local/bin\n",
            "Installing transformers-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for py-cpuinfo==9.0.0\n",
            "Best match: py-cpuinfo 9.0.0\n",
            "Adding py-cpuinfo 9.0.0 to easy-install.pth file\n",
            "Installing cpuinfo script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for blake3==1.0.5\n",
            "Best match: blake3 1.0.5\n",
            "Adding blake3 1.0.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tqdm==4.67.1\n",
            "Best match: tqdm 4.67.1\n",
            "Adding tqdm 4.67.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for requests==2.32.3\n",
            "Best match: requests 2.32.3\n",
            "Adding requests 2.32.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for numpy==2.0.2\n",
            "Best match: numpy 2.0.2\n",
            "Adding numpy 2.0.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing numpy-config script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sentencepiece==0.2.0\n",
            "Best match: sentencepiece 0.2.0\n",
            "Adding sentencepiece 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for psutil==5.9.5\n",
            "Best match: psutil 5.9.5\n",
            "Adding psutil 5.9.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cachetools==5.5.2\n",
            "Best match: cachetools 5.5.2\n",
            "Adding cachetools 5.5.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for regex==2024.11.6\n",
            "Best match: regex 2024.11.6\n",
            "Adding regex 2024.11.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for llvmlite==0.44.0\n",
            "Best match: llvmlite 0.44.0\n",
            "Adding llvmlite 0.44.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for intel-cmplr-lib-ur==2024.2.1\n",
            "Best match: intel-cmplr-lib-ur 2024.2.1\n",
            "Adding intel-cmplr-lib-ur 2024.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sympy==1.13.1\n",
            "Best match: sympy 1.13.1\n",
            "Adding sympy 1.13.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fsspec==2025.3.0\n",
            "Best match: fsspec 2025.3.0\n",
            "Adding fsspec 2025.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jinja2==3.1.6\n",
            "Best match: jinja2 3.1.6\n",
            "Adding jinja2 3.1.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for networkx==3.5\n",
            "Best match: networkx 3.5\n",
            "Adding networkx 3.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for multiprocess==0.70.16\n",
            "Best match: multiprocess 0.70.16\n",
            "Adding multiprocess 0.70.16 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for xxhash==3.5.0\n",
            "Best match: xxhash 3.5.0\n",
            "Adding xxhash 3.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pandas==2.2.2\n",
            "Best match: pandas 2.2.2\n",
            "Adding pandas 2.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for dill==0.3.8\n",
            "Best match: dill 0.3.8\n",
            "Adding dill 0.3.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pyarrow==18.1.0\n",
            "Best match: pyarrow 18.1.0\n",
            "Adding pyarrow 18.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for anyio==4.9.0\n",
            "Best match: anyio 4.9.0\n",
            "Adding anyio 4.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for astor==0.8.1\n",
            "Best match: astor 0.8.1\n",
            "Adding astor 0.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic-extra-types==2.10.5\n",
            "Best match: pydantic-extra-types 2.10.5\n",
            "Adding pydantic-extra-types 2.10.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jsonschema==4.25.0\n",
            "Best match: jsonschema 4.25.0\n",
            "Adding jsonschema 4.25.0 to easy-install.pth file\n",
            "Installing jsonschema script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for interegular==0.3.3\n",
            "Best match: interegular 0.3.3\n",
            "Adding interegular 0.3.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for starlette==0.47.2\n",
            "Best match: starlette 0.47.2\n",
            "Adding starlette 0.47.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typing-inspection==0.4.1\n",
            "Best match: typing-inspection 0.4.1\n",
            "Adding typing-inspection 0.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic-core==2.33.2\n",
            "Best match: pydantic-core 2.33.2\n",
            "Adding pydantic-core 2.33.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for annotated-types==0.7.0\n",
            "Best match: annotated-types 0.7.0\n",
            "Adding annotated-types 0.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sniffio==1.3.1\n",
            "Best match: sniffio 1.3.1\n",
            "Adding sniffio 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jiter==0.10.0\n",
            "Best match: jiter 0.10.0\n",
            "Adding jiter 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httpx==0.28.1\n",
            "Best match: httpx 0.28.1\n",
            "Adding httpx 0.28.1 to easy-install.pth file\n",
            "Installing httpx script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for distro==1.9.0\n",
            "Best match: distro 1.9.0\n",
            "Adding distro 1.9.0 to easy-install.pth file\n",
            "Installing distro script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for yarl==1.20.1\n",
            "Best match: yarl 1.20.1\n",
            "Adding yarl 1.20.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for propcache==0.3.2\n",
            "Best match: propcache 0.3.2\n",
            "Adding propcache 0.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for multidict==6.6.3\n",
            "Best match: multidict 6.6.3\n",
            "Adding multidict 6.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for frozenlist==1.7.0\n",
            "Best match: frozenlist 1.7.0\n",
            "Adding frozenlist 1.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for attrs==25.3.0\n",
            "Best match: attrs 25.3.0\n",
            "Adding attrs 25.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiosignal==1.4.0\n",
            "Best match: aiosignal 1.4.0\n",
            "Adding aiosignal 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiohappyeyeballs==2.6.1\n",
            "Best match: aiohappyeyeballs 2.6.1\n",
            "Adding aiohappyeyeballs 2.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for uvicorn==0.35.0\n",
            "Best match: uvicorn 0.35.0\n",
            "Adding uvicorn 0.35.0 to easy-install.pth file\n",
            "Installing uvicorn script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for email-validator==2.2.0\n",
            "Best match: email-validator 2.2.0\n",
            "Adding email-validator 2.2.0 to easy-install.pth file\n",
            "Installing email_validator script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-multipart==0.0.20\n",
            "Best match: python-multipart 0.0.20\n",
            "Adding python-multipart 0.0.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi-cli==0.0.8\n",
            "Best match: fastapi-cli 0.0.8\n",
            "Adding fastapi-cli 0.0.8 to easy-install.pth file\n",
            "Installing fastapi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for hf-xet==1.1.5\n",
            "Best match: hf-xet 1.1.5\n",
            "Adding hf-xet 1.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for safetensors==0.5.3\n",
            "Best match: safetensors 0.5.3\n",
            "Adding safetensors 0.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for certifi==2025.7.14\n",
            "Best match: certifi 2025.7.14\n",
            "Adding certifi 2025.7.14 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for urllib3==2.5.0\n",
            "Best match: urllib3 2.5.0\n",
            "Adding urllib3 2.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for idna==3.10\n",
            "Best match: idna 3.10\n",
            "Adding idna 3.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for charset-normalizer==3.4.2\n",
            "Best match: charset-normalizer 3.4.2\n",
            "Adding charset-normalizer 3.4.2 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for MarkupSafe==3.0.2\n",
            "Best match: MarkupSafe 3.0.2\n",
            "Adding MarkupSafe 3.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tzdata==2025.2\n",
            "Best match: tzdata 2025.2\n",
            "Adding tzdata 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pytz==2025.2\n",
            "Best match: pytz 2025.2\n",
            "Adding pytz 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-dateutil==2.9.0.post0\n",
            "Best match: python-dateutil 2.9.0.post0\n",
            "Adding python-dateutil 2.9.0.post0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for soxr==0.5.0.post1\n",
            "Best match: soxr 0.5.0.post1\n",
            "Adding soxr 0.5.0.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for soundfile==0.13.1\n",
            "Best match: soundfile 0.13.1\n",
            "Adding soundfile 0.13.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pycountry==24.6.1\n",
            "Best match: pycountry 24.6.1\n",
            "Adding pycountry 24.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rpds-py==0.26.0\n",
            "Best match: rpds-py 0.26.0\n",
            "Adding rpds-py 0.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for referencing==0.36.2\n",
            "Best match: referencing 0.36.2\n",
            "Adding referencing 0.36.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jsonschema-specifications==2025.4.1\n",
            "Best match: jsonschema-specifications 2025.4.1\n",
            "Adding jsonschema-specifications 2025.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httpcore==1.0.9\n",
            "Best match: httpcore 1.0.9\n",
            "Adding httpcore 1.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for websockets==15.0.1\n",
            "Best match: websockets 15.0.1\n",
            "Adding websockets 15.0.1 to easy-install.pth file\n",
            "Installing websockets script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for uvloop==0.21.0\n",
            "Best match: uvloop 0.21.0\n",
            "Adding uvloop 0.21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-dotenv==1.1.1\n",
            "Best match: python-dotenv 1.1.1\n",
            "Adding python-dotenv 1.1.1 to easy-install.pth file\n",
            "Installing dotenv script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httptools==0.6.4\n",
            "Best match: httptools 0.6.4\n",
            "Adding httptools 0.6.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for h11==0.16.0\n",
            "Best match: h11 0.16.0\n",
            "Adding h11 0.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for click==8.2.1\n",
            "Best match: click 8.2.1\n",
            "Adding click 8.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for dnspython==2.7.0\n",
            "Best match: dnspython 2.7.0\n",
            "Adding dnspython 2.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi-cloud-cli==0.1.5\n",
            "Best match: fastapi-cloud-cli 0.1.5\n",
            "Adding fastapi-cloud-cli 0.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rich-toolkit==0.14.9\n",
            "Best match: rich-toolkit 0.14.9\n",
            "Adding rich-toolkit 0.14.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typer==0.16.0\n",
            "Best match: typer 0.16.0\n",
            "Adding typer 0.16.0 to easy-install.pth file\n",
            "Installing typer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for six==1.17.0\n",
            "Best match: six 1.17.0\n",
            "Adding six 1.17.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cffi==1.17.1\n",
            "Best match: cffi 1.17.1\n",
            "Adding cffi 1.17.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sentry-sdk==2.34.1\n",
            "Best match: sentry-sdk 2.34.1\n",
            "Adding sentry-sdk 2.34.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rignore==0.6.4\n",
            "Best match: rignore 0.6.4\n",
            "Adding rignore 0.6.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rich==13.9.4\n",
            "Best match: rich 13.9.4\n",
            "Adding rich 13.9.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for shellingham==1.5.4\n",
            "Best match: shellingham 1.5.4\n",
            "Adding shellingham 1.5.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pycparser==2.22\n",
            "Best match: pycparser 2.22\n",
            "Adding pycparser 2.22 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pygments==2.19.2\n",
            "Best match: pygments 2.19.2\n",
            "Adding pygments 2.19.2 to easy-install.pth file\n",
            "Installing pygmentize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for markdown-it-py==3.0.0\n",
            "Best match: markdown-it-py 3.0.0\n",
            "Adding markdown-it-py 3.0.0 to easy-install.pth file\n",
            "Installing markdown-it script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mdurl==0.1.2\n",
            "Best match: mdurl 0.1.2\n",
            "Adding mdurl 0.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Finished processing dependencies for vllm==0.10.1.dev405+g31f09c615.cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3LUq6m0qUk1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ي/vllm_source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83e95ca-e427-4ff4-8e0b-f93ec25fc2ce",
        "id": "E55PRHlMUlXF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ي/vllm_source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git rev-parse HEAD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4eb1a36-160d-4c0a-94c1-93c7d8a2656d",
        "id": "v80uk99rUlXG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e8961e963a76feb3e2c080220e79d2d5a9d272f9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout 471fe6563"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2843466f-e605-4331-face-3cf7a7709e24",
        "id": "bAhIa3DFUlXH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: switching to '471fe6563'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 471fe6563 [TPU][V1] Implicitly adjust page size when there's SMEM OOM (#16871)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"importlib-metadata>=6.0,<=8.0.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0c1a4c-af9d-4407-ba74-55f232812cdc",
        "id": "NHFXpe4VUlXH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting importlib-metadata<=8.0.0,>=6.0\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.0.0,>=6.0) (3.23.0)\n",
            "Downloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: importlib-metadata\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-api 1.26.0 requires deprecated>=1.2.6, which is not installed.\n",
            "opentelemetry-sdk 1.26.0 requires opentelemetry-semantic-conventions==0.47b0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-http 1.26.0 requires deprecated>=1.2.6, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-http 1.26.0 requires opentelemetry-exporter-otlp-proto-common==1.26.0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-http 1.26.0 requires opentelemetry-proto==1.26.0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.26.0 requires deprecated>=1.2.6, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.26.0 requires opentelemetry-exporter-otlp-proto-common==1.26.0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.26.0 requires opentelemetry-proto==1.26.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed importlib-metadata-8.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"protobuf>=3.19,<5.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "c63d45b5-d76d-44ec-dbb6-c96f3ac82a21",
        "id": "hNRc2uDoUlXI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf<5.0,>=3.19\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-4.25.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "44999ff17d1048d5bbd4e6e97d43396d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ي/vllm_source\n",
        "!VLLM_TARGET_DEVICE=cpu python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bece9007-920b-4a9f-f188-4a87a1de7d8a",
        "id": "7ouk2HnhUlXJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ي/vllm_source\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/config/_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
            "\n",
            "        By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  corresp(dist, value, root_dir)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/config/_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: Apache Software License\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist._finalize_license_expression()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: Apache Software License\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self._finalize_license_expression()\n",
            "running install\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:90: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing vllm.egg-info/PKG-INFO\n",
            "writing dependency_links to vllm.egg-info/dependency_links.txt\n",
            "writing entry points to vllm.egg-info/entry_points.txt\n",
            "writing requirements to vllm.egg-info/requires.txt\n",
            "writing top-level names to vllm.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'vllm.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying vllm/collect_env.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/version.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/utils.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_custom_ops.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/logits_process.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/sampling_params.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/pooling_params.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_ipex_ops.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_version.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/scripts.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/beam_search.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/connections.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/sequence.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/scalar_type.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/envs.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/outputs.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/config.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/logger.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/jsontree.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/tracing.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/env_override.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/forward_context.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/test_utils.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/multimodal/image.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/video.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/parse.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/audio.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/profiling.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/inputs.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/processing.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/hasher.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/base.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/assets/image.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/video.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/audio.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/base.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/executor/ray_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/uniproc_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/executor_base.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/ray_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/msgspec_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/mp_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/multiproc_worker_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/worker/worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/hpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuron_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cpu_pooling_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/pooling_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_hpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/tpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuron_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/hpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/xpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cpu_enc_dec_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_tpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/enc_dec_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/xpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/tpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/model_runner_base.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cache_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/distributed/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/communication_op.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/parallel_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/plugins/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/plugins\n",
            "copying vllm/inputs/preprocess.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/data.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/parse.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/reasoning/abs_reasoning_parsers.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/granite_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/deepseek_r1_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/triton_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "copying vllm/triton_utils/importing.py -> build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "copying vllm/device_allocator/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "copying vllm/device_allocator/cumem.py -> build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "copying vllm/model_executor/parameter.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/pooling_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/custom_op.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/sampling_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/entrypoints/score_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/chat_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/launcher.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/llm.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/api_server.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/ssl.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/logger.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/attention/layer.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/selector.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/usage/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "copying vllm/usage/usage_lib.py -> build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "copying vllm/adapter_commons/models.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/request.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/engine/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/async_llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/async_timeout.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/protocol.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/arg_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/metrics_types.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/third_party/pynvml.py -> build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "copying vllm/third_party/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "copying vllm/logging_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/logging_utils/formatter.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/spec_decode/spec_decode_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/mlp_speculator_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/top1_proposer.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/proposer_worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/smaller_tp_proposer_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/util.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/mqa_scorer.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/draft_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/multi_step_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/medusa_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/ngram_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/batch_expansion.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/target_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/transformers_utils/tokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/tokenizer_base.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/detokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/s3_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/detokenizer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/config.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/processor.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/core/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/placeholder_block_space_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/block_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/evictor.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/platforms/cuda.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/rocm.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/neuron.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/cpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/hpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/tpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/xpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/lora/models.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/fully_sharded_layers.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/lora.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/request.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/peft_helper.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/resolver.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/v1/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/request.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/kv_cache_interface.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/outputs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/serial_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/profiler/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/layerwise_profile.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/prompt_adapter/models.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/request.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/compilation/compiler_interface.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/decorators.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/counter.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/backends.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/vllm_inductor_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fix_functionalization.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/monitor.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/pass_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fx_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/inductor_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/torch25_custom_graph_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/noop_elimination.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fusion.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/multi_output_match.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/distributed/kv_transfer/kv_connector_agent.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/kv_transfer_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/device_communicators/tpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cuda_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/base_device_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/neuron_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/custom_all_reduce_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/pynccl_wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/hpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/xpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/shm_broadcast.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/custom_all_reduce.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/pynccl.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cuda_wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_connector/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/mooncake_store_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/factory.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/simple_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/lmcache_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/model_executor/models/minicpm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_5_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/pixtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interfaces_base.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granite.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/idefics3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bloom.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/fairseq2_llama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_j.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/intern_vit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/grok1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mllama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpmv.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_mtp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_audio.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/stablelm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_onevision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/clip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/adapters.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/constant_size_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_5_omni_thinker.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/idefics2_vision_model.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bart.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmo2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama_eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/molmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/teleflm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/module_mapping.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3_small.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mixtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/zamba2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/telechat2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jais.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/dbrx.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_v2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/kimi_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mllama4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/orion.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/whisper.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/opt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/prithvi_geospatial_mae.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internlm2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/smolvlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_bigcode.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/baichuan.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpm3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoeshared.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mixtral_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internvl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/arctic.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/blip2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phimoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nvlm_d.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internlm2_ve.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/transformers.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/siglip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron_nas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_rm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mpt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/commandr.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mlp_speculator.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/plamo2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/chatglm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_next_video.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aya_vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/falcon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/chameleon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_text_01.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ultravox.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bert.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/starcoder2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/modernbert.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/blip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/fuyu.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm_audio.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3_mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/solar.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/paligemma.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/exaone.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_neox.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/persimmon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mistral3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/skyworkr1v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aria.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gritlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_next.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/moonvit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/florence2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen3_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/roberta.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/h2ovl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/layers/rejection_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/rotary_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/linear.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/pooler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/layernorm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/resampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/typical_acceptance_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/lightning_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/activation.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/spec_decode_base_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/logits_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/vocab_parallel_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/model_loader/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/neuron.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/tensorizer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/weight_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/guided_decoding/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/guided_fields.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/outlines_decoding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/xgrammar_decoding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/guidance_logits_processors.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/outlines_logits_processors.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/guidance_decoding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/layers/quantization/schema.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/torchao.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/ipex_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/experts_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gguf.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/aqlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/modelopt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/fbgemm_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq_triton.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/base_config.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/qqq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/tpu_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/moe_wna16.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/kv_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_marlin_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/bitsandbytes.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/ptpc_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/hqq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/deepspeedfp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/neuron_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/fused_moe/layer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/cutlass_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_torch_iterative.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_align_block_size.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_marlin_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/mamba/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_mixer2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_mixer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba2_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/quantization/quark/quark.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/quark_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/kernels/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/utils/machete_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/fp8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/w8a8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/int8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/layer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/allspark_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/quant_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/gptq_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/mamba/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_state_passing.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_bmm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/causal_conv1d.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/mamba_ssm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_combined.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/guided_decoding/reasoner/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/reasoner\n",
            "copying vllm/entrypoints/openai/serving_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_transcription.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/cli_args.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_chat.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_completion.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_pooling.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/run_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/logits_processors.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/api_server.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_score.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_tokenization.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_models.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/protocol.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/cli/collect_env.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/types.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/openai.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/main.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/openai/tool_parsers/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/cli/benchmark/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/throughput.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/main.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/latency.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/base.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/attention/backends/flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flashinfer.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/xformers.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/ipex_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/cpu_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/hpu_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/rocm_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/triton_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/blocksparse_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/placeholder_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/torch_sdpa.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/ops/triton_decode_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_merge_attn_states.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_flash_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/ipex_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/hpu_paged_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/prefix_prefill.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/chunked_prefill_paged_decode.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/nki_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/paged_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/merge_attn_states.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/backends/mla/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "copying vllm/attention/backends/mla/common.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "copying vllm/attention/ops/blocksparse_attention/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention\n",
            "copying vllm/attention/ops/blocksparse_attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention\n",
            "copying vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention\n",
            "copying vllm/attention/ops/blocksparse_attention/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention\n",
            "copying vllm/engine/multiprocessing/client.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/output_processor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/single_step.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/multi_step.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/stop_checker.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/util.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/transformers_utils/configs/mllama.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/olmo2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/telechat2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/jais.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nemotron.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/dbrx.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/kimi_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/internvl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/arctic.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nvlm_d.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mpt.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mlp_speculator.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/chatglm.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/cohere2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/falcon.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/ultravox.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/solar.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/exaone.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/skyworkr1v.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/moonvit.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/h2ovl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/tokenizer_group/tokenizer_group.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group\n",
            "copying vllm/transformers_utils/tokenizer_group/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group\n",
            "copying vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group\n",
            "copying vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group\n",
            "copying vllm/transformers_utils/tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "copying vllm/transformers_utils/tokenizers/mistral.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "copying vllm/transformers_utils/processors/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/transformers_utils/processors/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/core/block/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/prefix_caching_block.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/common.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/naive_block.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/block_table.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/cpu_gpu_block_allocator.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/lora/punica_wrapper/punica_hpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_base.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_selector.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_cpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_gpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops\n",
            "copying vllm/lora/ops/triton_ops/lora_expand.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_kernel_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_shrink.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/kernel_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/torch_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "copying vllm/lora/ops/torch_ops/lora_ops.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "copying vllm/v1/executor/ray_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/multiproc_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/structured_output/backend_guidance.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_xgrammar.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/request.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_types.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/metrics/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/loggers.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/stats.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/worker/worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/lora_model_runner_mixin.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/block_table.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_input_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/stats/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/stats\n",
            "copying vllm/v1/stats/common.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/stats\n",
            "copying vllm/v1/sample/rejection_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention\n",
            "copying vllm/v1/engine/core.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/mm_input_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/core_client.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/detokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/parallel_sampling.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/logprobs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/output_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/exceptions.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/async_llm.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/spec_decode/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/ngram_proposer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/core/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/block_pool.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/specialized_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/encoder_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/sample/ops/bad_words.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/topk_topp_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/penalties.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/tpu/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/attention/backends/flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/triton_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/mla/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/common.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/triton_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/core/sched/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/output.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:212: _Warning: Package 'vllm.benchmarks' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'vllm.benchmarks' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'vllm.benchmarks' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'vllm.benchmarks' to be distributed and are\n",
            "        already explicitly excluding 'vllm.benchmarks' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:212: _Warning: Package 'vllm.model_executor.layers.fused_moe.configs' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'vllm.model_executor.layers.fused_moe.configs' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'vllm.model_executor.layers.fused_moe.configs' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'vllm.model_executor.layers.fused_moe.configs' to be distributed and are\n",
            "        already explicitly excluding 'vllm.model_executor.layers.fused_moe.configs' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:212: _Warning: Package 'vllm.model_executor.layers.quantization.utils.configs' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'vllm.model_executor.layers.quantization.utils.configs' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'vllm.model_executor.layers.quantization.utils.configs' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'vllm.model_executor.layers.quantization.utils.configs' to be distributed and are\n",
            "        already explicitly excluding 'vllm.model_executor.layers.quantization.utils.configs' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:212: _Warning: Package 'vllm.vllm_flash_attn' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'vllm.vllm_flash_attn' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'vllm.vllm_flash_attn' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'vllm.vllm_flash_attn' to be distributed and are\n",
            "        already explicitly excluding 'vllm.vllm_flash_attn' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "copying vllm/py.typed -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/benchmarks/datasets.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/endpoint_request_func.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/latency.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/throughput.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/vllm_flash_attn/.gitkeep -> build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn\n",
            "copying vllm/vllm_flash_attn/fa_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/distributed/kv_transfer/README.md -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/README -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "running build_ext\n",
            "-- Build type: RelWithDebInfo\n",
            "-- Target device: cpu\n",
            "-- Found python matching: /usr/bin/python3.\n",
            "\u001b[33mCMake Warning at /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:22 (message):\n",
            "  static library kineto_LIBRARY-NOTFOUND not found.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:121 (append_torchlib_if_found)\n",
            "  CMakeLists.txt:81 (find_package)\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[33mCMake Warning at cmake/cpu_extension.cmake:107 (message):\n",
            "  vLLM CPU backend using AVX2 ISA\n",
            "Call Stack (most recent call first):\n",
            "  CMakeLists.txt:89 (include)\n",
            "\n",
            "\u001b[0m\n",
            "-- CPU extension compile flags: -mf16c;-fopenmp;-DVLLM_CPU_EXTENSION;-mavx2\n",
            "-- Enabling C extension.\n",
            "-- Configuring done (6.1s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/ي/vllm_source/build/temp.linux-x86_64-cpython-311\n",
            "ninja: no work to do.\n",
            "-- Install configuration: \"RelWithDebInfo\"\n",
            "-- Up-to-date: /content/ي/vllm_source/build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so\n",
            "Copying build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn/fa_utils.py to vllm/vllm_flash_attn/fa_utils.py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/collect_env.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/__init__.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/lazy_utils.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/ray_env.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/version.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/image.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/utils.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/__init__.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/registry.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/video.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/parse.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/audio.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/profiling.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/inputs.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/processing.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/hasher.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/base.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "creating build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/image.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/__init__.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/video.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/audio.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/base.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/ray_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/uniproc_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/executor_base.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/ray_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/msgspec_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/mp_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/multiproc_worker_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/__init__.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_custom_ops.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logits_process.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/worker_base.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/hpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuron_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/utils.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/__init__.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cpu_pooling_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/pooling_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_hpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/tpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuron_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/hpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/xpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cpu_enc_dec_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_tpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/enc_dec_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/xpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_neuron_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/tpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/model_runner_base.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_neuronx_distributed_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuronx_distributed_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cache_engine.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector_agent.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/README.md -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_transfer_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/mooncake_store_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/factory.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/simple_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/lmcache_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/communication_op.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/rebalance_execute.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/eplb_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/rebalance_algo.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/tpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/ray_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cuda_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/all2all.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/base_device_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/neuron_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/custom_all_reduce_utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/pynccl_wrapper.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/quick_all_reduce.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/hpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/xpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/shm_broadcast.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/custom_all_reduce.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/pynccl.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cuda_wrapper.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_events.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/parallel_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/tpu_distributed_utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/plugins\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/__init__.py -> build/bdist.linux-x86_64/egg/vllm/plugins\n",
            "creating build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/README.md -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/filesystem_resolver.py -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/preprocess.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/__init__.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/registry.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/data.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/parse.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/sampling_params.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/glm4_moe_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/qwen3_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/abs_reasoning_parsers.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/step3_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/gptoss_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/__init__.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/granite_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/hunyuan_a13b_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/deepseek_r1_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/mistral_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/pooling_params.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_ipex_ops.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn/fa_utils.py -> build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn/.gitkeep -> build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "creating build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/triton_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/triton_utils/importing.py -> build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/device_allocator/__init__.py -> build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/device_allocator/cumem.py -> build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_version.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/scripts.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/parameter.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aimv2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_5_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/pixtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interfaces_base.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granite.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ernie45.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_vl_01.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/idefics3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bloom.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/fairseq2_llama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/dots1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_j.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/intern_vit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/grok1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mllama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mimo_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpmv.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/voxtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ernie45_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_audio.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/stablelm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_onevision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/clip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/medusa.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/adapters.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bailing_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/hunyuan_v1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mimo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/constant_size_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_5_omni_thinker.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_moe_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/idefics2_vision_model.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/registry.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bart.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmo2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bert_with_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/tarsier.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/molmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/teleflm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/module_mapping.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3_small.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mixtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/zamba2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/telechat2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_1v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jais.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/exaone4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama_eagle3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/hyperclovax_vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/dbrx.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/step3_text.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_v2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/kimi_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mllama4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/orion.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/whisper.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/opt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/prithvi_geospatial_mae.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jina_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internlm2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/smolvlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3n.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_bigcode.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/baichuan.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoeshared.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mixtral_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internvl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/arctic.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/blip2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phimoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nvlm_d.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internlm2_ve.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ovis.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/transformers.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/siglip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_nas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_rm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mpt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/commandr.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4_multimodal.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mlp_speculator.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/plamo2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/chatglm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_next_video.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aya_vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/falcon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/chameleon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_text_01.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ultravox.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interns1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bert.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/arcee.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/starcoder2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/modernbert.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/blip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granite_speech.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/fuyu.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama4_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm_audio.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3_mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoehybrid.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/solar.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4flash.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/keye.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/paligemma.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/exaone.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_neox.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/persimmon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mistral3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/skyworkr1v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_oss.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aria.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gritlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_next.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/moonvit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_h.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/florence2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen3_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/roberta.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interns1_vit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/step3_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/falcon_h1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/h2ovl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/input_quant_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/schema.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/torchao.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/ipex_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/experts_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/quark.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/quark_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/mxfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gguf.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/aqlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/modelopt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/fbgemm_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/auto_round.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq_triton.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/base_config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/qqq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/tpu_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/moe_wna16.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/inc.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kv_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_marlin_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/rtn.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/bitsandbytes.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/ptpc_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/hqq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/machete_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/fp8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/w8a8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/int8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/layer_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/allspark_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/quant_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/gptq_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/bitblas_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/mxfp4_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/flashinfer_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/deepspeedfp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/neuron_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/deepgemm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rejection_sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/linear.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/layer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/README -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_batched_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/cutlass_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_pallas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deep_gemm_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_torch_iterative.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/cpu_fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/modular_kernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_align_block_size.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_marlin_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/mrope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/llama3_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/common.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/base.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/pooler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/layernorm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/resampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/typical_acceptance_sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/layernorm_gated.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_state_passing.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_bmm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/causal_conv1d.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/mamba_ssm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_combined.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/abstract.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_mixer2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_mixer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba2_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/lightning_attn.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/activation.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/spec_decode_base_sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/logits_processor.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/vocab_parallel_embedding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/pooling_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/sharded_state_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/runai_streamer_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/neuron.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tensorizer_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tensorizer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/neuronx_distributed.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/dummy_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/gguf_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/weight_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/base_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tpu.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/bitsandbytes_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/default_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/guided_fields.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/outlines_decoding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/xgrammar_decoding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/guidance_logits_processors.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/reasoner\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/reasoner/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/reasoner\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/outlines_logits_processors.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/guidance_decoding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/custom_op.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/sampling_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/score_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_engine.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_responses.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_transcription.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/cli_args.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/speech_to_text.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_chat.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_completion.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_pooling.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/run_batch.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/logits_processors.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/api_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_score.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_embedding.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_classification.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_tokenization.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_models.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/protocol.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/tool_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/harmony_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/chat_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/launcher.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/llm.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/api_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/collect_env.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/types.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/openai.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/main.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/serve.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/run_batch.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/throughput.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/main.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/serve.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/latency.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/base.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/ssl.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/logger.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/context.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/tool.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/beam_search.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/connections.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/layer.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/xformers.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/dual_chunk_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/ipex_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/differential_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/cpu_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/hpu_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/rocm_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/abstract.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/triton_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla/common.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/blocksparse_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/placeholder_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/torch_sdpa.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/pallas.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_decode_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_unified_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_merge_attn_states.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_flash_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention/utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention/interface.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/ipex_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/hpu_paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/prefix_prefill.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/chunked_prefill_paged_decode.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/nki_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/rocm_aiter_paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/pallas_kv_cache_update.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/merge_attn_states.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/selector.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/fa_utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/kv_sharing_utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/usage\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/usage/__init__.py -> build/bdist.linux-x86_64/egg/vllm/usage\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/usage/usage_lib.py -> build/bdist.linux-x86_64/egg/vllm/usage\n",
            "creating build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/models.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/utils.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/__init__.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/request.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/layers.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/metrics.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/async_llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/async_timeout.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/client.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/engine.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/single_step.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/multi_step.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/stop_checker.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/util.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/protocol.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/arg_utils.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/metrics_types.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/third_party/pynvml.py -> build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/third_party/__init__.py -> build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "creating build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/dump_input.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/formatter.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/sequence.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/spec_decode_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/__init__.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/mlp_speculator_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/metrics.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/top1_proposer.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/proposer_worker_base.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/smaller_tp_proposer_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/util.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/mqa_scorer.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/draft_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/multi_step_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/medusa_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/ngram_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/batch_expansion.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/target_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/scalar_type.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_chatml.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_deepseek_vl2.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/registry.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_blip2.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_fuyu.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_basic.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mllama.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/medusa.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/olmo2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/telechat2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/jais.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mistral.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/dbrx.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/kimi_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/internvl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/arctic.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nvlm_d.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/ovis.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mpt.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mlp_speculator.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/eagle.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/chatglm.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/algos.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/base.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/cohere2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/falcon.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/ultravox.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/solar.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/exaone.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/skyworkr1v.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/moonvit.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron_h.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/step3_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/h2ovl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_base.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/detokenizer.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/dynamic_module.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/s3_utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group/tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers/mistral.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/detokenizer_utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/config.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/ovis.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processor.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/envs.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/__init__.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/placeholder_block_space_manager.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block_manager.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/utils.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/__init__.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/prefix_caching_block.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/common.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/naive_block.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/block_table.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/cpu_gpu_block_allocator.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/evictor.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/scheduler.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/cuda.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/rocm.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/__init__.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/neuron.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/interface.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/cpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/hpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/tpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/xpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/models.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/fully_sharded_layers.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_hpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_base.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_selector.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_cpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_gpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_tpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_xpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/lora.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_expand.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_shrink_op.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_kernel_metadata.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_expand_op.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_shrink.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/kernel_utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/request.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/peft_helper.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/resolver.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/layers.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/tasks.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/outputs.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/ray_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/multiproc_executor.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/abstract.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_guidance.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_xgrammar.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/request.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_outlines.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_types.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/reader.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/loggers.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/stats.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/prometheus.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/ray_wrappers.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/worker_base.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/lora_model_runner_mixin.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/xpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/kv_connector_model_runner_mixin.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/cpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/xpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/cpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_input_batch.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/block_table.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_input_batch.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/stats\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/stats/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/stats\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/stats/common.py -> build/bdist.linux-x86_64/egg/vllm/v1/stats\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/pool/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/pool/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/rejection_sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/bad_words.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/topk_topp_sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/logprobs.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/penalties.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/logits_processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/xformers.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/triton_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flex_attention.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba1_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba_selectors.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/common.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/triton_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/cutlass_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/rocm_aiter_fa.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/tree_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/cpu_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/pallas.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/request.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/core.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/mm_input_cache.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/core_client.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/detokenizer.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/parallel_sampling.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/logprobs.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/output_processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/exceptions.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/async_llm.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/coordinator.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/medusa.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/metrics.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/eagle.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/ngram_proposer.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/kv_cache_interface.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/block_pool.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_coordinator.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/specialized_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/single_type_kv_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/encoder_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/interface.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/output.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/async_scheduler.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/scheduler.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/request_queue.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/outputs.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/serial_utils.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/config.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logger.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/tensor_schema.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/deep_gemm.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/jsontree.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/utils.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/__init__.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/layerwise_profile.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/py.typed -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/utils.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/__init__.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/endpoint_request_func.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/throughput.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/datasets.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/serve.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/latency.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "creating build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/utils.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/__init__.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/ready_checker.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/endpoint_request_func.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/tracing.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/models.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/utils.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/__init__.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/request.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/layers.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/env_override.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/forward_context.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/test_utils.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/compiler_interface.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/decorators.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/__init__.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/counter.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/wrapper.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/backends.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/vllm_inductor_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fusion_attn.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fix_functionalization.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/base_piecewise_backend.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/monitor.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/activation_quant_fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/pass_manager.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/sequence_parallelism.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fx_utils.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/collective_fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/inductor_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/torch25_custom_graph_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/noop_elimination.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/cuda_piecewise_backend.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/multi_output_match.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/collect_env.py to collect_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/lazy_utils.py to lazy_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/ray_env.py to ray_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/version.py to version.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/image.py to image.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/video.py to video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/parse.py to parse.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/audio.py to audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/profiling.py to profiling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/inputs.py to inputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/processing.py to processing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/hasher.py to hasher.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/image.py to image.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/video.py to video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/audio.py to audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/ray_distributed_executor.py to ray_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/uniproc_executor.py to uniproc_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/executor_base.py to executor_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/ray_utils.py to ray_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/msgspec_utils.py to msgspec_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/mp_distributed_executor.py to mp_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/multiproc_worker_utils.py to multiproc_worker_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_custom_ops.py to _custom_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logits_process.py to logits_process.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/worker_base.py to worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/hpu_model_runner.py to hpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuron_worker.py to neuron_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_model_runner.py to multi_step_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cpu_pooling_model_runner.py to cpu_pooling_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/pooling_model_runner.py to pooling_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_hpu_worker.py to multi_step_hpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/tpu_model_runner.py to tpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuron_model_runner.py to neuron_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/hpu_worker.py to hpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/xpu_model_runner.py to xpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cpu_enc_dec_model_runner.py to cpu_enc_dec_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/model_runner.py to model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cpu_worker.py to cpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_tpu_worker.py to multi_step_tpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/enc_dec_model_runner.py to enc_dec_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/xpu_worker.py to xpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_neuron_model_runner.py to multi_step_neuron_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_worker.py to multi_step_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/tpu_worker.py to tpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cpu_model_runner.py to cpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/model_runner_base.py to model_runner_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_neuronx_distributed_model_runner.py to multi_step_neuronx_distributed_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/worker.py to worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuronx_distributed_model_runner.py to neuronx_distributed_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cache_engine.py to cache_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector_agent.py to kv_connector_agent.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py to pynccl_pipe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py to mooncake_pipe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py to simple_buffer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py to mooncake_store.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_transfer_state.py to kv_transfer_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/mooncake_store_connector.py to mooncake_store_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/factory.py to factory.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py to shared_storage_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py to nixl_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py to p2p_nccl_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py to p2p_nccl_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py to tensor_memory_pool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py to multi_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py to lmcache_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/simple_connector.py to simple_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/lmcache_connector.py to lmcache_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/communication_op.py to communication_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/rebalance_execute.py to rebalance_execute.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/eplb_state.py to eplb_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/rebalance_algo.py to rebalance_algo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/tpu_communicator.py to tpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/ray_communicator.py to ray_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cpu_communicator.py to cpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cuda_communicator.py to cuda_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/all2all.py to all2all.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/base_device_communicator.py to base_device_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/neuron_communicator.py to neuron_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/custom_all_reduce_utils.py to custom_all_reduce_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/pynccl_wrapper.py to pynccl_wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/quick_all_reduce.py to quick_all_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/hpu_communicator.py to hpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/xpu_communicator.py to xpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/shm_broadcast.py to shm_broadcast.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/custom_all_reduce.py to custom_all_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/pynccl.py to pynccl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cuda_wrapper.py to cuda_wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_events.py to kv_events.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/parallel_state.py to parallel_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/tpu_distributed_utils.py to tpu_distributed_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers/filesystem_resolver.py to filesystem_resolver.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/preprocess.py to preprocess.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/data.py to data.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/parse.py to parse.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/sampling_params.py to sampling_params.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/glm4_moe_reasoning_parser.py to glm4_moe_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/qwen3_reasoning_parser.py to qwen3_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/abs_reasoning_parsers.py to abs_reasoning_parsers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/step3_reasoning_parser.py to step3_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/gptoss_reasoning_parser.py to gptoss_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/granite_reasoning_parser.py to granite_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/hunyuan_a13b_reasoning_parser.py to hunyuan_a13b_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/deepseek_r1_reasoning_parser.py to deepseek_r1_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/mistral_reasoning_parser.py to mistral_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/pooling_params.py to pooling_params.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_ipex_ops.py to _ipex_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn/fa_utils.py to fa_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/triton_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/triton_utils/importing.py to importing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/device_allocator/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/device_allocator/cumem.py to cumem.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_version.py to _version.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/scripts.py to scripts.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/parameter.py to parameter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aimv2.py to aimv2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm.py to minicpm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_5_vl.py to qwen2_5_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/pixtral.py to pixtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interfaces_base.py to interfaces_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm_eagle.py to minicpm_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granite.py to granite.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ernie45.py to ernie45.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi.py to phi.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_vl_01.py to minimax_vl_01.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/idefics3.py to idefics3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bloom.py to bloom.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/fairseq2_llama.py to fairseq2_llama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/dots1.py to dots1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_j.py to gpt_j.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/intern_vit.py to intern_vit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/grok1.py to grok1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek.py to deepseek.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mllama.py to mllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mimo_mtp.py to mimo_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpmv.py to minicpmv.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/voxtral.py to voxtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma2.py to gemma2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ernie45_moe.py to ernie45_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_mtp.py to deepseek_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_audio.py to qwen2_audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/stablelm.py to stablelm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/vision.py to vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_onevision.py to llava_onevision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/clip.py to clip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/adapters.py to adapters.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bailing_moe.py to bailing_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/hunyuan_v1.py to hunyuan_v1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mimo.py to mimo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava.py to llava.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/constant_size_cache.py to constant_size_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_5_omni_thinker.py to qwen2_5_omni_thinker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3.py to phi3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_moe_mtp.py to glm4_moe_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/idefics2_vision_model.py to idefics2_vision_model.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bart.py to bart.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma.py to gemma.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmo2.py to olmo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen3.py to qwen3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama_eagle.py to llama_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bert_with_rope.py to bert_with_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/tarsier.py to tarsier.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2.py to qwen2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/molmo.py to molmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/teleflm.py to teleflm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba_cache.py to mamba_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_vl.py to qwen2_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/module_mapping.py to module_mapping.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3_small.py to phi3_small.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mixtral.py to mixtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/zamba2.py to zamba2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3v.py to phi3v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/telechat2.py to telechat2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_1v.py to glm4_1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jais.py to jais.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/exaone4.py to exaone4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4.py to glm4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama_eagle3.py to llama_eagle3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_moe.py to qwen2_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/hyperclovax_vision.py to hyperclovax_vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron.py to nemotron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/dbrx.py to dbrx.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/step3_text.py to step3_text.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_v2.py to deepseek_v2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/kimi_vl.py to kimi_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_cache.py to minimax_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mllama4.py to mllama4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/orion.py to orion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/whisper.py to whisper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/opt.py to opt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/prithvi_geospatial_mae.py to prithvi_geospatial_mae.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm_utils.py to phi4mm_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jina_vl.py to jina_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmoe.py to olmoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internlm2.py to internlm2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/smolvlm.py to smolvlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3n.py to gemma3n.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_bigcode.py to gpt_bigcode.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/baichuan.py to baichuan.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm3.py to minicpm3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoeshared.py to granitemoeshared.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm.py to glm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen.py to qwen.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mixtral_quant.py to mixtral_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba2.py to mamba2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internvl.py to internvl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba.py to mamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/arctic.py to arctic.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/blip2.py to blip2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phimoe.py to phimoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama.py to llama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nvlm_d.py to nvlm_d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_moe.py to glm4_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internlm2_ve.py to internlm2_ve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/transformers.py to transformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/siglip.py to siglip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_nas.py to nemotron_nas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_rm.py to qwen2_rm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bamba.py to bamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mpt.py to mpt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/commandr.py to commandr.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt2.py to gpt2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmo.py to olmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4_multimodal.py to phi4_multimodal.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mlp_speculator.py to mlp_speculator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/plamo2.py to plamo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm.py to phi4mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/chatglm.py to chatglm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_next_video.py to llava_next_video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aya_vision.py to aya_vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen_vl.py to qwen_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/falcon.py to falcon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3.py to gemma3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/chameleon.py to chameleon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_text_01.py to minimax_text_01.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ultravox.py to ultravox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interns1.py to interns1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bert.py to bert.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/arcee.py to arcee.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/starcoder2.py to starcoder2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4v.py to glm4v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jamba.py to jamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/modernbert.py to modernbert.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/blip.py to blip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granite_speech.py to granite_speech.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/fuyu.py to fuyu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_vl.py to nemotron_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoe.py to granitemoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama4_eagle.py to llama4_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm_audio.py to phi4mm_audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3_mm.py to gemma3_mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama4.py to llama4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoehybrid.py to granitemoehybrid.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/solar.py to solar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4flash.py to phi4flash.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/keye.py to keye.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/paligemma.py to paligemma.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/exaone.py to exaone.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_neox.py to gpt_neox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/persimmon.py to persimmon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mistral3.py to mistral3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/skyworkr1v.py to skyworkr1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_oss.py to gpt_oss.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aria.py to aria.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gritlm.py to gritlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_next.py to llava_next.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpmo.py to minicpmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/moonvit.py to moonvit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_h.py to nemotron_h.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/florence2.py to florence2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen3_moe.py to qwen3_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/roberta.py to roberta.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interns1_vit.py to interns1_vit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/step3_vl.py to step3_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/falcon_h1.py to falcon_h1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/h2ovl.py to h2ovl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/input_quant_fp8.py to input_quant_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/schema.py to schema.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/torchao.py to torchao.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/marlin.py to marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/fp8.py to fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/ipex_quant.py to ipex_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/bitblas.py to bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/experts_int8.py to experts_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/quark.py to quark.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py to quark_w4a4_mxfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py to quark_w8a8_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py to quark_w8a8_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py to quark_scheme.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/quark_moe.py to quark_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/mxfp4.py to mxfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gguf.py to gguf.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq.py to gptq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq_marlin.py to awq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/aqlm.py to aqlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/modelopt.py to modelopt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py to conch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py to marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py to bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py to exllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py to machete.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py to dynamic_4bit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py to MPLinearKernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py to allspark.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py to aiter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py to cutlass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py to triton.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py to xla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py to ScaledMMLinearKernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq.py to awq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/fbgemm_fp8.py to fbgemm_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py to compressed_tensors_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py to compressed_tensors_wNa16.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py to compressed_tensors_w8a16_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py to compressed_tensors_w4a8_int.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py to compressed_tensors_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py to compressed_tensors_scheme.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py to compressed_tensors_w8a8_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py to compressed_tensors_w4a4_nvfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py to compressed_tensors_w8a8_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py to compressed_tensors_w4a16_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py to compressed_tensors_w4a16_nvfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py to triton_scaled_mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py to compressed_tensors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/auto_round.py to auto_round.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq_triton.py to awq_triton.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/base_config.py to base_config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_bitblas.py to gptq_bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/qqq.py to qqq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/tpu_int8.py to tpu_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/moe_wna16.py to moe_wna16.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/inc.py to inc.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kv_cache.py to kv_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_marlin_24.py to gptq_marlin_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/rtn.py to rtn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/bitsandbytes.py to bitsandbytes.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_marlin.py to gptq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/ptpc_fp8.py to ptpc_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/hqq_marlin.py to hqq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/machete_utils.py to machete_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py to nvfp4_emulation_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py to nvfp4_moe_support.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/fp8_utils.py to fp8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/w8a8_utils.py to w8a8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/int8_utils.py to int8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py to marlin_utils_test_qqq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py to marlin_utils_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test.py to marlin_utils_test.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/layer_utils.py to layer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/allspark_utils.py to allspark_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/quant_utils.py to quant_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py to marlin_utils_test_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils.py to marlin_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/gptq_utils.py to gptq_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/bitblas_utils.py to bitblas_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py to flashinfer_fp4_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py to marlin_utils_fp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/mxfp4_utils.py to mxfp4_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/flashinfer_utils.py to flashinfer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/deepspeedfp.py to deepspeedfp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/neuron_quant.py to neuron_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/deepgemm.py to deepgemm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rejection_sampler.py to rejection_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding.py to rotary_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/linear.py to linear.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/layer.py to layer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deep_gemm_moe.py to deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_moe.py to fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py to flashinfer_cutlass_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_batched_moe.py to fused_batched_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/cutlass_moe.py to cutlass_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py to moe_permute_unpermute.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_pallas.py to moe_pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/prepare_finalize.py to prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py to pplx_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py to deepep_ht_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deep_gemm_utils.py to deep_gemm_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py to flashinfer_cutlass_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py to triton_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_torch_iterative.py to moe_torch_iterative.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py to topk_weight_and_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/cpu_fused_moe.py to cpu_fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/modular_kernel.py to modular_kernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py to batched_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_align_block_size.py to moe_align_block_size.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_marlin_moe.py to fused_marlin_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py to batched_triton_or_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py to deepep_ll_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py to rocm_aiter_fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py to yarn_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/mrope.py to mrope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py to dynamic_ntk_alpha_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/llama3_rope.py to llama3_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py to ntk_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py to deepseek_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py to linear_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py to dual_chunk_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py to dynamic_ntk_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py to phi3_long_rope_scaled_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py to llama4_vision_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/pooler.py to pooler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/layernorm.py to layernorm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/resampler.py to resampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/typical_acceptance_sampler.py to typical_acceptance_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/layernorm_gated.py to layernorm_gated.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_state_passing.py to ssd_state_passing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py to ssd_chunk_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py to ssd_chunk_scan.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_bmm.py to ssd_bmm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/causal_conv1d.py to causal_conv1d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/mamba_ssm.py to mamba_ssm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_combined.py to ssd_combined.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_mixer2.py to mamba_mixer2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_mixer.py to mamba_mixer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba2_metadata.py to mamba2_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_utils.py to mamba_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/lightning_attn.py to lightning_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/activation.py to activation.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/spec_decode_base_sampler.py to spec_decode_base_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/logits_processor.py to logits_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/vocab_parallel_embedding.py to vocab_parallel_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/pooling_metadata.py to pooling_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/sharded_state_loader.py to sharded_state_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/loader.py to loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/runai_streamer_loader.py to runai_streamer_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/neuron.py to neuron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tensorizer_loader.py to tensorizer_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tensorizer.py to tensorizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/neuronx_distributed.py to neuronx_distributed.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/dummy_loader.py to dummy_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/gguf_loader.py to gguf_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/weight_utils.py to weight_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/base_loader.py to base_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tpu.py to tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/bitsandbytes_loader.py to bitsandbytes_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/default_loader.py to default_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/guided_fields.py to guided_fields.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/outlines_decoding.py to outlines_decoding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py to lm_format_enforcer_decoding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/xgrammar_decoding.py to xgrammar_decoding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/guidance_logits_processors.py to guidance_logits_processors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/reasoner/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/outlines_logits_processors.py to outlines_logits_processors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/guidance_decoding.py to guidance_decoding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/custom_op.py to custom_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/sampling_metadata.py to sampling_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/score_utils.py to score_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_engine.py to serving_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_responses.py to serving_responses.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_transcription.py to serving_transcription.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/cli_args.py to cli_args.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/speech_to_text.py to speech_to_text.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_chat.py to serving_chat.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_completion.py to serving_completion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_pooling.py to serving_pooling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/run_batch.py to run_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py to minimax_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py to mistral_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py to xlam_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py to phi4mini_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py to hermes_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py to step3_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py to llama_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py to granite_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py to internlm2_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py to deepseekv3_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py to glm4_moe_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py to pythonic_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py to jamba_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py to abstract_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py to granite_20b_fc_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py to kimi_k2_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py to llama4_pythonic_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py to hunyuan_a13b_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py to qwen3coder_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/logits_processors.py to logits_processors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/api_server.py to api_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_score.py to serving_score.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_embedding.py to serving_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_classification.py to serving_classification.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_tokenization.py to serving_tokenization.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_models.py to serving_models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/protocol.py to protocol.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/tool_server.py to tool_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/harmony_utils.py to harmony_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/chat_utils.py to chat_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/launcher.py to launcher.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/llm.py to llm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/api_server.py to api_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/collect_env.py to collect_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/types.py to types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/openai.py to openai.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/main.py to main.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/run_batch.py to run_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/throughput.py to throughput.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/main.py to main.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/latency.py to latency.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/ssl.py to ssl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/logger.py to logger.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/context.py to context.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/tool.py to tool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/beam_search.py to beam_search.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/connections.py to connections.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/layer.py to layer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flash_attn.py to flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/xformers.py to xformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/dual_chunk_flash_attn.py to dual_chunk_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/ipex_attn.py to ipex_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/differential_flash_attn.py to differential_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/cpu_mla.py to cpu_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/hpu_attn.py to hpu_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/rocm_flash_attn.py to rocm_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/triton_mla.py to triton_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/mla/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/mla/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/blocksparse_attn.py to blocksparse_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/placeholder_attn.py to placeholder_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/torch_sdpa.py to torch_sdpa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/pallas.py to pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_decode_attention.py to triton_decode_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_unified_attention.py to triton_unified_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_merge_attn_states.py to triton_merge_attn_states.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_flash_attention.py to triton_flash_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py to blocksparse_attention_kernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/ipex_attn.py to ipex_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/hpu_paged_attn.py to hpu_paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/prefix_prefill.py to prefix_prefill.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/chunked_prefill_paged_decode.py to chunked_prefill_paged_decode.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/nki_flash_attn.py to nki_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/rocm_aiter_paged_attn.py to rocm_aiter_paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/pallas_kv_cache_update.py to pallas_kv_cache_update.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/paged_attn.py to paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/merge_attn_states.py to merge_attn_states.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/selector.py to selector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/fa_utils.py to fa_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/kv_sharing_utils.py to kv_sharing_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/usage/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/usage/usage_lib.py to usage_lib.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/llm_engine.py to llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/async_llm_engine.py to async_llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/async_timeout.py to async_timeout.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/client.py to client.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/engine.py to engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/single_step.py to single_step.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/multi_step.py to multi_step.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/stop_checker.py to stop_checker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/util.py to util.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/protocol.py to protocol.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/arg_utils.py to arg_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/metrics_types.py to metrics_types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/third_party/pynvml.py to pynvml.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/third_party/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/dump_input.py to dump_input.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/formatter.py to formatter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/sequence.py to sequence.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/spec_decode_worker.py to spec_decode_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/mlp_speculator_worker.py to mlp_speculator_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/top1_proposer.py to top1_proposer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/proposer_worker_base.py to proposer_worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/smaller_tp_proposer_worker.py to smaller_tp_proposer_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/util.py to util.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/mqa_scorer.py to mqa_scorer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/draft_model_runner.py to draft_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/multi_step_worker.py to multi_step_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/medusa_worker.py to medusa_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/ngram_worker.py to ngram_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/batch_expansion.py to batch_expansion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/target_model_runner.py to target_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/scalar_type.py to scalar_type.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group.py to tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer.py to tokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mllama.py to mllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/olmo2.py to olmo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/telechat2.py to telechat2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/jais.py to jais.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron.py to nemotron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mistral.py to mistral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/dbrx.py to dbrx.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/kimi_vl.py to kimi_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/internvl.py to internvl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/arctic.py to arctic.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nvlm_d.py to nvlm_d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mpt.py to mpt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mlp_speculator.py to mlp_speculator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/chatglm.py to chatglm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/algos.py to algos.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/cohere2.py to cohere2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/falcon.py to falcon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/ultravox.py to ultravox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron_vl.py to nemotron_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/solar.py to solar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/exaone.py to exaone.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/skyworkr1v.py to skyworkr1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/moonvit.py to moonvit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron_h.py to nemotron_h.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/step3_vl.py to step3_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/h2ovl.py to h2ovl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_base.py to tokenizer_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/detokenizer.py to detokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/dynamic_module.py to dynamic_module.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/s3_utils.py to s3_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group/tokenizer_group.py to tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py to ray_tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py to base_tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers/mistral.py to mistral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/detokenizer_utils.py to detokenizer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processor.py to processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/envs.py to envs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/placeholder_block_space_manager.py to placeholder_block_space_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block_manager.py to block_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/prefix_caching_block.py to prefix_caching_block.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/naive_block.py to naive_block.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/block_table.py to block_table.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/cpu_gpu_block_allocator.py to cpu_gpu_block_allocator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/evictor.py to evictor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/scheduler.py to scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/cuda.py to cuda.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/rocm.py to rocm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/neuron.py to neuron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/cpu.py to cpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/hpu.py to hpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/tpu.py to tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/xpu.py to xpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/fully_sharded_layers.py to fully_sharded_layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_hpu.py to punica_hpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_base.py to punica_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_selector.py to punica_selector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_cpu.py to punica_cpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_gpu.py to punica_gpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_tpu.py to punica_tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_xpu.py to punica_xpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/lora.py to lora.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_expand.py to lora_expand.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_shrink_op.py to lora_shrink_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_kernel_metadata.py to lora_kernel_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_expand_op.py to lora_expand_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_shrink.py to lora_shrink.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/kernel_utils.py to kernel_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/peft_helper.py to peft_helper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/resolver.py to resolver.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/tasks.py to tasks.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/outputs.py to outputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/ray_distributed_executor.py to ray_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/multiproc_executor.py to multiproc_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_guidance.py to backend_guidance.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_xgrammar.py to backend_xgrammar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_outlines.py to backend_outlines.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_types.py to backend_types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/reader.py to reader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/loggers.py to loggers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/stats.py to stats.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/prometheus.py to prometheus.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/ray_wrappers.py to ray_wrappers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/worker_base.py to worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_worker.py to gpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_model_runner.py to gpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_model_runner.py to tpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/lora_model_runner_mixin.py to lora_model_runner_mixin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/xpu_model_runner.py to xpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/kv_connector_model_runner_mixin.py to kv_connector_model_runner_mixin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/cpu_worker.py to cpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/xpu_worker.py to xpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_worker.py to tpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/cpu_model_runner.py to cpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_input_batch.py to tpu_input_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/block_table.py to block_table.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_input_batch.py to gpu_input_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/stats/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/stats/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/pool/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/pool/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/rejection_sampler.py to rejection_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/bad_words.py to bad_words.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/topk_topp_sampler.py to topk_topp_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/logprobs.py to logprobs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/penalties.py to penalties.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/logits_processor.py to logits_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba_attn.py to mamba_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flash_attn.py to flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/xformers.py to xformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/triton_attn.py to triton_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flex_attention.py to flex_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba1_attn.py to mamba1_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba_selectors.py to mamba_selectors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/triton_mla.py to triton_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/cutlass_mla.py to cutlass_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/rocm_aiter_fa.py to rocm_aiter_fa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/tree_attn.py to tree_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/cpu_attn.py to cpu_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/pallas.py to pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/core.py to core.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/mm_input_cache.py to mm_input_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/core_client.py to core_client.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/detokenizer.py to detokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/llm_engine.py to llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/parallel_sampling.py to parallel_sampling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/logprobs.py to logprobs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/output_processor.py to output_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/exceptions.py to exceptions.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/async_llm.py to async_llm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/coordinator.py to coordinator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/processor.py to processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/ngram_proposer.py to ngram_proposer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/kv_cache_interface.py to kv_cache_interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/block_pool.py to block_pool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_coordinator.py to kv_cache_coordinator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/specialized_manager.py to specialized_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/single_type_kv_cache_manager.py to single_type_kv_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_utils.py to kv_cache_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/encoder_cache_manager.py to encoder_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/output.py to output.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/async_scheduler.py to async_scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/scheduler.py to scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/request_queue.py to request_queue.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_manager.py to kv_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/outputs.py to outputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/serial_utils.py to serial_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logger.py to logger.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/tensor_schema.py to tensor_schema.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/deep_gemm.py to deep_gemm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/jsontree.py to jsontree.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/layerwise_profile.py to layerwise_profile.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/endpoint_request_func.py to endpoint_request_func.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/throughput.py to throughput.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/datasets.py to datasets.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/latency.py to latency.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/ready_checker.py to ready_checker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/endpoint_request_func.py to endpoint_request_func.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/tracing.py to tracing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/env_override.py to env_override.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/forward_context.py to forward_context.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/test_utils.py to test_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/compiler_interface.py to compiler_interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/decorators.py to decorators.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/counter.py to counter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/wrapper.py to wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/backends.py to backends.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/vllm_inductor_pass.py to vllm_inductor_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fusion_attn.py to fusion_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fix_functionalization.py to fix_functionalization.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/base_piecewise_backend.py to base_piecewise_backend.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/monitor.py to monitor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/activation_quant_fusion.py to activation_quant_fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/pass_manager.py to pass_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/sequence_parallelism.py to sequence_parallelism.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fx_utils.py to fx_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/collective_fusion.py to collective_fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/inductor_pass.py to inductor_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/torch25_custom_graph_pass.py to torch25_custom_graph_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/noop_elimination.py to noop_elimination.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/cuda_piecewise_backend.py to cuda_piecewise_backend.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fusion.py to fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/multi_output_match.py to multi_output_match.cpython-311.pyc\n",
            "creating stub loader for vllm/_C.abi3.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_C.py to _C.cpython-311.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "vllm.__pycache__._C.cpython-311: module references __file__\n",
            "vllm.__pycache__.config.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.__pycache__.logger.cpython-311: module references __file__\n",
            "vllm.__pycache__.utils.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.compilation.__pycache__.inductor_pass.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.distributed.device_communicators.__pycache__.custom_all_reduce_utils.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.fused_moe.__pycache__.fused_moe.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.quantization.utils.__pycache__.fp8_utils.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.quantization.utils.__pycache__.int8_utils.cpython-311: module references __file__\n",
            "vllm.transformers_utils.chat_templates.__pycache__.registry.cpython-311: module references __file__\n",
            "vllm.utils.__pycache__.__init__.cpython-311: module MAY be using inspect.getsource\n",
            "creating 'dist/vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.11/dist-packages/vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.11/dist-packages/vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg\n",
            "Extracting vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg to /usr/local/lib/python3.11/dist-packages\n",
            "Adding vllm 0.8.5.dev120+g471fe6563.cpu to easy-install.pth file\n",
            "Installing vllm script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.11/dist-packages/vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg\n",
            "Processing dependencies for vllm==0.8.5.dev120+g471fe6563.cpu\n",
            "Searching for llguidance==0.7.30\n",
            "Best match: llguidance 0.7.30\n",
            "Adding llguidance 0.7.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for xgrammar==0.1.18\n",
            "Best match: xgrammar 0.1.18\n",
            "Processing xgrammar-0.1.18-py3.11-linux-x86_64.egg\n",
            "Adding xgrammar 0.1.18 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/xgrammar-0.1.18-py3.11-linux-x86_64.egg\n",
            "Searching for triton==3.2.0\n",
            "Best match: triton 3.2.0\n",
            "Adding triton 3.2.0 to easy-install.pth file\n",
            "Installing proton script to /usr/local/bin\n",
            "Installing proton-viewer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torch==2.6.0+cpu\n",
            "Best match: torch 2.6.0+cpu\n",
            "Adding torch 2.6.0+cpu to easy-install.pth file\n",
            "Installing torchfrtrace script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torchvision==0.21.0+cpu\n",
            "Best match: torchvision 0.21.0+cpu\n",
            "Adding torchvision 0.21.0+cpu to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torchaudio==2.6.0+cu124\n",
            "Best match: torchaudio 2.6.0+cu124\n",
            "Adding torchaudio 2.6.0+cu124 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for datasets==4.0.0\n",
            "Best match: datasets 4.0.0\n",
            "Adding datasets 4.0.0 to easy-install.pth file\n",
            "Installing datasets-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opentelemetry-semantic-conventions-ai==0.4.12\n",
            "Best match: opentelemetry-semantic-conventions-ai 0.4.12\n",
            "Processing opentelemetry_semantic_conventions_ai-0.4.12-py3.11.egg\n",
            "Adding opentelemetry-semantic-conventions-ai 0.4.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_semantic_conventions_ai-0.4.12-py3.11.egg\n",
            "Searching for opentelemetry-exporter-otlp==1.26.0\n",
            "Best match: opentelemetry-exporter-otlp 1.26.0\n",
            "Processing opentelemetry_exporter_otlp-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-exporter-otlp 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_exporter_otlp-1.26.0-py3.11.egg\n",
            "Searching for opentelemetry-api==1.26.0\n",
            "Best match: opentelemetry-api 1.26.0\n",
            "Processing opentelemetry_api-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-api 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_api-1.26.0-py3.11.egg\n",
            "Searching for opentelemetry-sdk==1.26.0\n",
            "Best match: opentelemetry-sdk 1.26.0\n",
            "Processing opentelemetry_sdk-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-sdk 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_sdk-1.26.0-py3.11.egg\n",
            "Searching for ninja==1.11.1.4\n",
            "Best match: ninja 1.11.1.4\n",
            "Adding ninja 1.11.1.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for scipy==1.16.1\n",
            "Best match: scipy 1.16.1\n",
            "Adding scipy 1.16.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-json-logger==3.3.0\n",
            "Best match: python-json-logger 3.3.0\n",
            "Adding python-json-logger 3.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for watchfiles==1.1.0\n",
            "Best match: watchfiles 1.1.0\n",
            "Adding watchfiles 1.1.0 to easy-install.pth file\n",
            "Installing watchfiles script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cloudpickle==3.1.1\n",
            "Best match: cloudpickle 3.1.1\n",
            "Adding cloudpickle 3.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for depyf==0.18.0\n",
            "Best match: depyf 0.18.0\n",
            "Processing depyf-0.18.0-py3.11.egg\n",
            "Adding depyf 0.18.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/depyf-0.18.0-py3.11.egg\n",
            "Searching for compressed-tensors==0.9.3\n",
            "Best match: compressed-tensors 0.9.3\n",
            "Processing compressed_tensors-0.9.3-py3.11.egg\n",
            "Adding compressed-tensors 0.9.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/compressed_tensors-0.9.3-py3.11.egg\n",
            "Searching for einops==0.8.1\n",
            "Best match: einops 0.8.1\n",
            "Adding einops 0.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for PyYAML==6.0.2\n",
            "Best match: PyYAML 6.0.2\n",
            "Adding PyYAML 6.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opencv-python-headless==4.12.0.88\n",
            "Best match: opencv-python-headless 4.12.0.88\n",
            "Adding opencv-python-headless 4.12.0.88 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mistral-common==1.8.3\n",
            "Best match: mistral-common 1.8.3\n",
            "Adding mistral-common 1.8.3 to easy-install.pth file\n",
            "Installing mistral_common script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for importlib-metadata==8.0.0\n",
            "Best match: importlib-metadata 8.0.0\n",
            "Adding importlib-metadata 8.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/setuptools/_vendor\n",
            "Searching for gguf==0.17.1\n",
            "Best match: gguf 0.17.1\n",
            "Adding gguf 0.17.1 to easy-install.pth file\n",
            "detected new path './setuptools/_vendor'\n",
            "Installing gguf-convert-endian script to /usr/local/bin\n",
            "Installing gguf-dump script to /usr/local/bin\n",
            "Installing gguf-editor-gui script to /usr/local/bin\n",
            "Installing gguf-new-metadata script to /usr/local/bin\n",
            "Installing gguf-set-metadata script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for msgspec==0.19.0\n",
            "Best match: msgspec 0.19.0\n",
            "Adding msgspec 0.19.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pyzmq==26.2.1\n",
            "Best match: pyzmq 26.2.1\n",
            "Adding pyzmq 26.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for partial-json-parser==0.2.1.1.post6\n",
            "Best match: partial-json-parser 0.2.1.1.post6\n",
            "Adding partial-json-parser 0.2.1.1.post6 to easy-install.pth file\n",
            "Installing json-playground script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for filelock==3.18.0\n",
            "Best match: filelock 3.18.0\n",
            "Adding filelock 3.18.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typing-extensions==4.14.1\n",
            "Best match: typing-extensions 4.14.1\n",
            "Adding typing-extensions 4.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for lark==1.2.2\n",
            "Best match: lark 1.2.2\n",
            "Adding lark 1.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for outlines==0.1.11\n",
            "Best match: outlines 0.1.11\n",
            "Processing outlines-0.1.11-py3.11.egg\n",
            "Adding outlines 0.1.11 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/outlines-0.1.11-py3.11.egg\n",
            "Searching for lm-format-enforcer==0.10.12\n",
            "Best match: lm-format-enforcer 0.10.12\n",
            "Adding lm-format-enforcer 0.10.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tiktoken==0.9.0\n",
            "Best match: tiktoken 0.9.0\n",
            "Adding tiktoken 0.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for prometheus-fastapi-instrumentator==7.1.0\n",
            "Best match: prometheus-fastapi-instrumentator 7.1.0\n",
            "Adding prometheus-fastapi-instrumentator 7.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pillow==11.3.0\n",
            "Best match: pillow 11.3.0\n",
            "Adding pillow 11.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for prometheus-client==0.22.1\n",
            "Best match: prometheus-client 0.22.1\n",
            "Adding prometheus-client 0.22.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic==2.11.7\n",
            "Best match: pydantic 2.11.7\n",
            "Adding pydantic 2.11.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for openai==1.98.0\n",
            "Best match: openai 1.98.0\n",
            "Adding openai 1.98.0 to easy-install.pth file\n",
            "Installing openai script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiohttp==3.12.15\n",
            "Best match: aiohttp 3.12.15\n",
            "Adding aiohttp 3.12.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi==0.116.1\n",
            "Best match: fastapi 0.116.1\n",
            "Adding fastapi 0.116.1 to easy-install.pth file\n",
            "Installing fastapi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for protobuf==4.25.8\n",
            "Best match: protobuf 4.25.8\n",
            "Adding protobuf 4.25.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tokenizers==0.21.4\n",
            "Best match: tokenizers 0.21.4\n",
            "Adding tokenizers 0.21.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for huggingface-hub==0.34.3\n",
            "Best match: huggingface-hub 0.34.3\n",
            "Adding huggingface-hub 0.34.3 to easy-install.pth file\n",
            "Installing hf script to /usr/local/bin\n",
            "Installing huggingface-cli script to /usr/local/bin\n",
            "Installing tiny-agents script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for transformers==4.55.0\n",
            "Best match: transformers 4.55.0\n",
            "Adding transformers 4.55.0 to easy-install.pth file\n",
            "Installing transformers script to /usr/local/bin\n",
            "Installing transformers-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for py-cpuinfo==9.0.0\n",
            "Best match: py-cpuinfo 9.0.0\n",
            "Adding py-cpuinfo 9.0.0 to easy-install.pth file\n",
            "Installing cpuinfo script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for blake3==1.0.5\n",
            "Best match: blake3 1.0.5\n",
            "Adding blake3 1.0.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tqdm==4.67.1\n",
            "Best match: tqdm 4.67.1\n",
            "Adding tqdm 4.67.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for requests==2.32.3\n",
            "Best match: requests 2.32.3\n",
            "Adding requests 2.32.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for numpy==2.0.2\n",
            "Best match: numpy 2.0.2\n",
            "Adding numpy 2.0.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing numpy-config script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sentencepiece==0.2.0\n",
            "Best match: sentencepiece 0.2.0\n",
            "Adding sentencepiece 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for psutil==5.9.5\n",
            "Best match: psutil 5.9.5\n",
            "Adding psutil 5.9.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cachetools==5.5.2\n",
            "Best match: cachetools 5.5.2\n",
            "Adding cachetools 5.5.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sympy==1.13.1\n",
            "Best match: sympy 1.13.1\n",
            "Adding sympy 1.13.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fsspec==2025.3.0\n",
            "Best match: fsspec 2025.3.0\n",
            "Adding fsspec 2025.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jinja2==3.1.6\n",
            "Best match: jinja2 3.1.6\n",
            "Adding jinja2 3.1.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for networkx==3.5\n",
            "Best match: networkx 3.5\n",
            "Adding networkx 3.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for packaging==25.0\n",
            "Best match: packaging 25.0\n",
            "Adding packaging 25.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for multiprocess==0.70.16\n",
            "Best match: multiprocess 0.70.16\n",
            "Adding multiprocess 0.70.16 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for xxhash==3.5.0\n",
            "Best match: xxhash 3.5.0\n",
            "Adding xxhash 3.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pandas==2.2.2\n",
            "Best match: pandas 2.2.2\n",
            "Adding pandas 2.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for dill==0.3.8\n",
            "Best match: dill 0.3.8\n",
            "Adding dill 0.3.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pyarrow==18.1.0\n",
            "Best match: pyarrow 18.1.0\n",
            "Adding pyarrow 18.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opentelemetry-exporter-otlp-proto-http==1.26.0\n",
            "Best match: opentelemetry-exporter-otlp-proto-http 1.26.0\n",
            "Processing opentelemetry_exporter_otlp_proto_http-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-exporter-otlp-proto-http 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_exporter_otlp_proto_http-1.26.0-py3.11.egg\n",
            "Searching for opentelemetry-exporter-otlp-proto-grpc==1.26.0\n",
            "Best match: opentelemetry-exporter-otlp-proto-grpc 1.26.0\n",
            "Processing opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-exporter-otlp-proto-grpc 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3.11.egg\n",
            "Searching for Deprecated==1.2.18\n",
            "Best match: Deprecated 1.2.18\n",
            "Processing Deprecated-1.2.18-py3.11.egg\n",
            "Adding Deprecated 1.2.18 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/Deprecated-1.2.18-py3.11.egg\n",
            "Searching for opentelemetry-semantic-conventions==0.47b0\n",
            "Best match: opentelemetry-semantic-conventions 0.47b0\n",
            "Processing opentelemetry_semantic_conventions-0.47b0-py3.11.egg\n",
            "Adding opentelemetry-semantic-conventions 0.47b0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_semantic_conventions-0.47b0-py3.11.egg\n",
            "Searching for anyio==4.9.0\n",
            "Best match: anyio 4.9.0\n",
            "Adding anyio 4.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for astor==0.8.1\n",
            "Best match: astor 0.8.1\n",
            "Adding astor 0.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic-extra-types==2.10.5\n",
            "Best match: pydantic-extra-types 2.10.5\n",
            "Adding pydantic-extra-types 2.10.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jsonschema==4.25.0\n",
            "Best match: jsonschema 4.25.0\n",
            "Adding jsonschema 4.25.0 to easy-install.pth file\n",
            "Installing jsonschema script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for zipp==3.23.0\n",
            "Best match: zipp 3.23.0\n",
            "Adding zipp 3.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for outlines-core==0.1.26\n",
            "Best match: outlines-core 0.1.26\n",
            "Processing outlines_core-0.1.26-py3.11-linux-x86_64.egg\n",
            "Adding outlines-core 0.1.26 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/outlines_core-0.1.26-py3.11-linux-x86_64.egg\n",
            "Searching for airportsdata==20250706\n",
            "Best match: airportsdata 20250706\n",
            "Processing airportsdata-20250706-py3.11.egg\n",
            "Adding airportsdata 20250706 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/airportsdata-20250706-py3.11.egg\n",
            "Searching for pycountry==24.6.1\n",
            "Best match: pycountry 24.6.1\n",
            "Adding pycountry 24.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for referencing==0.36.2\n",
            "Best match: referencing 0.36.2\n",
            "Adding referencing 0.36.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for diskcache==5.6.3\n",
            "Best match: diskcache 5.6.3\n",
            "Adding diskcache 5.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for nest-asyncio==1.6.0\n",
            "Best match: nest-asyncio 1.6.0\n",
            "Adding nest-asyncio 1.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for interegular==0.3.3\n",
            "Best match: interegular 0.3.3\n",
            "Adding interegular 0.3.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for regex==2024.11.6\n",
            "Best match: regex 2024.11.6\n",
            "Adding regex 2024.11.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for starlette==0.47.2\n",
            "Best match: starlette 0.47.2\n",
            "Adding starlette 0.47.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typing-inspection==0.4.1\n",
            "Best match: typing-inspection 0.4.1\n",
            "Adding typing-inspection 0.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic-core==2.33.2\n",
            "Best match: pydantic-core 2.33.2\n",
            "Adding pydantic-core 2.33.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for annotated-types==0.7.0\n",
            "Best match: annotated-types 0.7.0\n",
            "Adding annotated-types 0.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sniffio==1.3.1\n",
            "Best match: sniffio 1.3.1\n",
            "Adding sniffio 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jiter==0.10.0\n",
            "Best match: jiter 0.10.0\n",
            "Adding jiter 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httpx==0.28.1\n",
            "Best match: httpx 0.28.1\n",
            "Adding httpx 0.28.1 to easy-install.pth file\n",
            "Installing httpx script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for distro==1.9.0\n",
            "Best match: distro 1.9.0\n",
            "Adding distro 1.9.0 to easy-install.pth file\n",
            "Installing distro script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for yarl==1.20.1\n",
            "Best match: yarl 1.20.1\n",
            "Adding yarl 1.20.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for propcache==0.3.2\n",
            "Best match: propcache 0.3.2\n",
            "Adding propcache 0.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for multidict==6.6.3\n",
            "Best match: multidict 6.6.3\n",
            "Adding multidict 6.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for frozenlist==1.7.0\n",
            "Best match: frozenlist 1.7.0\n",
            "Adding frozenlist 1.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for attrs==25.3.0\n",
            "Best match: attrs 25.3.0\n",
            "Adding attrs 25.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiosignal==1.4.0\n",
            "Best match: aiosignal 1.4.0\n",
            "Adding aiosignal 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiohappyeyeballs==2.6.1\n",
            "Best match: aiohappyeyeballs 2.6.1\n",
            "Adding aiohappyeyeballs 2.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for uvicorn==0.35.0\n",
            "Best match: uvicorn 0.35.0\n",
            "Adding uvicorn 0.35.0 to easy-install.pth file\n",
            "Installing uvicorn script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for email-validator==2.2.0\n",
            "Best match: email-validator 2.2.0\n",
            "Adding email-validator 2.2.0 to easy-install.pth file\n",
            "Installing email_validator script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-multipart==0.0.20\n",
            "Best match: python-multipart 0.0.20\n",
            "Adding python-multipart 0.0.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi-cli==0.0.8\n",
            "Best match: fastapi-cli 0.0.8\n",
            "Adding fastapi-cli 0.0.8 to easy-install.pth file\n",
            "Installing fastapi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for hf-xet==1.1.5\n",
            "Best match: hf-xet 1.1.5\n",
            "Adding hf-xet 1.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for safetensors==0.5.3\n",
            "Best match: safetensors 0.5.3\n",
            "Adding safetensors 0.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for certifi==2025.7.14\n",
            "Best match: certifi 2025.7.14\n",
            "Adding certifi 2025.7.14 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for urllib3==2.5.0\n",
            "Best match: urllib3 2.5.0\n",
            "Adding urllib3 2.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for idna==3.10\n",
            "Best match: idna 3.10\n",
            "Adding idna 3.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for charset-normalizer==3.4.2\n",
            "Best match: charset-normalizer 3.4.2\n",
            "Adding charset-normalizer 3.4.2 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for MarkupSafe==3.0.2\n",
            "Best match: MarkupSafe 3.0.2\n",
            "Adding MarkupSafe 3.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tzdata==2025.2\n",
            "Best match: tzdata 2025.2\n",
            "Adding tzdata 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pytz==2025.2\n",
            "Best match: pytz 2025.2\n",
            "Adding pytz 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-dateutil==2.9.0.post0\n",
            "Best match: python-dateutil 2.9.0.post0\n",
            "Adding python-dateutil 2.9.0.post0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opentelemetry-proto==1.26.0\n",
            "Best match: opentelemetry-proto 1.26.0\n",
            "Processing opentelemetry_proto-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-proto 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_proto-1.26.0-py3.11.egg\n",
            "Searching for opentelemetry-exporter-otlp-proto-common==1.26.0\n",
            "Best match: opentelemetry-exporter-otlp-proto-common 1.26.0\n",
            "Processing opentelemetry_exporter_otlp_proto_common-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-exporter-otlp-proto-common 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_exporter_otlp_proto_common-1.26.0-py3.11.egg\n",
            "Searching for googleapis-common-protos==1.70.0\n",
            "Best match: googleapis-common-protos 1.70.0\n",
            "Adding googleapis-common-protos 1.70.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for grpcio==1.74.0\n",
            "Best match: grpcio 1.74.0\n",
            "Adding grpcio 1.74.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for wrapt==1.17.2\n",
            "Best match: wrapt 1.17.2\n",
            "Adding wrapt 1.17.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rpds-py==0.26.0\n",
            "Best match: rpds-py 0.26.0\n",
            "Adding rpds-py 0.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jsonschema-specifications==2025.4.1\n",
            "Best match: jsonschema-specifications 2025.4.1\n",
            "Adding jsonschema-specifications 2025.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httpcore==1.0.9\n",
            "Best match: httpcore 1.0.9\n",
            "Adding httpcore 1.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for websockets==15.0.1\n",
            "Best match: websockets 15.0.1\n",
            "Adding websockets 15.0.1 to easy-install.pth file\n",
            "Installing websockets script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for uvloop==0.21.0\n",
            "Best match: uvloop 0.21.0\n",
            "Adding uvloop 0.21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-dotenv==1.1.1\n",
            "Best match: python-dotenv 1.1.1\n",
            "Adding python-dotenv 1.1.1 to easy-install.pth file\n",
            "Installing dotenv script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httptools==0.6.4\n",
            "Best match: httptools 0.6.4\n",
            "Adding httptools 0.6.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for h11==0.16.0\n",
            "Best match: h11 0.16.0\n",
            "Adding h11 0.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for click==8.2.1\n",
            "Best match: click 8.2.1\n",
            "Adding click 8.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for dnspython==2.7.0\n",
            "Best match: dnspython 2.7.0\n",
            "Adding dnspython 2.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi-cloud-cli==0.1.5\n",
            "Best match: fastapi-cloud-cli 0.1.5\n",
            "Adding fastapi-cloud-cli 0.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rich-toolkit==0.14.9\n",
            "Best match: rich-toolkit 0.14.9\n",
            "Adding rich-toolkit 0.14.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typer==0.16.0\n",
            "Best match: typer 0.16.0\n",
            "Adding typer 0.16.0 to easy-install.pth file\n",
            "Installing typer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for six==1.17.0\n",
            "Best match: six 1.17.0\n",
            "Adding six 1.17.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sentry-sdk==2.34.1\n",
            "Best match: sentry-sdk 2.34.1\n",
            "Adding sentry-sdk 2.34.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rignore==0.6.4\n",
            "Best match: rignore 0.6.4\n",
            "Adding rignore 0.6.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rich==13.9.4\n",
            "Best match: rich 13.9.4\n",
            "Adding rich 13.9.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for shellingham==1.5.4\n",
            "Best match: shellingham 1.5.4\n",
            "Adding shellingham 1.5.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pygments==2.19.2\n",
            "Best match: pygments 2.19.2\n",
            "Adding pygments 2.19.2 to easy-install.pth file\n",
            "Installing pygmentize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for markdown-it-py==3.0.0\n",
            "Best match: markdown-it-py 3.0.0\n",
            "Adding markdown-it-py 3.0.0 to easy-install.pth file\n",
            "Installing markdown-it script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mdurl==0.1.2\n",
            "Best match: mdurl 0.1.2\n",
            "Adding mdurl 0.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Finished processing dependencies for vllm==0.8.5.dev120+g471fe6563.cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB16T979TLNd",
        "outputId": "1704a0bb-914a-4e9c-b03f-07748b623f83"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                                  Version\n",
            "---------------------------------------- ----------------------------\n",
            "absl-py                                  1.4.0\n",
            "accelerate                               1.9.0\n",
            "aiofiles                                 24.1.0\n",
            "aiohappyeyeballs                         2.6.1\n",
            "aiohttp                                  3.12.15\n",
            "aiosignal                                1.4.0\n",
            "airportsdata                             20250706\n",
            "alabaster                                1.0.0\n",
            "albucore                                 0.0.24\n",
            "albumentations                           2.0.8\n",
            "ale-py                                   0.11.2\n",
            "altair                                   5.5.0\n",
            "annotated-types                          0.7.0\n",
            "antlr4-python3-runtime                   4.9.3\n",
            "anyio                                    4.9.0\n",
            "anywidget                                0.9.18\n",
            "argon2-cffi                              25.1.0\n",
            "argon2-cffi-bindings                     25.1.0\n",
            "array_record                             0.7.2\n",
            "arviz                                    0.22.0\n",
            "astor                                    0.8.1\n",
            "astropy                                  7.1.0\n",
            "astropy-iers-data                        0.2025.7.28.0.41.50\n",
            "astunparse                               1.6.3\n",
            "atpublic                                 5.1\n",
            "attrs                                    25.3.0\n",
            "audioread                                3.0.1\n",
            "autocommand                              2.2.2\n",
            "autograd                                 1.8.0\n",
            "babel                                    2.17.0\n",
            "backcall                                 0.2.0\n",
            "backports.tarfile                        1.2.0\n",
            "beautifulsoup4                           4.13.4\n",
            "betterproto                              2.0.0b6\n",
            "bigframes                                2.13.0\n",
            "bigquery-magics                          0.10.1\n",
            "blake3                                   1.0.5\n",
            "bleach                                   6.2.0\n",
            "blinker                                  1.9.0\n",
            "blis                                     1.3.0\n",
            "blobfile                                 3.0.0\n",
            "blosc2                                   3.6.1\n",
            "bokeh                                    3.7.3\n",
            "Bottleneck                               1.4.2\n",
            "bqplot                                   0.12.45\n",
            "branca                                   0.8.1\n",
            "Brotli                                   1.1.0\n",
            "build                                    1.3.0\n",
            "CacheControl                             0.14.3\n",
            "cachetools                               5.5.2\n",
            "catalogue                                2.0.10\n",
            "cbor2                                    5.6.5\n",
            "certifi                                  2025.7.14\n",
            "cffi                                     1.17.1\n",
            "chardet                                  5.2.0\n",
            "charset-normalizer                       3.4.2\n",
            "chex                                     0.1.90\n",
            "clarabel                                 0.11.1\n",
            "click                                    8.2.1\n",
            "cloudpathlib                             0.21.1\n",
            "cloudpickle                              3.1.1\n",
            "cmake                                    3.31.6\n",
            "cmdstanpy                                1.2.5\n",
            "colorcet                                 3.1.0\n",
            "colorlover                               0.3.0\n",
            "colour                                   0.1.5\n",
            "community                                1.0.0b1\n",
            "compressed-tensors                       0.10.2\n",
            "confection                               0.1.5\n",
            "cons                                     0.4.7\n",
            "contourpy                                1.3.3\n",
            "cramjam                                  2.11.0\n",
            "cryptography                             43.0.3\n",
            "cuda-python                              12.6.2.post1\n",
            "cudf-cu12                                25.6.0\n",
            "cudf-polars-cu12                         25.6.0\n",
            "cufflinks                                0.17.3\n",
            "cuml-cu12                                25.6.0\n",
            "cupy-cuda12x                             13.3.0\n",
            "curl_cffi                                0.12.0\n",
            "cuvs-cu12                                25.6.1\n",
            "cvxopt                                   1.3.2\n",
            "cvxpy                                    1.6.7\n",
            "cycler                                   0.12.1\n",
            "cyipopt                                  1.5.0\n",
            "cymem                                    2.0.11\n",
            "Cython                                   3.0.12\n",
            "dask                                     2025.5.0\n",
            "dask-cuda                                25.6.0\n",
            "dask-cudf-cu12                           25.6.0\n",
            "dataproc-spark-connect                   0.8.3\n",
            "datasets                                 4.0.0\n",
            "db-dtypes                                1.4.3\n",
            "dbus-python                              1.2.18\n",
            "debugpy                                  1.8.15\n",
            "decorator                                4.4.2\n",
            "defusedxml                               0.7.1\n",
            "Deprecated                               1.2.18\n",
            "depyf                                    0.19.0\n",
            "diffusers                                0.34.0\n",
            "dill                                     0.3.8\n",
            "diskcache                                5.6.3\n",
            "distributed                              2025.5.0\n",
            "distributed-ucxx-cu12                    0.44.0\n",
            "distro                                   1.9.0\n",
            "dlib                                     19.24.6\n",
            "dm-tree                                  0.1.9\n",
            "dnspython                                2.7.0\n",
            "docstring_parser                         0.17.0\n",
            "docutils                                 0.21.2\n",
            "dopamine_rl                              4.1.2\n",
            "duckdb                                   1.3.2\n",
            "earthengine-api                          1.5.24\n",
            "easydict                                 1.13\n",
            "editdistance                             0.8.1\n",
            "eerepr                                   0.1.2\n",
            "einops                                   0.8.1\n",
            "email_validator                          2.2.0\n",
            "en_core_web_sm                           3.8.0\n",
            "entrypoints                              0.4\n",
            "et_xmlfile                               2.0.0\n",
            "etils                                    1.13.0\n",
            "etuples                                  0.3.10\n",
            "Farama-Notifications                     0.0.4\n",
            "fastai                                   2.7.19\n",
            "fastapi                                  0.116.1\n",
            "fastapi-cli                              0.0.8\n",
            "fastapi-cloud-cli                        0.1.5\n",
            "fastcore                                 1.7.29\n",
            "fastdownload                             0.0.7\n",
            "fastjsonschema                           2.21.1\n",
            "fastprogress                             1.0.3\n",
            "fastrlock                                0.8.3\n",
            "ffmpy                                    0.6.1\n",
            "filelock                                 3.18.0\n",
            "firebase-admin                           6.9.0\n",
            "Flask                                    3.1.1\n",
            "flatbuffers                              25.2.10\n",
            "flax                                     0.10.6\n",
            "folium                                   0.20.0\n",
            "fonttools                                4.59.0\n",
            "frozendict                               2.4.6\n",
            "frozenlist                               1.7.0\n",
            "fsspec                                   2025.3.0\n",
            "future                                   1.0.0\n",
            "gast                                     0.6.0\n",
            "gcsfs                                    2025.3.0\n",
            "GDAL                                     3.8.4\n",
            "gdown                                    5.2.0\n",
            "geemap                                   0.35.3\n",
            "geocoder                                 1.38.1\n",
            "geographiclib                            2.0\n",
            "geopandas                                1.1.1\n",
            "geopy                                    2.4.1\n",
            "gguf                                     0.17.1\n",
            "gin-config                               0.5.0\n",
            "gitdb                                    4.0.12\n",
            "GitPython                                3.1.45\n",
            "glob2                                    0.7\n",
            "google                                   2.0.3\n",
            "google-ai-generativelanguage             0.6.15\n",
            "google-api-core                          2.25.1\n",
            "google-api-python-client                 2.177.0\n",
            "google-auth                              2.38.0\n",
            "google-auth-httplib2                     0.2.0\n",
            "google-auth-oauthlib                     1.2.2\n",
            "google-cloud-aiplatform                  1.106.0\n",
            "google-cloud-bigquery                    3.35.1\n",
            "google-cloud-bigquery-connection         1.18.3\n",
            "google-cloud-bigquery-storage            2.32.0\n",
            "google-cloud-core                        2.4.3\n",
            "google-cloud-dataproc                    5.21.0\n",
            "google-cloud-datastore                   2.21.0\n",
            "google-cloud-firestore                   2.21.0\n",
            "google-cloud-functions                   1.20.4\n",
            "google-cloud-language                    2.17.2\n",
            "google-cloud-resource-manager            1.14.2\n",
            "google-cloud-spanner                     3.56.0\n",
            "google-cloud-storage                     2.19.0\n",
            "google-cloud-translate                   3.21.1\n",
            "google-colab                             1.0.0\n",
            "google-crc32c                            1.7.1\n",
            "google-genai                             1.28.0\n",
            "google-generativeai                      0.8.5\n",
            "google-pasta                             0.2.0\n",
            "google-resumable-media                   2.7.2\n",
            "googleapis-common-protos                 1.70.0\n",
            "googledrivedownloader                    1.1.0\n",
            "gradio                                   5.39.0\n",
            "gradio_client                            1.11.0\n",
            "graphviz                                 0.21\n",
            "greenlet                                 3.2.3\n",
            "groovy                                   0.1.2\n",
            "grpc-google-iam-v1                       0.14.2\n",
            "grpc-interceptor                         0.15.4\n",
            "grpcio                                   1.74.0\n",
            "grpcio-status                            1.71.2\n",
            "grpclib                                  0.4.8\n",
            "gspread                                  6.2.1\n",
            "gspread-dataframe                        4.0.0\n",
            "gym                                      0.25.2\n",
            "gym-notices                              0.1.0\n",
            "gymnasium                                1.2.0\n",
            "h11                                      0.16.0\n",
            "h2                                       4.2.0\n",
            "h5netcdf                                 1.6.3\n",
            "h5py                                     3.14.0\n",
            "hdbscan                                  0.8.40\n",
            "hf_transfer                              0.1.9\n",
            "hf-xet                                   1.1.5\n",
            "highspy                                  1.11.0\n",
            "holidays                                 0.77\n",
            "holoviews                                1.21.0\n",
            "hpack                                    4.1.0\n",
            "html5lib                                 1.1\n",
            "httpcore                                 1.0.9\n",
            "httpimport                               1.4.1\n",
            "httplib2                                 0.22.0\n",
            "httptools                                0.6.4\n",
            "httpx                                    0.28.1\n",
            "huggingface-hub                          0.34.3\n",
            "humanize                                 4.12.3\n",
            "hyperframe                               6.1.0\n",
            "hyperopt                                 0.2.7\n",
            "ibis-framework                           9.5.0\n",
            "idna                                     3.10\n",
            "imageio                                  2.37.0\n",
            "imageio-ffmpeg                           0.6.0\n",
            "imagesize                                1.4.1\n",
            "imbalanced-learn                         0.13.0\n",
            "immutabledict                            4.2.1\n",
            "importlib_metadata                       8.0.0\n",
            "importlib_resources                      6.5.2\n",
            "imutils                                  0.5.4\n",
            "inflect                                  7.5.0\n",
            "iniconfig                                2.1.0\n",
            "intel-cmplr-lib-ur                       2024.2.1\n",
            "intel_extension_for_pytorch              2.6.0\n",
            "intel-openmp                             2024.2.1\n",
            "interegular                              0.3.3\n",
            "ipyevents                                2.0.2\n",
            "ipyfilechooser                           0.6.0\n",
            "ipykernel                                6.17.1\n",
            "ipyleaflet                               0.20.0\n",
            "ipyparallel                              8.8.0\n",
            "ipython                                  7.34.0\n",
            "ipython-genutils                         0.2.0\n",
            "ipython-sql                              0.5.0\n",
            "ipytree                                  0.2.2\n",
            "ipywidgets                               7.7.1\n",
            "itsdangerous                             2.2.0\n",
            "jaraco.classes                           3.4.0\n",
            "jaraco.collections                       5.1.0\n",
            "jaraco.context                           6.0.1\n",
            "jaraco.functools                         4.2.1\n",
            "jaraco.text                              3.12.1\n",
            "jax                                      0.5.3\n",
            "jax-cuda12-pjrt                          0.5.3\n",
            "jax-cuda12-plugin                        0.5.3\n",
            "jaxlib                                   0.5.3\n",
            "jeepney                                  0.9.0\n",
            "jieba                                    0.42.1\n",
            "Jinja2                                   3.1.6\n",
            "jiter                                    0.10.0\n",
            "joblib                                   1.5.1\n",
            "jsonpatch                                1.33\n",
            "jsonpickle                               4.1.1\n",
            "jsonpointer                              3.0.0\n",
            "jsonschema                               4.25.0\n",
            "jsonschema-specifications                2025.4.1\n",
            "jupyter-client                           6.1.12\n",
            "jupyter-console                          6.1.0\n",
            "jupyter_core                             5.8.1\n",
            "jupyter_kernel_gateway                   2.5.2\n",
            "jupyter-leaflet                          0.20.0\n",
            "jupyter-server                           1.16.0\n",
            "jupyterlab_pygments                      0.3.0\n",
            "jupyterlab_widgets                       3.0.15\n",
            "jupytext                                 1.17.2\n",
            "kaggle                                   1.7.4.5\n",
            "kagglehub                                0.3.12\n",
            "keras                                    3.10.0\n",
            "keras-hub                                0.21.1\n",
            "keras-nlp                                0.21.1\n",
            "keyring                                  25.6.0\n",
            "keyrings.google-artifactregistry-auth    1.1.2\n",
            "kiwisolver                               1.4.8\n",
            "langchain                                0.3.27\n",
            "langchain-core                           0.3.72\n",
            "langchain-text-splitters                 0.3.9\n",
            "langcodes                                3.5.0\n",
            "langsmith                                0.4.9\n",
            "language_data                            1.3.0\n",
            "lark                                     1.2.2\n",
            "launchpadlib                             1.10.16\n",
            "lazr.restfulclient                       0.14.4\n",
            "lazr.uri                                 1.0.6\n",
            "lazy_loader                              0.4\n",
            "libclang                                 18.1.1\n",
            "libcudf-cu12                             25.6.0\n",
            "libcugraph-cu12                          25.6.0\n",
            "libcuml-cu12                             25.6.0\n",
            "libcuvs-cu12                             25.6.1\n",
            "libkvikio-cu12                           25.6.0\n",
            "libpysal                                 4.13.0\n",
            "libraft-cu12                             25.6.0\n",
            "librmm-cu12                              25.6.0\n",
            "librosa                                  0.11.0\n",
            "libucx-cu12                              1.18.1\n",
            "libucxx-cu12                             0.44.0\n",
            "lightgbm                                 4.6.0\n",
            "linkify-it-py                            2.0.3\n",
            "llguidance                               0.7.30\n",
            "llvmlite                                 0.44.0\n",
            "lm-format-enforcer                       0.10.12\n",
            "locket                                   1.0.0\n",
            "logical-unification                      0.4.6\n",
            "lxml                                     5.4.0\n",
            "Mako                                     1.1.3\n",
            "marisa-trie                              1.2.1\n",
            "Markdown                                 3.8.2\n",
            "markdown-it-py                           3.0.0\n",
            "MarkupSafe                               3.0.2\n",
            "matplotlib                               3.10.0\n",
            "matplotlib-inline                        0.1.7\n",
            "matplotlib-venn                          1.1.2\n",
            "mdit-py-plugins                          0.4.2\n",
            "mdurl                                    0.1.2\n",
            "miniKanren                               1.0.5\n",
            "missingno                                0.5.2\n",
            "mistral_common                           1.8.3\n",
            "mistune                                  3.1.3\n",
            "mizani                                   0.13.5\n",
            "mkl                                      2025.2.0\n",
            "ml_dtypes                                0.5.3\n",
            "mlxtend                                  0.23.4\n",
            "more-itertools                           10.7.0\n",
            "moviepy                                  1.0.3\n",
            "mpmath                                   1.3.0\n",
            "msgpack                                  1.1.1\n",
            "msgspec                                  0.19.0\n",
            "multidict                                6.6.3\n",
            "multipledispatch                         1.0.0\n",
            "multiprocess                             0.70.16\n",
            "multitasking                             0.0.12\n",
            "murmurhash                               1.0.13\n",
            "music21                                  9.3.0\n",
            "namex                                    0.1.0\n",
            "narwhals                                 2.0.1\n",
            "natsort                                  8.4.0\n",
            "nbclassic                                1.3.1\n",
            "nbclient                                 0.10.2\n",
            "nbconvert                                7.16.6\n",
            "nbformat                                 5.10.4\n",
            "ndindex                                  1.10.0\n",
            "nest-asyncio                             1.6.0\n",
            "networkx                                 3.5\n",
            "nibabel                                  5.3.2\n",
            "ninja                                    1.11.1.4\n",
            "nltk                                     3.9.1\n",
            "notebook                                 6.5.7\n",
            "notebook_shim                            0.2.4\n",
            "numba                                    0.61.2\n",
            "numba-cuda                               0.11.0\n",
            "numexpr                                  2.11.0\n",
            "numpy                                    2.0.2\n",
            "nvidia-cublas-cu12                       12.5.3.2\n",
            "nvidia-cuda-cupti-cu12                   12.5.82\n",
            "nvidia-cuda-nvcc-cu12                    12.5.82\n",
            "nvidia-cuda-nvrtc-cu12                   12.5.82\n",
            "nvidia-cuda-runtime-cu12                 12.5.82\n",
            "nvidia-cudnn-cu12                        9.3.0.75\n",
            "nvidia-cufft-cu12                        11.2.3.61\n",
            "nvidia-curand-cu12                       10.3.6.82\n",
            "nvidia-cusolver-cu12                     11.6.3.83\n",
            "nvidia-cusparse-cu12                     12.5.1.3\n",
            "nvidia-cusparselt-cu12                   0.6.2\n",
            "nvidia-ml-py                             12.575.51\n",
            "nvidia-nccl-cu12                         2.23.4\n",
            "nvidia-nvjitlink-cu12                    12.5.82\n",
            "nvidia-nvtx-cu12                         12.4.127\n",
            "nvtx                                     0.2.12\n",
            "nx-cugraph-cu12                          25.6.0\n",
            "oauth2client                             4.1.3\n",
            "oauthlib                                 3.3.1\n",
            "omegaconf                                2.3.0\n",
            "openai                                   1.98.0\n",
            "openai-harmony                           0.0.3\n",
            "opencv-contrib-python                    4.12.0.88\n",
            "opencv-python                            4.12.0.88\n",
            "opencv-python-headless                   4.12.0.88\n",
            "openpyxl                                 3.1.5\n",
            "opentelemetry-api                        1.26.0\n",
            "opentelemetry-exporter-otlp              1.26.0\n",
            "opentelemetry-exporter-otlp-proto-common 1.26.0\n",
            "opentelemetry-exporter-otlp-proto-grpc   1.26.0\n",
            "opentelemetry-exporter-otlp-proto-http   1.26.0\n",
            "opentelemetry-proto                      1.26.0\n",
            "opentelemetry-sdk                        1.26.0\n",
            "opentelemetry-semantic-conventions       0.47b0\n",
            "opentelemetry-semantic-conventions-ai    0.4.12\n",
            "opt_einsum                               3.4.0\n",
            "optax                                    0.2.5\n",
            "optree                                   0.17.0\n",
            "orbax-checkpoint                         0.11.20\n",
            "orjson                                   3.11.1\n",
            "osqp                                     1.0.4\n",
            "outlines                                 0.1.11\n",
            "outlines_core                            0.2.10\n",
            "packaging                                25.0\n",
            "pandas                                   2.2.2\n",
            "pandas-datareader                        0.10.0\n",
            "pandas-gbq                               0.29.2\n",
            "pandas-stubs                             2.2.2.240909\n",
            "pandocfilters                            1.5.1\n",
            "panel                                    1.7.5\n",
            "param                                    2.2.1\n",
            "parso                                    0.8.4\n",
            "parsy                                    2.1\n",
            "partd                                    1.4.2\n",
            "partial-json-parser                      0.2.1.1.post6\n",
            "patsy                                    1.0.1\n",
            "peewee                                   3.18.2\n",
            "peft                                     0.16.0\n",
            "pexpect                                  4.9.0\n",
            "pickleshare                              0.7.5\n",
            "pillow                                   11.3.0\n",
            "pip                                      25.2\n",
            "platformdirs                             4.3.8\n",
            "plotly                                   5.24.1\n",
            "plotnine                                 0.14.5\n",
            "pluggy                                   1.6.0\n",
            "ply                                      3.11\n",
            "polars                                   1.25.2\n",
            "pooch                                    1.8.2\n",
            "portpicker                               1.5.2\n",
            "preshed                                  3.0.10\n",
            "prettytable                              3.16.0\n",
            "proglog                                  0.1.12\n",
            "progressbar2                             4.5.0\n",
            "prometheus_client                        0.22.1\n",
            "prometheus-fastapi-instrumentator        7.1.0\n",
            "promise                                  2.3\n",
            "prompt_toolkit                           3.0.51\n",
            "propcache                                0.3.2\n",
            "prophet                                  1.1.7\n",
            "proto-plus                               1.26.1\n",
            "protobuf                                 4.25.8\n",
            "psutil                                   5.9.5\n",
            "psycopg2                                 2.9.10\n",
            "psygnal                                  0.14.0\n",
            "ptyprocess                               0.7.0\n",
            "py-cpuinfo                               9.0.0\n",
            "py4j                                     0.10.9.7\n",
            "pyarrow                                  18.1.0\n",
            "pyasn1                                   0.6.1\n",
            "pyasn1_modules                           0.4.2\n",
            "pybase64                                 1.4.2\n",
            "pycairo                                  1.28.0\n",
            "pycocotools                              2.0.10\n",
            "pycountry                                24.6.1\n",
            "pycparser                                2.22\n",
            "pycryptodomex                            3.23.0\n",
            "pydantic                                 2.11.7\n",
            "pydantic_core                            2.33.2\n",
            "pydantic-extra-types                     2.10.5\n",
            "pydata-google-auth                       1.9.1\n",
            "pydot                                    3.0.4\n",
            "pydotplus                                2.0.2\n",
            "PyDrive2                                 1.21.3\n",
            "pydub                                    0.25.1\n",
            "pyerfa                                   2.0.1.5\n",
            "pygame                                   2.6.1\n",
            "pygit2                                   1.18.1\n",
            "Pygments                                 2.19.2\n",
            "PyGObject                                3.42.0\n",
            "PyJWT                                    2.10.1\n",
            "pylibcudf-cu12                           25.6.0\n",
            "pylibcugraph-cu12                        25.6.0\n",
            "pylibraft-cu12                           25.6.0\n",
            "pymc                                     5.25.1\n",
            "pynndescent                              0.5.13\n",
            "pynvjitlink-cu12                         0.7.0\n",
            "pynvml                                   12.0.0\n",
            "pyogrio                                  0.11.0\n",
            "pyomo                                    6.9.2\n",
            "PyOpenGL                                 3.1.9\n",
            "pyOpenSSL                                24.2.1\n",
            "pyparsing                                3.2.3\n",
            "pyperclip                                1.9.0\n",
            "pyproj                                   3.7.1\n",
            "pyproject_hooks                          1.2.0\n",
            "pyshp                                    2.3.1\n",
            "PySocks                                  1.7.1\n",
            "pyspark                                  3.5.1\n",
            "pytensor                                 2.31.7\n",
            "pytest                                   8.4.1\n",
            "python-apt                               0.0.0\n",
            "python-box                               7.3.2\n",
            "python-dateutil                          2.9.0.post0\n",
            "python-dotenv                            1.1.1\n",
            "python-json-logger                       3.3.0\n",
            "python-louvain                           0.16\n",
            "python-multipart                         0.0.20\n",
            "python-slugify                           8.0.4\n",
            "python-snappy                            0.7.3\n",
            "python-utils                             3.9.1\n",
            "pytz                                     2025.2\n",
            "pyviz_comms                              3.0.6\n",
            "PyWavelets                               1.8.0\n",
            "PyYAML                                   6.0.2\n",
            "pyzmq                                    26.2.1\n",
            "raft-dask-cu12                           25.6.0\n",
            "rapids-dask-dependency                   25.6.0\n",
            "rapids-logger                            0.1.1\n",
            "ratelim                                  0.1.6\n",
            "referencing                              0.36.2\n",
            "regex                                    2024.11.6\n",
            "requests                                 2.32.3\n",
            "requests-oauthlib                        2.0.0\n",
            "requests-toolbelt                        1.0.0\n",
            "requirements-parser                      0.9.0\n",
            "rich                                     13.9.4\n",
            "rich-toolkit                             0.14.9\n",
            "rignore                                  0.6.4\n",
            "rmm-cu12                                 25.6.0\n",
            "roman-numerals-py                        3.1.0\n",
            "rpds-py                                  0.26.0\n",
            "rpy2                                     3.5.17\n",
            "rsa                                      4.9.1\n",
            "ruff                                     0.12.7\n",
            "safehttpx                                0.1.6\n",
            "safetensors                              0.5.3\n",
            "scikit-image                             0.25.2\n",
            "scikit-learn                             1.6.1\n",
            "scipy                                    1.16.1\n",
            "scooby                                   0.10.1\n",
            "scs                                      3.2.7.post2\n",
            "seaborn                                  0.13.2\n",
            "SecretStorage                            3.3.3\n",
            "semantic-version                         2.10.0\n",
            "Send2Trash                               1.8.3\n",
            "sentence-transformers                    4.1.0\n",
            "sentencepiece                            0.2.0\n",
            "sentry-sdk                               2.34.1\n",
            "setproctitle                             1.3.6\n",
            "setuptools                               79.0.1\n",
            "setuptools-scm                           8.3.1\n",
            "shap                                     0.48.0\n",
            "shapely                                  2.1.1\n",
            "shellingham                              1.5.4\n",
            "simple-parsing                           0.1.7\n",
            "simplejson                               3.20.1\n",
            "simsimd                                  6.5.0\n",
            "six                                      1.17.0\n",
            "sklearn-compat                           0.1.3\n",
            "sklearn-pandas                           2.2.0\n",
            "slicer                                   0.0.8\n",
            "smart_open                               7.3.0.post1\n",
            "smmap                                    5.0.2\n",
            "sniffio                                  1.3.1\n",
            "snowballstemmer                          3.0.1\n",
            "sortedcontainers                         2.4.0\n",
            "soundfile                                0.13.1\n",
            "soupsieve                                2.7\n",
            "soxr                                     0.5.0.post1\n",
            "spacy                                    3.8.7\n",
            "spacy-legacy                             3.0.12\n",
            "spacy-loggers                            1.0.5\n",
            "spanner-graph-notebook                   1.1.6\n",
            "Sphinx                                   8.2.3\n",
            "sphinxcontrib-applehelp                  2.0.0\n",
            "sphinxcontrib-devhelp                    2.0.0\n",
            "sphinxcontrib-htmlhelp                   2.1.0\n",
            "sphinxcontrib-jsmath                     1.0.1\n",
            "sphinxcontrib-qthelp                     2.0.0\n",
            "sphinxcontrib-serializinghtml            2.0.0\n",
            "SQLAlchemy                               2.0.42\n",
            "sqlglot                                  25.20.2\n",
            "sqlparse                                 0.5.3\n",
            "srsly                                    2.5.1\n",
            "stanio                                   0.5.1\n",
            "starlette                                0.47.2\n",
            "statsmodels                              0.14.5\n",
            "stringzilla                              3.12.5\n",
            "stumpy                                   1.13.0\n",
            "sympy                                    1.13.1\n",
            "tables                                   3.10.2\n",
            "tabulate                                 0.9.0\n",
            "tbb                                      2022.2.0\n",
            "tblib                                    3.1.0\n",
            "tcmlib                                   1.4.0\n",
            "tenacity                                 8.5.0\n",
            "tensorboard                              2.19.0\n",
            "tensorboard-data-server                  0.7.2\n",
            "tensorflow                               2.19.0\n",
            "tensorflow-datasets                      4.9.9\n",
            "tensorflow_decision_forests              1.12.0\n",
            "tensorflow-hub                           0.16.1\n",
            "tensorflow-io-gcs-filesystem             0.37.1\n",
            "tensorflow-metadata                      1.17.2\n",
            "tensorflow-probability                   0.25.0\n",
            "tensorflow-text                          2.19.0\n",
            "tensorstore                              0.1.76\n",
            "termcolor                                3.1.0\n",
            "terminado                                0.18.1\n",
            "text-unidecode                           1.3\n",
            "textblob                                 0.19.0\n",
            "tf_keras                                 2.19.0\n",
            "tf-slim                                  1.1.0\n",
            "thinc                                    8.3.6\n",
            "threadpoolctl                            3.6.0\n",
            "tifffile                                 2025.6.11\n",
            "tiktoken                                 0.9.0\n",
            "timm                                     1.0.19\n",
            "tinycss2                                 1.4.0\n",
            "tokenizers                               0.21.4\n",
            "toml                                     0.10.2\n",
            "tomli                                    2.0.1\n",
            "tomlkit                                  0.13.3\n",
            "toolz                                    0.12.1\n",
            "torch                                    2.6.0+cpu\n",
            "torchao                                  0.10.0\n",
            "torchaudio                               2.6.0+cu124\n",
            "torchdata                                0.11.0\n",
            "torchsummary                             1.5.1\n",
            "torchtune                                0.6.1\n",
            "torchvision                              0.21.0+cpu\n",
            "tornado                                  6.4.2\n",
            "tqdm                                     4.67.1\n",
            "traitlets                                5.7.1\n",
            "traittypes                               0.2.1\n",
            "transformers                             4.56.0.dev0\n",
            "treelite                                 4.4.1\n",
            "treescope                                0.1.9\n",
            "triton                                   3.2.0\n",
            "tsfresh                                  0.21.0\n",
            "tweepy                                   4.16.0\n",
            "typeguard                                4.4.4\n",
            "typer                                    0.16.0\n",
            "types-pytz                               2025.2.0.20250516\n",
            "types-setuptools                         80.9.0.20250801\n",
            "typing_extensions                        4.14.1\n",
            "typing-inspection                        0.4.1\n",
            "tzdata                                   2025.2\n",
            "tzlocal                                  5.3.1\n",
            "uc-micro-py                              1.0.3\n",
            "ucx-py-cu12                              0.44.0\n",
            "ucxx-cu12                                0.44.0\n",
            "umap-learn                               0.5.9.post2\n",
            "umf                                      0.11.0\n",
            "uritemplate                              4.2.0\n",
            "urllib3                                  2.5.0\n",
            "uvicorn                                  0.35.0\n",
            "uvloop                                   0.21.0\n",
            "vega-datasets                            0.9.0\n",
            "vllm                                     0.10.1.dev405+g31f09c615.cpu\n",
            "wadllib                                  1.3.6\n",
            "wandb                                    0.21.0\n",
            "wasabi                                   1.1.3\n",
            "watchfiles                               1.1.0\n",
            "wcwidth                                  0.2.13\n",
            "weasel                                   0.4.1\n",
            "webcolors                                24.11.1\n",
            "webencodings                             0.5.1\n",
            "websocket-client                         1.8.0\n",
            "websockets                               15.0.1\n",
            "Werkzeug                                 3.1.3\n",
            "wheel                                    0.45.1\n",
            "widgetsnbextension                       3.6.10\n",
            "wordcloud                                1.9.4\n",
            "wrapt                                    1.17.2\n",
            "wurlitzer                                3.1.1\n",
            "xarray                                   2025.7.1\n",
            "xarray-einstats                          0.9.1\n",
            "xgboost                                  3.0.3\n",
            "xgrammar                                 0.1.21\n",
            "xlrd                                     2.0.2\n",
            "xxhash                                   3.5.0\n",
            "xyzservices                              2025.4.0\n",
            "yarl                                     1.20.1\n",
            "ydf                                      0.13.0\n",
            "yellowbrick                              1.5\n",
            "yfinance                                 0.2.65\n",
            "zict                                     3.0.0\n",
            "zipp                                     3.23.0\n",
            "zstandard                                0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "هااااااااااااااااااااااام ثبت ترانسفورمرز من المصدر"
      ],
      "metadata": {
        "id": "ovl6UDjKTNdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "7b57fa0e-2129-43e5-838b-7d5b45f99264",
        "id": "3uNxesahTL1N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-ru6sr6ir\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-ru6sr6ir\n",
            "  Resolved https://github.com/huggingface/transformers to commit 513f76853b00bb30ee6d152d689c0e7f5359e55f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.0.dev0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.0.dev0) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (2025.7.14)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.56.0.dev0-py3-none-any.whl size=12229080 sha256=a52e4010cf81e80e3a1b3f92c3c7daf8a0f7c701af2ece6d5915b15f60068b3e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_ze0wguf/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.0\n",
            "    Uninstalling transformers-4.55.0:\n",
            "      Successfully uninstalled transformers-4.55.0\n",
            "Successfully installed transformers-4.56.0.dev0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "21b30c2ab59a4d0db26d1e66822e2dc2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "d-622B_CTUcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_3aKjN42TUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM\n",
        "\n",
        "# For generative models (runner=generate) only\n",
        "llm = LLM(model=\"facebook/opt-125m\", runner=\"generate\")  # Name or path of your model\n",
        "output = llm.generate(\"Hello, my name is\")\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "e1db394233fa43899307fad2e46b8934",
            "b16fa795b5714f7a965701d99fa5a6a9",
            "58bdb957986541dfae7c96870683f0e3",
            "e31352de146a4543a9943a4ffe7b7885",
            "de1cf4db0965418893affdff728e4657",
            "fbc2f64073f241e788b0471c1a819fc4",
            "767aff20608c4efab57c067b3c5b39c7",
            "d5dcff209678465cabc3bf3e93ca3110",
            "802c4974333d4337981fb0b12b1ceb3f",
            "efbce2f3117e4b7eb7af101d0c4cae2c",
            "b0461e28d9fd408ca24c61176ac56288",
            "22fd0008f1464101af99c34b8a45b409",
            "a4de452e80eb4dda94d8b4b60914d161",
            "88e684e7311d49c1a3349e81fb5ebea2",
            "d349d312108745eca23204d198667a33",
            "65482ce7b6eb4dcf8e5b9759391cb15c",
            "8227e7243ce64a4288dc5918f11ff8cd",
            "207e4474a1e4468da07fc5882a9a3068",
            "0c5ae18af56a471ebfe85f5768f4bbaa",
            "05ec6172671440fd8c8cdc6d7e52ecf9",
            "609cd13afa714ebaaa167fad49af815c",
            "458e7f4658254ed09d8384d83933bb44"
          ]
        },
        "outputId": "3d3ee3ca-c939-43a7-8871-c53b32f2c3e5",
        "id": "S4UTdJn0TL1P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 08-07 02:06:10 [utils.py:326] non-default args: {'model': 'facebook/opt-125m', 'runner': 'generate', 'disable_log_stats': True}\n",
            "INFO 08-07 02:06:29 [config.py:726] Resolved architecture: OPTForCausalLM\n",
            "INFO 08-07 02:06:29 [config.py:1765] Using max model len 2048\n",
            "INFO 08-07 02:06:29 [config.py:2594] Chunked prefill is enabled with max_num_batched_tokens=4096.\n",
            "INFO 08-07 02:07:45 [llm.py:290] Supported_tasks: ['generate']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1db394233fa43899307fad2e46b8934"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22fd0008f1464101af99c34b8a45b409"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RequestOutput(request_id=0, prompt='Hello, my name is', prompt_token_ids=[2, 31414, 6, 127, 766, 16], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Aubrey and I am here to help you grow your fashion website store from yesterday', token_ids=[17095, 5460, 8, 38, 524, 259, 7, 244, 47, 1733, 110, 2734, 998, 1400, 31, 2350], cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=None, lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "شغال"
      ],
      "metadata": {
        "id": "mJLj5f2DTVcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "# SPDX-FileCopyrightText: Copyright contributors to the vLLM project\n",
        "\n",
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "# Sample prompts.\n",
        "prompts = [\n",
        "    \"Hello, my name is\",\n",
        "    \"The president of the United States is\",\n",
        "    \"The capital of France is\",\n",
        "    \"The future of AI is\",\n",
        "]\n",
        "# Create a sampling params object.\n",
        "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Create an LLM.\n",
        "    llm = LLM(model=\"facebook/opt-125m\")\n",
        "    # Generate texts from the prompts.\n",
        "    # The output is a list of RequestOutput objects\n",
        "    # that contain the prompt, generated text, and other information.\n",
        "    outputs = llm.generate(prompts, sampling_params)\n",
        "    # Print the outputs.\n",
        "    print(\"\\nGenerated Outputs:\\n\" + \"-\" * 60)\n",
        "    for output in outputs:\n",
        "        prompt = output.prompt\n",
        "        generated_text = output.outputs[0].text\n",
        "        print(f\"Prompt:    {prompt!r}\")\n",
        "        print(f\"Output:    {generated_text!r}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428,
          "referenced_widgets": [
            "160fe0dd4b264d47831c5f554060fa4b",
            "5730cbd9f21841aca8f61729349030fc",
            "b6081c134a094923ae1e2a2bcab381de",
            "99a0b8a1ebab484ba5a77f07ddaa5ce3",
            "e1f27c991dce47099655d9740e5adf9a",
            "21d3e513d7834142b0cf433388273ef1",
            "3bdad1c10a4a4ca392bcd433c01238ff",
            "0e7f2783e1d64f5f81ae9e0f2511a182",
            "eaf9bb6c171741c9867df0cfd5ae08df",
            "5497467f238d48b8b113446dd75ace4f",
            "c43fe18d4e1b4f44b41367734ee516e6",
            "652f0cdcbe434d939f1865d97030f793",
            "83ecb9f98f744dc79ace01f5f31bf950",
            "533896b7ee584251aa6182749fbda9c0",
            "51ad4ca0fecd411cac0c4778189027bf",
            "e3b9f0b62cb540d69f51c8628c0cb125",
            "3c2b15e10a5a4300b6bf835986fb5ad0",
            "268cad636f6c4d8a99140c22b2d978ad",
            "842d7c0393204c99b7d8f66b57b23c23",
            "64541266cc1c4a30a4dd505b36e40c49",
            "bb87852fcc6a4884aa1e9a5d039484bd",
            "f1d894247278493db9f62fdfc9d9de74"
          ]
        },
        "outputId": "0a78384c-235a-494c-e0a8-41dbc654879b",
        "id": "zgcCSKqLTL1Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 08-07 02:07:53 [utils.py:326] non-default args: {'model': 'facebook/opt-125m', 'disable_log_stats': True}\n",
            "INFO 08-07 02:07:53 [config.py:726] Resolved architecture: OPTForCausalLM\n",
            "INFO 08-07 02:07:53 [config.py:1765] Using max model len 2048\n",
            "INFO 08-07 02:07:53 [config.py:2594] Chunked prefill is enabled with max_num_batched_tokens=4096.\n",
            "INFO 08-07 02:08:42 [llm.py:290] Supported_tasks: ['generate']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding requests:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "160fe0dd4b264d47831c5f554060fa4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "652f0cdcbe434d939f1865d97030f793"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Outputs:\n",
            "------------------------------------------------------------\n",
            "Prompt:    'Hello, my name is'\n",
            "Output:    \" Aubrey.  I'm a musician and I love it!   I\"\n",
            "------------------------------------------------------------\n",
            "Prompt:    'The president of the United States is'\n",
            "Output:    ' once again saying he will not campaign for Joe Biden in 2020.\\n\\nT'\n",
            "------------------------------------------------------------\n",
            "Prompt:    'The capital of France is'\n",
            "Output:    \" a firehouse?\\nYes it is, it's an old school firehouse\"\n",
            "------------------------------------------------------------\n",
            "Prompt:    'The future of AI is'\n",
            "Output:    ' here, and we are in the middle of a revolution\\n\\nHumans are'\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u2s7Ej_VTLLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2vKlofXTLIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0yJQeF5pTLFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ejCyK21pTLB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLDTPDorTK-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4AkBCUVWTK7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b7bvijmzTK3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ANv2N8JRTKzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfSXaxjYTKv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W83pDC6hTKsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "# SPDX-FileCopyrightText: Copyright contributors to the vLLM project\n",
        "\n",
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "# Sample prompts.\n",
        "prompts = [\n",
        "    \"Hello, my name is\",\n",
        "    \"The president of the United States is\",\n",
        "    \"The capital of France is\",\n",
        "    \"The future of AI is\",\n",
        "]\n",
        "# Create a sampling params object.\n",
        "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Create an LLM.\n",
        "    llm = LLM(model=\"facebook/opt-125m\")\n",
        "    # Generate texts from the prompts.\n",
        "    # The output is a list of RequestOutput objects\n",
        "    # that contain the prompt, generated text, and other information.\n",
        "    outputs = llm.generate(prompts, sampling_params)\n",
        "    # Print the outputs.\n",
        "    print(\"\\nGenerated Outputs:\\n\" + \"-\" * 60)\n",
        "    for output in outputs:\n",
        "        prompt = output.prompt\n",
        "        generated_text = output.outputs[0].text\n",
        "        print(f\"Prompt:    {prompt!r}\")\n",
        "        print(f\"Output:    {generated_text!r}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "eKCoRBktvrlc",
        "outputId": "41bcc28d-63a1-400a-abce-e39ad0165dda"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "Could not import module 'ProcessorMixin'. Are this object's requirements defined correctly?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrender_jinja_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torchvision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_fake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchvision::nms\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmeta_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/library.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0muse_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0muse_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_fake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m_register_fake\u001b[0;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_to_register\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registration_handles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_library/fake_impl.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, func, source)\u001b[0m\n\u001b[1;32m     30\u001b[0m             )\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_has_kernel_for_dispatch_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Meta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1412252846.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# SPDX-FileCopyrightText: Copyright contributors to the vLLM project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamplingParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Sample prompts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vllm_source/vllm/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__package__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vllm_source/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from vllm.beam_search import (BeamSearchInstance, BeamSearchOutput,\n\u001b[0m\u001b[1;32m     18\u001b[0m                               \u001b[0mBeamSearchSequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               create_sort_beams_key_function)\n",
            "\u001b[0;32m/content/vllm_source/vllm/beam_search.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vllm_source/vllm/sequence.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSingletonInputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimodal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiModalKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiModalPlaceholderDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vllm_source/vllm/inputs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mTokensPrompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_explicit_enc_dec_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    to_enc_dec_tuple_list, token_inputs, zip_enc_dec_prompts)\n\u001b[0;32m----> 9\u001b[0;31m from .registry import (DummyData, InputContext, InputProcessingContext,\n\u001b[0m\u001b[1;32m     10\u001b[0m                        InputRegistry)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vllm_source/vllm/inputs/registry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2295\u001b[0;31m                 raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m   2296\u001b[0m                     \u001b[0;34mf\"Could not import module '{name}'. Are this object's requirements defined correctly?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m                 ) from e\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: Could not import module 'ProcessorMixin'. Are this object's requirements defined correctly?",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZlRLz0lNvri8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VXpuWEHwvrfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NolVMdnBvrdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qEu3WCjHvrZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المترجمات والأدوات\n",
        "sudo apt-get update -y\n",
        "sudo apt-get install -y gcc-12 g++-12 libnuma-dev python3-dev\n",
        "sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12\n",
        "\n",
        "# استنساخ المشروع\n",
        "git clone https://github.com/vllm-project/vllm.git vllm_source\n",
        "cd vllm_source\n",
        "\n",
        "# تثبيت الحزم الأساسية وتثبيت vLLM\n",
        "pip install --upgrade pip\n",
        "pip install cmake>=3.26.1 wheel packaging ninja setuptools-scm>=8 numpy\n",
        "pip install -v -r requirements/cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu\n",
        "VLLM_TARGET_DEVICE=cpu python setup.py install\n"
      ],
      "metadata": {
        "id": "JPkOW5YTvrKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.5.1 torchvision==0.20.0 torchaudio==2.5.1 \\\n",
        "  --index-url https://download.pytorch.org/whl/cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld8qIGF-FHTS",
        "outputId": "a276c94f-f272-4bc7-9546-a184aa501e9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.5.1%2Bcpu-cp311-cp311-linux_x86_64.whl (174.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.0\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.20.0%2Bcpu-cp311-cp311-linux_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.5.1%2Bcpu-cp311-cp311-linux_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==2.5.1 and torchvision==0.20.0+cpu because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested torch==2.5.1\n",
            "    torchvision 0.20.0+cpu depends on torch==2.5.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "from transformers import ProcessorMixin\n",
        "from transformers import GenerationMixin\n",
        "print(\"Success! ProcessorMixin:\", ProcessorMixin, \"GenerationMixin imported successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "vR4vWWh6FWoC",
        "outputId": "b4678e5b-302f-41a4-c488-dab9645c42ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-404031467.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Success! ProcessorMixin:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GenerationMixin imported successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mregister_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roi_align\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmeta_roi_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"rois must have shape as Tensor[K, 5]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mregister_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mget_meta_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "prompts = [\n",
        "    \"Hello, my name is\",\n",
        "    \"The president of the United States is\",\n",
        "    \"The capital of France is\",\n",
        "    \"The future of AI is\",\n",
        "]\n",
        "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
        "\n",
        "llm = LLM(model=\"facebook/opt-125m\")\n",
        "\n",
        "outputs = llm.generate(prompts, sampling_params)\n",
        "\n",
        "# Print the outputs.\n",
        "for output in outputs:\n",
        "    prompt = output.prompt\n",
        "    generated_text = output.outputs[0].text\n",
        "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "_ORCGVCrxfqW",
        "outputId": "ce55515c-d0c6-4e2b-cf33-49f56979f302"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'ProcessorMixin' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2033193602.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamplingParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m prompts = [\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"Hello, my name is\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"The president of the United States is\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__package__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from vllm.beam_search import (BeamSearchInstance, BeamSearchOutput,\n\u001b[0m\u001b[1;32m     18\u001b[0m                               \u001b[0mBeamSearchSequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               create_sort_beams_key_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/beam_search.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/sequence.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSingletonInputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimodal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiModalKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiModalPlaceholderDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mTokensPrompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_explicit_enc_dec_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    to_enc_dec_tuple_list, token_inputs, zip_enc_dec_prompts)\n\u001b[0;32m----> 9\u001b[0;31m from .registry import (DummyData, InputContext, InputProcessingContext,\n\u001b[0m\u001b[1;32m     10\u001b[0m                        InputRegistry)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/registry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ProcessorMixin' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/vllm_source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDIvK8D_8oOn",
        "outputId": "48773b98-0ffa-4581-d0d3-fd8ee85ff344"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vllm_source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch upstream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkAbqwdv8lRx",
        "outputId": "b1677432-fc98-4aa1-85a0-ead403164949"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: 'upstream' does not appear to be a git repository\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. تحديث بيانات المستودع الأصلي\n",
        "!git fetch upstream\n",
        "\n",
        "# 2. إنشاء فرع جديد بناءً على الفرع الرئيسي للمستودع الأصلي\n",
        "!git checkout -b apply-generation-mixin upstream/main\n",
        "\n",
        "# 3. تطبيق التغييرات من commit المطلوب\n",
        "!git cherry-pick bbcf35deff9245eb9fbf4e0d6268949ba3321319\n",
        "\n",
        "# 4. (اختياري) حل أي تعارضات تظهر أثناء cherry-pick، ثم إجراء commit للتغييرات\n",
        "\n",
        "# 5. رفع الفرع إلى الريموت الخاص بك\n",
        "!git push -u origin apply-generation-mixin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB1EfwMgxf8G",
        "outputId": "9e7ec2cd-514b-459e-d4fa-acccee0fce51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: 'upstream' does not appear to be a git repository\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n",
            "fatal: 'upstream/main' is not a commit and a branch 'apply-generation-mixin' cannot be created from it\n",
            "fatal: bad object bbcf35deff9245eb9fbf4e0d6268949ba3321319\n",
            "error: src refspec apply-generation-mixin does not match any\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/vllm-project/vllm.git'\n",
            "\u001b[m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "-from transformers.modeling_utils import GenerationMixin\n",
        "+from transformers.generation.utils import GenerationMixin\n"
      ],
      "metadata": {
        "id": "rocKGjq7846x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch origin fix-importerror-generationMixin\n",
        "!git checkout -b apply-gen-mixin origin/fix-importerror-generationMixin\n",
        "!git cherry-pick bbcf35deff9245eb9fbf4e0d6268949ba3321319\n",
        "# حل أي تعارضات إن ظهرت، ثم:\n",
        "!git push -u origin apply-gen-mixin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0333T3zZ8zkw",
        "outputId": "10f6b913-8c74-4fa6-98e1-2264ad404c14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: couldn't find remote ref fix-importerror-generationMixin\n",
            "fatal: 'origin/fix-importerror-generationMixin' is not a commit and a branch 'apply-gen-mixin' cannot be created from it\n",
            "fatal: bad object bbcf35deff9245eb9fbf4e0d6268949ba3321319\n",
            "error: src refspec apply-gen-mixin does not match any\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/vllm-project/vllm.git'\n",
            "\u001b[m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add sij411 https://github.com/sij411/transformers.git"
      ],
      "metadata": {
        "id": "K0vz_eU_80Ag"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch sij411"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7llPErYO9J1Z",
        "outputId": "cc5cd0b2-18f8-49b2-9635-5455ee8cc031"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 206531, done.\u001b[K\n",
            "remote: Total 206531 (delta 0), reused 0 (delta 0), pack-reused 206531 (from 1)\u001b[K\n",
            "Receiving objects: 100% (206531/206531), 234.87 MiB | 20.10 MiB/s, done.\n",
            "Resolving deltas: 100% (149639/149639), done.\n",
            "From https://github.com/sij411/transformers\n",
            " * [new branch]            fix-importerror-generationMixin -> sij411/fix-importerror-generationMixin\n",
            " * [new branch]            main       -> sij411/main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -b fix-gen-mixin sij411/fix-importerror-generationMixin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05MVqaIY9KU4",
        "outputId": "6d60fcb4-c030-4176-c543-f9e11b80cee7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating files: 100% (7768/7768), done.\n",
            "Branch 'fix-gen-mixin' set up to track remote branch 'fix-importerror-generationMixin' from 'sij411'.\n",
            "Switched to a new branch 'fix-gen-mixin'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin fix-gen-mixin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JaKkgT59Y-g",
        "outputId": "9fdeb7d4-ed72-48fb-fc78-53075ce87eb1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git cherry-pick bbcf35deff9245eb9fbf4e0d6268949ba3321319"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nNyHIzW9Q1Y",
        "outputId": "4a9a8deb-4fe2-4e9b-dd8a-5c172a29d3f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: commit bbcf35deff9245eb9fbf4e0d6268949ba3321319 is a merge but no -m option was given.\n",
            "fatal: cherry-pick failed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ابحث عن موقع ملف __init__.py الخاص بـ generation\n",
        "!python - << 'EOF'\n",
        "import transformers, os\n",
        "path = os.path.join(os.path.dirname(transformers.__file__), \"generation\", \"__init__.py\")\n",
        "print(path)\n",
        "EOF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "z2WxKcuN98bQ",
        "outputId": "66511df4-3e59-49df-f18b-845c54eb13f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: warning: here-document at line 1 delimited by end-of-file (wanted `EOF')\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/__init__.py\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'EOF' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1162636412.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__init__.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mEOF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'EOF' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import transformers\n",
        "\n",
        "path = Path(transformers.__file__).parent / \"generation\" / \"__init__.py\"\n",
        "print(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K-KqzE898sQ",
        "outputId": "477dccde-f4cd-4a16-c6d7-ac2353b634eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i \"s|from transformers.generation import GenerationMixin|from transformers.generation.utils import GenerationMixin|\" /usr/local/lib/python3.11/dist-packages/transformers/generation/__init__.py\n"
      ],
      "metadata": {
        "id": "O4HAzof0-T1g"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import transformers\n",
        "\n",
        "path = Path(transformers.__file__).parent / \"generation\" / \"utils.py\"\n",
        "print(\"مسار الملف:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yozfzjuv-Y1Q",
        "outputId": "05066608-e70e-4672-ddde-1a9ece2d5a7d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مسار الملف: /usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "شغال\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\n",
        "\n",
        "# coding=utf-8\n",
        "# Copyright 2020 The Google AI Language Team Authors, Facebook AI Research authors and The HuggingFace Inc. team.\n",
        "# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "import copy\n",
        "import inspect\n",
        "import os\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from typing import TYPE_CHECKING, Any, Callable, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "from huggingface_hub import file_exists\n",
        "from packaging import version\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from ..cache_utils import (\n",
        "    Cache,\n",
        "    DynamicCache,\n",
        "    EncoderDecoderCache,\n",
        "    HybridChunkedCache,\n",
        "    OffloadedCache,\n",
        "    OffloadedHybridCache,\n",
        ")\n",
        "from ..configuration_utils import PretrainedConfig\n",
        "from ..dynamic_module_utils import (\n",
        "    check_python_requirements,\n",
        "    get_cached_module_file,\n",
        "    get_class_in_module,\n",
        "    resolve_trust_remote_code,\n",
        ")\n",
        "from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n",
        "from ..integrations.fsdp import is_fsdp_managed_module\n",
        "from ..masking_utils import create_masks_for_generate\n",
        "from ..modeling_outputs import CausalLMOutputWithPast, Seq2SeqLMOutput\n",
        "from ..pytorch_utils import isin_mps_friendly\n",
        "from ..tokenization_utils import ExtensionsTrie\n",
        "from ..utils import (\n",
        "    ModelOutput,\n",
        "    is_accelerate_available,\n",
        "    is_hqq_available,\n",
        "    is_optimum_quanto_available,\n",
        "    is_torchdynamo_exporting,\n",
        "    logging,\n",
        ")\n",
        "from .beam_constraints import DisjunctiveConstraint, PhrasalConstraint\n",
        "from .beam_search import BeamScorer, BeamSearchScorer, ConstrainedBeamSearchScorer\n",
        "from .candidate_generator import (\n",
        "    AssistantVocabTranslatorCache,\n",
        "    AssistedCandidateGenerator,\n",
        "    AssistedCandidateGeneratorDifferentTokenizers,\n",
        "    CandidateGenerator,\n",
        "    EarlyExitCandidateGenerator,\n",
        "    PromptLookupCandidateGenerator,\n",
        "    UniversalSpeculativeDecodingGenerator,\n",
        "    _prepare_attention_mask,\n",
        "    _prepare_token_type_ids,\n",
        ")\n",
        "from .configuration_utils import (\n",
        "    NEED_SETUP_CACHE_CLASSES_MAPPING,\n",
        "    QUANT_BACKEND_CLASSES_MAPPING,\n",
        "    CompileConfig,\n",
        "    GenerationConfig,\n",
        "    GenerationMode,\n",
        ")\n",
        "from .continuous_batching import ContinuousMixin\n",
        "from .logits_process import (\n",
        "    EncoderNoRepeatNGramLogitsProcessor,\n",
        "    EncoderRepetitionPenaltyLogitsProcessor,\n",
        "    EpsilonLogitsWarper,\n",
        "    EtaLogitsWarper,\n",
        "    ExponentialDecayLengthPenalty,\n",
        "    ForcedBOSTokenLogitsProcessor,\n",
        "    ForcedEOSTokenLogitsProcessor,\n",
        "    HammingDiversityLogitsProcessor,\n",
        "    InfNanRemoveLogitsProcessor,\n",
        "    LogitNormalization,\n",
        "    LogitsProcessorList,\n",
        "    MinLengthLogitsProcessor,\n",
        "    MinNewTokensLengthLogitsProcessor,\n",
        "    MinPLogitsWarper,\n",
        "    NoBadWordsLogitsProcessor,\n",
        "    NoRepeatNGramLogitsProcessor,\n",
        "    PrefixConstrainedLogitsProcessor,\n",
        "    RepetitionPenaltyLogitsProcessor,\n",
        "    SequenceBiasLogitsProcessor,\n",
        "    SuppressTokensAtBeginLogitsProcessor,\n",
        "    SuppressTokensLogitsProcessor,\n",
        "    TemperatureLogitsWarper,\n",
        "    TopKLogitsWarper,\n",
        "    TopPLogitsWarper,\n",
        "    TypicalLogitsWarper,\n",
        "    UnbatchedClassifierFreeGuidanceLogitsProcessor,\n",
        ")\n",
        "from .stopping_criteria import (\n",
        "    ConfidenceCriteria,\n",
        "    EosTokenCriteria,\n",
        "    MaxLengthCriteria,\n",
        "    MaxTimeCriteria,\n",
        "    StoppingCriteria,\n",
        "    StoppingCriteriaList,\n",
        "    StopStringCriteria,\n",
        ")\n",
        "\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    from ..modeling_utils import PreTrainedModel\n",
        "    from ..tokenization_utils_base import PreTrainedTokenizerBase\n",
        "    from .streamers import BaseStreamer\n",
        "\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "if is_accelerate_available():\n",
        "    from accelerate.hooks import AlignDevicesHook, add_hook_to_module\n",
        "\n",
        "\n",
        "# Variable names used to hold the cache at generation time\n",
        "ALL_CACHE_NAMES = [\n",
        "    \"past_key_values\",  # default\n",
        "    \"cache_params\",  # mamba-based models\n",
        "    \"state\",  # rwkv\n",
        "    \"mems\",  # xlnet\n",
        "    \"past_buckets_states\",  # reformer\n",
        "]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GenerateDecoderOnlyOutput(ModelOutput):\n",
        "    \"\"\"\n",
        "    Outputs of decoder-only generation models, when using non-beam methods.\n",
        "\n",
        "    Args:\n",
        "        sequences (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "            The generated sequences. The second dimension (sequence_length) is either equal to `max_length` or shorter\n",
        "            if all batches finished early due to the `eos_token_id`.\n",
        "        scores (`tuple(torch.FloatTensor)` *optional*, returned when `output_scores=True`):\n",
        "            Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n",
        "            at each generation step. Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for\n",
        "            each generated token), with each tensor of shape `(batch_size, config.vocab_size)`.\n",
        "        logits (`tuple(torch.FloatTensor)` *optional*, returned when `output_logits=True`):\n",
        "            Unprocessed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n",
        "            at each generation step. Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for\n",
        "            each generated token), with each tensor of shape `(batch_size, config.vocab_size)`.\n",
        "        attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size, num_heads, generated_length, sequence_length)`.\n",
        "        hidden_states (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_hidden_states=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size, generated_length, hidden_size)`.\n",
        "        past_key_values (`tuple(tuple(torch.FloatTensor)))`, *optional*, returned when `use_cache=True`):\n",
        "            Returns the model cache, used to speed up decoding. Different models have a different cache format, check\n",
        "            the model's documentation. Usually, a [`~cache_utils.Cache`] instance.\n",
        "    \"\"\"\n",
        "\n",
        "    sequences: torch.LongTensor\n",
        "    scores: Optional[tuple[torch.FloatTensor]] = None\n",
        "    logits: Optional[tuple[torch.FloatTensor]] = None\n",
        "    attentions: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    hidden_states: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    past_key_values: Optional[tuple[tuple[tuple[torch.FloatTensor]]]] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GenerateEncoderDecoderOutput(ModelOutput):\n",
        "    \"\"\"\n",
        "    Outputs of encoder-decoder generation models, when using non-beam methods.\n",
        "\n",
        "    Args:\n",
        "        sequences (`torch.LongTensor` of shape `(batch_size*num_return_sequences, sequence_length)`):\n",
        "            The generated sequences. The second dimension (sequence_length) is either equal to `max_length` or shorter\n",
        "            if all batches finished early due to the `eos_token_id`.\n",
        "        scores (`tuple(torch.FloatTensor)` *optional*, returned when `output_scores=True`):\n",
        "            Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n",
        "            at each generation step. Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for\n",
        "            each generated token), with each tensor of shape `(batch_size, config.vocab_size)`.\n",
        "        logits (`tuple(torch.FloatTensor)` *optional*, returned when `output_logits=True`):\n",
        "            Unprocessed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n",
        "            at each generation step. Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for\n",
        "            each generated token), with each tensor of shape `(batch_size, config.vocab_size)`.\n",
        "        encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`):\n",
        "            Tuple of `torch.FloatTensor` (one for each layer of the decoder) of shape `(batch_size, num_heads,\n",
        "            sequence_length, sequence_length)`.\n",
        "        encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`):\n",
        "            Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer) of\n",
        "            shape `(batch_size, sequence_length, hidden_size)`.\n",
        "        decoder_attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size, num_heads, generated_length, sequence_length)`.\n",
        "        cross_attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size, num_heads, generated_length, sequence_length)`.\n",
        "        decoder_hidden_states (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_hidden_states=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size, generated_length, hidden_size)`.\n",
        "        past_key_values (`tuple(tuple(torch.FloatTensor)))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n",
        "            Returns the model cache, used to speed up decoding. Different models have a different cache format, check\n",
        "            the model's documentation. Usually, a [`~cache_utils.Cache`] instance.\n",
        "    \"\"\"\n",
        "\n",
        "    sequences: torch.LongTensor\n",
        "    scores: Optional[tuple[torch.FloatTensor]] = None\n",
        "    logits: Optional[tuple[torch.FloatTensor]] = None\n",
        "    encoder_attentions: Optional[tuple[torch.FloatTensor]] = None\n",
        "    encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = None\n",
        "    decoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    cross_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    decoder_hidden_states: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    past_key_values: Optional[tuple[tuple[tuple[torch.FloatTensor]]]] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GenerateBeamDecoderOnlyOutput(ModelOutput):\n",
        "    \"\"\"\n",
        "    Outputs of decoder-only generation models, when using beam methods.\n",
        "\n",
        "    Args:\n",
        "        sequences (`torch.LongTensor` of shape `(batch_size*num_return_sequences, sequence_length)`):\n",
        "            The generated sequences. The second dimension (sequence_length) is either equal to `max_length` or shorter\n",
        "            if all batches finished early due to the `eos_token_id`.\n",
        "        sequences_scores (`torch.FloatTensor` of shape `(batch_size*num_return_sequences)`, *optional*, returned when `output_scores=True`):\n",
        "            Final beam scores of the generated `sequences`.\n",
        "        scores (`tuple(torch.FloatTensor)` *optional*, returned when `output_scores=True`):\n",
        "            Beam transition scores for each vocabulary token at each generation step. Beam transition scores consisting\n",
        "            of log probabilities of tokens conditioned on log softmax of previously generated tokens in this beam.\n",
        "            Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for each generated token),\n",
        "            with each tensor of shape `(batch_size*num_beams, config.vocab_size)`.\n",
        "        logits (`tuple(torch.FloatTensor)` *optional*, returned when `output_logits=True`):\n",
        "            Unprocessed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n",
        "            at each generation step. Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for\n",
        "            each generated token), with each tensor of shape `(batch_size*num_beams, config.vocab_size)`.\n",
        "        beam_indices (`torch.LongTensor`, *optional*, returned when `output_scores=True`):\n",
        "            Beam indices of generated token id at each generation step. `torch.LongTensor` of shape\n",
        "            `(batch_size*num_return_sequences, sequence_length)`.\n",
        "        attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size*num_beams, num_heads, generated_length, sequence_length)`.\n",
        "        hidden_states (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_hidden_states=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size*num_beams*num_return_sequences, generated_length, hidden_size)`.\n",
        "        past_key_values (`tuple(tuple(torch.FloatTensor)))`, *optional*, returned when `use_cache=True`):\n",
        "            Returns the model cache, used to speed up decoding. Different models have a different cache format, check\n",
        "            the model's documentation. Usually, a [`~cache_utils.Cache`] instance.\n",
        "    \"\"\"\n",
        "\n",
        "    sequences: torch.LongTensor\n",
        "    sequences_scores: Optional[torch.FloatTensor] = None\n",
        "    scores: Optional[tuple[torch.FloatTensor]] = None\n",
        "    logits: Optional[tuple[torch.FloatTensor]] = None\n",
        "    beam_indices: Optional[torch.LongTensor] = None\n",
        "    attentions: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    hidden_states: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    past_key_values: Optional[tuple[tuple[tuple[torch.FloatTensor]]]] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GenerateBeamEncoderDecoderOutput(ModelOutput):\n",
        "    \"\"\"\n",
        "    Outputs of encoder-decoder generation models, when using beam methods.\n",
        "\n",
        "    Args:\n",
        "        sequences (`torch.LongTensor` of shape `(batch_size*num_return_sequences, sequence_length)`):\n",
        "            The generated sequences. The second dimension (sequence_length) is either equal to `max_length` or shorter\n",
        "            if all batches finished early due to the `eos_token_id`.\n",
        "        sequences_scores (`torch.FloatTensor` of shape `(batch_size*num_return_sequences)`, *optional*, returned when `output_scores=True`):\n",
        "            Final beam scores of the generated `sequences`.\n",
        "        scores (`tuple(torch.FloatTensor)` *optional*, returned when `output_scores=True`):\n",
        "            Beam transition scores for each vocabulary token at each generation step. Beam transition scores consisting\n",
        "            of log probabilities of tokens conditioned on log softmax of previously generated tokens in this beam.\n",
        "            Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for each generated token),\n",
        "            with each tensor of shape `(batch_size*num_beams, config.vocab_size)`.\n",
        "        logits (`tuple(torch.FloatTensor)` *optional*, returned when `output_logits=True`):\n",
        "            Unprocessed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)\n",
        "            at each generation step. Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for\n",
        "            each generated token), with each tensor of shape `(batch_size*num_beams, config.vocab_size)`.\n",
        "        beam_indices (`torch.LongTensor`, *optional*, returned when `output_scores=True`):\n",
        "            Beam indices of generated token id at each generation step. `torch.LongTensor` of shape\n",
        "            `(batch_size*num_return_sequences, sequence_length)`.\n",
        "        encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True`):\n",
        "            Tuple of `torch.FloatTensor` (one for each layer of the decoder) of shape `(batch_size, num_heads,\n",
        "            sequence_length, sequence_length)`.\n",
        "        encoder_hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True`):\n",
        "            Tuple of `torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer) of\n",
        "            shape `(batch_size*num_beams*num_return_sequences, sequence_length, hidden_size)`.\n",
        "        decoder_attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size*num_beams*num_return_sequences, num_heads, generated_length,\n",
        "            sequence_length)`.\n",
        "        cross_attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size, num_heads, generated_length, sequence_length)`.\n",
        "        decoder_hidden_states (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_hidden_states=True`):\n",
        "            Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n",
        "            `torch.FloatTensor` of shape `(batch_size*num_beams*num_return_sequences, generated_length, hidden_size)`.\n",
        "        past_key_values (`tuple(tuple(torch.FloatTensor)))`, *optional*, returned when `use_cache=True`):\n",
        "            Returns the model cache, used to speed up decoding. Different models have a different cache format, check\n",
        "            the model's documentation. Usually, a [`~cache_utils.Cache`] instance.\n",
        "    \"\"\"\n",
        "\n",
        "    sequences: torch.LongTensor\n",
        "    sequences_scores: Optional[torch.FloatTensor] = None\n",
        "    scores: Optional[tuple[torch.FloatTensor]] = None\n",
        "    logits: Optional[tuple[torch.FloatTensor]] = None\n",
        "    beam_indices: Optional[torch.LongTensor] = None\n",
        "    encoder_attentions: Optional[tuple[torch.FloatTensor]] = None\n",
        "    encoder_hidden_states: Optional[tuple[torch.FloatTensor]] = None\n",
        "    decoder_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    cross_attentions: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    decoder_hidden_states: Optional[tuple[tuple[torch.FloatTensor]]] = None\n",
        "    past_key_values: Optional[tuple[tuple[tuple[torch.FloatTensor]]]] = None\n",
        "\n",
        "\n",
        "# TODO (joao): remove the equivalent classes and typing shortcuts below in v5\n",
        "# Equivalent classes (kept for retrocompatibility purposes)\n",
        "GreedySearchDecoderOnlyOutput = GenerateDecoderOnlyOutput\n",
        "ContrastiveSearchDecoderOnlyOutput = GenerateDecoderOnlyOutput\n",
        "SampleDecoderOnlyOutput = GenerateDecoderOnlyOutput\n",
        "\n",
        "ContrastiveSearchEncoderDecoderOutput = GenerateEncoderDecoderOutput\n",
        "GreedySearchEncoderDecoderOutput = GenerateEncoderDecoderOutput\n",
        "SampleEncoderDecoderOutput = GenerateEncoderDecoderOutput\n",
        "\n",
        "BeamSearchDecoderOnlyOutput = GenerateBeamDecoderOnlyOutput\n",
        "BeamSampleDecoderOnlyOutput = GenerateBeamDecoderOnlyOutput\n",
        "\n",
        "BeamSearchEncoderDecoderOutput = GenerateBeamEncoderDecoderOutput\n",
        "BeamSampleEncoderDecoderOutput = GenerateBeamEncoderDecoderOutput\n",
        "\n",
        "GreedySearchOutput = Union[GreedySearchEncoderDecoderOutput, GreedySearchDecoderOnlyOutput]\n",
        "SampleOutput = Union[SampleEncoderDecoderOutput, SampleDecoderOnlyOutput]\n",
        "BeamSearchOutput = Union[BeamSearchEncoderDecoderOutput, BeamSearchDecoderOnlyOutput]\n",
        "BeamSampleOutput = Union[BeamSampleEncoderDecoderOutput, BeamSampleDecoderOnlyOutput]\n",
        "ContrastiveSearchOutput = Union[ContrastiveSearchEncoderDecoderOutput, ContrastiveSearchDecoderOnlyOutput]\n",
        "\n",
        "# Typing shortcuts\n",
        "GenerateNonBeamOutput = Union[GenerateDecoderOnlyOutput, GenerateEncoderDecoderOutput]\n",
        "GenerateBeamOutput = Union[GenerateBeamDecoderOnlyOutput, GenerateBeamEncoderDecoderOutput]\n",
        "GenerateOutput = Union[GenerateNonBeamOutput, GenerateBeamOutput]\n",
        "\n",
        "\n",
        "class GenerationMixin(ContinuousMixin):\n",
        "    \"\"\"\n",
        "    A class containing all functions for auto-regressive text generation, to be used as a mixin in model classes.\n",
        "    Inheriting from this class causes the model to have special generation-related behavior, such as loading a\n",
        "    `GenerationConfig` at initialization time or ensuring `generate`-related tests are run in `transformers` CI.\n",
        "\n",
        "    A model class should inherit from `GenerationMixin` to enable calling methods like `generate`, or when it\n",
        "    has defined a custom `generate` method that relies on `GenerationMixin`, directly or indirectly, which\n",
        "    approximately shares the same interface to public methods like `generate`. Three examples:\n",
        "        - `LlamaForCausalLM` should inherit from `GenerationMixin` to enable calling `generate` and other public\n",
        "            methods in the mixin;\n",
        "        - `BlipForQuestionAnswering` has a custom `generate` method that approximately shares the same interface as\n",
        "           `GenerationMixin.generate` (it has a few extra arguments, and the same output). That function also calls\n",
        "           `GenerationMixin.generate` indirectly, through an inner model. As such, `BlipForQuestionAnswering` should\n",
        "           inherit from `GenerationMixin` to benefit from all generation-related automation in our codebase;\n",
        "        - `BarkModel` has a custom `generate` method and one of its inner models calls `GenerationMixin.generate`.\n",
        "            However, its `generate` does not share the same interface as `GenerationMixin.generate`. In this case,\n",
        "            `BarkModel` should NOT inherit from `GenerationMixin`, as it breaks the `generate` interface.\n",
        "\n",
        "    The class exposes [`~generation.GenerationMixin.generate`], which can be used for:\n",
        "        - *greedy decoding* if `num_beams=1` and `do_sample=False`\n",
        "        - *contrastive search* if `penalty_alpha>0` and `top_k>1`\n",
        "        - *multinomial sampling* if `num_beams=1` and `do_sample=True`\n",
        "        - *beam-search decoding* if `num_beams>1` and `do_sample=False`\n",
        "        - *beam-search multinomial sampling* if `num_beams>1` and `do_sample=True`\n",
        "        - *diverse beam-search decoding* if `num_beams>1` and `num_beam_groups>1`\n",
        "        - *constrained beam-search decoding* if `constraints!=None` or `force_words_ids!=None`\n",
        "        - *assisted decoding* if `assistant_model` or `prompt_lookup_num_tokens` is passed to `.generate()`\n",
        "\n",
        "    To learn more about decoding strategies refer to the [text generation strategies guide](../generation_strategies).\n",
        "    \"\"\"\n",
        "\n",
        "    def load_custom_generate(\n",
        "        self,\n",
        "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]] = None,\n",
        "        trust_remote_code: Optional[bool] = None,\n",
        "        **kwargs,\n",
        "    ) -> Callable:\n",
        "        \"\"\"\n",
        "        Loads and returns a custom generate function, given a model repo.\n",
        "\n",
        "        Args:\n",
        "            pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
        "                 Can be either:\n",
        "                    - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.\n",
        "                    - A path to a *directory* containing model weights saved using\n",
        "                      [`~PreTrainedModel.save_pretrained`], e.g., `./my_model_directory/`.\n",
        "            trust_remote_code (`bool`, *optional*):\n",
        "                Whether or not to allow for custom models defined on the Hub in their own modeling files. This option\n",
        "                should only be set to `True` for repositories you trust and in which you have read the code, as it will\n",
        "                execute code present on the Hub on your local machine.\n",
        "            **kwargs:\n",
        "                Additional keyword arguments for remote code loading.\n",
        "\n",
        "        Raises:\n",
        "            OSError: If `pretrained_model_name_or_path` does not contain a `custom_generate` subdirectory.\n",
        "\n",
        "        Returns:\n",
        "            A callable that can be used to generate text.\n",
        "        \"\"\"\n",
        "        # Does `pretrained_model_name_or_path` have a `custom_generate` subdirectory? If not -> OSError\n",
        "        is_local_code = os.path.exists(pretrained_model_name_or_path)\n",
        "        has_custom_generate_folder = True\n",
        "        if is_local_code:\n",
        "            if not os.path.exists(os.path.join(pretrained_model_name_or_path, \"custom_generate/generate.py\")):\n",
        "                has_custom_generate_folder = False\n",
        "        else:\n",
        "            if not file_exists(pretrained_model_name_or_path, \"custom_generate/generate.py\"):\n",
        "                has_custom_generate_folder = False\n",
        "\n",
        "        if not has_custom_generate_folder:\n",
        "            raise OSError(\n",
        "                f\"`{pretrained_model_name_or_path}` does not contain a `custom_generate` subdirectory with a \"\n",
        "                \"`generate.py` file, can't load the custom generate function.\"\n",
        "            )\n",
        "\n",
        "        # Handle opt-in `trust_remote_code` and related exceptions\n",
        "        error_message = (\n",
        "            f\"The repository `{pretrained_model_name_or_path}` contains custom generation code that will override \"\n",
        "            \"the default `generate` method.\"\n",
        "        )\n",
        "        resolve_trust_remote_code(\n",
        "            trust_remote_code,\n",
        "            pretrained_model_name_or_path,\n",
        "            has_local_code=is_local_code,\n",
        "            has_remote_code=not is_local_code,\n",
        "            error_message=error_message,\n",
        "        )\n",
        "\n",
        "        # Load the custom generate function\n",
        "        check_python_requirements(\n",
        "            pretrained_model_name_or_path, requirements_file=\"custom_generate/requirements.txt\", **kwargs\n",
        "        )\n",
        "        module = get_cached_module_file(\n",
        "            pretrained_model_name_or_path, module_file=\"custom_generate/generate.py\", **kwargs\n",
        "        )\n",
        "        custom_generate_function = get_class_in_module(\"generate\", module)\n",
        "        return custom_generate_function\n",
        "\n",
        "    def _cache_dependant_input_preparation(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        inputs_embeds: Optional[torch.FloatTensor],\n",
        "        cache_position: Optional[torch.LongTensor],\n",
        "    ) -> tuple[torch.FloatTensor, torch.LongTensor]:\n",
        "        \"\"\"\n",
        "        Generic cache-dependent input preparation\n",
        "        The code is put in a separate function to allow granular unit testing\n",
        "        as it needs a different implementation to be exportable.\n",
        "\n",
        "        If we have cache: let's slice `input_ids` through `cache_position`, to keep only the unprocessed tokens\n",
        "        - Exception 1: when passing input_embeds, input_ids may be missing entries\n",
        "        - Exception 2: some generation methods do special slicing of input_ids, so we don't need to do it here\n",
        "        - Exception 3: with synced GPUs cache_position may go out of bounds, but we only want dummy token in that case.\n",
        "        - Exception 4: If input_embeds are passed then slice it through `cache_position`, to keep only the unprocessed tokens and\n",
        "          generate the first token for each sequence. Later use the generated Input ids for continuation.\n",
        "\n",
        "        The current implementation does not rely on ``self`` and could be\n",
        "        a class method. It is left as a standard method to be easily rewritten.\n",
        "        \"\"\"\n",
        "        if is_torchdynamo_exporting():\n",
        "            return self._cache_dependant_input_preparation_exporting(input_ids, inputs_embeds, cache_position)\n",
        "        if inputs_embeds is not None and input_ids.shape[1] == 0:  # Exception 4\n",
        "            inputs_embeds = inputs_embeds[:, -cache_position.shape[0] :]\n",
        "        elif (\n",
        "            inputs_embeds is not None  # Exception 1\n",
        "            or (cache_position[-1] >= input_ids.shape[1])  # Exception 3\n",
        "        ):\n",
        "            input_ids = input_ids[:, -cache_position.shape[0] :]\n",
        "        elif input_ids.shape[1] != cache_position.shape[0]:  # Default case (the \"else\", a no op, is Exception 2)\n",
        "            input_ids = input_ids[:, cache_position]\n",
        "        return inputs_embeds, input_ids\n",
        "\n",
        "    def _cache_dependant_input_preparation_exporting(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        inputs_embeds: Optional[torch.FloatTensor],\n",
        "        cache_position: Optional[torch.LongTensor],\n",
        "    ) -> tuple[torch.FloatTensor, torch.LongTensor]:\n",
        "        \"\"\"\n",
        "        This method implements method ``_cache_dependant_input_preparation``\n",
        "        with :func:`torch.cond` to make it exportable with :func:`torch.export.export`.\n",
        "        The code is put in a separate function to allow granular unit testing.\n",
        "        \"\"\"\n",
        "        if inputs_embeds is None:\n",
        "            input_ids = input_ids[:, cache_position]\n",
        "        else:\n",
        "            # This is the code we need to implemented with torch.cond.\n",
        "            # if input_ids.shape[1] == 0:\n",
        "            #     inputs_embeds = inputs_embeds[:, -cache_position.shape[0] :]\n",
        "            # else:\n",
        "            #     if cache_position[-1] >= input_ids.shape[1]:\n",
        "            #         input_ids = input_ids[:, -cache_position.shape[0] :]\n",
        "            #     else:\n",
        "            #         if input_ids.shape[1] != cache_position.shape[0]:\n",
        "            #             input_ids = input_ids[:, cache_position]\n",
        "            # We need to clone the outputs to avoid aliasing.\n",
        "            def branch_1(inputs_embeds, cache_position):\n",
        "                return inputs_embeds[:, -cache_position.shape[0] :].clone()\n",
        "\n",
        "            def branch_2(input_ids, cache_position):\n",
        "                return input_ids[:, -cache_position.shape[0] :].clone()\n",
        "\n",
        "            def branch_3(input_ids, cache_position):\n",
        "                return input_ids[:, cache_position].clone()\n",
        "\n",
        "            inputs_embeds, input_ids = torch.cond(\n",
        "                input_ids.shape[1] == 0,\n",
        "                (\n",
        "                    lambda input_ids, inputs_embeds, cache_position: (\n",
        "                        branch_1(inputs_embeds, cache_position),\n",
        "                        input_ids.clone(),\n",
        "                    )\n",
        "                ),\n",
        "                (\n",
        "                    lambda input_ids, inputs_embeds, cache_position: (\n",
        "                        inputs_embeds,\n",
        "                        torch.cond(\n",
        "                            cache_position[-1] >= input_ids.shape[1],\n",
        "                            branch_2,\n",
        "                            lambda input_ids, cache_position: (\n",
        "                                torch.cond(\n",
        "                                    input_ids.shape[1] != cache_position.shape[0],\n",
        "                                    branch_3,\n",
        "                                    (lambda input_ids, cache_position: input_ids.clone()),\n",
        "                                    [input_ids, cache_position],\n",
        "                                )\n",
        "                            ),\n",
        "                            [input_ids, cache_position],\n",
        "                        ),\n",
        "                    )\n",
        "                ),\n",
        "                [input_ids, inputs_embeds, cache_position],\n",
        "            )\n",
        "        return inputs_embeds, input_ids\n",
        "\n",
        "    def prepare_inputs_for_generation(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        past_key_values: Optional[Cache] = None,\n",
        "        attention_mask: Optional[torch.LongTensor] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        cache_position: Optional[torch.LongTensor] = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Prepare the model inputs for generation. It includes operations like computing the 4D attention mask or\n",
        "        slicing inputs given the existing cache.\n",
        "\n",
        "        See the forward pass in the model documentation for expected arguments (different models might have different\n",
        "        requirements for e.g. `past_key_values`). This function should work as is for most LLMs.\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. Handle BC:\n",
        "        model_inputs = {}\n",
        "        model_inputs[\"cache_position\"] = cache_position\n",
        "\n",
        "        # 2. Generic cache-dependent input preparation\n",
        "        if past_key_values is not None:\n",
        "            model_inputs[\"past_key_values\"] = past_key_values\n",
        "            inputs_embeds, input_ids = self._cache_dependant_input_preparation(\n",
        "                input_ids, inputs_embeds, cache_position\n",
        "            )\n",
        "\n",
        "        # 3. Prepare base model inputs\n",
        "        input_ids_key = \"decoder_input_ids\" if self.config.is_encoder_decoder else \"input_ids\"\n",
        "        # if `inputs_embeds` are passed, we only want to use them in the 1st generation step for every prompt.\n",
        "        if not self.config.is_encoder_decoder:\n",
        "            if inputs_embeds is not None and len(cache_position) == inputs_embeds.shape[1]:\n",
        "                model_inputs[input_ids_key] = None\n",
        "                model_inputs[\"inputs_embeds\"] = inputs_embeds\n",
        "            else:\n",
        "                # `clone` calls in this function ensure a consistent stride. See #32227\n",
        "                model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)\n",
        "                model_inputs[\"inputs_embeds\"] = None\n",
        "        else:\n",
        "            model_inputs[input_ids_key] = input_ids.clone(memory_format=torch.contiguous_format)\n",
        "\n",
        "        # 4. Create missing `position_ids` on the fly\n",
        "        encoder_attention_mask = attention_mask if self.config.is_encoder_decoder else None\n",
        "        attention_mask = (\n",
        "            kwargs.pop(\"decoder_attention_mask\", None) if self.config.is_encoder_decoder else attention_mask\n",
        "        )\n",
        "        attention_mask_key = \"decoder_attention_mask\" if self.config.is_encoder_decoder else \"attention_mask\"\n",
        "        position_ids_key = \"decoder_position_ids\" if self.config.is_encoder_decoder else \"position_ids\"\n",
        "        if (\n",
        "            attention_mask is not None\n",
        "            and kwargs.get(position_ids_key) is None\n",
        "            and position_ids_key in set(inspect.signature(self.forward).parameters.keys())\n",
        "        ):\n",
        "            position_ids = attention_mask.long().cumsum(-1) - 1\n",
        "            position_ids.masked_fill_(attention_mask == 0, 1)\n",
        "            kwargs[position_ids_key] = position_ids  # placed in kwargs for further processing (see below)\n",
        "\n",
        "        # 5. Slice model inputs if it's an input that should have the same length as `input_ids`\n",
        "        for model_input_name in [\"position_ids\", \"token_type_ids\", \"decoder_position_ids\"]:\n",
        "            model_input = kwargs.get(model_input_name)\n",
        "            if model_input is not None:\n",
        "                if past_key_values is not None:\n",
        "                    current_input_length = (\n",
        "                        model_inputs[\"inputs_embeds\"].shape[1]\n",
        "                        if model_inputs.get(\"inputs_embeds\") is not None\n",
        "                        else model_inputs[input_ids_key].shape[1]\n",
        "                    )\n",
        "                    model_input = model_input[:, -current_input_length:]\n",
        "                    model_input = model_input.clone(memory_format=torch.contiguous_format)\n",
        "                model_inputs[model_input_name] = model_input\n",
        "\n",
        "        # 6. Create 4D attention mask is we are using a compilable cache (important for performant compiled forward\n",
        "        # pass)\n",
        "        if (\n",
        "            isinstance(past_key_values, Cache)\n",
        "            and past_key_values.is_compileable\n",
        "            and attention_mask is not None\n",
        "            and attention_mask.ndim == 2\n",
        "        ):\n",
        "            if not self.config.is_encoder_decoder and model_inputs[\"inputs_embeds\"] is not None:\n",
        "                batch_size, sequence_length, _ = model_inputs[\"inputs_embeds\"].shape\n",
        "            else:\n",
        "                batch_size, sequence_length = model_inputs[input_ids_key].shape[:2]\n",
        "\n",
        "            # Create the causal mask with fixed shape in advance, to reduce recompilations. If the function to create\n",
        "            # the 4D causal mask exists, it should be present in the base model (XXXModel class) or in its decoder.\n",
        "            base_model = getattr(self, self.base_model_prefix, self)\n",
        "            decoder = base_model.get_decoder() if hasattr(base_model, \"get_decoder\") else None\n",
        "            causal_mask_creation_function = getattr(\n",
        "                base_model, \"_prepare_4d_causal_attention_mask_with_cache_position\", None\n",
        "            )\n",
        "            if causal_mask_creation_function is None and decoder is not None:  # it may be in the decoder\n",
        "                causal_mask_creation_function = getattr(\n",
        "                    decoder, \"_prepare_4d_causal_attention_mask_with_cache_position\", None\n",
        "                )\n",
        "\n",
        "            # If it's not defined, it means the model uses the new general mask API\n",
        "            if causal_mask_creation_function is None:  # can't be found\n",
        "                token_type_ids = model_inputs.get(\"token_type_ids\", None)\n",
        "                position_ids = model_inputs.get(position_ids_key, None)\n",
        "                # Some models may overwrite the general one\n",
        "                causal_mask_creation_function = getattr(self, \"create_masks_for_generate\", create_masks_for_generate)\n",
        "                attention_mask = causal_mask_creation_function(\n",
        "                    config=self.config,\n",
        "                    # we only need batch size, seq_length and dtype here - we don't care about the values of the embeddings\n",
        "                    input_embeds=torch.empty((batch_size, sequence_length), dtype=self.dtype),\n",
        "                    attention_mask=attention_mask,\n",
        "                    cache_position=cache_position,\n",
        "                    past_key_values=past_key_values,\n",
        "                    position_ids=position_ids,\n",
        "                    token_type_ids=token_type_ids,\n",
        "                )\n",
        "            else:\n",
        "                attention_mask = causal_mask_creation_function(\n",
        "                    attention_mask,\n",
        "                    sequence_length=sequence_length,\n",
        "                    target_length=past_key_values.get_max_cache_shape(),\n",
        "                    dtype=self.dtype,\n",
        "                    cache_position=cache_position,\n",
        "                    batch_size=batch_size,\n",
        "                    config=self.config,\n",
        "                    past_key_values=past_key_values,\n",
        "                )\n",
        "        if attention_mask is not None:\n",
        "            model_inputs[attention_mask_key] = attention_mask\n",
        "\n",
        "        if encoder_attention_mask is not None:\n",
        "            model_inputs[\"attention_mask\"] = encoder_attention_mask\n",
        "\n",
        "        if \"flash\" in self.config._attn_implementation and self._supports_attention_backend:\n",
        "            tensor_kws = {\"dtype\": torch.int32, \"device\": self.device}\n",
        "            pos = model_inputs[\"position_ids\"][:, -1]\n",
        "\n",
        "            cu_seq_lens_k = torch.cat([torch.zeros(1, **tensor_kws), pos.cumsum(0).add(1)], 0)\n",
        "            max_length_k = int(pos.max()) + 1\n",
        "\n",
        "            bs, seq_len = input_ids.size()\n",
        "            q_len = torch.ones(bs, **tensor_kws) if seq_len == 1 else pos.to(torch.int32).add(1)\n",
        "            cu_seq_lens_q = torch.cat([torch.zeros(1, **tensor_kws), q_len.cumsum(0)], 0)\n",
        "            max_length_q = int(q_len.max())\n",
        "\n",
        "            model_inputs.update(\n",
        "                cu_seq_lens_q=cu_seq_lens_q.to(self.device),\n",
        "                cu_seq_lens_k=cu_seq_lens_k.to(self.device),\n",
        "                max_length_q=max_length_q,\n",
        "                max_length_k=max_length_k,\n",
        "            )\n",
        "        # 7. Forward ALL kwargs that are uninitialized (e.g. `use_cache`).\n",
        "        for key, value in kwargs.items():\n",
        "            if key not in model_inputs:\n",
        "                model_inputs[key] = value\n",
        "\n",
        "        # 8. Remove unexpected `generate` inputs (TODO @joao: fix trainer and examples)\n",
        "        model_inputs.pop(\"labels\", None)\n",
        "        return model_inputs\n",
        "\n",
        "    def _prepare_model_inputs(\n",
        "        self,\n",
        "        inputs: Optional[torch.Tensor] = None,\n",
        "        bos_token_id: Optional[torch.Tensor] = None,\n",
        "        model_kwargs: Optional[dict[str, torch.Tensor]] = None,\n",
        "    ) -> tuple[torch.Tensor, Optional[str], dict[str, torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        This function extracts the model-specific `inputs` for generation.\n",
        "        \"\"\"\n",
        "        # 1. retrieve all kwargs that are non-None or non-model input related.\n",
        "        # some encoder-decoder models have different names for model and encoder\n",
        "        if (\n",
        "            self.config.is_encoder_decoder\n",
        "            and hasattr(self, \"encoder\")\n",
        "            and self.encoder.main_input_name != self.main_input_name\n",
        "        ):\n",
        "            input_name = self.encoder.main_input_name\n",
        "        else:\n",
        "            input_name = self.main_input_name\n",
        "\n",
        "        model_kwargs = {k: v for k, v in model_kwargs.items() if v is not None or k != input_name}\n",
        "\n",
        "        # 2. check whether model_input_name is passed as kwarg\n",
        "        # if yes and `inputs` is None use kwarg inputs\n",
        "        inputs_kwarg = model_kwargs.pop(input_name, None)\n",
        "        if inputs_kwarg is not None and inputs is not None:\n",
        "            raise ValueError(\n",
        "                f\"`inputs`: {inputs}` were passed alongside {input_name} which is not allowed. \"\n",
        "                f\"Make sure to either pass {inputs} or {input_name}=...\"\n",
        "            )\n",
        "        elif inputs_kwarg is not None:\n",
        "            inputs = inputs_kwarg\n",
        "\n",
        "        # 3. In the presence of `inputs_embeds` for text models:\n",
        "        # - decoder-only models should complain if the user attempts to pass `inputs_embeds`, but the model\n",
        "        # doesn't have its forwarding implemented. `inputs_embeds` is kept in `model_kwargs` and can coexist with\n",
        "        # input_ids (`inputs_embeds` will be used in the 1st generation step, as opposed to `input_ids`)\n",
        "        # - encoder-decoder models should complain if the user attempts to pass `inputs_embeds` and `input_ids`, and\n",
        "        # pull the former to inputs. It will be used in place of `input_ids` to get the encoder hidden states.\n",
        "        if input_name == \"input_ids\" and \"inputs_embeds\" in model_kwargs:\n",
        "            if model_kwargs[\"inputs_embeds\"] is None:\n",
        "                model_kwargs.pop(\"inputs_embeds\")\n",
        "            elif not self.config.is_encoder_decoder:\n",
        "                has_inputs_embeds_forwarding = \"inputs_embeds\" in set(\n",
        "                    inspect.signature(self.prepare_inputs_for_generation).parameters.keys()\n",
        "                )\n",
        "                if not has_inputs_embeds_forwarding:\n",
        "                    raise ValueError(\n",
        "                        f\"You passed `inputs_embeds` to `.generate()`, but the model class {self.__class__.__name__} \"\n",
        "                        \"doesn't have its forwarding implemented. See the GPT2 implementation for an example \"\n",
        "                        \"(https://github.com/huggingface/transformers/pull/21405), and feel free to open a PR with it!\"\n",
        "                    )\n",
        "                # In this case, `input_ids` is moved to the `model_kwargs`, so a few automations (like the creation of\n",
        "                # the attention mask) can rely on the actual model input.\n",
        "                model_kwargs[\"input_ids\"] = self._maybe_initialize_input_ids_for_generation(\n",
        "                    inputs, bos_token_id, model_kwargs=model_kwargs\n",
        "                )\n",
        "                inputs, input_name = model_kwargs[\"inputs_embeds\"], \"inputs_embeds\"\n",
        "            else:\n",
        "                if inputs is not None:\n",
        "                    raise ValueError(\"You passed `inputs_embeds` and `input_ids` to `.generate()`. Please pick one.\")\n",
        "                inputs, input_name = model_kwargs[\"inputs_embeds\"], \"inputs_embeds\"\n",
        "\n",
        "        # 4. if `inputs` is still None, try to create `input_ids` from BOS token\n",
        "        inputs = self._maybe_initialize_input_ids_for_generation(inputs, bos_token_id, model_kwargs)\n",
        "        return inputs, input_name, model_kwargs\n",
        "\n",
        "    def _maybe_initialize_input_ids_for_generation(\n",
        "        self,\n",
        "        inputs: Optional[torch.Tensor] = None,\n",
        "        bos_token_id: Optional[torch.Tensor] = None,\n",
        "        model_kwargs: Optional[dict[str, torch.Tensor]] = None,\n",
        "    ) -> torch.LongTensor:\n",
        "        \"\"\"Initializes input ids for generation, if necessary.\"\"\"\n",
        "        if inputs is not None:\n",
        "            return inputs\n",
        "\n",
        "        encoder_outputs = model_kwargs.get(\"encoder_outputs\")\n",
        "        if self.config.is_encoder_decoder and encoder_outputs is not None:\n",
        "            # make dummy input_ids with value -100, as a sanity check ensuring that they won't be used for encoding\n",
        "            shape = encoder_outputs.last_hidden_state.size()[:-1]\n",
        "            return torch.ones(shape, dtype=torch.long, device=self.device) * -100\n",
        "\n",
        "        # If there is some tensor in `model_kwargs`, we can infer the batch size from it. This is helpful with\n",
        "        # soft-prompting or in multimodal implementations built on top of decoder-only language models.\n",
        "        batch_size = 1\n",
        "        for value in model_kwargs.values():\n",
        "            if isinstance(value, torch.Tensor):\n",
        "                batch_size = value.shape[0]\n",
        "                break\n",
        "\n",
        "        if \"inputs_embeds\" in model_kwargs:\n",
        "            return torch.ones((batch_size, 0), dtype=torch.long, device=self.device)\n",
        "\n",
        "        if bos_token_id is None:\n",
        "            raise ValueError(\"`bos_token_id` has to be defined when no `input_ids` are provided.\")\n",
        "\n",
        "        return torch.ones((batch_size, 1), dtype=torch.long, device=self.device) * bos_token_id\n",
        "\n",
        "    def _prepare_attention_mask_for_generation(\n",
        "        self,\n",
        "        inputs_tensor: torch.Tensor,\n",
        "        generation_config: GenerationConfig,\n",
        "        model_kwargs: dict[str, Any],\n",
        "    ) -> torch.LongTensor:\n",
        "        pad_token_id = generation_config._pad_token_tensor\n",
        "        eos_token_id = generation_config._eos_token_tensor\n",
        "\n",
        "        # `input_ids` may be present in the model kwargs, instead of being the main input (e.g. multimodal model)\n",
        "        if \"input_ids\" in model_kwargs and model_kwargs[\"input_ids\"].shape[1] > 0:\n",
        "            inputs_tensor = model_kwargs[\"input_ids\"]\n",
        "\n",
        "        # No information for attention mask inference -> return default attention mask\n",
        "        default_attention_mask = torch.ones(inputs_tensor.shape[:2], dtype=torch.long, device=inputs_tensor.device)\n",
        "        if pad_token_id is None:\n",
        "            return default_attention_mask\n",
        "\n",
        "        is_input_ids = len(inputs_tensor.shape) == 2 and inputs_tensor.dtype in [torch.int, torch.long]\n",
        "        if not is_input_ids:\n",
        "            return default_attention_mask\n",
        "\n",
        "        is_pad_token_in_inputs = (pad_token_id is not None) and (\n",
        "            isin_mps_friendly(elements=inputs_tensor, test_elements=pad_token_id).any()\n",
        "        )\n",
        "        is_pad_token_not_equal_to_eos_token_id = (eos_token_id is None) or ~(\n",
        "            isin_mps_friendly(elements=eos_token_id, test_elements=pad_token_id).any()\n",
        "        )\n",
        "        can_infer_attention_mask = is_pad_token_in_inputs * is_pad_token_not_equal_to_eos_token_id\n",
        "        attention_mask_from_padding = inputs_tensor.ne(pad_token_id).long()\n",
        "\n",
        "        attention_mask = (\n",
        "            attention_mask_from_padding * can_infer_attention_mask + default_attention_mask * ~can_infer_attention_mask\n",
        "        )\n",
        "        return attention_mask\n",
        "\n",
        "    def _prepare_encoder_decoder_kwargs_for_generation(\n",
        "        self,\n",
        "        inputs_tensor: torch.Tensor,\n",
        "        model_kwargs,\n",
        "        model_input_name: Optional[str],\n",
        "        generation_config: GenerationConfig,\n",
        "    ) -> dict[str, Any]:\n",
        "        # 1. get encoder\n",
        "        encoder = self.get_encoder()\n",
        "        # Compatibility with Accelerate big model inference: we need the encoder to outputs stuff on the same device\n",
        "        # as the inputs.\n",
        "        if hasattr(self, \"hf_device_map\"):\n",
        "            if hasattr(encoder, \"_hf_hook\"):\n",
        "                encoder._hf_hook.io_same_device = True\n",
        "            else:\n",
        "                add_hook_to_module(encoder, AlignDevicesHook(io_same_device=True))\n",
        "\n",
        "        # 2. Prepare encoder args and encoder kwargs from model kwargs and generation config.\n",
        "        irrelevant_prefix = [\"decoder_\", \"cross_attn\", \"use_cache\"]\n",
        "        encoder_kwargs = {\n",
        "            argument: value\n",
        "            for argument, value in model_kwargs.items()\n",
        "            if not any(argument.startswith(p) for p in irrelevant_prefix)\n",
        "        }\n",
        "        encoder_signature = set(inspect.signature(encoder.forward).parameters)\n",
        "        encoder_accepts_wildcard = \"kwargs\" in encoder_signature or \"model_kwargs\" in encoder_signature\n",
        "        if not encoder_accepts_wildcard:\n",
        "            encoder_kwargs = {\n",
        "                argument: value for argument, value in encoder_kwargs.items() if argument in encoder_signature\n",
        "            }\n",
        "        encoder_kwargs[\"output_attentions\"] = generation_config.output_attentions\n",
        "        encoder_kwargs[\"output_hidden_states\"] = generation_config.output_hidden_states\n",
        "\n",
        "        # 3. make sure that encoder returns `ModelOutput`\n",
        "        model_input_name = model_input_name if model_input_name is not None else self.main_input_name\n",
        "        encoder_kwargs[\"return_dict\"] = True\n",
        "        encoder_kwargs[model_input_name] = inputs_tensor\n",
        "        model_kwargs[\"encoder_outputs\"]: ModelOutput = encoder(**encoder_kwargs)  # type: ignore\n",
        "\n",
        "        return model_kwargs\n",
        "\n",
        "    def _prepare_decoder_input_ids_for_generation(\n",
        "        self,\n",
        "        batch_size: int,\n",
        "        model_input_name: str,\n",
        "        model_kwargs: dict[str, torch.Tensor],\n",
        "        decoder_start_token_id: torch.Tensor,\n",
        "        device: Optional[torch.device] = None,\n",
        "    ) -> tuple[torch.LongTensor, dict[str, torch.Tensor]]:\n",
        "        \"\"\"Prepares `decoder_input_ids` for generation with encoder-decoder models\"\"\"\n",
        "        # 1. Check whether the user has defined `decoder_input_ids` manually. To facilitate in terms of input naming,\n",
        "        # we also allow the user to pass it under `input_ids`, if the encoder does not use it as the main input.\n",
        "        if model_kwargs is not None and \"decoder_input_ids\" in model_kwargs:\n",
        "            decoder_input_ids = model_kwargs.pop(\"decoder_input_ids\")\n",
        "        elif \"input_ids\" in model_kwargs and model_input_name != \"input_ids\":\n",
        "            decoder_input_ids = model_kwargs.pop(\"input_ids\")\n",
        "        else:\n",
        "            decoder_input_ids = None\n",
        "\n",
        "        # 2. `decoder_start_token_id` must have shape (batch_size, 1)\n",
        "        if device is None:\n",
        "            device = self.device\n",
        "        if decoder_start_token_id.ndim == 1:\n",
        "            if decoder_start_token_id.shape[0] != batch_size:\n",
        "                raise ValueError(\n",
        "                    f\"`decoder_start_token_id` expected to have length {batch_size} but got {decoder_start_token_id.shape[0]}\"\n",
        "                )\n",
        "            decoder_start_token_id = decoder_start_token_id.view(-1, 1)\n",
        "        else:\n",
        "            decoder_start_token_id = (\n",
        "                torch.ones((batch_size, 1), dtype=torch.long, device=device) * decoder_start_token_id\n",
        "            )\n",
        "\n",
        "        # 3. Encoder-decoder models expect the `decoder_input_ids` to start with a special token. Let's ensure that.\n",
        "        # no user input -> use decoder_start_token_id as decoder_input_ids\n",
        "        if decoder_input_ids is None:\n",
        "            decoder_input_ids = decoder_start_token_id\n",
        "        # exception: Donut checkpoints have task-specific decoder starts and don't expect a BOS token. Note that the\n",
        "        # original checkpoints can't be detected through `self.__class__.__name__.lower()`, needing custom logic.\n",
        "        # See: https://github.com/huggingface/transformers/pull/31470\n",
        "        elif \"donut\" in self.__class__.__name__.lower() or (\n",
        "            self.config.model_type == \"vision-encoder-decoder\" and \"donut\" in self.config.encoder.model_type.lower()\n",
        "        ):\n",
        "            pass\n",
        "        elif self.config.model_type in [\"whisper\"]:\n",
        "            pass\n",
        "        # user input but doesn't start with decoder_start_token_id -> prepend decoder_start_token_id (and adjust\n",
        "        # decoder_attention_mask if provided)\n",
        "        elif (decoder_input_ids[:, 0] != decoder_start_token_id[:, 0]).all().item():\n",
        "            decoder_input_ids = torch.cat([decoder_start_token_id, decoder_input_ids], dim=-1)\n",
        "            if \"decoder_attention_mask\" in model_kwargs:\n",
        "                decoder_attention_mask = model_kwargs[\"decoder_attention_mask\"]\n",
        "                decoder_attention_mask = torch.cat(\n",
        "                    (torch.ones_like(decoder_attention_mask)[:, :1], decoder_attention_mask),\n",
        "                    dim=-1,\n",
        "                )\n",
        "                model_kwargs[\"decoder_attention_mask\"] = decoder_attention_mask\n",
        "\n",
        "        return decoder_input_ids, model_kwargs\n",
        "\n",
        "    @staticmethod\n",
        "    def _expand_inputs_for_generation(\n",
        "        expand_size: int = 1,\n",
        "        is_encoder_decoder: bool = False,\n",
        "        input_ids: Optional[torch.LongTensor] = None,\n",
        "        **model_kwargs,\n",
        "    ) -> tuple[torch.LongTensor, dict[str, Any]]:\n",
        "        \"\"\"Expands tensors from [batch_size, ...] to [batch_size * expand_size, ...]\"\"\"\n",
        "        # Do not call torch.repeat_interleave if expand_size is 1 because it clones\n",
        "        # the input tensor and thus requires more memory although no change is applied\n",
        "        if expand_size == 1:\n",
        "            return input_ids, model_kwargs\n",
        "\n",
        "        def _expand_dict_for_generation(dict_to_expand):\n",
        "            for key in dict_to_expand:\n",
        "                if (\n",
        "                    key != \"cache_position\"\n",
        "                    and dict_to_expand[key] is not None\n",
        "                    and isinstance(dict_to_expand[key], torch.Tensor)\n",
        "                ):\n",
        "                    dict_to_expand[key] = dict_to_expand[key].repeat_interleave(expand_size, dim=0)\n",
        "            return dict_to_expand\n",
        "\n",
        "        if input_ids is not None:\n",
        "            input_ids = input_ids.repeat_interleave(expand_size, dim=0)\n",
        "\n",
        "        model_kwargs = _expand_dict_for_generation(model_kwargs)\n",
        "\n",
        "        if is_encoder_decoder:\n",
        "            if model_kwargs.get(\"encoder_outputs\") is None:\n",
        "                raise ValueError(\"If `is_encoder_decoder` is True, make sure that `encoder_outputs` is defined.\")\n",
        "            model_kwargs[\"encoder_outputs\"] = _expand_dict_for_generation(model_kwargs[\"encoder_outputs\"])\n",
        "\n",
        "        return input_ids, model_kwargs\n",
        "\n",
        "    def _update_model_kwargs_for_generation(\n",
        "        self,\n",
        "        outputs: ModelOutput,\n",
        "        model_kwargs: dict[str, Any],\n",
        "        is_encoder_decoder: bool = False,\n",
        "        num_new_tokens: int = 1,\n",
        "    ) -> dict[str, Any]:\n",
        "        # update past_key_values keeping its naming used in model code\n",
        "        for possible_cache_name in ALL_CACHE_NAMES:\n",
        "            if possible_cache_name in outputs:\n",
        "                # TODO (joao): remove output/input mismatch when these old models (xlnet, reformer) are deprecated\n",
        "                if possible_cache_name in (\"past_buckets_states\", \"mems\"):\n",
        "                    cache_name = \"past_key_values\"\n",
        "                else:\n",
        "                    cache_name = possible_cache_name\n",
        "                model_kwargs[cache_name] = getattr(outputs, possible_cache_name)\n",
        "                break\n",
        "\n",
        "        # update token_type_ids with last value\n",
        "        if \"token_type_ids\" in model_kwargs:\n",
        "            token_type_ids = model_kwargs[\"token_type_ids\"]\n",
        "            model_kwargs[\"token_type_ids\"] = torch.cat([token_type_ids, token_type_ids[:, -1].unsqueeze(-1)], dim=-1)\n",
        "\n",
        "        if not is_encoder_decoder:\n",
        "            # update attention mask\n",
        "            if \"attention_mask\" in model_kwargs:\n",
        "                attention_mask = model_kwargs[\"attention_mask\"]\n",
        "                model_kwargs[\"attention_mask\"] = torch.cat(\n",
        "                    [attention_mask, attention_mask.new_ones((attention_mask.shape[0], 1))], dim=-1\n",
        "                )\n",
        "        else:\n",
        "            # update decoder attention mask\n",
        "            if \"decoder_attention_mask\" in model_kwargs:\n",
        "                decoder_attention_mask = model_kwargs[\"decoder_attention_mask\"]\n",
        "                model_kwargs[\"decoder_attention_mask\"] = torch.cat(\n",
        "                    [decoder_attention_mask, decoder_attention_mask.new_ones((decoder_attention_mask.shape[0], 1))],\n",
        "                    dim=-1,\n",
        "                )\n",
        "\n",
        "        if model_kwargs.get(\"use_cache\", True):\n",
        "            model_kwargs[\"cache_position\"] = model_kwargs[\"cache_position\"][-1:] + num_new_tokens\n",
        "        else:\n",
        "            past_positions = model_kwargs.pop(\"cache_position\")\n",
        "            new_positions = torch.arange(\n",
        "                past_positions[-1] + 1, past_positions[-1] + num_new_tokens + 1, dtype=past_positions.dtype\n",
        "            ).to(past_positions.device)\n",
        "            model_kwargs[\"cache_position\"] = torch.cat((past_positions, new_positions))\n",
        "        return model_kwargs\n",
        "\n",
        "    def _get_candidate_generator(\n",
        "        self,\n",
        "        generation_config: GenerationConfig,\n",
        "        input_ids: torch.LongTensor,\n",
        "        inputs_tensor: torch.Tensor,\n",
        "        assistant_model: \"PreTrainedModel\",\n",
        "        logits_processor: LogitsProcessorList,\n",
        "        target_tokenizer: \"PreTrainedTokenizerBase\",\n",
        "        assistant_tokenizer: \"PreTrainedTokenizerBase\",\n",
        "        model_kwargs: dict,\n",
        "    ) -> CandidateGenerator:\n",
        "        \"\"\"\n",
        "        Returns the candidate generator to be used in `assisted_generation`\n",
        "        \"\"\"\n",
        "        different_tokenizers = all(v is not None for v in (assistant_model, target_tokenizer, assistant_tokenizer))\n",
        "\n",
        "        if generation_config.assistant_early_exit is not None:\n",
        "            candidate_generator = EarlyExitCandidateGenerator(\n",
        "                input_ids=input_ids,\n",
        "                assistant_model=self,\n",
        "                generation_config=generation_config,\n",
        "                model_kwargs=model_kwargs,\n",
        "                inputs_tensor=inputs_tensor,\n",
        "                logits_processor=logits_processor,\n",
        "            )\n",
        "        elif generation_config.prompt_lookup_num_tokens is not None:\n",
        "            candidate_generator = PromptLookupCandidateGenerator(\n",
        "                eos_token_id=generation_config._eos_token_tensor,\n",
        "                num_output_tokens=generation_config.prompt_lookup_num_tokens,\n",
        "                max_matching_ngram_size=generation_config.max_matching_ngram_size,\n",
        "                max_length=generation_config.max_length,\n",
        "            )\n",
        "        elif different_tokenizers:\n",
        "            if generation_config.do_sample is True:\n",
        "                atm_translator = AssistantVocabTranslatorCache.get_translator(\n",
        "                    target_tokenizer,\n",
        "                    assistant_tokenizer,\n",
        "                    self.config.get_text_config().vocab_size,\n",
        "                    assistant_model=assistant_model,\n",
        "                    assistant_prune_lm_head=True,  # prune LM head of assistant model\n",
        "                )\n",
        "                # Since we prune the LM head, we cannot use the repetition penalty on the assistant model due to mismatches between token ids and logits index\n",
        "                assistant_model.generation_config.repetition_penalty = None\n",
        "                candidate_generator = UniversalSpeculativeDecodingGenerator(\n",
        "                    input_ids=input_ids,\n",
        "                    assistant_model=assistant_model,\n",
        "                    generation_config=generation_config,\n",
        "                    model_kwargs=model_kwargs,\n",
        "                    inputs_tensor=inputs_tensor,\n",
        "                    logits_processor=logits_processor,\n",
        "                    target_tokenizer=target_tokenizer,\n",
        "                    assistant_tokenizer=assistant_tokenizer,\n",
        "                    atm_translator=atm_translator,\n",
        "                )\n",
        "            elif generation_config.do_sample is False:\n",
        "                candidate_generator = AssistedCandidateGeneratorDifferentTokenizers(\n",
        "                    input_ids=input_ids,\n",
        "                    assistant_model=assistant_model,\n",
        "                    generation_config=generation_config,\n",
        "                    model_kwargs=model_kwargs,\n",
        "                    inputs_tensor=inputs_tensor,\n",
        "                    logits_processor=logits_processor,\n",
        "                    target_tokenizer=target_tokenizer,\n",
        "                    assistant_tokenizer=assistant_tokenizer,\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    f\"Invalid value for `do_sample`: expected a boolean, got {type(generation_config.do_sample).__name__}\"\n",
        "                )\n",
        "        else:\n",
        "            candidate_generator = AssistedCandidateGenerator(\n",
        "                input_ids=input_ids,\n",
        "                assistant_model=assistant_model,\n",
        "                generation_config=generation_config,\n",
        "                model_kwargs=model_kwargs,\n",
        "                inputs_tensor=inputs_tensor,\n",
        "                logits_processor=logits_processor,\n",
        "            )\n",
        "        return candidate_generator\n",
        "\n",
        "    def _get_logits_processor(\n",
        "        self,\n",
        "        generation_config: GenerationConfig,\n",
        "        input_ids_seq_length: Optional[int] = None,\n",
        "        encoder_input_ids: torch.LongTensor = None,\n",
        "        prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], list[int]]] = None,\n",
        "        logits_processor: Optional[LogitsProcessorList] = None,\n",
        "        device: Optional[str] = None,\n",
        "        model_kwargs: Optional[dict[str, Any]] = None,\n",
        "        negative_prompt_ids: Optional[torch.Tensor] = None,\n",
        "        negative_prompt_attention_mask: Optional[torch.Tensor] = None,\n",
        "    ) -> LogitsProcessorList:\n",
        "        \"\"\"\n",
        "        This class returns a [`LogitsProcessorList`] list object that contains all relevant [`LogitsProcessor`]\n",
        "        instances used to modify the scores of the language model head.\n",
        "        \"\"\"\n",
        "        # instantiate processors list\n",
        "        processors = LogitsProcessorList()\n",
        "        if logits_processor is None:\n",
        "            logits_processor = []\n",
        "\n",
        "        if generation_config.guidance_scale is not None and generation_config.guidance_scale != 1:\n",
        "            processors.append(\n",
        "                UnbatchedClassifierFreeGuidanceLogitsProcessor(\n",
        "                    generation_config.guidance_scale,\n",
        "                    self,\n",
        "                    unconditional_ids=negative_prompt_ids,\n",
        "                    unconditional_attention_mask=negative_prompt_attention_mask,\n",
        "                    use_cache=generation_config.use_cache,\n",
        "                )\n",
        "            )\n",
        "        if generation_config.sequence_bias is not None:\n",
        "            processors.append(SequenceBiasLogitsProcessor(sequence_bias=generation_config.sequence_bias))\n",
        "\n",
        "        if generation_config.diversity_penalty is not None and generation_config.diversity_penalty > 0.0:\n",
        "            processors.append(\n",
        "                HammingDiversityLogitsProcessor(\n",
        "                    diversity_penalty=generation_config.diversity_penalty,\n",
        "                    num_beams=generation_config.num_beams,\n",
        "                    num_beam_groups=generation_config.num_beam_groups,\n",
        "                )\n",
        "            )\n",
        "        if (\n",
        "            generation_config.encoder_repetition_penalty is not None\n",
        "            and generation_config.encoder_repetition_penalty != 1.0\n",
        "        ):\n",
        "            if len(encoder_input_ids.shape) == 2:\n",
        "                processors.append(\n",
        "                    EncoderRepetitionPenaltyLogitsProcessor(\n",
        "                        penalty=generation_config.encoder_repetition_penalty,\n",
        "                        encoder_input_ids=encoder_input_ids,\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                warnings.warn(\n",
        "                    \"Passing `encoder_repetition_penalty` requires some form of `input_ids` to be passed to \"\n",
        "                    \"`generate`, ignoring the argument.\",\n",
        "                    UserWarning,\n",
        "                )\n",
        "        if generation_config.repetition_penalty is not None and generation_config.repetition_penalty != 1.0:\n",
        "            processors.append(RepetitionPenaltyLogitsProcessor(penalty=generation_config.repetition_penalty))\n",
        "        if generation_config.no_repeat_ngram_size is not None and generation_config.no_repeat_ngram_size > 0:\n",
        "            processors.append(NoRepeatNGramLogitsProcessor(generation_config.no_repeat_ngram_size))\n",
        "        if (\n",
        "            generation_config.encoder_no_repeat_ngram_size is not None\n",
        "            and generation_config.encoder_no_repeat_ngram_size > 0\n",
        "        ):\n",
        "            if len(encoder_input_ids.shape) == 2:\n",
        "                processors.append(\n",
        "                    EncoderNoRepeatNGramLogitsProcessor(\n",
        "                        generation_config.encoder_no_repeat_ngram_size,\n",
        "                        encoder_input_ids,\n",
        "                    )\n",
        "                )\n",
        "            else:\n",
        "                warnings.warn(\n",
        "                    \"Passing `encoder_no_repeat_ngram_size` requires some form of `input_ids` to be passed to \"\n",
        "                    \"`generate`, ignoring the argument.\",\n",
        "                    UserWarning,\n",
        "                )\n",
        "        if generation_config.bad_words_ids is not None:\n",
        "            processors.append(\n",
        "                NoBadWordsLogitsProcessor(\n",
        "                    generation_config.bad_words_ids,\n",
        "                    generation_config._eos_token_tensor,\n",
        "                )\n",
        "            )\n",
        "        if (\n",
        "            generation_config.min_length is not None\n",
        "            and getattr(generation_config, \"_eos_token_tensor\", None) is not None\n",
        "            and generation_config.min_length > 0\n",
        "        ):\n",
        "            processors.append(\n",
        "                MinLengthLogitsProcessor(\n",
        "                    generation_config.min_length,\n",
        "                    generation_config._eos_token_tensor,\n",
        "                    device=device,\n",
        "                )\n",
        "            )\n",
        "        if (\n",
        "            generation_config.min_new_tokens is not None\n",
        "            and getattr(generation_config, \"_eos_token_tensor\", None) is not None\n",
        "            and generation_config.min_new_tokens > 0\n",
        "        ):\n",
        "            processors.append(\n",
        "                MinNewTokensLengthLogitsProcessor(\n",
        "                    input_ids_seq_length,\n",
        "                    generation_config.min_new_tokens,\n",
        "                    generation_config._eos_token_tensor,\n",
        "                    device=device,\n",
        "                )\n",
        "            )\n",
        "        if prefix_allowed_tokens_fn is not None:\n",
        "            processors.append(\n",
        "                PrefixConstrainedLogitsProcessor(\n",
        "                    prefix_allowed_tokens_fn,\n",
        "                    generation_config.num_beams // generation_config.num_beam_groups,\n",
        "                )\n",
        "            )\n",
        "        if generation_config.forced_bos_token_id is not None:\n",
        "            processors.append(\n",
        "                ForcedBOSTokenLogitsProcessor(\n",
        "                    generation_config.forced_bos_token_id,\n",
        "                )\n",
        "            )\n",
        "        if generation_config.forced_eos_token_id is not None:\n",
        "            processors.append(\n",
        "                ForcedEOSTokenLogitsProcessor(\n",
        "                    generation_config.max_length,\n",
        "                    generation_config.forced_eos_token_id,\n",
        "                    device=device,\n",
        "                )\n",
        "            )\n",
        "        if generation_config.remove_invalid_values is True:\n",
        "            processors.append(InfNanRemoveLogitsProcessor())\n",
        "        if generation_config.exponential_decay_length_penalty is not None:\n",
        "            processors.append(\n",
        "                ExponentialDecayLengthPenalty(\n",
        "                    generation_config.exponential_decay_length_penalty,\n",
        "                    generation_config._eos_token_tensor,\n",
        "                    input_ids_seq_length,\n",
        "                )\n",
        "            )\n",
        "        if generation_config.suppress_tokens is not None:\n",
        "            processors.append(\n",
        "                SuppressTokensLogitsProcessor(\n",
        "                    generation_config.suppress_tokens,\n",
        "                    device=device,\n",
        "                )\n",
        "            )\n",
        "        if generation_config.begin_suppress_tokens is not None:\n",
        "            begin_index = input_ids_seq_length\n",
        "            begin_index = (\n",
        "                begin_index\n",
        "                if (input_ids_seq_length > 1 or generation_config.forced_bos_token_id is None)\n",
        "                else begin_index + 1\n",
        "            )\n",
        "            processors.append(\n",
        "                SuppressTokensAtBeginLogitsProcessor(\n",
        "                    generation_config.begin_suppress_tokens,\n",
        "                    begin_index,\n",
        "                    device=device,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # TODO (joao): find a strategy to specify the order of the processors\n",
        "        processors = self._merge_criteria_processor_list(processors, logits_processor)\n",
        "\n",
        "        # Processors previously known as `LogitsWarpers`, only applied with sampling strategies\n",
        "        if generation_config.do_sample:\n",
        "            # In beam methods, we need to keep at least one non-eos token to explore continuations that might have a\n",
        "            # better score (i.e. keep len(list(generation_config._eos_token_tensor)) + 1)\n",
        "            if generation_config.num_beams > 1:\n",
        "                if isinstance(generation_config._eos_token_tensor, list):\n",
        "                    min_tokens_to_keep = len(generation_config._eos_token_tensor) + 1\n",
        "                elif isinstance(generation_config._eos_token_tensor, torch.Tensor):\n",
        "                    min_tokens_to_keep = generation_config._eos_token_tensor.shape[0] + 1\n",
        "                else:\n",
        "                    min_tokens_to_keep = 2\n",
        "            else:\n",
        "                min_tokens_to_keep = 1\n",
        "\n",
        "            # the following idea is largely copied from this PR: https://github.com/huggingface/transformers/pull/5420/files\n",
        "            # all samplers can be found in `generation_utils_samplers.py`\n",
        "            if generation_config.temperature is not None and generation_config.temperature != 1.0:\n",
        "                processors.append(TemperatureLogitsWarper(generation_config.temperature))\n",
        "            if generation_config.top_k is not None and generation_config.top_k != 0:\n",
        "                processors.append(\n",
        "                    TopKLogitsWarper(top_k=generation_config.top_k, min_tokens_to_keep=min_tokens_to_keep)\n",
        "                )\n",
        "            if generation_config.top_p is not None and generation_config.top_p < 1.0:\n",
        "                processors.append(\n",
        "                    TopPLogitsWarper(top_p=generation_config.top_p, min_tokens_to_keep=min_tokens_to_keep)\n",
        "                )\n",
        "            if generation_config.min_p is not None:\n",
        "                # Applied after temperature scaling (see https://github.com/ggerganov/llama.cpp/pull/3841#issuecomment-2073826084)\n",
        "                processors.append(\n",
        "                    MinPLogitsWarper(min_p=generation_config.min_p, min_tokens_to_keep=min_tokens_to_keep)\n",
        "                )\n",
        "            if generation_config.typical_p is not None and generation_config.typical_p < 1.0:\n",
        "                processors.append(\n",
        "                    TypicalLogitsWarper(mass=generation_config.typical_p, min_tokens_to_keep=min_tokens_to_keep)\n",
        "                )\n",
        "            if generation_config.epsilon_cutoff is not None and 0.0 < generation_config.epsilon_cutoff < 1.0:\n",
        "                processors.append(\n",
        "                    EpsilonLogitsWarper(\n",
        "                        epsilon=generation_config.epsilon_cutoff, min_tokens_to_keep=min_tokens_to_keep\n",
        "                    )\n",
        "                )\n",
        "            if generation_config.eta_cutoff is not None and 0.0 < generation_config.eta_cutoff < 1.0:\n",
        "                processors.append(\n",
        "                    EtaLogitsWarper(\n",
        "                        epsilon=generation_config.eta_cutoff, min_tokens_to_keep=min_tokens_to_keep, device=device\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        # Watermarking should be after all logits processing is finished (see #34630)\n",
        "        if generation_config.watermarking_config is not None:\n",
        "            processors.append(\n",
        "                generation_config.watermarking_config.construct_processor(\n",
        "                    self.config.get_text_config().vocab_size, device\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # `LogitNormalization` should always be the last logit processor, when present\n",
        "        if generation_config.renormalize_logits is True:\n",
        "            processors.append(LogitNormalization())\n",
        "        return processors\n",
        "\n",
        "    def _get_stopping_criteria(\n",
        "        self,\n",
        "        generation_config: GenerationConfig,\n",
        "        stopping_criteria: Optional[StoppingCriteriaList],\n",
        "        tokenizer: Optional[\"PreTrainedTokenizerBase\"] = None,\n",
        "        **kwargs,\n",
        "    ) -> StoppingCriteriaList:\n",
        "        criteria = StoppingCriteriaList()\n",
        "        if generation_config.max_length is not None:\n",
        "            max_position_embeddings = getattr(self.config, \"max_position_embeddings\", None)\n",
        "            criteria.append(\n",
        "                MaxLengthCriteria(\n",
        "                    max_length=generation_config.max_length,\n",
        "                    max_position_embeddings=max_position_embeddings,\n",
        "                )\n",
        "            )\n",
        "        if generation_config.max_time is not None:\n",
        "            criteria.append(MaxTimeCriteria(max_time=generation_config.max_time))\n",
        "        if generation_config.stop_strings is not None:\n",
        "            if tokenizer is None:\n",
        "                raise ValueError(\n",
        "                    \"There are one or more stop strings, either in the arguments to `generate` or in the \"\n",
        "                    \"model's generation config, but we could not locate a tokenizer. When generating with \"\n",
        "                    \"stop strings, you must pass the model's tokenizer to the `tokenizer` argument of `generate`.\"\n",
        "                )\n",
        "            criteria.append(StopStringCriteria(stop_strings=generation_config.stop_strings, tokenizer=tokenizer))\n",
        "        if generation_config._eos_token_tensor is not None:\n",
        "            criteria.append(EosTokenCriteria(eos_token_id=generation_config._eos_token_tensor))\n",
        "        if (\n",
        "            generation_config.is_assistant\n",
        "            and generation_config.assistant_confidence_threshold is not None\n",
        "            and generation_config.assistant_confidence_threshold > 0\n",
        "        ):\n",
        "            criteria.append(\n",
        "                ConfidenceCriteria(assistant_confidence_threshold=generation_config.assistant_confidence_threshold)\n",
        "            )\n",
        "        criteria = self._merge_criteria_processor_list(criteria, stopping_criteria)\n",
        "        return criteria\n",
        "\n",
        "    def _merge_criteria_processor_list(\n",
        "        self,\n",
        "        default_list: Union[LogitsProcessorList, StoppingCriteriaList],\n",
        "        custom_list: Union[LogitsProcessorList, StoppingCriteriaList],\n",
        "    ) -> Union[LogitsProcessorList, StoppingCriteriaList]:\n",
        "        \"\"\"\n",
        "        Merge user-defined processors/criteria with the ones instantiated inside `generate`. In case the same\n",
        "        processor/criteria is present on both lists, use the user-defined one.\n",
        "\n",
        "        (Note: up to v4.49.0, this function threw an exception is the same logit processor was found twice.)\n",
        "        \"\"\"\n",
        "        if len(custom_list) == 0:\n",
        "            return default_list\n",
        "\n",
        "        final_list = type(default_list)()\n",
        "        for default in default_list:\n",
        "            using_custom = False\n",
        "            for custom in custom_list:\n",
        "                if type(custom) is type(default):\n",
        "                    object_type = \"stopping criteria\" if isinstance(custom, StoppingCriteria) else \"logits processor\"\n",
        "                    logger.warning_once(\n",
        "                        f\"A custom {object_type} of type {type(custom)} has been passed to `.generate()`, but it \"\n",
        "                        f\"was also created in `.generate()`, given its parameterization. The custom {type(custom)} \"\n",
        "                        f\"will take precedence. Please check the docstring of {type(custom)} to see related \"\n",
        "                        \"`.generate()` flags.\"\n",
        "                    )\n",
        "                    final_list.append(custom)\n",
        "                    using_custom = True\n",
        "                    break\n",
        "            if not using_custom:\n",
        "                final_list.append(default)\n",
        "\n",
        "        for custom in custom_list:\n",
        "            if custom not in final_list:\n",
        "                final_list.append(custom)\n",
        "        return final_list\n",
        "\n",
        "    def compute_transition_scores(\n",
        "        self,\n",
        "        sequences: torch.Tensor,\n",
        "        scores: tuple[torch.Tensor],\n",
        "        beam_indices: Optional[torch.Tensor] = None,\n",
        "        normalize_logits: bool = False,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Computes the transition scores of sequences given the generation scores (and beam indices, if beam search was\n",
        "        used). This is a convenient method to quickly obtain the scores of the selected tokens at generation time.\n",
        "\n",
        "        Parameters:\n",
        "            sequences (`torch.LongTensor`):\n",
        "                The generated sequences. The second dimension (sequence_length) is either equal to `max_length` or\n",
        "                shorter if all batches finished early due to the `eos_token_id`.\n",
        "            scores (`tuple(torch.FloatTensor)`):\n",
        "                Transition scores for each vocabulary token at each generation step. Beam transition scores consisting\n",
        "                of log probabilities of tokens conditioned on log softmax of previously generated tokens in this beam.\n",
        "                Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for each generated token),\n",
        "                with each tensor of shape `(batch_size*num_beams, config.vocab_size)`.\n",
        "            beam_indices (`torch.LongTensor`, *optional*):\n",
        "                Beam indices of generated token id at each generation step. `torch.LongTensor` of shape\n",
        "                `(batch_size*num_return_sequences, sequence_length)`. Only required if a `num_beams>1` at\n",
        "                generate-time.\n",
        "            normalize_logits (`bool`, *optional*, defaults to `False`):\n",
        "                Whether to normalize the logits (which, for legacy reasons, may be unnormalized).\n",
        "\n",
        "        Return:\n",
        "            `torch.Tensor`: A `torch.Tensor` of shape `(batch_size*num_return_sequences, sequence_length)` containing\n",
        "                the transition scores (logits)\n",
        "\n",
        "        Examples:\n",
        "\n",
        "        ```python\n",
        "        >>> from transformers import GPT2Tokenizer, AutoModelForCausalLM\n",
        "        >>> import numpy as np\n",
        "\n",
        "        >>> tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "        >>> model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
        "        >>> tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "        >>> inputs = tokenizer([\"Today is\"], return_tensors=\"pt\")\n",
        "\n",
        "        >>> # Example 1: Print the scores for each token generated with Greedy Search\n",
        "        >>> outputs = model.generate(**inputs, max_new_tokens=5, return_dict_in_generate=True, output_scores=True)\n",
        "        >>> transition_scores = model.compute_transition_scores(\n",
        "        ...     outputs.sequences, outputs.scores, normalize_logits=True\n",
        "        ... )\n",
        "        >>> # input_length is the length of the input prompt for decoder-only models, like the GPT family, and 1 for\n",
        "        >>> # encoder-decoder models, like BART or T5.\n",
        "        >>> input_length = 1 if model.config.is_encoder_decoder else inputs.input_ids.shape[1]\n",
        "        >>> generated_tokens = outputs.sequences[:, input_length:]\n",
        "        >>> for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
        "        ...     # | token | token string | log probability | probability\n",
        "        ...     print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.numpy():.3f} | {np.exp(score.numpy()):.2%}\")\n",
        "        |   262 |  the     | -1.414 | 24.33%\n",
        "        |  1110 |  day     | -2.609 | 7.36%\n",
        "        |   618 |  when    | -2.010 | 13.40%\n",
        "        |   356 |  we      | -1.859 | 15.58%\n",
        "        |   460 |  can     | -2.508 | 8.14%\n",
        "\n",
        "        >>> # Example 2: Reconstruct the sequence scores from Beam Search\n",
        "        >>> outputs = model.generate(\n",
        "        ...     **inputs,\n",
        "        ...     max_new_tokens=5,\n",
        "        ...     num_beams=4,\n",
        "        ...     num_return_sequences=4,\n",
        "        ...     return_dict_in_generate=True,\n",
        "        ...     output_scores=True,\n",
        "        ... )\n",
        "        >>> transition_scores = model.compute_transition_scores(\n",
        "        ...     outputs.sequences, outputs.scores, outputs.beam_indices, normalize_logits=False\n",
        "        ... )\n",
        "        >>> # If you sum the generated tokens' scores and apply the length penalty, you'll get the sequence scores.\n",
        "        >>> # Tip 1: recomputing the scores is only guaranteed to match with `normalize_logits=False`. Depending on the\n",
        "        >>> # use case, you might want to recompute it with `normalize_logits=True`.\n",
        "        >>> # Tip 2: the output length does NOT include the input length\n",
        "        >>> output_length = np.sum(transition_scores.numpy() < 0, axis=1)\n",
        "        >>> length_penalty = model.generation_config.length_penalty\n",
        "        >>> reconstructed_scores = transition_scores.sum(axis=1) / (output_length**length_penalty)\n",
        "        >>> print(np.allclose(outputs.sequences_scores, reconstructed_scores))\n",
        "        True\n",
        "        ```\"\"\"\n",
        "        # 1. In absence of `beam_indices`, we can assume that we come from e.g. greedy search, which is equivalent\n",
        "        # to a beam search approach were the first (and only) beam is always selected\n",
        "        if beam_indices is None:\n",
        "            beam_indices = torch.arange(scores[0].shape[0]).view(-1, 1).to(sequences.device)\n",
        "            beam_indices = beam_indices.expand(-1, len(scores))\n",
        "\n",
        "        # 2. reshape scores as [batch_size*vocab_size, # generation steps] with # generation steps being\n",
        "        # seq_len - input_length\n",
        "        scores = torch.stack(scores).reshape(len(scores), -1).transpose(0, 1)\n",
        "\n",
        "        # 3. Optionally normalize the logits (across the vocab dimension)\n",
        "        if normalize_logits:\n",
        "            scores = scores.reshape(-1, self.config.get_text_config().vocab_size, scores.shape[-1])\n",
        "            scores = torch.nn.functional.log_softmax(scores, dim=1)\n",
        "            scores = scores.reshape(-1, scores.shape[-1])\n",
        "\n",
        "        # 4. cut beam_indices to longest beam length\n",
        "        beam_indices_mask = beam_indices < 0\n",
        "        max_beam_length = (1 - beam_indices_mask.long()).sum(-1).max()\n",
        "        beam_indices = beam_indices.clone()[:, :max_beam_length]\n",
        "        beam_indices_mask = beam_indices_mask[:, :max_beam_length]\n",
        "\n",
        "        # 5. Set indices of beams that finished early to 0; such indices will be masked correctly afterwards\n",
        "        beam_indices[beam_indices_mask] = 0\n",
        "\n",
        "        # 6. multiply beam_indices with vocab size to gather correctly from scores\n",
        "        beam_sequence_indices = beam_indices * self.config.get_text_config().vocab_size\n",
        "\n",
        "        # 7. Define which indices contributed to scores\n",
        "        cut_idx = sequences.shape[-1] - max_beam_length\n",
        "        indices = sequences[:, cut_idx:] + beam_sequence_indices\n",
        "\n",
        "        # 8. Compute scores\n",
        "        transition_scores = scores.gather(0, indices)\n",
        "\n",
        "        # 9. Mask out transition_scores of beams that stopped early\n",
        "        transition_scores[beam_indices_mask] = 0\n",
        "\n",
        "        return transition_scores\n",
        "\n",
        "    def _validate_assistant(self, assistant_model, tokenizer, assistant_tokenizer):\n",
        "        if assistant_model is None:\n",
        "            return\n",
        "\n",
        "        if self.config.is_encoder_decoder and not assistant_model.config.is_encoder_decoder:\n",
        "            attributes_to_check = [\"encoder_attention_heads\", \"encoder_ffn_dim\", \"encoder_layers\"]\n",
        "            attributes_to_check = [attr for attr in dir(assistant_model.config) if attr in attributes_to_check]\n",
        "            are_equal = all(\n",
        "                getattr(self.config, attr) == getattr(assistant_model.config, attr) for attr in attributes_to_check\n",
        "            )\n",
        "            if not are_equal:\n",
        "                raise ValueError(\n",
        "                    \"The main model and the assistant don't have compatible encoder-dependent input shapes. \"\n",
        "                    \"Ensure you load the assistant with the correct encoder-decoder class, e.g. `AutoModelForSpeechSeq2Seq` for Whisper.\"\n",
        "                )\n",
        "\n",
        "        doc_reference = (\n",
        "            \"(see https://huggingface.co/docs/transformers/en/generation_strategies#universal-assisted-decoding)\"\n",
        "        )\n",
        "        if self.config.get_text_config().vocab_size == assistant_model.config.get_text_config().vocab_size:\n",
        "            if assistant_tokenizer is not None:\n",
        "                raise ValueError(\n",
        "                    f\"`assistant_tokenizer` is not required when the main and assistant models use the same tokenizer. Please omit `assistant_tokenizer` from `generate()` {doc_reference}.\"\n",
        "                )\n",
        "        else:\n",
        "            if tokenizer is None or assistant_tokenizer is None:\n",
        "                raise ValueError(\n",
        "                    f\"The main and assistant models have different tokenizers. Please provide `tokenizer` and `assistant_tokenizer` to `generate()` {doc_reference}.\"\n",
        "                )\n",
        "\n",
        "    def _validate_model_kwargs(self, model_kwargs: dict[str, Any]):\n",
        "        \"\"\"Validates model kwargs for generation. Generate argument typos will also be caught here.\"\"\"\n",
        "        # Excludes arguments that are handled before calling any model function\n",
        "        if self.config.is_encoder_decoder:\n",
        "            for key in [\"decoder_input_ids\"]:\n",
        "                model_kwargs.pop(key, None)\n",
        "\n",
        "        unused_model_args = []\n",
        "        model_args = set(inspect.signature(self.prepare_inputs_for_generation).parameters)\n",
        "        # `kwargs`/`model_kwargs` is often used to handle optional forward pass inputs like `attention_mask`. If\n",
        "        # `prepare_inputs_for_generation` doesn't accept them, then a stricter check can be made ;)\n",
        "        if \"kwargs\" in model_args or \"model_kwargs\" in model_args:\n",
        "            model_args |= set(inspect.signature(self.forward).parameters)\n",
        "\n",
        "        # Encoder-Decoder models may also need Encoder arguments from `model_kwargs`\n",
        "        if self.config.is_encoder_decoder:\n",
        "            base_model = getattr(self, self.base_model_prefix, None)\n",
        "\n",
        "            # allow encoder kwargs\n",
        "            encoder = getattr(self, \"encoder\", None)\n",
        "            # `MusicgenForConditionalGeneration` has `text_encoder` and `audio_encoder`.\n",
        "            # Also, it has `base_model_prefix = \"encoder_decoder\"` but there is no `self.encoder_decoder`\n",
        "            # TODO: A better way to handle this.\n",
        "            if encoder is None and base_model is not None:\n",
        "                encoder = getattr(base_model, \"encoder\", None)\n",
        "\n",
        "            if encoder is not None:\n",
        "                encoder_model_args = set(inspect.signature(encoder.forward).parameters)\n",
        "                model_args |= encoder_model_args\n",
        "\n",
        "            # allow decoder kwargs\n",
        "            decoder = getattr(self, \"decoder\", None)\n",
        "            if decoder is None and base_model is not None:\n",
        "                decoder = getattr(base_model, \"decoder\", None)\n",
        "\n",
        "            if decoder is not None:\n",
        "                decoder_model_args = set(inspect.signature(decoder.forward).parameters)\n",
        "                model_args |= {f\"decoder_{x}\" for x in decoder_model_args}\n",
        "\n",
        "        for key, value in model_kwargs.items():\n",
        "            if value is not None and key not in model_args:\n",
        "                unused_model_args.append(key)\n",
        "\n",
        "        if unused_model_args:\n",
        "            raise ValueError(\n",
        "                f\"The following `model_kwargs` are not used by the model: {unused_model_args} (note: typos in the\"\n",
        "                \" generate arguments will also show up in this list)\"\n",
        "            )\n",
        "\n",
        "    def _validate_generated_length(self, generation_config, input_ids_length, has_default_max_length):\n",
        "        \"\"\"Performs validation related to the resulting generated length\"\"\"\n",
        "        # 1. Max length warnings related to poor parameterization\n",
        "        if has_default_max_length and generation_config.max_new_tokens is None and generation_config.max_length == 20:\n",
        "            # 20 is the default max_length of the generation config\n",
        "            warnings.warn(\n",
        "                f\"Using the model-agnostic default `max_length` (={generation_config.max_length}) to control the \"\n",
        "                \"generation length. We recommend setting `max_new_tokens` to control the maximum length of the \"\n",
        "                \"generation.\",\n",
        "                UserWarning,\n",
        "            )\n",
        "        if input_ids_length >= generation_config.max_length:\n",
        "            input_ids_string = \"decoder_input_ids\" if self.config.is_encoder_decoder else \"input_ids\"\n",
        "            raise ValueError(\n",
        "                f\"Input length of {input_ids_string} is {input_ids_length}, but `max_length` is set to\"\n",
        "                f\" {generation_config.max_length}. This can lead to unexpected behavior. You should consider\"\n",
        "                \" increasing `max_length` or, better yet, setting `max_new_tokens`.\"\n",
        "            )\n",
        "\n",
        "        # 2. Min length warnings due to unfeasible parameter combinations\n",
        "        min_length_error_suffix = (\n",
        "            \" Generation will stop at the defined maximum length. You should decrease the minimum length and/or \"\n",
        "            \"increase the maximum length.\"\n",
        "        )\n",
        "        if has_default_max_length:\n",
        "            min_length_error_suffix += (\n",
        "                f\" Note that `max_length` is set to {generation_config.max_length}, its default value.\"\n",
        "            )\n",
        "        if generation_config.min_length is not None and generation_config.min_length > generation_config.max_length:\n",
        "            warnings.warn(\n",
        "                f\"Unfeasible length constraints: `min_length` ({generation_config.min_length}) is larger than\"\n",
        "                f\" the maximum possible length ({generation_config.max_length}).\" + min_length_error_suffix,\n",
        "                UserWarning,\n",
        "            )\n",
        "        if generation_config.min_new_tokens is not None:\n",
        "            min_length = generation_config.min_new_tokens + input_ids_length\n",
        "            if min_length > generation_config.max_length:\n",
        "                warnings.warn(\n",
        "                    f\"Unfeasible length constraints: `min_new_tokens` ({generation_config.min_new_tokens}), when \"\n",
        "                    f\"added to the prompt length ({input_ids_length}), is larger than\"\n",
        "                    f\" the maximum possible length ({generation_config.max_length}).\" + min_length_error_suffix,\n",
        "                    UserWarning,\n",
        "                )\n",
        "\n",
        "    def _prepare_generated_length(\n",
        "        self,\n",
        "        generation_config,\n",
        "        has_default_max_length,\n",
        "        has_default_min_length,\n",
        "        model_input_name,\n",
        "        input_ids_length,\n",
        "        inputs_tensor,\n",
        "    ):\n",
        "        \"\"\"Prepared max and min length in generation configs to avoid clashes between similar attributes\"\"\"\n",
        "\n",
        "        if generation_config.max_new_tokens is not None:\n",
        "            if not has_default_max_length and generation_config.max_length is not None:\n",
        "                logger.warning(\n",
        "                    f\"Both `max_new_tokens` (={generation_config.max_new_tokens}) and `max_length`(=\"\n",
        "                    f\"{generation_config.max_length}) seem to have been set. `max_new_tokens` will take precedence. \"\n",
        "                    \"Please refer to the documentation for more information. \"\n",
        "                    \"(https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\"\n",
        "                )\n",
        "            generation_config.max_length = generation_config.max_new_tokens + input_ids_length\n",
        "\n",
        "        # if both `inputs_embeds` and `input_ids` are passed, we do not correct the length\n",
        "        # otherwise we need total length [inputs-embeds-len + new-tokens-len] to not go beyond indicated `max_length``\n",
        "        elif (\n",
        "            model_input_name == \"inputs_embeds\"\n",
        "            and input_ids_length != inputs_tensor.shape[1]\n",
        "            and not self.config.is_encoder_decoder\n",
        "        ):\n",
        "            generation_config.max_length -= inputs_tensor.shape[1]\n",
        "        elif has_default_max_length:  # by default let's always generate 20 new tokens\n",
        "            if generation_config.max_length == GenerationConfig().max_length:\n",
        "                generation_config.max_length = generation_config.max_length + input_ids_length\n",
        "                max_position_embeddings = getattr(self.config, \"max_position_embeddings\", None)\n",
        "                if max_position_embeddings is not None:\n",
        "                    generation_config.max_length = min(generation_config.max_length, max_position_embeddings)\n",
        "\n",
        "        # same for min length\n",
        "        if generation_config.min_new_tokens is not None:\n",
        "            if not has_default_min_length:\n",
        "                logger.warning(\n",
        "                    f\"Both `min_new_tokens` (={generation_config.min_new_tokens}) and `min_length`(=\"\n",
        "                    f\"{generation_config.min_length}) seem to have been set. `min_new_tokens` will take precedence. \"\n",
        "                    \"Please refer to the documentation for more information. \"\n",
        "                    \"(https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\"\n",
        "                )\n",
        "            generation_config.min_length = generation_config.min_new_tokens + input_ids_length\n",
        "\n",
        "        elif (\n",
        "            model_input_name == \"inputs_embeds\"\n",
        "            and input_ids_length != inputs_tensor.shape[1]\n",
        "            and not self.config.is_encoder_decoder\n",
        "        ):\n",
        "            generation_config.min_length = max(generation_config.min_length - inputs_tensor.shape[1], 0)\n",
        "\n",
        "        return generation_config\n",
        "\n",
        "    def _prepare_generation_config(\n",
        "        self, generation_config: Optional[GenerationConfig], use_model_defaults: Optional[bool] = None, **kwargs: dict\n",
        "    ) -> tuple[GenerationConfig, dict]:\n",
        "        \"\"\"\n",
        "        Prepares the base generation config, then applies any generation configuration options from kwargs. This\n",
        "        function handles retrocompatibility with respect to configuration files.\n",
        "        \"\"\"\n",
        "        # parameterization priority:\n",
        "        # kwargs > non-global default values in `generation_config` > `model.generation_config` > GenerationConfig()\n",
        "        # TODO (joao): per-model generation config classes.\n",
        "\n",
        "        using_model_generation_config = False\n",
        "        if generation_config is None:\n",
        "            # legacy: users may modify the model configuration to control generation. To trigger this legacy behavior,\n",
        "            # the following conditions must be met\n",
        "            # 1) the generation config must have been created from the model config (`_from_model_config` field);\n",
        "            # 2) the generation config must have seen no modification since its creation (the hash is the same);\n",
        "            # 3) there are non-default generation parameters in the model config.\n",
        "            # 4) the user must have set new generation parameters in the model config.\n",
        "            if (\n",
        "                self.generation_config._from_model_config  # 1)\n",
        "                and self.generation_config._original_object_hash == hash(self.generation_config)  # 2)\n",
        "                and len(self.config._get_non_default_generation_parameters()) > 0  # 3)\n",
        "            ):\n",
        "                new_generation_config = GenerationConfig.from_model_config(self.config)\n",
        "                if new_generation_config != self.generation_config:  # 4)\n",
        "                    warnings.warn(\n",
        "                        \"You have modified the pretrained model configuration to control generation. This is a\"\n",
        "                        \" deprecated strategy to control generation and will be removed in v5.\"\n",
        "                        \" Please use and modify the model generation configuration (see\"\n",
        "                        \" https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\",\n",
        "                        UserWarning,\n",
        "                    )\n",
        "                    self.generation_config = new_generation_config\n",
        "\n",
        "            generation_config = self.generation_config\n",
        "            using_model_generation_config = True\n",
        "\n",
        "        # `torch.export.export` usually raises an exception if it is called\n",
        "        # with ``strict=True``. deepcopy can only be processed if ``strict=False``.\n",
        "        generation_config = copy.deepcopy(generation_config)\n",
        "\n",
        "        if not using_model_generation_config:\n",
        "            # If `generation_config` is provided:\n",
        "            # - `use_model_defaults`: let's fallback ALL default values to the model's generation config\n",
        "            # - otherwise: legacy behavior, let's just make sure we have the tokens defined\n",
        "            model_base_version = version.parse(version.parse(self.generation_config.transformers_version).base_version)\n",
        "            if use_model_defaults is True or (\n",
        "                use_model_defaults is None and model_base_version >= version.parse(\"4.50.0\")\n",
        "            ):\n",
        "                modified_values = {}\n",
        "                global_default_generation_config = GenerationConfig()\n",
        "                model_generation_config = self.generation_config\n",
        "                # we iterate over the model's generation config: it may hold custom keys, which we'll want to copy\n",
        "                for key, model_gen_config_value in model_generation_config.__dict__.items():\n",
        "                    if key.startswith(\"_\") or key == \"transformers_version\":  # metadata\n",
        "                        continue\n",
        "                    global_default_value = getattr(global_default_generation_config, key, None)\n",
        "                    custom_gen_config_value = getattr(generation_config, key, None)\n",
        "                    if (\n",
        "                        custom_gen_config_value == global_default_value\n",
        "                        and model_gen_config_value != global_default_value\n",
        "                    ):\n",
        "                        modified_values[key] = model_gen_config_value\n",
        "                        setattr(generation_config, key, model_gen_config_value)\n",
        "                # edge case: we may set `temperature=0.0` and `do_sample=False`, but the model defaults to\n",
        "                # `do_sample=True`\n",
        "                if generation_config.temperature == 0.0:\n",
        "                    generation_config.do_sample = False\n",
        "                if use_model_defaults is None and len(modified_values) > 0:\n",
        "                    logger.warning_once(\n",
        "                        f\"`generation_config` default values have been modified to match model-specific defaults: \"\n",
        "                        f\"{modified_values}. If this is not desired, please set these values explicitly.\"\n",
        "                    )\n",
        "            else:\n",
        "                if generation_config.bos_token_id is None:\n",
        "                    generation_config.bos_token_id = self.generation_config.bos_token_id\n",
        "                if generation_config.eos_token_id is None:\n",
        "                    generation_config.eos_token_id = self.generation_config.eos_token_id\n",
        "                if generation_config.pad_token_id is None:\n",
        "                    generation_config.pad_token_id = self.generation_config.pad_token_id\n",
        "                if generation_config.decoder_start_token_id is None:\n",
        "                    generation_config.decoder_start_token_id = self.generation_config.decoder_start_token_id\n",
        "\n",
        "        # Finally, apply any passed kwargs\n",
        "        model_kwargs = generation_config.update(**kwargs)\n",
        "\n",
        "        return generation_config, model_kwargs\n",
        "\n",
        "    def _get_initial_cache_position(self, seq_length, device, model_kwargs):\n",
        "        \"\"\"Calculates `cache_position` for the pre-fill stage based on `input_ids` and optionally past length\"\"\"\n",
        "        # `torch.compile`-friendly `torch.arange` from a shape -- the lines below are equivalent to `torch.arange`\n",
        "        if \"cache_position\" in model_kwargs and model_kwargs[\"cache_position\"] is not None:\n",
        "            return model_kwargs\n",
        "        if \"inputs_embeds\" in model_kwargs and not self.config.is_encoder_decoder:\n",
        "            cache_position = torch.ones_like(model_kwargs[\"inputs_embeds\"][0, :, 0], dtype=torch.int64).cumsum(0) - 1\n",
        "        elif \"decoder_inputs_embeds\" in model_kwargs and self.config.is_encoder_decoder:\n",
        "            cache_position = (\n",
        "                torch.ones_like(model_kwargs[\"decoder_inputs_embeds\"][0, :, 0], dtype=torch.int64).cumsum(0) - 1\n",
        "            )\n",
        "        else:\n",
        "            cache_position = torch.ones(seq_length, dtype=torch.int64, device=device).cumsum(0) - 1\n",
        "\n",
        "        past_length = 0\n",
        "        if model_kwargs.get(\"past_key_values\") is not None:\n",
        "            cache = model_kwargs[\"past_key_values\"]\n",
        "            past_length = 0\n",
        "            if not isinstance(cache, Cache):\n",
        "                past_length = cache[0][0].shape[2]\n",
        "            elif hasattr(cache, \"get_seq_length\") and cache.get_seq_length() is not None:\n",
        "                past_length = cache.get_seq_length()\n",
        "\n",
        "            cache_position = cache_position[past_length:]\n",
        "\n",
        "        model_kwargs[\"cache_position\"] = cache_position\n",
        "        return model_kwargs\n",
        "\n",
        "    def _get_layer_device_map_for_cache_init(self) -> Optional[dict[int, Union[str, int]]]:\n",
        "        \"\"\"\n",
        "        Returns the device map for each decoder layer, to allocate the cache on the right device.\n",
        "        Inspired from `dispatch_model` in accelerate.\n",
        "        \"\"\"\n",
        "        execution_device_map = None\n",
        "\n",
        "        if hasattr(self, \"hf_device_map\"):\n",
        "            if set(self.hf_device_map.values()) == {\"cpu\"} or set(self.hf_device_map.values()) == {\"cpu\", \"disk\"}:\n",
        "                main_device = \"cpu\"\n",
        "            else:\n",
        "                main_device = [d for d in self.hf_device_map.values() if d not in [\"cpu\", \"disk\"]][0]\n",
        "            execution_device_map = {\n",
        "                name: main_device if device in [\"cpu\", \"disk\"] else device\n",
        "                for name, device in self.hf_device_map.items()\n",
        "            }\n",
        "\n",
        "        # No `execution_device_map` -> rely on `self.device` to allocate the cache\n",
        "        if execution_device_map is None:\n",
        "            return None\n",
        "\n",
        "        # Single device for all layers\n",
        "        num_hidden_layers = self.config.get_text_config().num_hidden_layers\n",
        "        if len(execution_device_map) == 1 and \"\" in execution_device_map:\n",
        "            return dict.fromkeys(range(num_hidden_layers), execution_device_map[\"\"])\n",
        "\n",
        "        # Multiple devices in `execution_device_map` -> we need to map decoder layers to the correct device.\n",
        "        layer_device_map = {}\n",
        "        # Case 1: The model has a `get_decoder` method, we can use it to find the decoder name.\n",
        "        if hasattr(self, \"get_decoder\"):\n",
        "            decoder_name = None\n",
        "            for name, module in self.named_modules():\n",
        "                if module is self.get_decoder():\n",
        "                    decoder_name = name\n",
        "                    break\n",
        "            if decoder_name is None:\n",
        "                raise RuntimeError(\n",
        "                    \"`model.get_decoder()` is not returning a named module of the model. This is unexpected, please \"\n",
        "                    \"open an issue on GitHub.\"\n",
        "                )\n",
        "\n",
        "            decoder_mapped_modules = [\n",
        "                module_name for module_name in execution_device_map if decoder_name in module_name\n",
        "            ]\n",
        "            # The decoder name may be present in `execution_device_map` in two forms:\n",
        "            # a) each layer has a device mapping\n",
        "            if len(decoder_mapped_modules) >= num_hidden_layers:\n",
        "                for idx in range(num_hidden_layers):\n",
        "                    for module_name in decoder_mapped_modules:\n",
        "                        if f\".{idx}.\" in f\"{module_name}.\":\n",
        "                            layer_device_map[idx] = execution_device_map[module_name]\n",
        "                            break\n",
        "\n",
        "            # b) the whole module is mapped to a single device. If the decoder name is NOT present in the device map,\n",
        "            # then the mapping is done in a parent module\n",
        "            else:\n",
        "                while True:\n",
        "                    if decoder_name in execution_device_map:\n",
        "                        layer_device_map = dict.fromkeys(range(num_hidden_layers), execution_device_map[decoder_name])\n",
        "                        break\n",
        "                    elif \".\" in decoder_name:\n",
        "                        decoder_name = decoder_name.rsplit(\".\", 1)[0]  # gets the name of the parent module\n",
        "                    else:\n",
        "                        raise RuntimeError(f\"Decoder name {decoder_name} not found in execution device map\")\n",
        "\n",
        "        # Case 2: Legacy code path: assume the decoder layers are named as `(...).X` (X being the layer index)\n",
        "        else:\n",
        "            for layer in execution_device_map:\n",
        "                for idx in range(num_hidden_layers):\n",
        "                    if f\".{idx}.\" in f\"{layer}.\":\n",
        "                        layer_device_map[idx] = execution_device_map[layer]\n",
        "                        break\n",
        "\n",
        "        for idx in range(num_hidden_layers):\n",
        "            if idx not in layer_device_map:\n",
        "                raise RuntimeError(f\"layer {idx} has not been mapped to a device.\")\n",
        "        return layer_device_map\n",
        "\n",
        "    def _get_cache(\n",
        "        self, cache_implementation: str, batch_size: int, max_cache_len: int, device: torch.device, model_kwargs\n",
        "    ) -> Cache:\n",
        "        \"\"\"\n",
        "        Sets a cache for `generate`, that will persist across calls. A new cache will only be initialized a\n",
        "        new `generate` call requires a larger cache or uses a different batch size.\n",
        "\n",
        "        Returns the resulting cache object.\n",
        "        \"\"\"\n",
        "        if cache_implementation == \"hybrid\" and \"llama4\" in getattr(self.config, \"model_type\", \"\"):\n",
        "            cache_implementation = \"hybrid_chunked\"\n",
        "\n",
        "        cache_cls: Cache = NEED_SETUP_CACHE_CLASSES_MAPPING[cache_implementation]\n",
        "        requires_cross_attention_cache = (\n",
        "            self.config.is_encoder_decoder or model_kwargs.get(\"encoder_outputs\") is not None\n",
        "        )\n",
        "\n",
        "        if hasattr(self, \"_cache\"):\n",
        "            cache_to_check = self._cache.self_attention_cache if requires_cross_attention_cache else self._cache\n",
        "\n",
        "        if cache_implementation == \"sliding_window\":\n",
        "            max_cache_len = min(self.config.sliding_window, max_cache_len)\n",
        "\n",
        "        need_new_cache = (\n",
        "            not hasattr(self, \"_cache\")\n",
        "            or (not isinstance(cache_to_check, cache_cls))\n",
        "            or cache_to_check.max_batch_size != batch_size\n",
        "            or isinstance(\n",
        "                cache_to_check, (HybridChunkedCache, OffloadedHybridCache)\n",
        "            )  # due to internal slicing, we always re-init\n",
        "            or cache_to_check.max_cache_len < max_cache_len\n",
        "        )\n",
        "\n",
        "        if requires_cross_attention_cache and hasattr(self, \"_cache\"):\n",
        "            need_new_cache = (\n",
        "                need_new_cache\n",
        "                or self._cache.cross_attention_cache.max_cache_len != model_kwargs[\"encoder_outputs\"][0].shape[1]\n",
        "            )\n",
        "\n",
        "        if need_new_cache:\n",
        "            if hasattr(self.config, \"_pre_quantization_dtype\"):\n",
        "                cache_dtype = self.config._pre_quantization_dtype\n",
        "            else:\n",
        "                cache_dtype = self.dtype\n",
        "\n",
        "            layer_device_map = self._get_layer_device_map_for_cache_init()\n",
        "            cache_kwargs = {\n",
        "                \"config\": self.config.get_text_config(),\n",
        "                \"max_batch_size\": batch_size,\n",
        "                \"max_cache_len\": max_cache_len,\n",
        "                \"dtype\": cache_dtype,\n",
        "                \"device\": device,\n",
        "                \"layer_device_map\": layer_device_map,\n",
        "            }\n",
        "            if cache_implementation in [\"static\", \"hybrid\", \"offloaded_static\"]:\n",
        "                cache_kwargs.update({\"tp_size\": self.tp_size})\n",
        "\n",
        "            self._cache = cache_cls(**cache_kwargs)\n",
        "            if requires_cross_attention_cache:\n",
        "                encoder_kwargs = cache_kwargs.copy()\n",
        "                encoder_kwargs[\"max_cache_len\"] = model_kwargs[\"encoder_outputs\"][0].shape[1]\n",
        "                self._cache = EncoderDecoderCache(self._cache, cache_cls(**encoder_kwargs))\n",
        "        else:\n",
        "            self._cache.reset()\n",
        "        return self._cache\n",
        "\n",
        "    @classmethod\n",
        "    def _supports_default_dynamic_cache(cls) -> bool:\n",
        "        \"\"\"\n",
        "        Return `True` if current model can use a `DynamicCache` instance when initializing the `past_key_values`.\n",
        "        This adds exception for some models like `Mamba` models which use their own caches\n",
        "        and do not need to initialize the Cache in advance in order to save memory (because no back and forth\n",
        "        `to_legacy_cache` and `from_legacy_cache` will be performed for mamba-based models).\n",
        "        \"\"\"\n",
        "        # NOTE: remove xlnet/reformer when the models are deprecated, non-standard model architecture/cache name\n",
        "        return not cls._is_stateful and all(\n",
        "            special_model_name not in cls.__name__.lower()\n",
        "            for special_model_name in [\n",
        "                \"reformer\",\n",
        "                \"minimax\",\n",
        "                \"xlnet\",\n",
        "                \"lfm2\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def _prepare_cache_for_generation(\n",
        "        self,\n",
        "        generation_config: GenerationConfig,\n",
        "        model_kwargs: dict,\n",
        "        assistant_model: \"PreTrainedModel\",\n",
        "        batch_size: int,\n",
        "        max_cache_length: int,\n",
        "        device: torch.device,\n",
        "    ) -> bool:\n",
        "        \"\"\"\n",
        "        Prepares the cache for generation (if applicable), given `generate`'s parameterization. If a cache is\n",
        "        instantiated, writes it to `model_kwargs`, under the name expected by the model.\n",
        "        \"\"\"\n",
        "\n",
        "        is_hybrid_cache = any(class_name in self.__class__.__name__.lower() for class_name in [\"mamba\", \"falconh1\"])\n",
        "        cache_name = \"past_key_values\" if not is_hybrid_cache else \"cache_params\"\n",
        "\n",
        "        requires_cross_attention_cache = (\n",
        "            self.config.is_encoder_decoder or model_kwargs.get(\"encoder_outputs\") is not None\n",
        "        )\n",
        "\n",
        "        # Quick escape route 1: if the user specifies a cache, we only need to:\n",
        "        # a) check for conflicting `generate` arguments\n",
        "        # b) convert to the new cache format (if the user passes a legacy cache and model supports it)\n",
        "        user_defined_cache = model_kwargs.get(cache_name)\n",
        "        if user_defined_cache is not None:\n",
        "            if generation_config.cache_implementation is not None:\n",
        "                raise ValueError(\n",
        "                    f\"Passing both `cache_implementation` (used to initialize certain caches) and `{cache_name}` (a \"\n",
        "                    \"Cache object) is unsupported. Please use only one of the two.\"\n",
        "                )\n",
        "            if isinstance(user_defined_cache, tuple) and self._supports_default_dynamic_cache():\n",
        "                model_kwargs[cache_name] = (\n",
        "                    DynamicCache.from_legacy_cache(user_defined_cache)\n",
        "                    if not requires_cross_attention_cache\n",
        "                    else EncoderDecoderCache.from_legacy_cache(user_defined_cache)\n",
        "                )\n",
        "            return\n",
        "\n",
        "        # Quick escape route 2: if the user specifies no cache is to be used. (conflicting arguments are handled in\n",
        "        # `generation_config.validate()`)\n",
        "        if generation_config.use_cache is False:\n",
        "            return\n",
        "\n",
        "        # Quick escape route 3: model that only supports legacy caches or models that supply it in `prepare_inputs_for_generation` (mamba, zamba, ...)\n",
        "        if not self._supports_default_dynamic_cache():\n",
        "            if generation_config.cache_implementation is not None:\n",
        "                warnings.warn(\n",
        "                    \"This model does not support `Cache` instances, it only supports the legacy cache format (tuple \"\n",
        "                    f\"of tuples). `cache_implementation` (set to {generation_config.cache_implementation}) will be \"\n",
        "                    \"ignored.\",\n",
        "                    UserWarning,\n",
        "                )\n",
        "            return\n",
        "\n",
        "        # Otherwise we NEED to prepare a cache, based on `generation_config.cache_implementation`\n",
        "\n",
        "        # TODO(joao): support static caches in assisted generation. assisted generation needs to roll back caches,\n",
        "        # which is only supported in dynamic caches atm\n",
        "        if assistant_model is not None and generation_config.cache_implementation is not None:\n",
        "            logger.warning_once(\n",
        "                \"An assistant model is provided, using a dynamic cache instead of a cache of type=\"\n",
        "                f\"'{generation_config.cache_implementation}'.\"\n",
        "            )\n",
        "            generation_config.cache_implementation = None\n",
        "\n",
        "        generation_config.cache_implementation = generation_config.cache_implementation or getattr(\n",
        "            self.config.get_text_config(decoder=True), \"cache_implementation\", None\n",
        "        )\n",
        "        if generation_config.cache_implementation is not None:\n",
        "            if generation_config.cache_implementation in NEED_SETUP_CACHE_CLASSES_MAPPING:\n",
        "                if generation_config.cache_implementation == \"static\" and not self._can_compile_fullgraph:\n",
        "                    raise ValueError(\n",
        "                        \"This model does not support `cache_implementation='static'`. Please check the following \"\n",
        "                        \"issue: https://github.com/huggingface/transformers/issues/28981\"\n",
        "                    )\n",
        "                model_kwargs[cache_name] = self._get_cache(\n",
        "                    cache_implementation=generation_config.cache_implementation,\n",
        "                    batch_size=max(generation_config.num_beams, generation_config.num_return_sequences) * batch_size,\n",
        "                    max_cache_len=max_cache_length,\n",
        "                    device=device,\n",
        "                    model_kwargs=model_kwargs,\n",
        "                )\n",
        "            elif generation_config.cache_implementation == \"quantized\":\n",
        "                if self.config.is_encoder_decoder or not self._supports_default_dynamic_cache():\n",
        "                    raise ValueError(\n",
        "                        \"This model does not support the quantized cache. If you want your model to support quantized \"\n",
        "                        \"cache, please open an issue and tag @zucchini-nlp.\"\n",
        "                    )\n",
        "\n",
        "                cache_config = (\n",
        "                    generation_config.cache_config\n",
        "                    if generation_config.cache_config is not None\n",
        "                    else {\"backend\": \"quanto\"}\n",
        "                )\n",
        "                cache_class = QUANT_BACKEND_CLASSES_MAPPING[cache_config[\"backend\"]]\n",
        "\n",
        "                if cache_config[\"backend\"] == \"quanto\" and not is_optimum_quanto_available():\n",
        "                    raise ImportError(\n",
        "                        \"You need to install optimum-quanto in order to use KV cache quantization with optimum-quanto backend. \"\n",
        "                        \"Please install it via  with `pip install optimum-quanto`\"\n",
        "                    )\n",
        "                elif cache_config[\"backend\"] == \"HQQ\" and not is_hqq_available():\n",
        "                    raise ImportError(\n",
        "                        \"You need to install `HQQ` in order to use KV cache quantization with HQQ backend. \"\n",
        "                        \"Please install it via  with `pip install hqq`\"\n",
        "                    )\n",
        "\n",
        "                model_kwargs[cache_name] = cache_class(**cache_config)\n",
        "            elif generation_config.cache_implementation == \"offloaded\":\n",
        "                model_kwargs[cache_name] = OffloadedCache()\n",
        "            elif generation_config.cache_implementation == \"dynamic\":\n",
        "                model_kwargs[cache_name] = DynamicCache()\n",
        "\n",
        "        # Use DynamicCache() instance by default. This will avoid back and forth from legacy format that\n",
        "        # keeps copying the cache thus using much more memory\n",
        "        else:\n",
        "            model_kwargs[cache_name] = (\n",
        "                DynamicCache()\n",
        "                if not requires_cross_attention_cache\n",
        "                else EncoderDecoderCache(DynamicCache(), DynamicCache())\n",
        "            )\n",
        "\n",
        "    def _supports_logits_to_keep(self) -> bool:\n",
        "        \"\"\"\n",
        "        Return True if the current model supports the keyword argument `logits_to_keep` in forward()\n",
        "        to save memory. Checking it in this way allows to avoid using a new model attribute.\n",
        "        \"\"\"\n",
        "        return \"logits_to_keep\" in set(inspect.signature(self.forward).parameters.keys())\n",
        "\n",
        "    def _prepare_special_tokens(\n",
        "        self,\n",
        "        generation_config: GenerationConfig,\n",
        "        kwargs_has_attention_mask: Optional[bool] = None,\n",
        "        device: Optional[Union[torch.device, str]] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Prepares the special tokens for generation, overwriting the generation config with their processed versions\n",
        "        converted to tensor.\n",
        "\n",
        "        Note that `generation_config` is changed in place and stops being serializable after this method is called.\n",
        "        That is no problem if called within `generate` (`generation_config` is a local copy that doesn't leave the\n",
        "        function). However, if called outside `generate`, consider creating a copy of `generation_config` first.\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert special tokens to tensors\n",
        "        def _tensor_or_none(token, device=None):\n",
        "            if token is None:\n",
        "                return token\n",
        "\n",
        "            device = device if device is not None else self.device\n",
        "            if isinstance(token, torch.Tensor):\n",
        "                return token.to(device)\n",
        "            return torch.tensor(token, device=device, dtype=torch.long)\n",
        "\n",
        "        bos_token_tensor = _tensor_or_none(generation_config.bos_token_id, device=device)\n",
        "        eos_token_tensor = _tensor_or_none(generation_config.eos_token_id, device=device)\n",
        "        pad_token_tensor = _tensor_or_none(generation_config.pad_token_id, device=device)\n",
        "        decoder_start_token_tensor = _tensor_or_none(generation_config.decoder_start_token_id, device=device)\n",
        "\n",
        "        # for BC we also try to get `decoder_start_token_id` or `bos_token_id` (#30892)\n",
        "        if self.config.is_encoder_decoder:\n",
        "            decoder_start_token_tensor = (\n",
        "                decoder_start_token_tensor if decoder_start_token_tensor is not None else bos_token_tensor\n",
        "            )\n",
        "\n",
        "        # We can have more than one eos token. Always treat it as a 1D tensor (when it exists).\n",
        "        if eos_token_tensor is not None and eos_token_tensor.ndim == 0:\n",
        "            eos_token_tensor = eos_token_tensor.unsqueeze(0)\n",
        "\n",
        "        # Set pad token if unset (and there are conditions to do so)\n",
        "        if pad_token_tensor is None and eos_token_tensor is not None:\n",
        "            if kwargs_has_attention_mask is not None and not kwargs_has_attention_mask:\n",
        "                logger.warning(\n",
        "                    \"The attention mask and the pad token id were not set. As a consequence, you may observe \"\n",
        "                    \"unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\"\n",
        "                )\n",
        "            pad_token_tensor = eos_token_tensor[0]\n",
        "            logger.warning(f\"Setting `pad_token_id` to `eos_token_id`:{pad_token_tensor} for open-end generation.\")\n",
        "\n",
        "        # Sanity checks/warnings\n",
        "        if self.config.is_encoder_decoder and decoder_start_token_tensor is None:\n",
        "            raise ValueError(\n",
        "                \"`decoder_start_token_id` or `bos_token_id` has to be defined for encoder-decoder generation.\"\n",
        "            )\n",
        "        if (\n",
        "            eos_token_tensor is not None\n",
        "            and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()\n",
        "        ):\n",
        "            if kwargs_has_attention_mask is not None and not kwargs_has_attention_mask:\n",
        "                logger.warning_once(\n",
        "                    \"The attention mask is not set and cannot be inferred from input because pad token is same as \"\n",
        "                    \"eos token. As a consequence, you may observe unexpected behavior. Please pass your input's \"\n",
        "                    \"`attention_mask` to obtain reliable results.\"\n",
        "                )\n",
        "        if eos_token_tensor is not None and (\n",
        "            torch.is_floating_point(eos_token_tensor) or (eos_token_tensor < 0).any()\n",
        "        ):\n",
        "            logger.warning(\n",
        "                f\"`eos_token_id` should consist of positive integers, but is {eos_token_tensor}. Your generation \"\n",
        "                \"will not stop until the maximum length is reached. Depending on other flags, it may even crash.\"\n",
        "            )\n",
        "\n",
        "        # Update generation config with the updated special tokens tensors\n",
        "        # NOTE: this must be written into a different attribute name than the one holding the original special tokens\n",
        "        # (in their non-tensor form), in order to enable end-to-end compilation. See\n",
        "        # https://pytorch.org/docs/stable/torch.compiler_cudagraph_trees.html#limitations\n",
        "        generation_config._bos_token_tensor = bos_token_tensor\n",
        "        generation_config._eos_token_tensor = eos_token_tensor\n",
        "        generation_config._pad_token_tensor = pad_token_tensor\n",
        "        generation_config._decoder_start_token_tensor = decoder_start_token_tensor\n",
        "\n",
        "    def _valid_auto_compile_criteria(self, model_kwargs: dict, generation_config: GenerationConfig) -> bool:\n",
        "        \"\"\"\n",
        "        Determines whether to trigger auto-compilation of the model's forward pass at generation time.\n",
        "        \"\"\"\n",
        "        # Override: honor `disable_compile` flag\n",
        "        if generation_config.disable_compile:\n",
        "            return False\n",
        "\n",
        "        # Base logic\n",
        "        valid_hardware = self.device.type == \"cuda\" or bool(\n",
        "            generation_config.compile_config is not None and generation_config.compile_config._compile_all_devices\n",
        "        )\n",
        "        using_compilable_cache = (\n",
        "            isinstance(model_kwargs.get(\"past_key_values\"), Cache) and model_kwargs[\"past_key_values\"].is_compileable\n",
        "        )\n",
        "        # TODO @raushan `self._can_compile_fullgraph` can be removed and inferred from model arch (e.g. MoE doesn't support compile)\n",
        "        can_compile = valid_hardware and using_compilable_cache and self._can_compile_fullgraph\n",
        "\n",
        "        # Exception 1: Some quantization methods do not support compilation\n",
        "        if getattr(self, \"hf_quantizer\", None) is not None:\n",
        "            can_compile &= self.hf_quantizer.is_compileable\n",
        "\n",
        "        if hasattr(self, \"hf_device_map\"):\n",
        "            all_model_devices = set(self.hf_device_map.values())\n",
        "            # Exception 2: Don't compile if the model is using CPU offload (as of April 2025, this results in a crash)\n",
        "            has_cpu_offload = \"cpu\" in all_model_devices and len(all_model_devices) > 1\n",
        "            can_compile &= not has_cpu_offload\n",
        "\n",
        "            # Exception 3: Disk offload is not supported for compilation\n",
        "            has_disk_offload = \"disk\" in all_model_devices\n",
        "            can_compile &= not has_disk_offload\n",
        "\n",
        "        # Finally: if the user has manually specified compilation options, but compilation is not possible, let's warn\n",
        "        # them\n",
        "        if generation_config.compile_config is not None and not can_compile:\n",
        "            logger.warning_once(\n",
        "                \"You have set `compile_config`, but we are unable to meet the criteria for compilation. Compilation \"\n",
        "                \"will be skipped.\"\n",
        "            )\n",
        "\n",
        "        return can_compile\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(\n",
        "        self,\n",
        "        inputs: Optional[torch.Tensor] = None,\n",
        "        generation_config: Optional[GenerationConfig] = None,\n",
        "        logits_processor: Optional[LogitsProcessorList] = None,\n",
        "        stopping_criteria: Optional[StoppingCriteriaList] = None,\n",
        "        prefix_allowed_tokens_fn: Optional[Callable[[int, torch.Tensor], list[int]]] = None,\n",
        "        synced_gpus: Optional[bool] = None,\n",
        "        assistant_model: Optional[\"PreTrainedModel\"] = None,\n",
        "        streamer: Optional[\"BaseStreamer\"] = None,\n",
        "        negative_prompt_ids: Optional[torch.Tensor] = None,\n",
        "        negative_prompt_attention_mask: Optional[torch.Tensor] = None,\n",
        "        use_model_defaults: Optional[bool] = None,\n",
        "        custom_generate: Optional[str] = None,\n",
        "        **kwargs,\n",
        "    ) -> Union[GenerateOutput, torch.LongTensor]:\n",
        "        r\"\"\"\n",
        "\n",
        "        Generates sequences of token ids for models with a language modeling head.\n",
        "\n",
        "        <Tip warning={true}>\n",
        "\n",
        "        Most generation-controlling parameters are set in `generation_config` which, if not passed, will be set to the\n",
        "        model's default generation configuration. You can override any `generation_config` by passing the corresponding\n",
        "        parameters to generate(), e.g. `.generate(inputs, num_beams=4, do_sample=True)`.\n",
        "\n",
        "        For an overview of generation strategies and code examples, check out the [following\n",
        "        guide](../generation_strategies).\n",
        "\n",
        "        </Tip>\n",
        "\n",
        "        Parameters:\n",
        "            inputs (`torch.Tensor` of varying shape depending on the modality, *optional*):\n",
        "                The sequence used as a prompt for the generation or as model inputs to the encoder. If `None` the\n",
        "                method initializes it with `bos_token_id` and a batch size of 1. For decoder-only models `inputs`\n",
        "                should be in the format of `input_ids`. For encoder-decoder models *inputs* can represent any of\n",
        "                `input_ids`, `input_values`, `input_features`, or `pixel_values`.\n",
        "            generation_config ([`~generation.GenerationConfig`], *optional*):\n",
        "                The generation configuration to be used as base parametrization for the generation call. `**kwargs`\n",
        "                passed to generate matching the attributes of `generation_config` will override them. If\n",
        "                `generation_config` is not provided, the default will be used, which has the following loading\n",
        "                priority: 1) from the `generation_config.json` model file, if it exists; 2) from the model\n",
        "                configuration. Please note that unspecified parameters will inherit [`~generation.GenerationConfig`]'s\n",
        "                default values, whose documentation should be checked to parameterize generation.\n",
        "            logits_processor (`LogitsProcessorList`, *optional*):\n",
        "                Custom logits processors that complement the default logits processors built from arguments and\n",
        "                generation config. If a logit processor is passed that is already created with the arguments or a\n",
        "                generation config an error is thrown. This feature is intended for advanced users.\n",
        "            stopping_criteria (`StoppingCriteriaList`, *optional*):\n",
        "                Custom stopping criteria that complements the default stopping criteria built from arguments and a\n",
        "                generation config. If a stopping criteria is passed that is already created with the arguments or a\n",
        "                generation config an error is thrown. If your stopping criteria depends on the `scores` input, make\n",
        "                sure you pass `return_dict_in_generate=True, output_scores=True` to `generate`. This feature is\n",
        "                intended for advanced users.\n",
        "            prefix_allowed_tokens_fn (`Callable[[int, torch.Tensor], list[int]]`, *optional*):\n",
        "                If provided, this function constraints the beam search to allowed tokens only at each step. If not\n",
        "                provided no constraint is applied. This function takes 2 arguments: the batch ID `batch_id` and\n",
        "                `input_ids`. It has to return a list with the allowed tokens for the next generation step conditioned\n",
        "                on the batch ID `batch_id` and the previously generated tokens `inputs_ids`. This argument is useful\n",
        "                for constrained generation conditioned on the prefix, as described in [Autoregressive Entity\n",
        "                Retrieval](https://huggingface.co/papers/2010.00904).\n",
        "            synced_gpus (`bool`, *optional*):\n",
        "                Whether to continue running the while loop until max_length. Unless overridden, this flag will be set\n",
        "                to `True` if using `FullyShardedDataParallel` or DeepSpeed ZeRO Stage 3 with multiple GPUs to avoid\n",
        "                deadlocking if one GPU finishes generating before other GPUs. Otherwise, defaults to `False`.\n",
        "            assistant_model (`PreTrainedModel`, *optional*):\n",
        "                An assistant model that can be used to accelerate generation. The assistant model must have the exact\n",
        "                same tokenizer. The acceleration is achieved when forecasting candidate tokens with the assistant model\n",
        "                is much faster than running generation with the model you're calling generate from. As such, the\n",
        "                assistant model should be much smaller.\n",
        "            streamer (`BaseStreamer`, *optional*):\n",
        "                Streamer object that will be used to stream the generated sequences. Generated tokens are passed\n",
        "                through `streamer.put(token_ids)` and the streamer is responsible for any further processing.\n",
        "            negative_prompt_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "                The negative prompt needed for some processors such as CFG. The batch size must match the input batch\n",
        "                size. This is an experimental feature, subject to breaking API changes in future versions.\n",
        "            negative_prompt_attention_mask (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "                Attention_mask for `negative_prompt_ids`.\n",
        "            use_model_defaults (`bool`, *optional*):\n",
        "                When it is `True`, unset parameters in `generation_config` will be set to the model-specific default\n",
        "                generation configuration (`model.generation_config`), as opposed to the global defaults\n",
        "                (`GenerationConfig()`). If unset, models saved starting from `v4.50` will consider this flag to be\n",
        "                `True`.\n",
        "            custom_generate (`str`, *optional*):\n",
        "                A string containing the name of a huggingface.co repository. If provided, the custom `generate`\n",
        "                function defined in that reposity's `custom_generate/generate.py` file will be executed instead of the\n",
        "                standard `generate` method. Note that the logic is for generation is entirely defined in that\n",
        "                repository, and the return type may be different from the standard `generate` method.\n",
        "            kwargs (`dict[str, Any]`, *optional*):\n",
        "                Ad hoc parametrization of `generation_config` and/or additional model-specific kwargs that will be\n",
        "                forwarded to the `forward` function of the model. If the model is an encoder-decoder model, encoder\n",
        "                specific kwargs should not be prefixed and decoder specific kwargs should be prefixed with *decoder_*.\n",
        "\n",
        "        Return:\n",
        "            [`~utils.ModelOutput`] or `torch.LongTensor`: A [`~utils.ModelOutput`] (if `return_dict_in_generate=True`\n",
        "            or when `config.return_dict_in_generate=True`) or a `torch.LongTensor`.\n",
        "\n",
        "                If the model is *not* an encoder-decoder model (`model.config.is_encoder_decoder=False`), the possible\n",
        "                [`~utils.ModelOutput`] types are:\n",
        "\n",
        "                    - [`~generation.GenerateDecoderOnlyOutput`],\n",
        "                    - [`~generation.GenerateBeamDecoderOnlyOutput`]\n",
        "\n",
        "                If the model is an encoder-decoder model (`model.config.is_encoder_decoder=True`), the possible\n",
        "                [`~utils.ModelOutput`] types are:\n",
        "\n",
        "                    - [`~generation.GenerateEncoderDecoderOutput`],\n",
        "                    - [`~generation.GenerateBeamEncoderDecoderOutput`]\n",
        "        \"\"\"\n",
        "        # 0. If requested, load an arbitrary generation recipe from the Hub and run it instead\n",
        "        trust_remote_code = kwargs.pop(\"trust_remote_code\", None)\n",
        "        if custom_generate is not None:\n",
        "            # Get all `generate` arguments in a single variable. Custom functions are responsible for handling them:\n",
        "            # they receive the same inputs as `generate`, with `model` instead of `self` and excluding the arguments to\n",
        "            # trigger the custom generation. They can access to methods from `GenerationMixin` through `model`.\n",
        "            global_keys_to_exclude = {\n",
        "                \"self\",\n",
        "                \"kwargs\",\n",
        "                \"global_keys_to_exclude\",\n",
        "                \"trust_remote_code\",\n",
        "                \"custom_generate\",\n",
        "            }\n",
        "            generate_arguments = {key: value for key, value in locals().items() if key not in global_keys_to_exclude}\n",
        "            generate_arguments.update(kwargs)\n",
        "\n",
        "            custom_generate_function = self.load_custom_generate(\n",
        "                custom_generate, trust_remote_code=trust_remote_code, **kwargs\n",
        "            )\n",
        "            return custom_generate_function(model=self, **generate_arguments)\n",
        "\n",
        "        # 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call\n",
        "        tokenizer = kwargs.pop(\"tokenizer\", None)  # Pull this out first, we only use it for stopping criteria\n",
        "        assistant_tokenizer = kwargs.pop(\"assistant_tokenizer\", None)  # only used for assisted generation\n",
        "\n",
        "        generation_config, model_kwargs = self._prepare_generation_config(\n",
        "            generation_config, use_model_defaults, **kwargs\n",
        "        )\n",
        "        self._validate_model_kwargs(model_kwargs.copy())\n",
        "        self._validate_assistant(assistant_model, tokenizer, assistant_tokenizer)\n",
        "\n",
        "        # 2. Set generation parameters if not already defined\n",
        "        if synced_gpus is None:\n",
        "            synced_gpus = (is_deepspeed_zero3_enabled() or is_fsdp_managed_module(self)) and dist.get_world_size() > 1\n",
        "\n",
        "        logits_processor = logits_processor if logits_processor is not None else LogitsProcessorList()\n",
        "        stopping_criteria = stopping_criteria if stopping_criteria is not None else StoppingCriteriaList()\n",
        "\n",
        "        accepts_attention_mask = \"attention_mask\" in set(inspect.signature(self.forward).parameters.keys())\n",
        "        requires_attention_mask = \"encoder_outputs\" not in model_kwargs\n",
        "        kwargs_has_attention_mask = model_kwargs.get(\"attention_mask\", None) is not None\n",
        "\n",
        "        # 3. Define model inputs\n",
        "        inputs_tensor, model_input_name, model_kwargs = self._prepare_model_inputs(\n",
        "            inputs, generation_config.bos_token_id, model_kwargs\n",
        "        )\n",
        "        batch_size = inputs_tensor.shape[0]\n",
        "\n",
        "        device = inputs_tensor.device\n",
        "        self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)\n",
        "\n",
        "        # decoder-only models must use left-padding for batched generation.\n",
        "        if not self.config.is_encoder_decoder:\n",
        "            # If `input_ids` was given, check if the last id in any sequence is `pad_token_id`\n",
        "            # Note: If using, `inputs_embeds` this check does not work, because we want to be more hands-off.\n",
        "            if (\n",
        "                generation_config._pad_token_tensor is not None\n",
        "                and batch_size > 1\n",
        "                and len(inputs_tensor.shape) == 2\n",
        "                and torch.sum(inputs_tensor[:, -1] == generation_config._pad_token_tensor) > 0\n",
        "            ):\n",
        "                logger.warning(\n",
        "                    \"A decoder-only architecture is being used, but right-padding was detected! For correct \"\n",
        "                    \"generation results, please set `padding_side='left'` when initializing the tokenizer.\"\n",
        "                )\n",
        "\n",
        "        # 4. Define other model kwargs\n",
        "        # decoder-only models with inputs_embeds forwarding must use caching (otherwise we can't detect whether we are\n",
        "        # generating the first new token or not, and we only want to use the embeddings for the first new token)\n",
        "        if not self.config.is_encoder_decoder and model_input_name == \"inputs_embeds\":\n",
        "            generation_config.use_cache = True\n",
        "\n",
        "        if not kwargs_has_attention_mask and requires_attention_mask and accepts_attention_mask:\n",
        "            model_kwargs[\"attention_mask\"] = self._prepare_attention_mask_for_generation(\n",
        "                inputs_tensor, generation_config, model_kwargs\n",
        "            )\n",
        "        elif kwargs_has_attention_mask:\n",
        "            # TODO (joao): generalize this check with other types of inputs\n",
        "            if model_input_name == \"input_ids\" and len(model_kwargs[\"attention_mask\"].shape) > 2:\n",
        "                raise ValueError(\"`attention_mask` passed to `generate` must be 2D.\")\n",
        "\n",
        "        if self.config.is_encoder_decoder and \"encoder_outputs\" not in model_kwargs:\n",
        "            # if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\n",
        "            model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n",
        "                inputs_tensor, model_kwargs, model_input_name, generation_config\n",
        "            )\n",
        "\n",
        "        # 5. Prepare `input_ids` which will be used for auto-regressive generation\n",
        "        if self.config.is_encoder_decoder:\n",
        "            input_ids, model_kwargs = self._prepare_decoder_input_ids_for_generation(\n",
        "                batch_size=batch_size,\n",
        "                model_input_name=model_input_name,\n",
        "                model_kwargs=model_kwargs,\n",
        "                decoder_start_token_id=generation_config._decoder_start_token_tensor,\n",
        "                device=inputs_tensor.device,\n",
        "            )\n",
        "        else:\n",
        "            input_ids = inputs_tensor if model_input_name == \"input_ids\" else model_kwargs.pop(\"input_ids\")\n",
        "\n",
        "        if generation_config.token_healing:\n",
        "            input_ids = self.heal_tokens(input_ids, tokenizer)\n",
        "\n",
        "        if streamer is not None:\n",
        "            streamer.put(input_ids.cpu())\n",
        "\n",
        "        # 6. Prepare `max_length` depending on other stopping criteria.\n",
        "        input_ids_length = input_ids.shape[1]\n",
        "        has_default_max_length = kwargs.get(\"max_length\") is None and generation_config.max_length is not None\n",
        "        has_default_min_length = kwargs.get(\"min_length\") is None and generation_config.min_length is not None\n",
        "        generation_config = self._prepare_generated_length(\n",
        "            generation_config=generation_config,\n",
        "            has_default_max_length=has_default_max_length,\n",
        "            has_default_min_length=has_default_min_length,\n",
        "            model_input_name=model_input_name,\n",
        "            inputs_tensor=inputs_tensor,\n",
        "            input_ids_length=input_ids_length,\n",
        "        )\n",
        "\n",
        "        # If the model supports `logits_to_keep` in forward(), set it to 1 to avoid computing the whole\n",
        "        # logit matrix. This can save a lot of memory during the first forward pass. Note that assisted decoding\n",
        "        # dynamically overrides this value as it can need more than the last token logits\n",
        "        if self._supports_logits_to_keep() and \"logits_to_keep\" not in model_kwargs:\n",
        "            model_kwargs[\"logits_to_keep\"] = 1\n",
        "\n",
        "        self._validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n",
        "\n",
        "        # 7. Prepare the cache.\n",
        "        # - `model_kwargs` may be updated in place with a cache as defined by the parameters in `generation_config`.\n",
        "        # - different models have a different cache name expected by the model (default = \"past_key_values\")\n",
        "        # - `max_length`, prepared above, is used to determine the maximum cache length\n",
        "        max_cache_length = generation_config.max_length - 1\n",
        "        if (\n",
        "            inputs_tensor.shape[1] != input_ids_length\n",
        "            and model_input_name == \"inputs_embeds\"\n",
        "            and not self.config.is_encoder_decoder\n",
        "        ):\n",
        "            max_cache_length += inputs_tensor.shape[1]\n",
        "        self._prepare_cache_for_generation(\n",
        "            generation_config, model_kwargs, assistant_model, batch_size, max_cache_length, device\n",
        "        )\n",
        "\n",
        "        # 8. determine generation mode\n",
        "        generation_mode = generation_config.get_generation_mode(assistant_model)\n",
        "\n",
        "        if streamer is not None and (generation_config.num_beams > 1):\n",
        "            raise ValueError(\n",
        "                \"`streamer` cannot be used with beam search (yet!). Make sure that `num_beams` is set to 1.\"\n",
        "            )\n",
        "\n",
        "        if self.device.type != input_ids.device.type:\n",
        "            warnings.warn(\n",
        "                \"You are calling .generate() with the `input_ids` being on a device type different\"\n",
        "                f\" than your model's device. `input_ids` is on {input_ids.device.type}, whereas the model\"\n",
        "                f\" is on {self.device.type}. You may experience unexpected behaviors or slower generation.\"\n",
        "                \" Please make sure that you have put `input_ids` to the\"\n",
        "                f\" correct device by calling for example input_ids = input_ids.to('{self.device.type}') before\"\n",
        "                \" running `.generate()`.\",\n",
        "                UserWarning,\n",
        "            )\n",
        "\n",
        "        # 9. prepare logits processors and stopping criteria\n",
        "        prepared_logits_processor = self._get_logits_processor(\n",
        "            generation_config=generation_config,\n",
        "            input_ids_seq_length=input_ids_length,\n",
        "            encoder_input_ids=inputs_tensor,\n",
        "            prefix_allowed_tokens_fn=prefix_allowed_tokens_fn,\n",
        "            logits_processor=logits_processor,\n",
        "            device=inputs_tensor.device,\n",
        "            model_kwargs=model_kwargs,\n",
        "            negative_prompt_ids=negative_prompt_ids,\n",
        "            negative_prompt_attention_mask=negative_prompt_attention_mask,\n",
        "        )\n",
        "        prepared_stopping_criteria = self._get_stopping_criteria(\n",
        "            generation_config=generation_config, stopping_criteria=stopping_criteria, tokenizer=tokenizer, **kwargs\n",
        "        )\n",
        "\n",
        "        # Set model_kwargs `use_cache` so we can use it later in forward runs\n",
        "        model_kwargs[\"use_cache\"] = generation_config.use_cache\n",
        "\n",
        "        # 10. go into different generation modes\n",
        "        if generation_mode == GenerationMode.ASSISTED_GENERATION:\n",
        "            if generation_config.num_return_sequences > 1:\n",
        "                raise ValueError(\n",
        "                    \"num_return_sequences has to be 1 when doing assisted generate, \"\n",
        "                    f\"but is {generation_config.num_return_sequences}.\"\n",
        "                )\n",
        "            if batch_size > 1:\n",
        "                raise ValueError(\"assisted generate is only supported for batch_size = 1\")\n",
        "            if not model_kwargs[\"use_cache\"]:\n",
        "                raise ValueError(\"assisted generate requires `use_cache=True`\")\n",
        "            if generation_config.cache_implementation in [\"static\", \"hybrid\", \"sliding_window\"]:\n",
        "                raise ValueError(\"assisted generate is not supported with Static cache classes`\")\n",
        "            if self._is_stateful:\n",
        "                # In assisted generation we need the ability to confirm whether the model would pick certain tokens,\n",
        "                # which is not possible with stateful models (they can't reset to a previous subset of generated text)\n",
        "                raise ValueError(\n",
        "                    f\"assisted generation is not supported with stateful models, such as {self.__class__.__name__}\"\n",
        "                )\n",
        "\n",
        "            # 11. Get the candidate generator, given the parameterization\n",
        "            candidate_generator = self._get_candidate_generator(\n",
        "                generation_config=generation_config,\n",
        "                input_ids=input_ids,\n",
        "                inputs_tensor=inputs_tensor,\n",
        "                assistant_model=assistant_model,\n",
        "                logits_processor=logits_processor,\n",
        "                target_tokenizer=tokenizer,\n",
        "                assistant_tokenizer=assistant_tokenizer,\n",
        "                model_kwargs=model_kwargs,\n",
        "            )\n",
        "\n",
        "            # 12. run assisted generate\n",
        "            result = self._assisted_decoding(\n",
        "                input_ids,\n",
        "                candidate_generator=candidate_generator,\n",
        "                logits_processor=prepared_logits_processor,\n",
        "                stopping_criteria=prepared_stopping_criteria,\n",
        "                generation_config=generation_config,\n",
        "                synced_gpus=synced_gpus,\n",
        "                streamer=streamer,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "        elif generation_mode == GenerationMode.DOLA_GENERATION:\n",
        "            if not trust_remote_code:\n",
        "                logger.warning_once(\n",
        "                    \"DoLa Decoding is scheduled to be moved to a `custom_generate` repository in v4.55.0. \"\n",
        "                    \"To prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\"\n",
        "                )\n",
        "            if self._is_stateful:\n",
        "                # DoLa decoding was not designed for stateful models, and would require some changes\n",
        "                raise ValueError(\n",
        "                    f\"dola decoding is not supported with stateful models, such as {self.__class__.__name__}\"\n",
        "                )\n",
        "            result = self._dola_decoding(\n",
        "                input_ids,\n",
        "                dola_layers=generation_config.dola_layers,\n",
        "                logits_processor=prepared_logits_processor,\n",
        "                stopping_criteria=prepared_stopping_criteria,\n",
        "                generation_config=generation_config,\n",
        "                synced_gpus=synced_gpus,\n",
        "                streamer=streamer,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "\n",
        "        elif generation_mode == GenerationMode.CONTRASTIVE_SEARCH:\n",
        "            if not trust_remote_code:\n",
        "                logger.warning_once(\n",
        "                    \"Contrastive Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \"\n",
        "                    \"To prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\"\n",
        "                )\n",
        "            if not model_kwargs[\"use_cache\"]:\n",
        "                raise ValueError(\"Contrastive search requires `use_cache=True`\")\n",
        "            if self._is_stateful:\n",
        "                # Just like assisted generation, we need to be able to rollback to a previous state (see comment above)\n",
        "                raise ValueError(\n",
        "                    f\"contrastive search is not supported with stateful models, such as {self.__class__.__name__}\"\n",
        "                )\n",
        "\n",
        "            result = self._contrastive_search(\n",
        "                input_ids,\n",
        "                logits_processor=prepared_logits_processor,\n",
        "                stopping_criteria=prepared_stopping_criteria,\n",
        "                generation_config=generation_config,\n",
        "                synced_gpus=synced_gpus,\n",
        "                streamer=streamer,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "\n",
        "        elif generation_mode in (GenerationMode.SAMPLE, GenerationMode.GREEDY_SEARCH):\n",
        "            # 11. expand input_ids with `num_return_sequences` additional sequences per batch\n",
        "            input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
        "                input_ids=input_ids,\n",
        "                expand_size=generation_config.num_return_sequences,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "\n",
        "            # 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\n",
        "            result = self._sample(\n",
        "                input_ids,\n",
        "                logits_processor=prepared_logits_processor,\n",
        "                stopping_criteria=prepared_stopping_criteria,\n",
        "                generation_config=generation_config,\n",
        "                synced_gpus=synced_gpus,\n",
        "                streamer=streamer,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "\n",
        "        elif generation_mode in (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n",
        "            # 11. interleave input_ids with `num_beams` additional sequences per batch\n",
        "            input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
        "                input_ids=input_ids,\n",
        "                expand_size=generation_config.num_beams,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "            # 12. run beam sample\n",
        "            result = self._beam_search(\n",
        "                input_ids,\n",
        "                logits_processor=prepared_logits_processor,\n",
        "                stopping_criteria=prepared_stopping_criteria,\n",
        "                generation_config=generation_config,\n",
        "                synced_gpus=synced_gpus,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "\n",
        "        elif generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n",
        "            logger.warning_once(\n",
        "                \"Group Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \"\n",
        "                \"To prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\"\n",
        "            )\n",
        "            # 11. prepare beam search scorer\n",
        "            beam_scorer = BeamSearchScorer(\n",
        "                batch_size=batch_size,\n",
        "                num_beams=generation_config.num_beams,\n",
        "                device=inputs_tensor.device,\n",
        "                length_penalty=generation_config.length_penalty,\n",
        "                do_early_stopping=generation_config.early_stopping,\n",
        "                num_beam_hyps_to_keep=generation_config.num_return_sequences,\n",
        "                num_beam_groups=generation_config.num_beam_groups,\n",
        "                max_length=generation_config.max_length,\n",
        "            )\n",
        "            # 12. interleave input_ids with `num_beams` additional sequences per batch\n",
        "            input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
        "                input_ids=input_ids,\n",
        "                expand_size=generation_config.num_beams,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "            # 13. run beam search\n",
        "            result = self._group_beam_search(\n",
        "                input_ids,\n",
        "                beam_scorer,\n",
        "                logits_processor=prepared_logits_processor,\n",
        "                stopping_criteria=prepared_stopping_criteria,\n",
        "                generation_config=generation_config,\n",
        "                synced_gpus=synced_gpus,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "\n",
        "        elif generation_mode == GenerationMode.CONSTRAINED_BEAM_SEARCH:\n",
        "            logger.warning_once(\n",
        "                \"Constrained Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \"\n",
        "                \"To prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\"\n",
        "            )\n",
        "            final_constraints = []\n",
        "            if generation_config.constraints is not None:\n",
        "                final_constraints = generation_config.constraints\n",
        "\n",
        "            if generation_config.force_words_ids is not None:\n",
        "\n",
        "                def typeerror():\n",
        "                    raise ValueError(\n",
        "                        \"`force_words_ids` has to either be a `list[list[list[int]]]` or `list[list[int]]` \"\n",
        "                        f\"of positive integers, but is {generation_config.force_words_ids}.\"\n",
        "                    )\n",
        "\n",
        "                if (\n",
        "                    not isinstance(generation_config.force_words_ids, list)\n",
        "                    or len(generation_config.force_words_ids) == 0\n",
        "                ):\n",
        "                    typeerror()\n",
        "\n",
        "                for word_ids in generation_config.force_words_ids:\n",
        "                    if isinstance(word_ids[0], list):\n",
        "                        if not isinstance(word_ids, list) or len(word_ids) == 0:\n",
        "                            typeerror()\n",
        "                        if any(not isinstance(token_ids, list) for token_ids in word_ids):\n",
        "                            typeerror()\n",
        "                        if any(\n",
        "                            any((not isinstance(token_id, int) or token_id < 0) for token_id in token_ids)\n",
        "                            for token_ids in word_ids\n",
        "                        ):\n",
        "                            typeerror()\n",
        "\n",
        "                        constraint = DisjunctiveConstraint(word_ids)\n",
        "                    else:\n",
        "                        if not isinstance(word_ids, list) or len(word_ids) == 0:\n",
        "                            typeerror()\n",
        "                        if any((not isinstance(token_id, int) or token_id < 0) for token_id in word_ids):\n",
        "                            typeerror()\n",
        "\n",
        "                        constraint = PhrasalConstraint(word_ids)\n",
        "                    final_constraints.append(constraint)\n",
        "\n",
        "            # 11. prepare beam search scorer\n",
        "            constrained_beam_scorer = ConstrainedBeamSearchScorer(\n",
        "                constraints=final_constraints,\n",
        "                batch_size=batch_size,\n",
        "                num_beams=generation_config.num_beams,\n",
        "                device=inputs_tensor.device,\n",
        "                length_penalty=generation_config.length_penalty,\n",
        "                do_early_stopping=generation_config.early_stopping,\n",
        "                num_beam_hyps_to_keep=generation_config.num_return_sequences,\n",
        "                max_length=generation_config.max_length,\n",
        "            )\n",
        "            # 12. interleave input_ids with `num_beams` additional sequences per batch\n",
        "            input_ids, model_kwargs = self._expand_inputs_for_generation(\n",
        "                input_ids=input_ids,\n",
        "                expand_size=generation_config.num_beams,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "            # 13. run beam search\n",
        "            result = self._constrained_beam_search(\n",
        "                input_ids,\n",
        "                constrained_beam_scorer=constrained_beam_scorer,\n",
        "                logits_processor=prepared_logits_processor,\n",
        "                stopping_criteria=prepared_stopping_criteria,\n",
        "                generation_config=generation_config,\n",
        "                synced_gpus=synced_gpus,\n",
        "                **model_kwargs,\n",
        "            )\n",
        "\n",
        "        # Convert to legacy cache format if requested\n",
        "        if (\n",
        "            generation_config.return_legacy_cache is True\n",
        "            and hasattr(result, \"past_key_values\")\n",
        "            and getattr(result.past_key_values, \"to_legacy_cache\") is not None\n",
        "        ):\n",
        "            result.past_key_values = result.past_key_values.to_legacy_cache()\n",
        "        return result\n",
        "\n",
        "    def _has_unfinished_sequences(self, this_peer_finished: bool, synced_gpus: bool, device: torch.device) -> bool:\n",
        "        \"\"\"\n",
        "        Returns whether there are still unfinished sequences in the device. The existence of unfinished sequences is\n",
        "        fed through `this_peer_finished`. ZeRO stage 3-friendly.\n",
        "        \"\"\"\n",
        "        if synced_gpus:\n",
        "            # Under synced_gpus the `forward` call must continue until all gpus complete their sequence.\n",
        "            # The following logic allows an early break if all peers finished generating their sequence\n",
        "            this_peer_finished_flag = torch.tensor(0.0 if this_peer_finished else 1.0, device=device)\n",
        "            # send 0.0 if we finished, 1.0 otherwise\n",
        "            dist.all_reduce(this_peer_finished_flag, op=dist.ReduceOp.SUM)\n",
        "            # did all peers finish? the reduced sum will be 0.0 then\n",
        "            if this_peer_finished_flag.item() == 0.0:\n",
        "                return False\n",
        "        elif this_peer_finished:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def heal_tokens(\n",
        "        self, input_ids: torch.LongTensor, tokenizer: Optional[\"PreTrainedTokenizerBase\"] = None\n",
        "    ) -> torch.LongTensor:\n",
        "        r\"\"\"\n",
        "        Generates sequences of token ids for models with a language modeling head.\n",
        "        Parameters:\n",
        "            input_ids (`torch.LongTensor`): The sequence used as a prompt for the generation.\n",
        "            tokenizer (`PreTrainedTokenizerBase`, *optional*): The tokenizer used to decode the input ids.\n",
        "        Return:\n",
        "            `torch.LongTensor` where each sequence has its tail token replaced with its appropriate extension.\n",
        "        \"\"\"\n",
        "        if tokenizer is None:\n",
        "            raise ValueError(\n",
        "                \" When generating with token healing, you must pass the model's tokenizer to the `tokenizer` \"\n",
        "                \"argument of `generate`.\"\n",
        "            )\n",
        "\n",
        "        bos_token_id, pad_token_id = tokenizer.bos_token_id, tokenizer.pad_token_id\n",
        "        vocab_trie = ExtensionsTrie(tokenizer.get_vocab())\n",
        "        generation_config = GenerationConfig(max_new_tokens=1, pad_token_id=pad_token_id)\n",
        "\n",
        "        # assumption: leading/trailing whitespace is not meaningful, so the prompts are\n",
        "        # stripped before re-tokenizing to desensitize generation to whitespace artefacts\n",
        "        prompts = [p.strip() for p in tokenizer.batch_decode(input_ids, skip_special_tokens=True)]\n",
        "        input_ids = tokenizer(\n",
        "            prompts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "        ).input_ids.to(input_ids.device)\n",
        "\n",
        "        # replace bos with pad to not condition healing on it\n",
        "        input_ids = torch.where(input_ids == bos_token_id, pad_token_id, input_ids)\n",
        "\n",
        "        \"\"\"\n",
        "        the latter code assumes the input_ids is not empty,\n",
        "        input_id has to be checked if contains elements\n",
        "\t\t\"\"\"\n",
        "        if input_ids.numel() == 0:\n",
        "            return input_ids\n",
        "\n",
        "        tail_ids = input_ids[:, -1].tolist()\n",
        "\n",
        "        space_tok = tokenizer.convert_ids_to_tokens(tokenizer.convert_tokens_to_ids(\" \"))[0]\n",
        "        # tail tokens are used for a prefix search, thus, whitespaces are replaced with\n",
        "        # their tokenization (e.g. 'Ġ') to enable search for tokens prefixed with a whitespace\n",
        "        tail_toks = (tokenizer.decode(t).replace(\" \", space_tok) for t in tail_ids)\n",
        "\n",
        "        for batch_idx, (tail_id, tail_tok) in enumerate(zip(tail_ids, tail_toks)):\n",
        "            batch_ids = input_ids[batch_idx]\n",
        "            if torch.all(batch_ids == pad_token_id).item():\n",
        "                continue  # skip empty sequences (all pad ids)\n",
        "\n",
        "            # apply bias for alternatives (extensions) to the tail token\n",
        "            \"\"\"\n",
        "            seq_bias key has to be tuple with int so have to use\n",
        "            tokenizer function to convert str to int\n",
        "\t\t\t\"\"\"\n",
        "            seq_bias = {\n",
        "                (tokenizer.convert_tokens_to_ids(alt_tok),): 10.0 for alt_tok in vocab_trie.extensions(prefix=tail_tok)\n",
        "            }\n",
        "\n",
        "            if len(seq_bias) == 1:\n",
        "                continue  # skip if there are no token alternatives to heal with\n",
        "\n",
        "            # slightly favor original token to limit aggressive healing e.g. 'http' -> 'https'\n",
        "            seq_bias[(tail_id,)] += 1.0\n",
        "            generation_config.update(sequence_bias=seq_bias)\n",
        "\n",
        "            trimmed_ids = batch_ids[:-1]\n",
        "\n",
        "            \"\"\"\n",
        "            the latter code assumes trimmed_ids is not empty\n",
        "            so have to check the its element count\n",
        "\t\t\t\"\"\"\n",
        "            if trimmed_ids.numel() == 0:\n",
        "                continue\n",
        "\n",
        "            # if the prompt is a single (non-pad) token, regenerate from bos\n",
        "            if len(batch_ids[batch_ids != pad_token_id]) == 1:\n",
        "                trimmed_ids[-1] = bos_token_id\n",
        "\n",
        "            input_ids[batch_idx] = self.generate(trimmed_ids.unsqueeze(0), generation_config=generation_config)\n",
        "\n",
        "        return input_ids\n",
        "\n",
        "    def _dola_decoding(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        dola_layers: Union[str, list[int]],\n",
        "        logits_processor: LogitsProcessorList,\n",
        "        stopping_criteria: StoppingCriteriaList,\n",
        "        generation_config: GenerationConfig,\n",
        "        synced_gpus: bool,\n",
        "        streamer: \"BaseStreamer\",\n",
        "        **model_kwargs,\n",
        "    ) -> Union[GenerateNonBeamOutput, torch.LongTensor]:\n",
        "        r\"\"\"\n",
        "        Generates sequences of token ids for models with a language modeling head using **dola decoding** and can be\n",
        "        used for decoder-only text models.\n",
        "        The method is based on the paper \"DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language\n",
        "        Models\" (https://huggingface.co/papers/2309.03883) in ICLR 2024.\n",
        "\n",
        "        Parameters:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "                The sequence used as a prompt for the generation.\n",
        "            dola_layers (`Union[str, list[int]]`):\n",
        "                The candidate layers used in contrasting layers of DoLa. It can be either 1) 'low' or 'high', which\n",
        "                means the lower part or higher part of the model layers, respectively, or 2) a list of layer indices\n",
        "                to be used for candidate layers. The 0-th layer is the word embedding layer of the model.\n",
        "            logits_processor (`LogitsProcessorList`):\n",
        "                An instance of [`LogitsProcessorList`]. List of instances of class derived from [`LogitsProcessor`]\n",
        "                used to modify the prediction scores of the language modeling head applied at each generation step.\n",
        "            stopping_criteria (`StoppingCriteriaList`, *optional*):\n",
        "                An instance of [`StoppingCriteriaList`]. List of instances of class derived from [`StoppingCriteria`]\n",
        "                used to tell if the generation loop should stop.\n",
        "            generation_config ([`~generation.GenerationConfig`]):\n",
        "                The generation configuration to be used as parametrization of the decoding method.\n",
        "            synced_gpus (`bool`):\n",
        "                Whether to continue running the while loop until max_length (needed to avoid deadlocking with\n",
        "                `FullyShardedDataParallel` and DeepSpeed ZeRO Stage 3).\n",
        "            streamer (`BaseStreamer`, *optional*):\n",
        "                Streamer object that will be used to stream the generated sequences. Generated tokens are passed\n",
        "                through `streamer.put(token_ids)` and the streamer is responsible for any further processing.\n",
        "            model_kwargs:\n",
        "                Additional model specific keyword arguments will be forwarded to the `forward` function of the model.\n",
        "                If model is an encoder-decoder model the kwargs should include `encoder_outputs`.\n",
        "\n",
        "        Return:\n",
        "            [`~generation.GenerateDecoderOnlyOutput`], [`~generation.GenerateEncoderDecoderOutput`]\n",
        "            or `torch.LongTensor`: A `torch.LongTensor` containing the generated tokens (default behaviour) or a\n",
        "            [`~generation.GenerateDecoderOnlyOutput`] if `model.config.is_encoder_decoder=False` and\n",
        "            `return_dict_in_generate=True` or a [`~generation.GenerateEncoderDecoderOutput`] if\n",
        "            `model.config.is_encoder_decoder=True`.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.config.is_encoder_decoder:\n",
        "            raise ValueError(\"DoLa decoding is only available for decoder-only models.\")\n",
        "        # init values\n",
        "\n",
        "        pad_token_id = generation_config._pad_token_tensor\n",
        "        output_attentions = generation_config.output_attentions\n",
        "        output_hidden_states = generation_config.output_hidden_states\n",
        "        output_scores = generation_config.output_scores\n",
        "        output_logits = generation_config.output_logits\n",
        "        return_dict_in_generate = generation_config.return_dict_in_generate\n",
        "        has_eos_stopping_criteria = any(hasattr(criteria, \"eos_token_id\") for criteria in stopping_criteria)\n",
        "        do_sample = generation_config.do_sample\n",
        "\n",
        "        # init attention / hidden states / scores tuples\n",
        "        scores = () if (return_dict_in_generate and output_scores) else None\n",
        "        raw_logits = () if (return_dict_in_generate and output_logits) else None\n",
        "        decoder_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        cross_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        decoder_hidden_states = () if (return_dict_in_generate and output_hidden_states) else None\n",
        "\n",
        "        # keep track of which sequences are already finished\n",
        "        batch_size, cur_length = input_ids.shape[:2]\n",
        "        unfinished_sequences = torch.ones(batch_size, dtype=torch.long, device=input_ids.device)\n",
        "        model_kwargs = self._get_initial_cache_position(cur_length, input_ids.device, model_kwargs)\n",
        "\n",
        "        this_peer_finished = False\n",
        "\n",
        "        # prepare layers for DoLa decoding\n",
        "        final_layer = self.config.get_text_config().num_hidden_layers\n",
        "        # if the model has tied word embeddings, we skip the word embeddings (0-th) layer and start from the 2nd layer,\n",
        "        # as the early exit from word embeddings will become identity function\n",
        "        # if the model is really shallow (<=2 layers), we use the 1st layer if it's not the final layer and the 0-th\n",
        "        # layer otherwise. Notice that DoLa does not help shallow models much.\n",
        "        if not self.config.tie_word_embeddings:\n",
        "            start_layer = 0\n",
        "        elif final_layer > 2:\n",
        "            start_layer = 2\n",
        "        elif final_layer == 2:\n",
        "            start_layer = 1\n",
        "        else:\n",
        "            start_layer = 0\n",
        "\n",
        "        # For `N`-layer models with `N <= 40` layers, the layers of `range(0, N // 2, 2)` and `range(N // 2, N, 2)`\n",
        "        # are used for `'low'` and `'high'` layers, respectively.\n",
        "        # For models with `N > 40` layers, the layers of `range(0, 20, 2)` and `range(N - 20, N, 2)` are used for\n",
        "        # `'low'` and `'high'` layers, respectively.\n",
        "        if isinstance(dola_layers, str) and dola_layers == \"low\":\n",
        "            if start_layer == final_layer // 2:\n",
        "                candidate_premature_layers = [start_layer]\n",
        "            else:\n",
        "                candidate_premature_layers = (\n",
        "                    list(range(start_layer, final_layer // 2, 2))\n",
        "                    if final_layer <= 40\n",
        "                    else list(range(start_layer, 20, 2))\n",
        "                )\n",
        "        elif isinstance(dola_layers, str) and dola_layers == \"high\":\n",
        "            candidate_premature_layers = (\n",
        "                list(range(final_layer // 2, final_layer, 2))\n",
        "                if final_layer <= 40\n",
        "                else list(range(final_layer - 20, final_layer, 2))\n",
        "            )\n",
        "        # Set the `dola_layers` to a list of integers for layer indices to contrast manually specified layers.\n",
        "        elif isinstance(dola_layers, list):\n",
        "            candidate_premature_layers = [i for i in dola_layers if i < final_layer]\n",
        "        else:\n",
        "            raise ValueError(\"dola_layers must be either 'low', 'high' or a list of integers.\")\n",
        "\n",
        "        lm_head = self.get_output_embeddings()\n",
        "        if lm_head is None:\n",
        "            raise ValueError(\"DoLa is not supported for models that don't have output embeddings.\")\n",
        "\n",
        "        while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n",
        "            # prepare model inputs\n",
        "            model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
        "\n",
        "            # forward pass to get next token\n",
        "            outputs = self(\n",
        "                **model_inputs,\n",
        "                return_dict=True,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=True,\n",
        "            )\n",
        "\n",
        "            # .float() is needed to retain precision for later logits manipulations\n",
        "            final_layer_next_token_logits = outputs.logits[:, -1, :].detach().to(copy=True, dtype=torch.float32)\n",
        "            final_logits = outputs.logits[:, -1, :].float()\n",
        "            candidate_premature_logits = {}\n",
        "            for candidate_premature_layer in candidate_premature_layers:\n",
        "                candidate_premature_logits[candidate_premature_layer] = lm_head(\n",
        "                    outputs.hidden_states[candidate_premature_layer][:, -1, :]\n",
        "                ).to(final_logits.device)\n",
        "\n",
        "            # synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\n",
        "            model_kwargs = self._update_model_kwargs_for_generation(\n",
        "                outputs,\n",
        "                model_kwargs,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "            )\n",
        "            if synced_gpus and this_peer_finished:\n",
        "                continue\n",
        "\n",
        "            next_token_logits = _dola_select_contrast(\n",
        "                candidate_premature_layers, candidate_premature_logits, final_logits\n",
        "            )\n",
        "            next_token_logits = next_token_logits.to(input_ids.device)\n",
        "            # pre-process distribution\n",
        "            next_token_scores = logits_processor(input_ids, next_token_logits)\n",
        "\n",
        "            # Store scores, attentions and hidden_states when required\n",
        "            if return_dict_in_generate:\n",
        "                if output_scores:\n",
        "                    scores += (next_token_scores,)\n",
        "                if output_logits:\n",
        "                    raw_logits += (final_layer_next_token_logits,)\n",
        "                if output_attentions:\n",
        "                    decoder_attentions += (\n",
        "                        (outputs.decoder_attentions,) if self.config.is_encoder_decoder else (outputs.attentions,)\n",
        "                    )\n",
        "                    if self.config.is_encoder_decoder:\n",
        "                        cross_attentions += (outputs.cross_attentions,)\n",
        "\n",
        "                if output_hidden_states:\n",
        "                    decoder_hidden_states += (\n",
        "                        (outputs.decoder_hidden_states,)\n",
        "                        if self.config.is_encoder_decoder\n",
        "                        else (outputs.hidden_states,)\n",
        "                    )\n",
        "\n",
        "            if do_sample:  # sample\n",
        "                probs = nn.functional.softmax(next_token_scores, dim=-1)\n",
        "                next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
        "            else:  # argmax\n",
        "                next_tokens = torch.argmax(next_token_scores, dim=-1)\n",
        "\n",
        "            # finished sentences should have their next token be a padding token\n",
        "            if has_eos_stopping_criteria:\n",
        "                next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)\n",
        "\n",
        "            # update generated ids, model inputs, and length for next step\n",
        "            input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)\n",
        "            if streamer is not None:\n",
        "                streamer.put(next_tokens.cpu())\n",
        "\n",
        "            # stop when each sentence is finished\n",
        "            unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)\n",
        "            this_peer_finished = unfinished_sequences.max() == 0\n",
        "\n",
        "        if streamer is not None:\n",
        "            streamer.end()\n",
        "\n",
        "        if return_dict_in_generate:\n",
        "            return GenerateDecoderOnlyOutput(\n",
        "                sequences=input_ids,\n",
        "                scores=scores,\n",
        "                logits=raw_logits,\n",
        "                attentions=decoder_attentions,\n",
        "                hidden_states=decoder_hidden_states,\n",
        "                past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "            )\n",
        "        else:\n",
        "            return input_ids\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _contrastive_search(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        logits_processor: LogitsProcessorList,\n",
        "        stopping_criteria: StoppingCriteriaList,\n",
        "        generation_config: GenerationConfig,\n",
        "        synced_gpus: bool,\n",
        "        streamer: Optional[\"BaseStreamer\"],\n",
        "        **model_kwargs,\n",
        "    ) -> Union[GenerateNonBeamOutput, torch.LongTensor]:\n",
        "        r\"\"\"\n",
        "        Generates sequences of token ids for models with a language modeling head using **contrastive search** and can\n",
        "        be used for text-decoder, text-to-text, speech-to-text, and vision-to-text models.\n",
        "\n",
        "        Parameters:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "                The sequence used as a prompt for the generation.\n",
        "            logits_processor (`LogitsProcessorList`):\n",
        "                An instance of [`LogitsProcessorList`]. List of instances of class derived from [`LogitsProcessor`]\n",
        "                used to modify the prediction scores of the language modeling head applied at each generation step.\n",
        "            stopping_criteria (`StoppingCriteriaList`):\n",
        "                An instance of [`StoppingCriteriaList`]. List of instances of class derived from [`StoppingCriteria`]\n",
        "                used to tell if the generation loop should stop.\n",
        "            generation_config ([`~generation.GenerationConfig`]):\n",
        "                The generation configuration to be used as parametrization of the decoding method.\n",
        "            synced_gpus (`bool`):\n",
        "                Whether to continue running the while loop until max_length (needed to avoid deadlocking with\n",
        "                `FullyShardedDataParallel` and DeepSpeed ZeRO Stage 3).\n",
        "            streamer (`BaseStreamer`, *optional*):\n",
        "                Streamer object that will be used to stream the generated sequences. Generated tokens are passed\n",
        "                through `streamer.put(token_ids)` and the streamer is responsible for any further processing.\n",
        "            model_kwargs:\n",
        "                Additional model specific keyword arguments will be forwarded to the `forward` function of the model.\n",
        "                If model is an encoder-decoder model the kwargs should include `encoder_outputs`.\n",
        "\n",
        "        Return:\n",
        "            [`~generation.GenerateDecoderOnlyOutput`], [`~generation.GenerateEncoderDecoderOutput`]\n",
        "            or `torch.LongTensor`: A `torch.LongTensor` containing the generated tokens (default behaviour) or a\n",
        "            [`~generation.GenerateDecoderOnlyOutput`] if `model.config.is_encoder_decoder=False` and\n",
        "            `return_dict_in_generate=True` or a [`~generation.GenerateEncoderDecoderOutput`] if\n",
        "            `model.config.is_encoder_decoder=True`.\n",
        "        \"\"\"\n",
        "        # init values\n",
        "        has_eos_stopping_criteria = any(hasattr(criteria, \"eos_token_id\") for criteria in stopping_criteria)\n",
        "        top_k = generation_config.top_k\n",
        "        penalty_alpha = generation_config.penalty_alpha\n",
        "        pad_token_id = generation_config._pad_token_tensor\n",
        "        output_attentions = generation_config.output_attentions\n",
        "        output_hidden_states = generation_config.output_hidden_states\n",
        "        output_scores = generation_config.output_scores\n",
        "        output_logits = generation_config.output_logits\n",
        "        return_dict_in_generate = generation_config.return_dict_in_generate\n",
        "        sequential = generation_config.low_memory\n",
        "\n",
        "        # init attention / hidden states / scores tuples\n",
        "        raw_logits = () if (return_dict_in_generate and output_logits) else None\n",
        "        scores = () if (return_dict_in_generate and output_scores) else None\n",
        "        decoder_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        cross_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        decoder_hidden_states = () if (return_dict_in_generate and output_hidden_states) else None\n",
        "\n",
        "        # if model is an encoder-decoder, retrieve encoder attention weights and hidden states\n",
        "        if return_dict_in_generate and self.config.is_encoder_decoder:\n",
        "            encoder_attentions = model_kwargs[\"encoder_outputs\"].get(\"attentions\") if output_attentions else None\n",
        "            encoder_hidden_states = (\n",
        "                model_kwargs[\"encoder_outputs\"].get(\"hidden_states\") if output_hidden_states else None\n",
        "            )\n",
        "\n",
        "        # keep track of which sequences are already finished\n",
        "        batch_size, cur_len = input_ids.shape[:2]\n",
        "        unfinished_sequences = torch.ones(batch_size, dtype=torch.long, device=input_ids.device)\n",
        "        model_kwargs = self._get_initial_cache_position(cur_len, input_ids.device, model_kwargs)\n",
        "\n",
        "        # Create cosine_matrix_mask based on the attention_mask\n",
        "        cosine_matrix_mask = torch.ones_like(input_ids, dtype=torch.long)\n",
        "        if self.config.is_encoder_decoder:\n",
        "            if \"decoder_attention_mask\" in model_kwargs and model_kwargs[\"decoder_attention_mask\"] is not None:\n",
        "                cosine_matrix_mask = model_kwargs[\"decoder_attention_mask\"]\n",
        "        else:\n",
        "            cosine_matrix_mask = model_kwargs[\"attention_mask\"]\n",
        "        cosine_matrix_mask = cosine_matrix_mask.repeat_interleave(top_k, dim=0)\n",
        "\n",
        "        this_peer_finished = False\n",
        "\n",
        "        while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n",
        "            # if the first step in the loop, encode all the prefix and obtain: (1) past_key_values;\n",
        "            # (2) last_hidden_states; (3) logit_for_next_step; (4) update model kwargs for the next step\n",
        "            if model_kwargs.get(\"past_key_values\") is None or (\n",
        "                isinstance(model_kwargs[\"past_key_values\"], (Cache, EncoderDecoderCache))\n",
        "                and model_kwargs[\"past_key_values\"].get_seq_length() == 0\n",
        "            ):\n",
        "                # prepare inputs\n",
        "                model_kwargs[\"use_cache\"] = True\n",
        "                model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
        "\n",
        "                # encode the given prefix and prepare model inputs; encoder-decoder model process the prefix and save\n",
        "                # the `encoder_outputs`\n",
        "                outputs = self(\n",
        "                    **model_inputs, return_dict=True, output_hidden_states=True, output_attentions=output_attentions\n",
        "                )\n",
        "\n",
        "                # last decoder hidden states will be used to compute the degeneration penalty (cosine similarity with\n",
        "                # previous tokens)\n",
        "                if self.config.is_encoder_decoder:\n",
        "                    last_hidden_states = outputs.decoder_hidden_states[-1]\n",
        "                else:\n",
        "                    last_hidden_states = outputs.hidden_states[-1]\n",
        "\n",
        "                # next logit for contrastive search to select top-k candidate tokens\n",
        "                # Copy is needed to avoid keeping a hanging ref to outputs.logits which may be very large for this first iteration\n",
        "                # (the clone itself is always small)\n",
        "                # torch.float32 is needed to retain precision for later logits manipulations\n",
        "                logit_for_next_step = outputs.logits[:, -1, :].to(\n",
        "                    copy=True, dtype=torch.float32, device=input_ids.device\n",
        "                )\n",
        "\n",
        "                model_kwargs = self._update_model_kwargs_for_generation(\n",
        "                    outputs,\n",
        "                    model_kwargs,\n",
        "                    is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "                )\n",
        "\n",
        "                if not sequential:\n",
        "                    # Expands model inputs top_k times, for batched forward passes (akin to beam search).\n",
        "                    # input_ids is required for expanding visual inputs in qwen2vl\n",
        "                    _, model_kwargs = self._expand_inputs_for_generation(\n",
        "                        input_ids=input_ids,\n",
        "                        expand_size=top_k,\n",
        "                        is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "                        **model_kwargs,\n",
        "                    )\n",
        "\n",
        "                past_key_values = model_kwargs.get(\"past_key_values\")\n",
        "                if past_key_values is None:\n",
        "                    raise ValueError(\n",
        "                        f\"{self.__class__.__name__} does not support caching and therefore **can't** be used \"\n",
        "                        \"for contrastive search.\"\n",
        "                    )\n",
        "                elif (\n",
        "                    not isinstance(past_key_values[0], (tuple, torch.Tensor))\n",
        "                    or past_key_values[0][0].shape[0] != batch_size\n",
        "                ):\n",
        "                    raise ValueError(\n",
        "                        f\"{self.__class__.__name__} does not have a standard cache format and therefore **can't** be \"\n",
        "                        \"used for contrastive search without further modifications.\"\n",
        "                    )\n",
        "\n",
        "            # contrastive_search main logic start:\n",
        "            # contrastive search decoding consists of two steps: (1) candidate tokens recall; (2) candidate re-rank by\n",
        "            # degeneration penalty\n",
        "            processed_logit_for_next_step = logits_processor(input_ids, logit_for_next_step)\n",
        "            next_probs = nn.functional.softmax(processed_logit_for_next_step, dim=-1)\n",
        "\n",
        "            top_k_probs, top_k_ids = torch.topk(next_probs, dim=-1, k=top_k)\n",
        "\n",
        "            # Store scores, attentions and hidden_states when required\n",
        "            if return_dict_in_generate:\n",
        "                if output_logits:\n",
        "                    raw_logits += (logit_for_next_step,)\n",
        "                if output_scores:\n",
        "                    scores += (processed_logit_for_next_step,)\n",
        "                if output_attentions:\n",
        "                    decoder_attentions += (\n",
        "                        (outputs.decoder_attentions,) if self.config.is_encoder_decoder else (outputs.attentions,)\n",
        "                    )\n",
        "                    if self.config.is_encoder_decoder:\n",
        "                        cross_attentions += (outputs.cross_attentions,)\n",
        "\n",
        "                if output_hidden_states:\n",
        "                    decoder_hidden_states += (\n",
        "                        (outputs.decoder_hidden_states,)\n",
        "                        if self.config.is_encoder_decoder\n",
        "                        else (outputs.hidden_states,)\n",
        "                    )\n",
        "\n",
        "            # This is needed to properly delete outputs.logits which may be very large for this first iteration\n",
        "            # Otherwise a reference to outputs.logits is kept all along until after the next call to self.forward()\n",
        "            del outputs\n",
        "\n",
        "            if not sequential:\n",
        "                # Replicates the new past_key_values to match the `top_k` candidates\n",
        "                past = model_kwargs[\"past_key_values\"]\n",
        "                # If it is a static cache, modify it in-place layer after layer to save memory\n",
        "                if isinstance(past, DynamicCache) or (\n",
        "                    isinstance(past, EncoderDecoderCache) and isinstance(past.self_attention_cache, DynamicCache)\n",
        "                ):\n",
        "                    past.batch_repeat_interleave(top_k)\n",
        "                else:\n",
        "                    new_key_values = []\n",
        "                    for layer in past:\n",
        "                        items = []\n",
        "                        # item is either the key or the value matrix\n",
        "                        for item in layer:\n",
        "                            items.append(item.repeat_interleave(top_k, dim=0))\n",
        "                        new_key_values.append(tuple(items))\n",
        "\n",
        "                    past = tuple(new_key_values)\n",
        "\n",
        "                model_kwargs[\"past_key_values\"] = past\n",
        "\n",
        "            if sequential:\n",
        "                all_outputs = []\n",
        "                for i in range(top_k):\n",
        "                    # compute the candidate tokens by the language model and collect their hidden_states\n",
        "                    next_model_inputs = self.prepare_inputs_for_generation(top_k_ids[:, i].view(-1, 1), **model_kwargs)\n",
        "\n",
        "                    outputs = self(\n",
        "                        **next_model_inputs,\n",
        "                        return_dict=True,\n",
        "                        output_hidden_states=True,\n",
        "                        output_attentions=output_attentions,\n",
        "                    )\n",
        "                    if isinstance(outputs[\"past_key_values\"], DynamicCache) or (\n",
        "                        isinstance(outputs[\"past_key_values\"], EncoderDecoderCache)\n",
        "                        and isinstance(outputs[\"past_key_values\"].self_attention_cache, DynamicCache)\n",
        "                    ):\n",
        "                        # Remove past K-V from output since we don't need to stack later\n",
        "                        outputs[\"past_key_values\"] = None\n",
        "                        # Remove last token from past K-V since we don't want to append it at this point\n",
        "                        model_kwargs[\"past_key_values\"].crop(-1)\n",
        "\n",
        "                    all_outputs.append(outputs)\n",
        "                outputs = stack_model_outputs(all_outputs, self.config.get_text_config())\n",
        "\n",
        "            else:\n",
        "                # compute the candidate tokens by the language model and collect their hidden_states\n",
        "                # assembles top_k_ids into batch of size k\n",
        "                next_model_inputs = self.prepare_inputs_for_generation(top_k_ids.view(-1, 1), **model_kwargs)\n",
        "\n",
        "                outputs = self(\n",
        "                    **next_model_inputs,\n",
        "                    return_dict=True,\n",
        "                    output_hidden_states=True,\n",
        "                    output_attentions=output_attentions,\n",
        "                )\n",
        "\n",
        "            # This is essential to avoid having a last reference to the big past K-V and double the necessary memory\n",
        "            # in the next loop\n",
        "            del next_model_inputs\n",
        "\n",
        "            # name is different for encoder-decoder and decoder-only models\n",
        "            if self.config.is_encoder_decoder:\n",
        "                next_hidden = outputs.decoder_hidden_states[-1]\n",
        "                full_hidden_states = outputs.decoder_hidden_states\n",
        "            else:\n",
        "                next_hidden = outputs.hidden_states[-1]\n",
        "                full_hidden_states = outputs.hidden_states\n",
        "\n",
        "            # .float() is needed to retain precision for later logits manipulations\n",
        "            logits = outputs.logits[:, -1, :].float()\n",
        "            context_hidden = last_hidden_states.repeat_interleave(top_k, dim=0)\n",
        "\n",
        "            # compute the degeneration penalty and re-rank the candidates based on the degeneration penalty and the\n",
        "            # model confidence. Keeping `selected_idx` on CPU enables multi-device contrastive search and doesn't\n",
        "            # introduce (noticeable) slowdowns on single-device runs.\n",
        "            selected_idx = _ranking_fast(\n",
        "                context_hidden, next_hidden, top_k_probs, cosine_matrix_mask, penalty_alpha, top_k\n",
        "            )\n",
        "            cosine_matrix_mask = torch.cat(\n",
        "                [cosine_matrix_mask, cosine_matrix_mask.new_ones((cosine_matrix_mask.shape[0], 1))], dim=-1\n",
        "            )\n",
        "            selected_idx = selected_idx.to(\"cpu\")\n",
        "\n",
        "            # This will be used instead of the previous inneficient torch.stack(torch.split())\n",
        "            augmented_idx = torch.tensor([x + i * top_k for i, x in enumerate(selected_idx)])\n",
        "\n",
        "            # prepare for the next step: (1) next token_id; (2) past_key_values; (3) last_hidden_states for computing\n",
        "            # the degeneration penalty; (4) logits for selecting next top-k candidates; (5) selected tokens scores\n",
        "            # (model confidence minus degeneration penalty); (6) decoder hidden_states\n",
        "            next_tokens = top_k_ids[range(len(top_k_ids)), selected_idx]\n",
        "            next_hidden = torch.stack(torch.split(next_hidden.squeeze(dim=1), top_k))\n",
        "            next_hidden = next_hidden[range(batch_size), selected_idx, :]\n",
        "            last_hidden_states = torch.cat([last_hidden_states, next_hidden.unsqueeze(1)], dim=1)\n",
        "\n",
        "            next_decoder_hidden_states = ()\n",
        "            for layer in full_hidden_states:\n",
        "                layer = torch.stack(torch.split(layer, top_k))[range(batch_size), selected_idx, :]\n",
        "                next_decoder_hidden_states += (layer,)\n",
        "\n",
        "            # generate past_key_values cache of only the selected token\n",
        "            if sequential:\n",
        "                next_model_input = self.prepare_inputs_for_generation(\n",
        "                    top_k_ids[:, selected_idx].view(-1, 1), **model_kwargs\n",
        "                )\n",
        "\n",
        "                selected_outputs = self(\n",
        "                    **next_model_input,\n",
        "                    return_dict=True,\n",
        "                    output_hidden_states=False,\n",
        "                    output_attentions=False,\n",
        "                )\n",
        "                next_past_key_values = selected_outputs[\"past_key_values\"]\n",
        "\n",
        "            else:\n",
        "                next_past_key_values = None\n",
        "                for possible_cache_name in ALL_CACHE_NAMES:\n",
        "                    next_past_key_values = next_past_key_values or getattr(outputs, possible_cache_name, None)\n",
        "                # Do it in-place layer per layer to save memory\n",
        "                if isinstance(next_past_key_values, DynamicCache) or (\n",
        "                    isinstance(next_past_key_values, EncoderDecoderCache)\n",
        "                    and isinstance(next_past_key_values.self_attention_cache, DynamicCache)\n",
        "                ):\n",
        "                    next_past_key_values.batch_select_indices(augmented_idx)\n",
        "                else:\n",
        "                    new_key_values = []\n",
        "                    for layer in next_past_key_values:\n",
        "                        items = []\n",
        "                        # item is either the key or the value matrix\n",
        "                        for item in layer:\n",
        "                            items.append(item[augmented_idx, ...])\n",
        "                        new_key_values.append(tuple(items))\n",
        "\n",
        "                    next_past_key_values = tuple(new_key_values)\n",
        "\n",
        "            logit_for_next_step = torch.stack(torch.split(logits, top_k))[range(batch_size), selected_idx, :]\n",
        "            logit_for_next_step = logit_for_next_step.to(input_ids.device)\n",
        "\n",
        "            # Rebuilds the relevant parts of the model output for the selected token, for use in the next iteration\n",
        "            if self.config.is_encoder_decoder:\n",
        "                next_step_cross_attentions = ()\n",
        "                next_step_decoder_attentions = ()\n",
        "                if output_attentions:\n",
        "                    for layer in outputs.cross_attentions:\n",
        "                        layer = torch.stack(torch.split(layer, top_k, dim=0))[range(batch_size), selected_idx, ...]\n",
        "                        next_step_cross_attentions += (layer,)\n",
        "                    for layer in outputs.decoder_attentions:\n",
        "                        layer = torch.stack(torch.split(layer, top_k, dim=0))[range(batch_size), selected_idx, ...]\n",
        "                        next_step_decoder_attentions += (layer,)\n",
        "                outputs = Seq2SeqLMOutput(\n",
        "                    past_key_values=next_past_key_values,\n",
        "                    decoder_hidden_states=next_decoder_hidden_states,\n",
        "                    decoder_attentions=next_step_decoder_attentions or None,\n",
        "                    cross_attentions=next_step_cross_attentions or None,\n",
        "                )\n",
        "            else:\n",
        "                next_step_attentions = ()\n",
        "                if output_attentions:\n",
        "                    for layer in outputs.attentions:\n",
        "                        layer = torch.stack(torch.split(layer, top_k, dim=0))[range(batch_size), selected_idx, ...]\n",
        "                        next_step_attentions += (layer,)\n",
        "                outputs = CausalLMOutputWithPast(\n",
        "                    past_key_values=next_past_key_values,\n",
        "                    hidden_states=next_decoder_hidden_states,\n",
        "                    attentions=next_step_attentions or None,\n",
        "                )\n",
        "            # contrastive_search main logic end\n",
        "\n",
        "            # synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\n",
        "            model_kwargs = self._update_model_kwargs_for_generation(\n",
        "                outputs,\n",
        "                model_kwargs,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "            )\n",
        "            if synced_gpus and this_peer_finished:\n",
        "                continue\n",
        "\n",
        "            # finished sentences should have their next token be a padding token\n",
        "            if has_eos_stopping_criteria:\n",
        "                next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)\n",
        "\n",
        "            # update generated ids, model inputs, and length for next step\n",
        "            input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)\n",
        "            if streamer is not None:\n",
        "                streamer.put(next_tokens.cpu())\n",
        "\n",
        "            # stop when each sentence is finished\n",
        "            unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)\n",
        "            this_peer_finished = unfinished_sequences.max() == 0\n",
        "\n",
        "        if streamer is not None:\n",
        "            streamer.end()\n",
        "\n",
        "        if return_dict_in_generate:\n",
        "            # Contrastive search works by forward looking at the next token, so we need to exclude it from\n",
        "            # `past_key_values` to be consistent with the other decoding methods\n",
        "            if model_kwargs.get(\"past_key_values\") is not None:\n",
        "                if isinstance(model_kwargs[\"past_key_values\"], DynamicCache) or (\n",
        "                    isinstance(model_kwargs[\"past_key_values\"], EncoderDecoderCache)\n",
        "                    and isinstance(model_kwargs[\"past_key_values\"].self_attention_cache, DynamicCache)\n",
        "                ):\n",
        "                    model_kwargs[\"past_key_values\"].crop(-1)\n",
        "                else:\n",
        "                    past_key_values = []\n",
        "                    for layer in model_kwargs[\"past_key_values\"]:\n",
        "                        layer_past_key_values = []\n",
        "                        for item in layer:\n",
        "                            layer_past_key_values.append(item[..., :-1, :])\n",
        "                        past_key_values.append(tuple(layer_past_key_values))\n",
        "                    model_kwargs[\"past_key_values\"] = tuple(past_key_values)\n",
        "\n",
        "            if self.config.is_encoder_decoder:\n",
        "                return GenerateEncoderDecoderOutput(\n",
        "                    sequences=input_ids,\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    encoder_attentions=encoder_attentions,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    decoder_attentions=decoder_attentions,\n",
        "                    cross_attentions=cross_attentions,\n",
        "                    decoder_hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "            else:\n",
        "                return GenerateDecoderOnlyOutput(\n",
        "                    sequences=input_ids,\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    attentions=decoder_attentions,\n",
        "                    hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "        else:\n",
        "            return input_ids\n",
        "\n",
        "    def _sample(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        logits_processor: LogitsProcessorList,\n",
        "        stopping_criteria: StoppingCriteriaList,\n",
        "        generation_config: GenerationConfig,\n",
        "        synced_gpus: bool,\n",
        "        streamer: Optional[\"BaseStreamer\"],\n",
        "        **model_kwargs,\n",
        "    ) -> Union[GenerateNonBeamOutput, torch.LongTensor]:\n",
        "        r\"\"\"\n",
        "        Generates sequences of token ids for models with a language modeling head using **multinomial sampling** and\n",
        "        can be used for text-decoder, text-to-text, speech-to-text, and vision-to-text models.\n",
        "\n",
        "        Parameters:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "                The sequence used as a prompt for the generation.\n",
        "            logits_processor (`LogitsProcessorList`):\n",
        "                An instance of [`LogitsProcessorList`]. List of instances of class derived from [`LogitsProcessor`]\n",
        "                used to modify the prediction scores of the language modeling head applied at each generation step.\n",
        "            stopping_criteria (`StoppingCriteriaList`):\n",
        "                An instance of [`StoppingCriteriaList`]. List of instances of class derived from [`StoppingCriteria`]\n",
        "                used to tell if the generation loop should stop.\n",
        "            generation_config ([`~generation.GenerationConfig`]):\n",
        "                The generation configuration to be used as parametrization of the decoding method.\n",
        "            synced_gpus (`bool`):\n",
        "                Whether to continue running the while loop until max_length (needed to avoid deadlocking with\n",
        "                `FullyShardedDataParallel` and DeepSpeed ZeRO Stage 3).\n",
        "            streamer (`BaseStreamer`, *optional*):\n",
        "                Streamer object that will be used to stream the generated sequences. Generated tokens are passed\n",
        "                through `streamer.put(token_ids)` and the streamer is responsible for any further processing.\n",
        "            model_kwargs:\n",
        "                Additional model specific kwargs will be forwarded to the `forward` function of the model. If model is\n",
        "                an encoder-decoder model the kwargs should include `encoder_outputs`.\n",
        "\n",
        "        Return:\n",
        "            [`~generation.GenerateDecoderOnlyOutput`], [`~generation.GenerateEncoderDecoderOutput`] or `torch.LongTensor`:\n",
        "            A `torch.LongTensor` containing the generated tokens (default behaviour) or a\n",
        "            [`~generation.GenerateDecoderOnlyOutput`] if `model.config.is_encoder_decoder=False` and\n",
        "            `return_dict_in_generate=True` or a [`~generation.GenerateEncoderDecoderOutput`] if\n",
        "            `model.config.is_encoder_decoder=True`.\n",
        "        \"\"\"\n",
        "        # init values\n",
        "        pad_token_id = generation_config._pad_token_tensor\n",
        "        output_attentions = generation_config.output_attentions\n",
        "        output_hidden_states = generation_config.output_hidden_states\n",
        "        output_scores = generation_config.output_scores\n",
        "        output_logits = generation_config.output_logits\n",
        "        return_dict_in_generate = generation_config.return_dict_in_generate\n",
        "        has_eos_stopping_criteria = any(hasattr(criteria, \"eos_token_id\") for criteria in stopping_criteria)\n",
        "        do_sample = generation_config.do_sample\n",
        "\n",
        "        # init attention / hidden states / scores tuples\n",
        "        scores = () if (return_dict_in_generate and output_scores) else None\n",
        "        raw_logits = () if (return_dict_in_generate and output_logits) else None\n",
        "        decoder_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        cross_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        decoder_hidden_states = () if (return_dict_in_generate and output_hidden_states) else None\n",
        "\n",
        "        # if model is an encoder-decoder, retrieve encoder attention weights and hidden states\n",
        "        if return_dict_in_generate and self.config.is_encoder_decoder:\n",
        "            encoder_attentions = model_kwargs[\"encoder_outputs\"].get(\"attentions\") if output_attentions else None\n",
        "            encoder_hidden_states = (\n",
        "                model_kwargs[\"encoder_outputs\"].get(\"hidden_states\") if output_hidden_states else None\n",
        "            )\n",
        "\n",
        "        # keep track of which sequences are already finished\n",
        "        batch_size, cur_len = input_ids.shape[:2]\n",
        "        this_peer_finished = False\n",
        "        unfinished_sequences = torch.ones(batch_size, dtype=torch.long, device=input_ids.device)\n",
        "        model_kwargs = self._get_initial_cache_position(cur_len, input_ids.device, model_kwargs)\n",
        "\n",
        "        model_forward = self.__call__\n",
        "        compile_forward = self._valid_auto_compile_criteria(model_kwargs, generation_config)\n",
        "        if compile_forward:\n",
        "            os.environ[\"TOKENIZERS_PARALLELISM\"] = \"0\"\n",
        "            # If we use FA2 and a static cache, we cannot compile with fullgraph\n",
        "            if self.config._attn_implementation == \"flash_attention_2\" and getattr(\n",
        "                model_kwargs.get(\"past_key_values\"), \"is_compileable\", False\n",
        "            ):\n",
        "                if generation_config.compile_config is None:\n",
        "                    generation_config.compile_config = CompileConfig(fullgraph=False)\n",
        "                # only raise warning if the user passed an explicit compile-config (otherwise, simply change the default without confusing the user)\n",
        "                elif generation_config.compile_config.fullgraph:\n",
        "                    logger.warning_once(\n",
        "                        \"When using Flash Attention 2 and a static cache, you cannot use the option `CompileConfig(fullgraph=True)` as \"\n",
        "                        \"FA2 introduces graph breaks. We overrode the option with `fullgraph=False`.\"\n",
        "                    )\n",
        "                    generation_config.compile_config.fullgraph = False\n",
        "            model_forward = self.get_compiled_call(generation_config.compile_config)\n",
        "\n",
        "        if generation_config.prefill_chunk_size is not None:\n",
        "            model_kwargs = self._prefill_chunking(input_ids, generation_config, **model_kwargs)\n",
        "            is_prefill = False\n",
        "        else:\n",
        "            is_prefill = True\n",
        "\n",
        "        while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n",
        "            # prepare model inputs\n",
        "            model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
        "\n",
        "            # prepare variable output controls (note: some models won't accept all output controls)\n",
        "            model_inputs.update({\"output_attentions\": output_attentions} if output_attentions else {})\n",
        "            model_inputs.update({\"output_hidden_states\": output_hidden_states} if output_hidden_states else {})\n",
        "\n",
        "            if is_prefill:\n",
        "                outputs = self(**model_inputs, return_dict=True)\n",
        "                is_prefill = False\n",
        "            else:\n",
        "                outputs = model_forward(**model_inputs, return_dict=True)\n",
        "\n",
        "            # synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\n",
        "            model_kwargs = self._update_model_kwargs_for_generation(\n",
        "                outputs,\n",
        "                model_kwargs,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "            )\n",
        "            if synced_gpus and this_peer_finished:\n",
        "                continue\n",
        "\n",
        "            # Copy is needed to avoid keeping a hanging ref to outputs.logits which may be very large for first iteration\n",
        "            # (the clone itself is always small)\n",
        "            next_token_logits = outputs.logits[:, -1, :].to(copy=True, dtype=torch.float32, device=input_ids.device)\n",
        "\n",
        "            # pre-process distribution\n",
        "            next_token_scores = logits_processor(input_ids, next_token_logits)\n",
        "\n",
        "            # Store scores, attentions and hidden_states when required\n",
        "            if return_dict_in_generate:\n",
        "                if output_scores:\n",
        "                    scores += (next_token_scores,)\n",
        "                if output_logits:\n",
        "                    raw_logits += (next_token_logits,)\n",
        "                if output_attentions:\n",
        "                    decoder_attentions += (\n",
        "                        (outputs.decoder_attentions,) if self.config.is_encoder_decoder else (outputs.attentions,)\n",
        "                    )\n",
        "                    if self.config.is_encoder_decoder:\n",
        "                        cross_attentions += (outputs.cross_attentions,)\n",
        "\n",
        "                if output_hidden_states:\n",
        "                    decoder_hidden_states += (\n",
        "                        (outputs.decoder_hidden_states,)\n",
        "                        if self.config.is_encoder_decoder\n",
        "                        else (outputs.hidden_states,)\n",
        "                    )\n",
        "\n",
        "            # token selection\n",
        "            if do_sample:\n",
        "                probs = nn.functional.softmax(next_token_scores, dim=-1)\n",
        "                # TODO (joao): this OP throws \"skipping cudagraphs due to ['incompatible ops']\", find solution\n",
        "                next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
        "            else:\n",
        "                next_tokens = torch.argmax(next_token_scores, dim=-1)\n",
        "\n",
        "            # finished sentences should have their next token be a padding token\n",
        "            if has_eos_stopping_criteria:\n",
        "                next_tokens = next_tokens * unfinished_sequences + pad_token_id * (1 - unfinished_sequences)\n",
        "\n",
        "            # update generated ids, model inputs, and length for next step\n",
        "            input_ids = torch.cat([input_ids, next_tokens[:, None]], dim=-1)\n",
        "            if streamer is not None:\n",
        "                streamer.put(next_tokens.cpu())\n",
        "\n",
        "            unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)\n",
        "            this_peer_finished = unfinished_sequences.max() == 0\n",
        "            cur_len += 1\n",
        "\n",
        "            # This is needed to properly delete outputs.logits which may be very large for first iteration\n",
        "            # Otherwise a reference to outputs is kept which keeps the logits alive in the next iteration\n",
        "            del outputs\n",
        "\n",
        "        if streamer is not None:\n",
        "            streamer.end()\n",
        "\n",
        "        if return_dict_in_generate:\n",
        "            if self.config.is_encoder_decoder:\n",
        "                return GenerateEncoderDecoderOutput(\n",
        "                    sequences=input_ids,\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    encoder_attentions=encoder_attentions,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    decoder_attentions=decoder_attentions,\n",
        "                    cross_attentions=cross_attentions,\n",
        "                    decoder_hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "            else:\n",
        "                return GenerateDecoderOnlyOutput(\n",
        "                    sequences=input_ids,\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    attentions=decoder_attentions,\n",
        "                    hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "        else:\n",
        "            return input_ids\n",
        "\n",
        "    @staticmethod\n",
        "    def _flatten_beam_dim(tensor: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"[batch_size, num_beams, ...] -> [batch_size * num_beams, ...]\"\"\"\n",
        "        shape = list(tensor.shape)\n",
        "        return torch.reshape(tensor, [shape[0] * shape[1]] + shape[2:])\n",
        "\n",
        "    @staticmethod\n",
        "    def _unflatten_beam_dim(tensor: torch.Tensor, batch_size: int, num_beams: int) -> torch.Tensor:\n",
        "        \"\"\"[batch_size * num_beams, ...] -> [batch_size, num_beams, ...]\"\"\"\n",
        "        shape = list(tensor.shape)\n",
        "        return torch.reshape(tensor, [batch_size, num_beams] + shape[1:])\n",
        "\n",
        "    @staticmethod\n",
        "    def _gather_beams(tensor: torch.Tensor, beam_indices: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Gathers the beam slices indexed by beam_indices into new beam array.\n",
        "\n",
        "        Args:\n",
        "            tensor (`torch.Tensor`): A tensor containing data to be gathered. The tensor is a 2D or a 3D tensor\n",
        "                with the two first dimensions depicting the batch and the beam dimensions.\n",
        "            beam_indices (`torch.Tensor` of shape `(batch_size, num_beams_to_select)`): The indices of the beams to\n",
        "                select .\n",
        "\n",
        "        Returns:\n",
        "            A tensor with the selected beams\n",
        "        \"\"\"\n",
        "        # `take_along_dim` requires its indices arg to have the same number of dims as `input`\n",
        "        while len(beam_indices.shape) < len(tensor.shape):\n",
        "            beam_indices = beam_indices.unsqueeze(-1)\n",
        "        gathered_tensor = torch.take_along_dim(input=tensor, indices=beam_indices, dim=1)\n",
        "        return gathered_tensor\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_early_stop_heuristic(\n",
        "        is_early_stop_heuristic_unsatisfied: torch.Tensor,\n",
        "        running_beam_scores: torch.Tensor,\n",
        "        beam_scores: torch.Tensor,\n",
        "        is_sent_finished: torch.Tensor,\n",
        "        cur_len: int,\n",
        "        max_length: int,\n",
        "        decoder_prompt_len: int,\n",
        "        early_stopping: Union[bool, str],\n",
        "        length_penalty: float,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Determine whether early stopping is possible by checking if the best possible score of running beams\n",
        "        could still improve upon the finished ones.\n",
        "\n",
        "        Mechanism:\n",
        "        - Without a length penalty, beam scores typically decrease as more tokens are generated.\n",
        "        So, if the *best possible* score from any running beam is already worse than the *worst* finished beam,\n",
        "        we can safely stop early.\n",
        "        - With a length penalty, scores may increase with longer sequences. In this case, we use heuristics\n",
        "        to estimate the best possible score — though this estimate may not always be correct — and stop\n",
        "        if no further improvement seems likely.\n",
        "\n",
        "        We apply different heuristics depending on the value of `early_stopping`:\n",
        "        1. `early_stopping == False`:\n",
        "        -> Use a heuristic that assumes the best score comes from the current length minus the decoder prompt length.\n",
        "        -> See detailed discussion: https://github.com/huggingface/transformers/pull/20901#issuecomment-1369845565\n",
        "\n",
        "        2. `early_stopping == \"never\"`:\n",
        "        -> Estimate the best score using either `max_length` or `cur_len`, depending on the sign of `length_penalty`.\n",
        "        -> A positive length penalty favors longer sequences, so we use `max_length` in that case.\n",
        "\n",
        "        NOTE: the canonical beam search implementation can be replicated with `early_stopping=\"never\"` and\n",
        "        `length_penalty=0.0`, which are NOT the default flags. The default behavior was empirically found to produce\n",
        "        better sequences (prior to 2022), and changing it is BC breaking.\n",
        "        \"\"\"\n",
        "        if early_stopping == \"never\" and length_penalty > 0.0:\n",
        "            best_hypothetical_length = max_length - decoder_prompt_len\n",
        "        else:\n",
        "            best_hypothetical_length = cur_len - decoder_prompt_len\n",
        "        best_possible_running_score = running_beam_scores[:, :1] / (best_hypothetical_length**length_penalty)\n",
        "        worst_finished_score = torch.where(is_sent_finished, torch.min(beam_scores, dim=1, keepdim=True)[0], -1.0e9)\n",
        "        return is_early_stop_heuristic_unsatisfied & torch.any(\n",
        "            best_possible_running_score > worst_finished_score, dim=-1, keepdim=True\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _beam_search_has_unfinished_sequences(\n",
        "        is_early_stop_heuristic_unsatisfied: torch.Tensor,\n",
        "        is_sent_finished: torch.Tensor,\n",
        "        next_token_hits_stopping_criteria: torch.Tensor,\n",
        "        early_stopping: Union[bool, str],\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Beam Search stopping condition -- halts the generation loop if any of these conditions becomes False\n",
        "        \"\"\"\n",
        "        # a. Can the open beams improve the top completed scores?\n",
        "        improvement_possible = torch.any(is_early_stop_heuristic_unsatisfied)\n",
        "\n",
        "        # b. Is there still a beam without fully completed sequences? This is only relevant if early_stopping is\n",
        "        # enabled, where we want to finish as soon as all beams have a completed sequence.\n",
        "        exists_open_beam = ~(torch.all(is_sent_finished) & (early_stopping is True))\n",
        "\n",
        "        # c. Have we hit a stopping criteria with all running sequences and have no way to continue? e.g. we have\n",
        "        # reached `max_length``\n",
        "        valid_continuations = ~torch.all(next_token_hits_stopping_criteria)\n",
        "\n",
        "        return improvement_possible & exists_open_beam & valid_continuations\n",
        "\n",
        "    def _get_top_k_continuations(\n",
        "        self,\n",
        "        accumulated_log_probs: torch.Tensor,\n",
        "        running_sequences: torch.Tensor,\n",
        "        running_beam_indices: torch.Tensor,\n",
        "        cur_len: int,\n",
        "        decoder_prompt_len: int,\n",
        "        do_sample: bool,\n",
        "        beams_to_keep: int,\n",
        "        num_beams: int,\n",
        "        vocab_size: int,\n",
        "        batch_size: int,\n",
        "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Get top-K continuations given the accumulated log probs on the next token.\n",
        "\n",
        "        A few notes to understand what's going on:\n",
        "        1. Each item in batch has `num_beams` * `vocab_size` candidate continuations. For each item, get the\n",
        "        top K [K = (number of EOS tokens + 1) * `num_beams`] candidates with the highest accumulated\n",
        "        log-probabilities, or sample them without replacement using the accumulated scores\n",
        "        2. We gather the top K (as opposed to `num_beams`, or any number lower than K) here so that we have at\n",
        "        least `num_beams` sequences remaining to continue the live beam search.\n",
        "        3. Note that other stopping criteria might result in impossible to continue beams, i.e. all continuations\n",
        "        selected in this step hit the stopping criteria.\n",
        "        \"\"\"\n",
        "        # TODO (joao): This function should take an optional beam scorer function, to manipulate the scores after\n",
        "        # token selection. The function should be an argument exposed, so that custom scoring functions can be\n",
        "        # defined.\n",
        "\n",
        "        # Gather the top K scores from _all_ beams.\n",
        "        if do_sample:\n",
        "            topk_indices = torch.multinomial(\n",
        "                nn.functional.softmax(accumulated_log_probs, dim=-1), num_samples=beams_to_keep\n",
        "            )\n",
        "            topk_log_probs = torch.gather(input=accumulated_log_probs, dim=1, index=topk_indices)\n",
        "        else:\n",
        "            topk_log_probs, topk_indices = torch.topk(accumulated_log_probs, k=beams_to_keep)\n",
        "\n",
        "        # Gather K top beams, recover the beam index by floor division and token id by modulo division\n",
        "        topk_current_beam_indices = topk_indices // vocab_size\n",
        "        topk_running_beam_indices = self._gather_beams(running_beam_indices, topk_current_beam_indices)\n",
        "        topk_running_sequences = self._gather_beams(running_sequences, topk_current_beam_indices)\n",
        "        topk_ids = topk_indices % vocab_size\n",
        "\n",
        "        # Update sequences for the K top-k new sequences.\n",
        "        topk_running_sequences[:, :, cur_len] = topk_ids\n",
        "\n",
        "        # we want to store the beam indices with batch information -> real beam index = beam index % num beams\n",
        "        batch_offset = torch.arange(batch_size, device=topk_ids.device).view(-1, 1) * num_beams\n",
        "        batch_modified_indices = topk_current_beam_indices + batch_offset\n",
        "        topk_running_beam_indices[:, :, cur_len - decoder_prompt_len] = batch_modified_indices\n",
        "\n",
        "        return topk_log_probs, topk_running_sequences, topk_running_beam_indices\n",
        "\n",
        "    def _get_running_beams_for_next_iteration(\n",
        "        self,\n",
        "        topk_log_probs: torch.Tensor,\n",
        "        topk_running_sequences: torch.Tensor,\n",
        "        topk_running_beam_indices: torch.Tensor,\n",
        "        next_token_hits_stopping_criteria: torch.Tensor,\n",
        "        num_beams: int,\n",
        "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Given the top-K continuations, their scores, and whether they hit a stopping criteria, select the\n",
        "        best non-finished beams to continue beam search in the next iteration.\n",
        "        \"\"\"\n",
        "        # To prevent these just finished sequences from being used in subsequent iterations, set their log probs\n",
        "        # to a very large negative value\n",
        "        topk_running_log_probs = topk_log_probs + next_token_hits_stopping_criteria.to(torch.float32) * -1.0e9\n",
        "\n",
        "        next_topk_indices = torch.topk(topk_running_log_probs, k=num_beams)[1]\n",
        "        running_sequences = self._gather_beams(topk_running_sequences, next_topk_indices)\n",
        "        running_beam_scores = self._gather_beams(topk_running_log_probs, next_topk_indices)\n",
        "        running_beam_indices = self._gather_beams(topk_running_beam_indices, next_topk_indices)\n",
        "        return running_sequences, running_beam_scores, running_beam_indices\n",
        "\n",
        "    def _update_finished_beams(\n",
        "        self,\n",
        "        sequences: torch.Tensor,\n",
        "        topk_running_sequences: torch.Tensor,\n",
        "        beam_scores: torch.Tensor,\n",
        "        topk_log_probs: torch.Tensor,\n",
        "        beam_indices: torch.Tensor,\n",
        "        topk_running_beam_indices: torch.Tensor,\n",
        "        is_early_stop_heuristic_unsatisfied: torch.Tensor,\n",
        "        is_sent_finished: torch.Tensor,\n",
        "        next_token_hits_stopping_criteria: torch.Tensor,\n",
        "        top_num_beam_mask: torch.Tensor,\n",
        "        num_beams: int,\n",
        "        cur_len: int,\n",
        "        decoder_prompt_len: int,\n",
        "        length_penalty: float,\n",
        "        early_stopping: Union[bool, str],\n",
        "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Updates the finished beams if (and only if) there are new completed sequences that have a higher score than\n",
        "        the current finished sequences.\n",
        "        \"\"\"\n",
        "        # Only the top `num_beam` sequences can be considered for the final returned sequences. Remember: the\n",
        "        # remaining sequences only exist as a backup to ensure that we have at least `num_beams` sequences to\n",
        "        # continue.\n",
        "        did_top_num_beams_just_finished = next_token_hits_stopping_criteria & top_num_beam_mask[None, :]\n",
        "\n",
        "        # Further process topk logits for the finished beams\n",
        "        # - add length penalty\n",
        "        topk_log_probs = topk_log_probs / ((cur_len + 1 - decoder_prompt_len) ** length_penalty)\n",
        "        # - make sure no scores can be added anymore if beam is full and early stopping is on\n",
        "        beams_in_batch_are_full = torch.all(is_sent_finished, axis=-1, keepdims=True) & (early_stopping is True)\n",
        "        topk_log_probs += beams_in_batch_are_full.to(torch.float32) * -1.0e9\n",
        "        # - make sure no scores can be added anymore if improvement is not possible\n",
        "        topk_log_probs += (~is_early_stop_heuristic_unsatisfied).to(torch.float32) * -1.0e9\n",
        "\n",
        "        # - make sure still running sequences cannot be chosen as finalized beam\n",
        "        topk_log_probs += (~did_top_num_beams_just_finished) * -1.0e9\n",
        "\n",
        "        # Get finalized  `num_beam` sequences for the next generation step -- combine the previous finalized\n",
        "        # data with the new finalized sequences (if any, non-finalized sequences have a very large negative score\n",
        "        # in this step), and keep the best `num_beams` sequences.\n",
        "        merged_sequences = torch.cat((sequences, topk_running_sequences), dim=1)\n",
        "        merged_scores = torch.cat((beam_scores, topk_log_probs), dim=1)\n",
        "        merged_beam_indices = torch.cat((beam_indices, topk_running_beam_indices), dim=1)\n",
        "        merged_is_sent_finished = torch.cat((is_sent_finished, did_top_num_beams_just_finished), dim=1)\n",
        "        topk_merged_indices = torch.topk(merged_scores, k=num_beams)[1]\n",
        "        sequences = self._gather_beams(merged_sequences, topk_merged_indices)\n",
        "        beam_scores = self._gather_beams(merged_scores, topk_merged_indices)\n",
        "        beam_indices = self._gather_beams(merged_beam_indices, topk_merged_indices)\n",
        "        is_sent_finished = self._gather_beams(merged_is_sent_finished, topk_merged_indices)\n",
        "        return sequences, beam_scores, beam_indices, is_sent_finished\n",
        "\n",
        "    # end of auxiliary functions for beam search\n",
        "\n",
        "    def _beam_search(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        logits_processor: LogitsProcessorList,\n",
        "        stopping_criteria: StoppingCriteriaList,\n",
        "        generation_config: GenerationConfig,\n",
        "        synced_gpus: bool,\n",
        "        **model_kwargs,\n",
        "    ) -> Union[GenerateBeamOutput, torch.LongTensor]:\n",
        "        r\"\"\"\n",
        "        Generates sequences of token ids for models with a language modeling head using **beam search decoding** and\n",
        "        can be used for text-decoder, text-to-text, speech-to-text, and vision-to-text models.\n",
        "\n",
        "        If it's the first time you're diving into Beam Search, we recommend you read the following blog post:\n",
        "        https://huggingface.co/blog/how-to-generate (especially the beam search section).\n",
        "\n",
        "        You can recompute the sequence scores from the individual scores using the `compute_transition_scores` function\n",
        "        (https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationMixin.compute_transition_scores)\n",
        "\n",
        "        Parameters:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size*num_beams, sequence_length)`):\n",
        "                The sequence used as a prompt for the generation.\n",
        "            logits_processor (`LogitsProcessorList`):\n",
        "                An instance of [`LogitsProcessorList`]. List of instances of class derived from [`LogitsProcessor`]\n",
        "                used to modify the prediction scores of the language modeling head applied at each generation step.\n",
        "            stopping_criteria (`StoppingCriteriaList`:\n",
        "                An instance of [`StoppingCriteriaList`]. List of instances of class derived from [`StoppingCriteria`]\n",
        "                used to tell if the generation loop should stop.\n",
        "            generation_config ([`~generation.GenerationConfig`]):\n",
        "                The generation configuration to be used as parametrization of the decoding method.\n",
        "            synced_gpus (`bool`):\n",
        "                Whether to continue running the while loop until max_length (needed to avoid deadlocking with\n",
        "                `FullyShardedDataParallel` and DeepSpeed ZeRO Stage 3).\n",
        "            model_kwargs:\n",
        "                Additional model specific kwargs will be forwarded to the `forward` function of the model. If model is\n",
        "                an encoder-decoder model the kwargs should include `encoder_outputs`.\n",
        "\n",
        "        Return:\n",
        "            [`generation.GenerateBeamDecoderOnlyOutput`], [`~generation.GenerateBeamEncoderDecoderOutput`] or\n",
        "            `torch.LongTensor`: A `torch.LongTensor` containing the generated tokens (default behaviour) or a\n",
        "            [`~generation.GenerateBeamDecoderOnlyOutput`] if `model.config.is_encoder_decoder=False` and\n",
        "            `return_dict_in_generate=True` or a [`~generation.GenerateBeamEncoderDecoderOutput`] if\n",
        "            `model.config.is_encoder_decoder=True`.\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. init beam_search values\n",
        "        pad_token_id = generation_config._pad_token_tensor\n",
        "        eos_token_id = generation_config._eos_token_tensor\n",
        "        output_attentions = generation_config.output_attentions\n",
        "        output_hidden_states = generation_config.output_hidden_states\n",
        "        output_scores = generation_config.output_scores\n",
        "        output_logits = generation_config.output_logits\n",
        "        return_dict_in_generate = generation_config.return_dict_in_generate\n",
        "        do_sample = generation_config.do_sample\n",
        "        early_stopping = generation_config.early_stopping\n",
        "        length_penalty = generation_config.length_penalty\n",
        "        max_length = generation_config.max_length\n",
        "        num_beams = generation_config.num_beams\n",
        "        num_return_sequences = generation_config.num_return_sequences\n",
        "\n",
        "        batch_size_unflattened, cur_len = input_ids.shape[:2]\n",
        "        batch_size = batch_size_unflattened // num_beams\n",
        "        # TODO (joao): standardize special cases\n",
        "        if self.__class__.__name__ == \"MoshiDepthDecoder\":\n",
        "            vocab_size = self.config.audio_vocab_size\n",
        "        elif self.__class__.__name__ == \"ImageGPTForCausalImageModeling\":\n",
        "            vocab_size = self.get_output_embeddings().out_features\n",
        "        else:\n",
        "            vocab_size = self.config.get_text_config().vocab_size\n",
        "        decoder_prompt_len = cur_len\n",
        "        this_peer_finished = False\n",
        "\n",
        "        # At each beam search step, we want to keep top K [K = (number of EOS tokens + 1) * `num_beams`] candidates\n",
        "        # with the highest log-probabilities, or sample K continuations without replacement. We gather the top K\n",
        "        # (as opposed to `num_beams`, or any number lower than K) so that we have at least `num_beams` sequences\n",
        "        # non-finished to continue the live beam search, in case the top `num_beams` all select an EOS token.\n",
        "        n_eos_tokens = eos_token_id.shape[0] if eos_token_id is not None else 0\n",
        "        beams_to_keep = max(2, 1 + n_eos_tokens) * num_beams\n",
        "        top_num_beam_mask = torch.cat(\n",
        "            (torch.ones((num_beams), dtype=torch.bool), torch.zeros((beams_to_keep - num_beams), dtype=torch.bool)),\n",
        "            dim=0,\n",
        "        ).to(input_ids.device)\n",
        "\n",
        "        model_kwargs = self._get_initial_cache_position(cur_len, input_ids.device, model_kwargs)\n",
        "\n",
        "        # (joao) feature lost in the refactor. Probably won't implement, hurts readability with minimal gains (there\n",
        "        # are newer low-memory alternatives like the offloaded cache)\n",
        "        sequential = generation_config.low_memory\n",
        "        if sequential:\n",
        "            raise ValueError(\n",
        "                \"`low_memory=True` is not supported after the beam search refactor. Please check the discussion in \"\n",
        "                \"#35802 *after the PR got merged*, and add a comment there if your questions are not yet answered.\"\n",
        "            )\n",
        "\n",
        "        # 2. init output tuples\n",
        "        all_scores = () if (return_dict_in_generate and output_scores) else None\n",
        "        raw_logits = () if (return_dict_in_generate and output_logits) else None\n",
        "        beam_indices = () if (return_dict_in_generate and output_logits) else None\n",
        "        decoder_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        cross_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        decoder_hidden_states = () if (return_dict_in_generate and output_hidden_states) else None\n",
        "\n",
        "        # if model is an encoder-decoder, retrieve encoder attention weights and hidden states\n",
        "        if return_dict_in_generate and self.config.is_encoder_decoder:\n",
        "            encoder_attentions = model_kwargs[\"encoder_outputs\"].get(\"attentions\") if output_attentions else None\n",
        "            encoder_hidden_states = (\n",
        "                model_kwargs[\"encoder_outputs\"].get(\"hidden_states\") if output_hidden_states else None\n",
        "            )\n",
        "\n",
        "        # 3. init running tensors and static-shaped placeholders\n",
        "\n",
        "        # per batch, beam-item holding current token in loop and completed sequences\n",
        "        output_fill_value = pad_token_id or eos_token_id[0] if eos_token_id is not None else -1\n",
        "        running_sequences = torch.full(\n",
        "            (batch_size, num_beams, max_length),\n",
        "            fill_value=output_fill_value,\n",
        "            dtype=torch.int64,\n",
        "            device=input_ids.device,\n",
        "        )\n",
        "        running_sequences[:, :, :cur_len] = self._unflatten_beam_dim(input_ids, batch_size, num_beams)\n",
        "        sequences = running_sequences.detach().clone()\n",
        "\n",
        "        # per batch, beam-item score, logprobs\n",
        "        # initialise score of first beam with 0 and the rest with -1e9. This makes sure that only tokens\n",
        "        # of the first beam are considered to avoid sampling the exact same tokens across all beams.\n",
        "        running_beam_scores = torch.zeros((batch_size, num_beams), dtype=torch.float, device=input_ids.device)\n",
        "        running_beam_scores[:, 1:] = -1e9\n",
        "        beam_scores = torch.full((batch_size, num_beams), fill_value=-1e9, dtype=torch.float, device=input_ids.device)\n",
        "\n",
        "        # per batch, beam-item state bit indicating if sentence has finished.\n",
        "        is_sent_finished = torch.zeros((batch_size, num_beams), dtype=torch.bool, device=input_ids.device)\n",
        "\n",
        "        # per batch state bit indicating if there is a possibility to improve the best finished sentence.\n",
        "        is_early_stop_heuristic_unsatisfied = torch.ones((batch_size, 1), dtype=torch.bool, device=input_ids.device)\n",
        "\n",
        "        # per batch, beam-item state bit indicating if there are valid continuations.\n",
        "        next_token_hits_stopping_criteria = torch.zeros(\n",
        "            (batch_size, num_beams), dtype=torch.bool, device=input_ids.device\n",
        "        )\n",
        "\n",
        "        # per batch selected beam indices\n",
        "        running_beam_indices = torch.full(\n",
        "            (batch_size, num_beams, max_length - cur_len), fill_value=-1, dtype=torch.int32, device=input_ids.device\n",
        "        )\n",
        "        beam_indices = running_beam_indices.detach().clone()\n",
        "\n",
        "        # 4. run the generation loop\n",
        "        while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n",
        "            # a. Forward current tokens, obtain the logits\n",
        "            flat_running_sequences = self._flatten_beam_dim(running_sequences[:, :, :cur_len])\n",
        "            model_inputs = self.prepare_inputs_for_generation(flat_running_sequences, **model_kwargs)\n",
        "\n",
        "            # prepare variable output controls (note: some models won't accept all output controls)\n",
        "            model_inputs.update({\"output_attentions\": output_attentions} if output_attentions else {})\n",
        "            model_inputs.update({\"output_hidden_states\": output_hidden_states} if output_hidden_states else {})\n",
        "\n",
        "            model_outputs = self(**model_inputs, return_dict=True)\n",
        "\n",
        "            # synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\n",
        "            model_kwargs = self._update_model_kwargs_for_generation(\n",
        "                model_outputs,\n",
        "                model_kwargs,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "            )\n",
        "            if synced_gpus and this_peer_finished:\n",
        "                continue\n",
        "\n",
        "            # Copy is needed to avoid keeping a hanging ref\n",
        "            logits = model_outputs.logits[:, -1, :].to(copy=True, dtype=torch.float32, device=input_ids.device)\n",
        "\n",
        "            # b. Compute log probs -- get log probabilities from logits, process logits with processors (*e.g.*\n",
        "            # `temperature`, ...), and add new logprobs to existing running logprobs scores.\n",
        "            log_probs = nn.functional.log_softmax(logits, dim=-1)\n",
        "            log_probs = logits_processor(flat_running_sequences, log_probs)\n",
        "\n",
        "            # Store logits, attentions and hidden_states when required\n",
        "            if return_dict_in_generate:\n",
        "                if output_logits:\n",
        "                    raw_logits += (logits.clone(),)\n",
        "                if return_dict_in_generate and output_scores:\n",
        "                    all_scores += (log_probs.clone(),)\n",
        "\n",
        "                if output_attentions:\n",
        "                    decoder_attentions += (\n",
        "                        (model_outputs.decoder_attentions,)\n",
        "                        if self.config.is_encoder_decoder\n",
        "                        else (model_outputs.attentions,)\n",
        "                    )\n",
        "                    if self.config.is_encoder_decoder:\n",
        "                        cross_attentions += (model_outputs.cross_attentions,)\n",
        "\n",
        "                if output_hidden_states:\n",
        "                    decoder_hidden_states += (\n",
        "                        (model_outputs.decoder_hidden_states,)\n",
        "                        if self.config.is_encoder_decoder\n",
        "                        else (model_outputs.hidden_states,)\n",
        "                    )\n",
        "\n",
        "            # This is needed to properly delete logits which may be very large for first iteration\n",
        "            # Otherwise a reference to outputs is kept which keeps the logits alive in the next iteration\n",
        "            del model_outputs\n",
        "\n",
        "            log_probs = self._unflatten_beam_dim(log_probs, batch_size, num_beams)\n",
        "            log_probs = log_probs + running_beam_scores[:, :, None]\n",
        "            log_probs = torch.reshape(log_probs, (batch_size, num_beams * vocab_size))\n",
        "\n",
        "            # c. Retrieve top-K continuations, i.e. select the next token (greedy or sampling) and then keep the best\n",
        "            # continuations among all beams based on the accumulated scores.\n",
        "            topk_log_probs, topk_running_sequences, topk_running_beam_indices = self._get_top_k_continuations(\n",
        "                accumulated_log_probs=log_probs,\n",
        "                running_sequences=running_sequences,\n",
        "                running_beam_indices=running_beam_indices,\n",
        "                cur_len=cur_len,\n",
        "                decoder_prompt_len=decoder_prompt_len,\n",
        "                do_sample=do_sample,\n",
        "                beams_to_keep=beams_to_keep,\n",
        "                num_beams=num_beams,\n",
        "                vocab_size=vocab_size,\n",
        "                batch_size=batch_size,\n",
        "            )\n",
        "\n",
        "            # d. Check which running sequences have finished\n",
        "            next_token_hits_stopping_criteria = stopping_criteria(\n",
        "                self._flatten_beam_dim(topk_running_sequences[:, :, : cur_len + 1]),  # remove unfilled token indexes\n",
        "                all_scores,\n",
        "            )\n",
        "            next_token_hits_stopping_criteria = self._unflatten_beam_dim(\n",
        "                next_token_hits_stopping_criteria, batch_size, beams_to_keep\n",
        "            )\n",
        "\n",
        "            # e. Get the non-finished running `num_beams` sequences for the next generation step\n",
        "            running_sequences, running_beam_scores, running_beam_indices = self._get_running_beams_for_next_iteration(\n",
        "                topk_log_probs=topk_log_probs,\n",
        "                topk_running_sequences=topk_running_sequences,\n",
        "                topk_running_beam_indices=topk_running_beam_indices,\n",
        "                next_token_hits_stopping_criteria=next_token_hits_stopping_criteria,\n",
        "                num_beams=num_beams,\n",
        "            )\n",
        "\n",
        "            # f. Update the completed beams if a new high score in a finished sequence is found\n",
        "            sequences, beam_scores, beam_indices, is_sent_finished = self._update_finished_beams(\n",
        "                sequences=sequences,\n",
        "                topk_running_sequences=topk_running_sequences,\n",
        "                beam_scores=beam_scores,\n",
        "                topk_log_probs=topk_log_probs,\n",
        "                beam_indices=beam_indices,\n",
        "                topk_running_beam_indices=topk_running_beam_indices,\n",
        "                is_early_stop_heuristic_unsatisfied=is_early_stop_heuristic_unsatisfied,\n",
        "                is_sent_finished=is_sent_finished,\n",
        "                next_token_hits_stopping_criteria=next_token_hits_stopping_criteria,\n",
        "                top_num_beam_mask=top_num_beam_mask,\n",
        "                num_beams=num_beams,\n",
        "                cur_len=cur_len,\n",
        "                decoder_prompt_len=decoder_prompt_len,\n",
        "                length_penalty=length_penalty,\n",
        "                early_stopping=early_stopping,\n",
        "            )\n",
        "\n",
        "            # g. Prepare remaining data for the next iteration, including computing the stopping condition for\n",
        "            # beam search as a whole (as opposed to individual beams, i.e. `stopping_criteria`)\n",
        "\n",
        "            # pluck the cache from the beam indices that will be used in the next iteration\n",
        "            # NOTE: we need to check if `self._reorder_cache` exists for special models like RAG, RecurrentGemma etc.\n",
        "            if model_kwargs.get(\"past_key_values\", None) is not None:\n",
        "                beam_idx = self._flatten_beam_dim(running_beam_indices[..., cur_len - decoder_prompt_len])\n",
        "                if hasattr(self, \"_reorder_cache\"):\n",
        "                    model_kwargs[\"past_key_values\"] = self._reorder_cache(model_kwargs[\"past_key_values\"], beam_idx)\n",
        "                else:\n",
        "                    model_kwargs[\"past_key_values\"].reorder_cache(beam_idx)\n",
        "\n",
        "            cur_len = cur_len + 1\n",
        "            is_early_stop_heuristic_unsatisfied = self._check_early_stop_heuristic(\n",
        "                is_early_stop_heuristic_unsatisfied=is_early_stop_heuristic_unsatisfied,\n",
        "                running_beam_scores=running_beam_scores,\n",
        "                beam_scores=beam_scores,\n",
        "                is_sent_finished=is_sent_finished,\n",
        "                cur_len=cur_len,\n",
        "                max_length=max_length,\n",
        "                decoder_prompt_len=decoder_prompt_len,\n",
        "                early_stopping=early_stopping,\n",
        "                length_penalty=length_penalty,\n",
        "            )\n",
        "            this_peer_finished = not self._beam_search_has_unfinished_sequences(\n",
        "                is_early_stop_heuristic_unsatisfied,\n",
        "                is_sent_finished,\n",
        "                next_token_hits_stopping_criteria,\n",
        "                early_stopping,\n",
        "            )\n",
        "\n",
        "        # 5. prepare outputs\n",
        "        # Take best beams for each batch (the score is sorted in descending order)\n",
        "        sequences = self._flatten_beam_dim(sequences[:, :num_return_sequences, :])\n",
        "        beam_scores = self._flatten_beam_dim(beam_scores[:, :num_return_sequences])\n",
        "        beam_indices = self._flatten_beam_dim(beam_indices[:, :num_return_sequences, :])\n",
        "\n",
        "        # Crop the static-shaped tensors to the actual size.\n",
        "        # `beam_indices` is initialized with -1s, and is updated with the beam index of the generated token at each\n",
        "        # step. We can use it to detect the generated length, which may be != `cur_len`  (e.g. selected beam is from a\n",
        "        # previous decoding iteration)\n",
        "        max_generated_length = ((beam_indices + 1).bool()).sum(dim=1).max()\n",
        "        output_length = decoder_prompt_len + max_generated_length\n",
        "        sequences = sequences[:, :output_length]\n",
        "        beam_indices = beam_indices[:, :max_generated_length]\n",
        "\n",
        "        if return_dict_in_generate:\n",
        "            if not output_scores:\n",
        "                beam_scores = None\n",
        "\n",
        "            if self.config.is_encoder_decoder:\n",
        "                return GenerateBeamEncoderDecoderOutput(\n",
        "                    sequences=sequences,\n",
        "                    sequences_scores=beam_scores,\n",
        "                    scores=all_scores,\n",
        "                    logits=raw_logits,\n",
        "                    beam_indices=beam_indices,\n",
        "                    encoder_attentions=encoder_attentions,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    decoder_attentions=decoder_attentions,\n",
        "                    cross_attentions=cross_attentions,\n",
        "                    decoder_hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "            else:\n",
        "                return GenerateBeamDecoderOnlyOutput(\n",
        "                    sequences=sequences,\n",
        "                    sequences_scores=beam_scores,\n",
        "                    scores=all_scores,\n",
        "                    logits=raw_logits,\n",
        "                    beam_indices=beam_indices,\n",
        "                    attentions=decoder_attentions,\n",
        "                    hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "        else:\n",
        "            return sequences\n",
        "\n",
        "    def _group_beam_search(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        beam_scorer: BeamScorer,\n",
        "        logits_processor: LogitsProcessorList,\n",
        "        stopping_criteria: StoppingCriteriaList,\n",
        "        generation_config: GenerationConfig,\n",
        "        synced_gpus: bool,\n",
        "        **model_kwargs,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        Generates sequences of token ids for models with a language modeling head using **diverse beam search\n",
        "        decoding** and can be used for text-decoder, text-to-text, speech-to-text, and vision-to-text models.\n",
        "\n",
        "        Parameters:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size*num_beams, sequence_length)`):\n",
        "                The sequence used as a prompt for the generation.\n",
        "            beam_scorer (`BeamScorer`):\n",
        "                An derived instance of [`BeamScorer`] that defines how beam hypotheses are constructed, stored and\n",
        "                sorted during generation. For more information, the documentation of [`BeamScorer`] should be read.\n",
        "            logits_processor (`LogitsProcessorList`):\n",
        "                An instance of [`LogitsProcessorList`]. List of instances of class derived from [`LogitsProcessor`]\n",
        "                used to modify the prediction scores of the language modeling head applied at each generation step.\n",
        "            stopping_criteria (`StoppingCriteriaList`):\n",
        "                An instance of [`StoppingCriteriaList`]. List of instances of class derived from [`StoppingCriteria`]\n",
        "                used to tell if the generation loop should stop.\n",
        "            generation_config ([`~generation.GenerationConfig`]):\n",
        "                The generation configuration to be used as parametrization of the decoding method.\n",
        "            synced_gpus (`bool`):\n",
        "                Whether to continue running the while loop until max_length (needed to avoid deadlocking with\n",
        "                `FullyShardedDataParallel` and DeepSpeed ZeRO Stage 3).\n",
        "            model_kwargs:\n",
        "                Additional model specific kwargs that will be forwarded to the `forward` function of the model. If\n",
        "                model is an encoder-decoder model the kwargs should include `encoder_outputs`.\n",
        "\n",
        "        Return:\n",
        "            [`~generation.GenerateBeamDecoderOnlyOutput`], [`~generation.GenerateBeamEncoderDecoderOutput`] or\n",
        "            `torch.LongTensor`: A `torch.LongTensor` containing the generated tokens (default behaviour) or a\n",
        "            [`~generation.GenerateBeamDecoderOnlyOutput`] if `model.config.is_encoder_decoder=False` and\n",
        "            `return_dict_in_generate=True` or a [`~generation.GenerateBeamEncoderDecoderOutput`] if\n",
        "            `model.config.is_encoder_decoder=True`.\n",
        "        \"\"\"\n",
        "        # init values\n",
        "        pad_token_id = generation_config._pad_token_tensor\n",
        "        eos_token_id = generation_config._eos_token_tensor\n",
        "        output_attentions = generation_config.output_attentions\n",
        "        output_hidden_states = generation_config.output_hidden_states\n",
        "        output_scores = generation_config.output_scores\n",
        "        output_logits = generation_config.output_logits\n",
        "        return_dict_in_generate = generation_config.return_dict_in_generate\n",
        "\n",
        "        num_beams = beam_scorer.num_beams\n",
        "        num_beam_groups = beam_scorer.num_beam_groups\n",
        "        num_sub_beams = num_beams // num_beam_groups\n",
        "        batch_size = len(beam_scorer._beam_hyps) // num_beam_groups\n",
        "        device = input_ids.device\n",
        "\n",
        "        batch_beam_size, cur_len = input_ids.shape\n",
        "        model_kwargs = self._get_initial_cache_position(cur_len, input_ids.device, model_kwargs)\n",
        "\n",
        "        if return_dict_in_generate and output_scores:\n",
        "            beam_indices = [tuple(() for _ in range(num_sub_beams * batch_size)) for _ in range(num_beam_groups)]\n",
        "        else:\n",
        "            beam_indices = None\n",
        "\n",
        "        if num_beams * batch_size != batch_beam_size:\n",
        "            raise ValueError(\n",
        "                f\"Batch dimension of `input_ids` should be {num_beams * batch_size}, but is {batch_beam_size}.\"\n",
        "            )\n",
        "\n",
        "        # init attention / hidden states / scores tuples\n",
        "        scores = () if (return_dict_in_generate and output_scores) else None\n",
        "        raw_logits = () if (return_dict_in_generate and output_logits) else None\n",
        "        decoder_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        cross_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        decoder_hidden_states = () if (return_dict_in_generate and output_hidden_states) else None\n",
        "\n",
        "        # if model is an encoder-decoder, retrieve encoder attention weights and hidden states\n",
        "        if return_dict_in_generate and self.config.is_encoder_decoder:\n",
        "            encoder_attentions = model_kwargs[\"encoder_outputs\"].get(\"attentions\") if output_attentions else None\n",
        "            encoder_hidden_states = (\n",
        "                model_kwargs[\"encoder_outputs\"].get(\"hidden_states\") if output_hidden_states else None\n",
        "            )\n",
        "\n",
        "        # initialise score of first beam of each group with 0 and the rest with -1e9. This ensures that the beams in\n",
        "        # the same group don't produce same tokens every time.\n",
        "        beam_scores = torch.full((batch_size, num_beams), -1e9, dtype=torch.float, device=device)\n",
        "        beam_scores[:, ::num_sub_beams] = 0\n",
        "        beam_scores = beam_scores.view((batch_size * num_beams,))\n",
        "\n",
        "        this_peer_finished = False\n",
        "\n",
        "        decoder_prompt_len = input_ids.shape[1]  # record the prompt length of decoder\n",
        "        while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n",
        "            # predicted tokens in cur_len step\n",
        "            current_tokens = torch.zeros(batch_size * num_beams, dtype=input_ids.dtype, device=device)\n",
        "\n",
        "            # indices which will form the beams in the next time step\n",
        "            reordering_indices = torch.zeros(batch_size * num_beams, dtype=torch.long, device=device)\n",
        "\n",
        "            # do one decoder step on all beams of all sentences in batch\n",
        "            model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
        "\n",
        "            # prepare variable output controls (note: some models won't accept all output controls)\n",
        "            model_inputs.update({\"output_attentions\": output_attentions} if output_attentions else {})\n",
        "            model_inputs.update({\"output_hidden_states\": output_hidden_states} if output_hidden_states else {})\n",
        "\n",
        "            outputs = self(**model_inputs, return_dict=True)\n",
        "\n",
        "            # synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\n",
        "            model_kwargs = self._update_model_kwargs_for_generation(\n",
        "                outputs,\n",
        "                model_kwargs,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "            )\n",
        "            if synced_gpus and this_peer_finished:\n",
        "                cur_len = cur_len + 1\n",
        "                continue\n",
        "\n",
        "            if output_scores:\n",
        "                processed_score = torch.zeros_like(outputs.logits[:, -1, :])\n",
        "            if output_logits:\n",
        "                # Copy is needed to avoid keeping a hanging ref to outputs.logits which may be very large for first iteration\n",
        "                # (the clone itself is always small)\n",
        "                raw_logit_score = outputs.logits[:, -1, :].to(copy=True, device=input_ids.device)\n",
        "\n",
        "            for beam_group_idx in range(num_beam_groups):\n",
        "                group_start_idx = beam_group_idx * num_sub_beams\n",
        "                group_end_idx = min(group_start_idx + num_sub_beams, num_beams)\n",
        "                group_size = group_end_idx - group_start_idx\n",
        "\n",
        "                # indices of beams of current group among all sentences in batch\n",
        "                batch_group_indices = []\n",
        "\n",
        "                for batch_idx in range(batch_size):\n",
        "                    batch_group_indices.extend(\n",
        "                        [batch_idx * num_beams + idx for idx in range(group_start_idx, group_end_idx)]\n",
        "                    )\n",
        "                group_input_ids = input_ids[batch_group_indices]\n",
        "\n",
        "                # select outputs of beams of current group only\n",
        "                # No need to clone() the logits here as they will not retain outputs.logits at the end of the loop\n",
        "                # .float() is needed to retain precision for later logits manipulations\n",
        "                next_token_logits = outputs.logits[batch_group_indices, -1, :].to(\n",
        "                    dtype=torch.float32, device=input_ids.device\n",
        "                )\n",
        "\n",
        "                next_token_scores = nn.functional.log_softmax(\n",
        "                    next_token_logits, dim=-1\n",
        "                )  # (batch_size * group_size, vocab_size)\n",
        "                vocab_size = next_token_scores.shape[-1]\n",
        "\n",
        "                next_token_scores_processed = logits_processor(\n",
        "                    group_input_ids, next_token_scores, current_tokens=current_tokens, beam_group_idx=beam_group_idx\n",
        "                )\n",
        "                next_token_scores = next_token_scores_processed + beam_scores[batch_group_indices].unsqueeze(-1)\n",
        "                next_token_scores = next_token_scores.expand_as(next_token_scores_processed)\n",
        "\n",
        "                if output_scores:\n",
        "                    processed_score[batch_group_indices] = next_token_scores_processed\n",
        "\n",
        "                # reshape for beam search\n",
        "                next_token_scores = next_token_scores.view(batch_size, group_size * vocab_size)\n",
        "\n",
        "                # Sample 1 + len(eos_token_id) next tokens for each beam so we have at least 1 non eos token per beam.\n",
        "                n_eos_tokens = eos_token_id.shape[0] if eos_token_id is not None else 0\n",
        "                next_token_scores, next_tokens = torch.topk(\n",
        "                    next_token_scores, max(2, 1 + n_eos_tokens) * group_size, dim=1, largest=True, sorted=True\n",
        "                )\n",
        "\n",
        "                next_indices = torch.div(next_tokens, vocab_size, rounding_mode=\"floor\")\n",
        "                next_tokens = next_tokens % vocab_size\n",
        "\n",
        "                # stateless\n",
        "                process_beam_indices = sum(beam_indices, ()) if beam_indices is not None else None\n",
        "                beam_outputs = beam_scorer.process(\n",
        "                    group_input_ids,\n",
        "                    next_token_scores,\n",
        "                    next_tokens,\n",
        "                    next_indices,\n",
        "                    pad_token_id=pad_token_id,\n",
        "                    eos_token_id=eos_token_id,\n",
        "                    beam_indices=process_beam_indices,\n",
        "                    group_index=beam_group_idx,\n",
        "                    decoder_prompt_len=decoder_prompt_len,\n",
        "                )\n",
        "                beam_scores[batch_group_indices] = beam_outputs[\"next_beam_scores\"]\n",
        "                beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
        "                beam_idx = beam_outputs[\"next_beam_indices\"]\n",
        "\n",
        "                if return_dict_in_generate and output_scores:\n",
        "                    beam_indices[beam_group_idx] = tuple(\n",
        "                        beam_indices[beam_group_idx][beam_idx[i]] + (beam_idx[i],) for i in range(len(beam_indices[0]))\n",
        "                    )\n",
        "\n",
        "                input_ids[batch_group_indices] = group_input_ids[beam_idx]\n",
        "                group_input_ids = torch.cat([group_input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
        "                current_tokens[batch_group_indices] = group_input_ids[:, -1]\n",
        "\n",
        "                # (beam_idx // group_size) -> batch_idx\n",
        "                # (beam_idx % group_size) -> offset of idx inside the group\n",
        "                reordering_indices[batch_group_indices] = (\n",
        "                    num_beams * torch.div(beam_idx, group_size, rounding_mode=\"floor\")\n",
        "                    + group_start_idx\n",
        "                    + (beam_idx % group_size)\n",
        "                )\n",
        "\n",
        "            # Store scores, attentions and hidden_states when required\n",
        "            if return_dict_in_generate:\n",
        "                if output_scores:\n",
        "                    scores += (processed_score,)\n",
        "                if output_logits:\n",
        "                    raw_logits += (raw_logit_score,)\n",
        "                if output_attentions:\n",
        "                    decoder_attentions += (\n",
        "                        (outputs.decoder_attentions,) if self.config.is_encoder_decoder else (outputs.attentions,)\n",
        "                    )\n",
        "                    if self.config.is_encoder_decoder:\n",
        "                        cross_attentions += (outputs.cross_attentions,)\n",
        "\n",
        "                if output_hidden_states:\n",
        "                    decoder_hidden_states += (\n",
        "                        (outputs.decoder_hidden_states,)\n",
        "                        if self.config.is_encoder_decoder\n",
        "                        else (outputs.hidden_states,)\n",
        "                    )\n",
        "\n",
        "            input_ids = torch.cat([input_ids, current_tokens.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "            # This is needed to properly delete outputs.logits which may be very large for first iteration\n",
        "            # Otherwise a reference to outputs is kept which keeps the logits alive in the next iteration\n",
        "            # IMPORTANT: Note that this should appear BEFORE the call to _reorder_cache() to save the maximum memory\n",
        "            # (that way the memory peak does not include outputs.logits)\n",
        "            del outputs\n",
        "\n",
        "            # NOTE: we need to check if `self._reorder_cache` exists for special models like RAG, RecurrentGemma etc.\n",
        "            if model_kwargs.get(\"past_key_values\", None) is not None:\n",
        "                if hasattr(self, \"_reorder_cache\"):\n",
        "                    model_kwargs[\"past_key_values\"] = self._reorder_cache(\n",
        "                        model_kwargs[\"past_key_values\"], reordering_indices\n",
        "                    )\n",
        "                else:\n",
        "                    model_kwargs[\"past_key_values\"].reorder_cache(reordering_indices)\n",
        "\n",
        "            # increase cur_len\n",
        "            cur_len = cur_len + 1\n",
        "\n",
        "            if beam_scorer.is_done or all(stopping_criteria(input_ids, scores)):\n",
        "                this_peer_finished = True\n",
        "\n",
        "        final_beam_indices = sum(beam_indices, ()) if beam_indices is not None else None\n",
        "        sequence_outputs = beam_scorer.finalize(\n",
        "            input_ids,\n",
        "            beam_scores,\n",
        "            next_tokens,\n",
        "            next_indices,\n",
        "            pad_token_id=pad_token_id,\n",
        "            eos_token_id=eos_token_id,\n",
        "            max_length=stopping_criteria.max_length,\n",
        "            beam_indices=final_beam_indices,\n",
        "            decoder_prompt_len=decoder_prompt_len,\n",
        "        )\n",
        "\n",
        "        if return_dict_in_generate:\n",
        "            if not output_scores:\n",
        "                sequence_outputs[\"sequence_scores\"] = None\n",
        "\n",
        "            if self.config.is_encoder_decoder:\n",
        "                return GenerateBeamEncoderDecoderOutput(\n",
        "                    sequences=sequence_outputs[\"sequences\"],\n",
        "                    sequences_scores=sequence_outputs[\"sequence_scores\"],\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    beam_indices=sequence_outputs[\"beam_indices\"],\n",
        "                    encoder_attentions=encoder_attentions,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    decoder_attentions=decoder_attentions,\n",
        "                    cross_attentions=cross_attentions,\n",
        "                    decoder_hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "            else:\n",
        "                return GenerateBeamDecoderOnlyOutput(\n",
        "                    sequences=sequence_outputs[\"sequences\"],\n",
        "                    sequences_scores=sequence_outputs[\"sequence_scores\"],\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    beam_indices=sequence_outputs[\"beam_indices\"],\n",
        "                    attentions=decoder_attentions,\n",
        "                    hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "        else:\n",
        "            return sequence_outputs[\"sequences\"]\n",
        "\n",
        "    def _constrained_beam_search(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        constrained_beam_scorer: ConstrainedBeamSearchScorer,\n",
        "        logits_processor: LogitsProcessorList,\n",
        "        stopping_criteria: StoppingCriteriaList,\n",
        "        generation_config: GenerationConfig,\n",
        "        synced_gpus: bool,\n",
        "        **model_kwargs,\n",
        "    ) -> Union[GenerateBeamOutput, torch.LongTensor]:\n",
        "        r\"\"\"\n",
        "        Generates sequences of token ids for models with a language modeling head using **constrained beam search\n",
        "        decoding** and can be used for text-decoder, text-to-text, speech-to-text, and vision-to-text models.\n",
        "\n",
        "        Parameters:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size*num_beams, sequence_length)`):\n",
        "                The sequence used as a prompt for the generation.\n",
        "            constrained_beam_scorer (`ConstrainedBeamSearchScorer`):\n",
        "                A derived instance of [`BeamScorer`] that defines how beam hypotheses are constructed, stored and\n",
        "                sorted during generation, while satisfying a list of positive constraints. For more information, the\n",
        "                documentation of [`ConstrainedBeamSearchScorer`] should be read.\n",
        "            logits_processor (`LogitsProcessorList`):\n",
        "                An instance of [`LogitsProcessorList`]. List of instances of class derived from [`LogitsProcessor`]\n",
        "                used to modify the prediction scores of the language modeling head applied at each generation step.\n",
        "            stopping_criteria (`StoppingCriteriaList`):\n",
        "                An instance of [`StoppingCriteriaList`]. List of instances of class derived from [`StoppingCriteria`]\n",
        "                used to tell if the generation loop should stop.\n",
        "            generation_config ([`~generation.GenerationConfig`]):\n",
        "                The generation configuration to be used as parametrization of the decoding method.\n",
        "            synced_gpus (`bool`):\n",
        "                Whether to continue running the while loop until max_length (needed to avoid deadlocking with\n",
        "                `FullyShardedDataParallel` and DeepSpeed ZeRO Stage 3).\n",
        "            model_kwargs:\n",
        "                Additional model specific kwargs will be forwarded to the `forward` function of the model. If model is\n",
        "                an encoder-decoder model the kwargs should include `encoder_outputs`.\n",
        "\n",
        "        Return:\n",
        "            [`~generation.GenerateBeamDecoderOnlyOutput`], [`~generation.GenerateBeamEncoderDecoderOutput`] or\n",
        "            `torch.LongTensor`: A `torch.LongTensor` containing the generated tokens (default behaviour) or a\n",
        "            [`~generation.GenerateBeamDecoderOnlyOutput`] if `model.config.is_encoder_decoder=False` and\n",
        "            `return_dict_in_generate=True` or a [`~generation.GenerateBeamEncoderDecoderOutput`] if\n",
        "            `model.config.is_encoder_decoder=True`.\n",
        "        \"\"\"\n",
        "        # init values\n",
        "        pad_token_id = generation_config._pad_token_tensor\n",
        "        eos_token_id = generation_config._eos_token_tensor\n",
        "        output_attentions = generation_config.output_attentions\n",
        "        output_hidden_states = generation_config.output_hidden_states\n",
        "        output_scores = generation_config.output_scores\n",
        "        output_logits = generation_config.output_logits\n",
        "        return_dict_in_generate = generation_config.return_dict_in_generate\n",
        "\n",
        "        batch_size = len(constrained_beam_scorer._beam_hyps)\n",
        "        num_beams = constrained_beam_scorer.num_beams\n",
        "\n",
        "        batch_beam_size, cur_len = input_ids.shape[:2]\n",
        "        model_kwargs = self._get_initial_cache_position(cur_len, input_ids.device, model_kwargs)\n",
        "\n",
        "        if num_beams * batch_size != batch_beam_size:\n",
        "            raise ValueError(\n",
        "                f\"Batch dimension of `input_ids` should be {num_beams * batch_size}, but is {batch_beam_size}.\"\n",
        "            )\n",
        "\n",
        "        # init attention / hidden states / scores tuples\n",
        "        scores = () if (return_dict_in_generate and output_scores) else None\n",
        "        raw_logits = () if (return_dict_in_generate and output_logits) else None\n",
        "        beam_indices = (\n",
        "            tuple(() for _ in range(batch_beam_size)) if (return_dict_in_generate and output_scores) else None\n",
        "        )\n",
        "        decoder_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        cross_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        decoder_hidden_states = () if (return_dict_in_generate and output_hidden_states) else None\n",
        "\n",
        "        # if model is an encoder-decoder, retrieve encoder attention weights and hidden states\n",
        "        if return_dict_in_generate and self.config.is_encoder_decoder:\n",
        "            encoder_attentions = model_kwargs[\"encoder_outputs\"].get(\"attentions\") if output_attentions else None\n",
        "            encoder_hidden_states = (\n",
        "                model_kwargs[\"encoder_outputs\"].get(\"hidden_states\") if output_hidden_states else None\n",
        "            )\n",
        "\n",
        "        # initialise score of first beam with 0 and the rest with -1e9. This makes sure that only tokens\n",
        "        # of the first beam are considered to avoid sampling the exact same tokens across all beams.\n",
        "        beam_scores = torch.zeros((batch_size, num_beams), dtype=torch.float, device=input_ids.device)\n",
        "        beam_scores[:, 1:] = -1e9\n",
        "        beam_scores = beam_scores.view((batch_size * num_beams,))\n",
        "\n",
        "        this_peer_finished = False\n",
        "\n",
        "        decoder_prompt_len = input_ids.shape[1]  # record the prompt length of decoder\n",
        "        while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n",
        "            model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)\n",
        "\n",
        "            # prepare variable output controls (note: some models won't accept all output controls)\n",
        "            model_inputs.update({\"output_attentions\": output_attentions} if output_attentions else {})\n",
        "            model_inputs.update({\"output_hidden_states\": output_hidden_states} if output_hidden_states else {})\n",
        "\n",
        "            outputs = self(**model_inputs, return_dict=True)\n",
        "\n",
        "            # synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\n",
        "            model_kwargs = self._update_model_kwargs_for_generation(\n",
        "                outputs,\n",
        "                model_kwargs,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "            )\n",
        "            if synced_gpus and this_peer_finished:\n",
        "                cur_len = cur_len + 1\n",
        "                continue\n",
        "\n",
        "            # Copy is needed to avoid keeping a hanging ref to outputs.logits which may be very large for first iteration\n",
        "            # (the clone itself is always small)\n",
        "            # .float() is needed to retain precision for later logits manipulations\n",
        "            next_token_logits = outputs.logits[:, -1, :].to(copy=True, dtype=torch.float32, device=input_ids.device)\n",
        "            next_token_scores = nn.functional.log_softmax(\n",
        "                next_token_logits, dim=-1\n",
        "            )  # (batch_size * num_beams, vocab_size)\n",
        "\n",
        "            next_token_scores_processed = logits_processor(input_ids, next_token_scores)\n",
        "\n",
        "            next_token_scores = next_token_scores_processed + beam_scores[:, None].expand_as(\n",
        "                next_token_scores_processed\n",
        "            )\n",
        "\n",
        "            scores_for_all_vocab = next_token_scores.clone()\n",
        "\n",
        "            # Store scores, attentions and hidden_states when required\n",
        "            if return_dict_in_generate:\n",
        "                if output_scores:\n",
        "                    scores += (next_token_scores,)\n",
        "                if output_logits:\n",
        "                    raw_logits += (next_token_logits,)\n",
        "                if output_attentions:\n",
        "                    decoder_attentions += (\n",
        "                        (outputs.decoder_attentions,) if self.config.is_encoder_decoder else (outputs.attentions,)\n",
        "                    )\n",
        "                    if self.config.is_encoder_decoder:\n",
        "                        cross_attentions += (outputs.cross_attentions,)\n",
        "\n",
        "                if output_hidden_states:\n",
        "                    decoder_hidden_states += (\n",
        "                        (outputs.decoder_hidden_states,)\n",
        "                        if self.config.is_encoder_decoder\n",
        "                        else (outputs.hidden_states,)\n",
        "                    )\n",
        "\n",
        "            # reshape for beam search\n",
        "            vocab_size = next_token_scores.shape[-1]\n",
        "            next_token_scores = next_token_scores.view(batch_size, num_beams * vocab_size)\n",
        "\n",
        "            # Sample 1 + len(eos_token_id) next tokens for each beam so we have at least 1 non eos token per beam.\n",
        "            n_eos_tokens = eos_token_id.shape[0] if eos_token_id is not None else 0\n",
        "            next_token_scores, next_tokens = torch.topk(\n",
        "                next_token_scores, max(2, 1 + n_eos_tokens) * num_beams, dim=1, largest=True, sorted=True\n",
        "            )\n",
        "\n",
        "            next_indices = (next_tokens / vocab_size).long()\n",
        "            next_tokens = next_tokens % vocab_size\n",
        "\n",
        "            # stateless\n",
        "            beam_outputs = constrained_beam_scorer.process(\n",
        "                input_ids,\n",
        "                next_token_scores,\n",
        "                next_tokens,\n",
        "                next_indices,\n",
        "                scores_for_all_vocab,\n",
        "                pad_token_id=pad_token_id,\n",
        "                eos_token_id=eos_token_id,\n",
        "                beam_indices=beam_indices,\n",
        "                decoder_prompt_len=decoder_prompt_len,\n",
        "            )\n",
        "            beam_scores = beam_outputs[\"next_beam_scores\"]\n",
        "            beam_next_tokens = beam_outputs[\"next_beam_tokens\"]\n",
        "            beam_idx = beam_outputs[\"next_beam_indices\"]\n",
        "\n",
        "            input_ids = torch.cat([input_ids[beam_idx, :], beam_next_tokens.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "            # This is needed to properly delete outputs.logits which may be very large for first iteration\n",
        "            # Otherwise a reference to outputs is kept which keeps the logits alive in the next iteration\n",
        "            # IMPORTANT: Note that this should appear BEFORE the call to _reorder_cache() to save the maximum memory\n",
        "            # (that way the memory peak does not include outputs.logits)\n",
        "            del outputs\n",
        "\n",
        "            # NOTE: we need to check if `self._reorder_cache` exists for special models like RAG, RecurrentGemma etc.\n",
        "            if model_kwargs.get(\"past_key_values\", None) is not None:\n",
        "                if hasattr(self, \"_reorder_cache\"):\n",
        "                    model_kwargs[\"past_key_values\"] = self._reorder_cache(model_kwargs[\"past_key_values\"], beam_idx)\n",
        "                else:\n",
        "                    model_kwargs[\"past_key_values\"].reorder_cache(beam_idx)\n",
        "\n",
        "            if return_dict_in_generate and output_scores:\n",
        "                beam_indices = tuple(beam_indices[beam_idx[i]] + (beam_idx[i],) for i in range(len(beam_indices)))\n",
        "\n",
        "            # increase cur_len\n",
        "            cur_len = cur_len + 1\n",
        "\n",
        "            if constrained_beam_scorer.is_done or all(stopping_criteria(input_ids, scores)):\n",
        "                this_peer_finished = True\n",
        "\n",
        "        sequence_outputs = constrained_beam_scorer.finalize(\n",
        "            input_ids,\n",
        "            beam_scores,\n",
        "            next_tokens,\n",
        "            next_indices,\n",
        "            pad_token_id=pad_token_id,\n",
        "            eos_token_id=eos_token_id,\n",
        "            max_length=stopping_criteria.max_length,\n",
        "            beam_indices=beam_indices,\n",
        "            decoder_prompt_len=decoder_prompt_len,\n",
        "        )\n",
        "\n",
        "        if return_dict_in_generate:\n",
        "            if not output_scores:\n",
        "                sequence_outputs[\"sequence_scores\"] = None\n",
        "            if self.config.is_encoder_decoder:\n",
        "                return GenerateBeamEncoderDecoderOutput(\n",
        "                    sequences=sequence_outputs[\"sequences\"],\n",
        "                    sequences_scores=sequence_outputs[\"sequence_scores\"],\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    beam_indices=sequence_outputs[\"beam_indices\"],\n",
        "                    encoder_attentions=encoder_attentions,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    decoder_attentions=decoder_attentions,\n",
        "                    cross_attentions=cross_attentions,\n",
        "                    decoder_hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "            else:\n",
        "                return GenerateBeamDecoderOnlyOutput(\n",
        "                    sequences=sequence_outputs[\"sequences\"],\n",
        "                    sequences_scores=sequence_outputs[\"sequence_scores\"],\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    beam_indices=sequence_outputs[\"beam_indices\"],\n",
        "                    attentions=decoder_attentions,\n",
        "                    hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "        else:\n",
        "            return sequence_outputs[\"sequences\"]\n",
        "\n",
        "    def _assisted_decoding(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor,\n",
        "        candidate_generator: CandidateGenerator,\n",
        "        logits_processor: LogitsProcessorList,\n",
        "        stopping_criteria: StoppingCriteriaList,\n",
        "        generation_config: GenerationConfig,\n",
        "        synced_gpus: bool,\n",
        "        streamer: Optional[\"BaseStreamer\"],\n",
        "        **model_kwargs,\n",
        "    ) -> Union[GenerateNonBeamOutput, torch.LongTensor]:\n",
        "        r\"\"\"\n",
        "        Generates sequences of token ids for models with a language modeling head using **greedy decoding** or\n",
        "        **sample** (depending on `do_sample`), assisted by candidate sequences. Assisted generation is an example of a\n",
        "        candidate decoding strategy. Can be used for text-decoder, text-to-text, speech-to-text, and vision-to-text\n",
        "        models.\n",
        "\n",
        "        Parameters:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "                The sequence used as a prompt for the generation.\n",
        "            candidate_generator (`CandidateGenerator`):\n",
        "                A derived instance of [`CandidateGenerator`] that defines how candidate sequences are generated. For\n",
        "                more information, the documentation of [`CandidateGenerator`] should be read.\n",
        "            logits_processor (`LogitsProcessorList`):\n",
        "                An instance of [`LogitsProcessorList`]. List of instances of class derived from [`LogitsProcessor`]\n",
        "                used to modify the prediction scores of the language modeling head applied at each generation step.\n",
        "            stopping_criteria (`StoppingCriteriaList`):\n",
        "                An instance of [`StoppingCriteriaList`]. List of instances of class derived from [`StoppingCriteria`]\n",
        "                used to tell if the generation loop should stop.\n",
        "            generation_config ([`~generation.GenerationConfig`]):\n",
        "                The generation configuration to be used as parametrization of the decoding method.\n",
        "            synced_gpus (`bool`):\n",
        "                Whether to continue running the while loop until max_length (needed to avoid deadlocking with\n",
        "                `FullyShardedDataParallel` and DeepSpeed ZeRO Stage 3).\n",
        "            streamer (`BaseStreamer`, *optional*):\n",
        "                Streamer object that will be used to stream the generated sequences. Generated tokens are passed\n",
        "                through `streamer.put(token_ids)` and the streamer is responsible for any further processing.\n",
        "            model_kwargs:\n",
        "                Additional model specific keyword arguments will be forwarded to the `forward` function of the model.\n",
        "                If model is an encoder-decoder model the kwargs should include `encoder_outputs`.\n",
        "\n",
        "        Return:\n",
        "            [`~generation.GenerateDecoderOnlyOutput`], [`~generation.GenerateEncoderDecoderOutput`] or\n",
        "            `torch.LongTensor`: A `torch.LongTensor` containing the generated tokens (default behaviour) or a\n",
        "            [`~generation.GenerateDecoderOnlyOutput`] if `model.config.is_encoder_decoder=False` and\n",
        "            `return_dict_in_generate=True` or a [`~generation.GenerateEncoderDecoderOutput`] if\n",
        "            `model.config.is_encoder_decoder=True`.\n",
        "        \"\"\"\n",
        "        # init values\n",
        "        do_sample = generation_config.do_sample\n",
        "        output_attentions = generation_config.output_attentions\n",
        "        output_hidden_states = generation_config.output_hidden_states\n",
        "        output_scores = generation_config.output_scores\n",
        "        output_logits = generation_config.output_logits\n",
        "        return_dict_in_generate = generation_config.return_dict_in_generate\n",
        "\n",
        "        # init attention / hidden states / scores tuples\n",
        "        scores = () if (return_dict_in_generate and output_scores) else None\n",
        "        raw_logits = () if (return_dict_in_generate and output_logits) else None\n",
        "        decoder_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        cross_attentions = () if (return_dict_in_generate and output_attentions) else None\n",
        "        decoder_hidden_states = () if (return_dict_in_generate and output_hidden_states) else None\n",
        "\n",
        "        # if model is an encoder-decoder, retrieve encoder attention weights and hidden states\n",
        "        if return_dict_in_generate and self.config.is_encoder_decoder:\n",
        "            encoder_attentions = model_kwargs[\"encoder_outputs\"].get(\"attentions\") if output_attentions else None\n",
        "            encoder_hidden_states = (\n",
        "                model_kwargs[\"encoder_outputs\"].get(\"hidden_states\") if output_hidden_states else None\n",
        "            )\n",
        "\n",
        "        # keep track of which sequences are already finished\n",
        "        batch_size, cur_len = input_ids.shape[:2]\n",
        "        unfinished_sequences = torch.ones(batch_size, dtype=torch.long, device=input_ids.device)\n",
        "        model_kwargs = self._get_initial_cache_position(cur_len, input_ids.device, model_kwargs)\n",
        "\n",
        "        this_peer_finished = False\n",
        "        is_first_iteration = True  # to preserve the same API in the output as other generation methods\n",
        "        while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):\n",
        "            cur_len = input_ids.shape[1]\n",
        "\n",
        "            #  1. Fetch candidate sequences from a `CandidateGenerator` and move to the correct device\n",
        "            candidate_input_ids, candidate_logits = candidate_generator.get_candidates(input_ids)\n",
        "            candidate_input_ids = candidate_input_ids.to(self.device)\n",
        "            if candidate_logits is not None:\n",
        "                candidate_logits = candidate_logits.to(self.device)\n",
        "\n",
        "            candidate_length = candidate_input_ids.shape[1] - input_ids.shape[1]\n",
        "            is_done_candidate = stopping_criteria(candidate_input_ids, None)\n",
        "\n",
        "            # 2. Use the original model to obtain the next token logits given the candidate sequence. We obtain\n",
        "            # `candidate_length + 1` relevant logits from this process: in the event that all candidates are correct,\n",
        "            # we use this forward pass to also pick the subsequent logits in the original model.\n",
        "\n",
        "            # 2.1. Prepare the model inputs\n",
        "            candidate_kwargs = copy.copy(model_kwargs)\n",
        "            candidate_kwargs = _prepare_attention_mask(\n",
        "                candidate_kwargs, candidate_input_ids.shape[1], self.config.is_encoder_decoder\n",
        "            )\n",
        "            candidate_kwargs = _prepare_token_type_ids(candidate_kwargs, candidate_input_ids.shape[1])\n",
        "            if \"cache_position\" in candidate_kwargs:\n",
        "                candidate_kwargs[\"cache_position\"] = torch.cat(\n",
        "                    (\n",
        "                        candidate_kwargs[\"cache_position\"],\n",
        "                        torch.arange(cur_len, cur_len + candidate_length, device=input_ids.device, dtype=torch.long),\n",
        "                    ),\n",
        "                    dim=0,\n",
        "                )\n",
        "\n",
        "            model_inputs = self.prepare_inputs_for_generation(candidate_input_ids, **candidate_kwargs)\n",
        "            if \"logits_to_keep\" in model_inputs:\n",
        "                model_inputs[\"logits_to_keep\"] = candidate_length + 1\n",
        "\n",
        "            # 2.2. Run a forward pass on the candidate sequence\n",
        "            # prepare variable output controls (note: some models won't accept all output controls)\n",
        "            model_inputs.update({\"output_attentions\": output_attentions} if output_attentions else {})\n",
        "            model_inputs.update({\"output_hidden_states\": output_hidden_states} if output_hidden_states else {})\n",
        "\n",
        "            outputs = self(**model_inputs)\n",
        "\n",
        "            # 2.3. Process the new logits\n",
        "            # .float() is needed to retain precision for later logits manipulations\n",
        "            new_logits = outputs.logits[:, -candidate_length - 1 :].to(\n",
        "                dtype=torch.float32, device=input_ids.device\n",
        "            )  # excludes the input prompt if present\n",
        "            next_token_logits = new_logits.clone()\n",
        "            if len(logits_processor) > 0:\n",
        "                for i in range(candidate_length + 1):\n",
        "                    new_logits[:, i, :] = logits_processor(candidate_input_ids[:, : cur_len + i], new_logits[:, i, :])\n",
        "\n",
        "            # 3. Select the accepted tokens. There are two possible cases:\n",
        "            # Case 1: `do_sample=True` and we have logits for the candidates (originally from speculative decoding)\n",
        "            # 👉 Apply algorithm 1 from the speculative decoding paper (https://huggingface.co/papers/2211.17192).\n",
        "            if do_sample and candidate_logits is not None:\n",
        "                valid_tokens, n_matches = _speculative_sampling(\n",
        "                    candidate_input_ids,\n",
        "                    candidate_logits,\n",
        "                    candidate_length,\n",
        "                    new_logits,\n",
        "                    is_done_candidate,\n",
        "                )\n",
        "\n",
        "            # Case 2: all other cases (originally from assisted generation) 👉 Compare the tokens selected from the\n",
        "            # original model logits with the candidate tokens. We can keep the candidate tokens until the first\n",
        "            # mismatch, or until the max length is reached.\n",
        "            else:\n",
        "                if do_sample:\n",
        "                    probs = new_logits.softmax(dim=-1)\n",
        "                    selected_tokens = torch.multinomial(probs[0, :, :], num_samples=1).squeeze(1)[None, :]\n",
        "                else:\n",
        "                    selected_tokens = new_logits.argmax(dim=-1)\n",
        "\n",
        "                candidate_new_tokens = candidate_input_ids[:, cur_len:]\n",
        "                n_matches = ((~(candidate_new_tokens == selected_tokens[:, :-1])).cumsum(dim=-1) < 1).sum()\n",
        "\n",
        "                # Ensure we don't generate beyond max_len or an EOS token\n",
        "                if is_done_candidate and n_matches == candidate_length:\n",
        "                    n_matches -= 1\n",
        "                valid_tokens = selected_tokens[:, : n_matches + 1]\n",
        "\n",
        "            # 4. Update variables according to the number of matching assistant tokens. Remember: the token generated\n",
        "            # by the model after the last candidate match is also valid, as it is generated from a correct sequence.\n",
        "            # Because of this last token, assisted generation search reduces to a normal greedy search/sample if there\n",
        "            # is no match.\n",
        "\n",
        "            # 4.1. Get the valid continuation, after the matching tokens\n",
        "            input_ids = torch.cat((input_ids, valid_tokens), dim=-1)\n",
        "            if streamer is not None:\n",
        "                streamer.put(valid_tokens.cpu())\n",
        "            new_cur_len = input_ids.shape[1]\n",
        "\n",
        "            # 4.2. Discard past key values relative to unused assistant tokens\n",
        "            outputs.past_key_values.crop(new_cur_len - 1)\n",
        "\n",
        "            # 5. Update the candidate generation strategy if needed\n",
        "            candidate_generator.update_candidate_strategy(input_ids, new_logits, n_matches)\n",
        "\n",
        "            # synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\n",
        "            model_kwargs = self._update_model_kwargs_for_generation(\n",
        "                outputs,\n",
        "                model_kwargs,\n",
        "                is_encoder_decoder=self.config.is_encoder_decoder,\n",
        "                num_new_tokens=n_matches + 1,\n",
        "            )\n",
        "            if synced_gpus and this_peer_finished:\n",
        "                continue\n",
        "\n",
        "            # Store scores, attentions and hidden_states when required\n",
        "            # Assistant: modified to append one tuple element per token, as in the other generation methods.\n",
        "            if return_dict_in_generate:\n",
        "                newly_added_length = n_matches + 1\n",
        "                if output_scores:\n",
        "                    scores += tuple(new_logits[:, i, :] for i in range(newly_added_length))\n",
        "                if output_logits:\n",
        "                    raw_logits += tuple(next_token_logits[:, i, :] for i in range(newly_added_length))\n",
        "\n",
        "                newly_added_length = new_cur_len if is_first_iteration else newly_added_length\n",
        "                if output_attentions:\n",
        "                    if self.config.is_encoder_decoder:\n",
        "                        cross_attentions = _split_model_outputs(\n",
        "                            cross_attentions, outputs.cross_attentions, cur_len, newly_added_length\n",
        "                        )\n",
        "                        decoder_attentions = _split_model_outputs(\n",
        "                            decoder_attentions,\n",
        "                            outputs.decoder_attentions,\n",
        "                            cur_len,\n",
        "                            newly_added_length,\n",
        "                            is_decoder_attention=True,\n",
        "                        )\n",
        "                    # some (V)LLMs have hard requirement on SDPA and thus never return attn\n",
        "                    elif outputs.attentions[0] is not None:\n",
        "                        decoder_attentions = _split_model_outputs(\n",
        "                            decoder_attentions,\n",
        "                            outputs.attentions,\n",
        "                            cur_len,\n",
        "                            newly_added_length,\n",
        "                            is_decoder_attention=True,\n",
        "                        )\n",
        "                if output_hidden_states:\n",
        "                    if self.config.is_encoder_decoder:\n",
        "                        decoder_hidden_states = _split_model_outputs(\n",
        "                            decoder_hidden_states, outputs.decoder_hidden_states, cur_len, newly_added_length\n",
        "                        )\n",
        "                    else:\n",
        "                        decoder_hidden_states = _split_model_outputs(\n",
        "                            decoder_hidden_states, outputs.hidden_states, cur_len, newly_added_length\n",
        "                        )\n",
        "\n",
        "            unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)\n",
        "            this_peer_finished = unfinished_sequences.max() == 0\n",
        "            is_first_iteration = False\n",
        "\n",
        "        if streamer is not None:\n",
        "            streamer.end()\n",
        "\n",
        "        if (\n",
        "            hasattr(candidate_generator, \"assistant_model\")\n",
        "            and candidate_generator.assistant_model.generation_config.num_assistant_tokens_schedule == \"heuristic\"\n",
        "        ):\n",
        "            candidate_generator.assistant_model.generation_config.num_assistant_tokens = (\n",
        "                candidate_generator.num_assistant_tokens\n",
        "            )\n",
        "        if return_dict_in_generate:\n",
        "            if self.config.is_encoder_decoder:\n",
        "                return GenerateEncoderDecoderOutput(\n",
        "                    sequences=input_ids,\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    encoder_attentions=encoder_attentions,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    decoder_attentions=decoder_attentions,\n",
        "                    cross_attentions=cross_attentions,\n",
        "                    decoder_hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "            else:\n",
        "                return GenerateDecoderOnlyOutput(\n",
        "                    sequences=input_ids,\n",
        "                    scores=scores,\n",
        "                    logits=raw_logits,\n",
        "                    attentions=decoder_attentions,\n",
        "                    hidden_states=decoder_hidden_states,\n",
        "                    past_key_values=model_kwargs.get(\"past_key_values\"),\n",
        "                )\n",
        "        else:\n",
        "            return input_ids\n",
        "\n",
        "    def _prefill_chunking(self, input_ids: torch.LongTensor, generation_config: GenerationConfig, **model_kwargs):\n",
        "        # Even if we are not compiling the forward, flex is always compiled when used. With chunk prefill, we may\n",
        "        # end up needing just a bit more graphs than the default (which is 8). Doing this avoids very cryptic warnings\n",
        "        torch._dynamo.config.cache_size_limit = 64\n",
        "\n",
        "        chunk_size = generation_config.prefill_chunk_size\n",
        "        # Only chunk up the token just before last, so that decoding is completely performed outside this function\n",
        "        # (here we simply prefill the cache)\n",
        "        input_chunks = torch.split(input_ids[:, :-1], chunk_size, dim=-1)\n",
        "\n",
        "        if \"past_key_values\" not in model_kwargs:\n",
        "            raise ValueError(\"Cannot use prefill chunking without a cache\")\n",
        "\n",
        "        model_forward = self.forward\n",
        "\n",
        "        compile_forward = self._valid_auto_compile_criteria(model_kwargs, generation_config)\n",
        "        if compile_forward:\n",
        "            model_forward = self.get_compiled_call(generation_config.compile_config)\n",
        "\n",
        "        attention_mask = model_kwargs.pop(\"attention_mask\", None)\n",
        "\n",
        "        past_length = 0\n",
        "        for input_chunk in input_chunks:\n",
        "            current_length = past_length + input_chunk.shape[-1]\n",
        "            # Prepare inputs\n",
        "            if attention_mask is not None:\n",
        "                model_kwargs[\"attention_mask\"] = attention_mask[:, :current_length]\n",
        "            model_kwargs[\"cache_position\"] = torch.arange(\n",
        "                past_length, current_length, dtype=torch.long, device=input_chunk.device\n",
        "            )\n",
        "            model_kwargs[\"position_ids\"] = model_kwargs[\"cache_position\"].unsqueeze(0)\n",
        "            model_inputs = self.prepare_inputs_for_generation(input_chunk, **model_kwargs)\n",
        "\n",
        "            outputs = model_forward(**model_inputs, return_dict=True)\n",
        "\n",
        "            model_kwargs[\"past_key_values\"] = outputs.past_key_values\n",
        "            past_length = current_length\n",
        "\n",
        "        model_kwargs[\"attention_mask\"] = attention_mask\n",
        "        model_kwargs[\"cache_position\"] = model_kwargs[\"cache_position\"][-1:] + 1\n",
        "        _ = model_kwargs.pop(\"position_ids\", None)\n",
        "\n",
        "        return model_kwargs\n",
        "\n",
        "\n",
        "def _speculative_sampling(\n",
        "    candidate_input_ids,\n",
        "    candidate_logits,\n",
        "    candidate_length,\n",
        "    new_logits,\n",
        "    is_done_candidate,\n",
        "):\n",
        "    \"\"\"\n",
        "    Applies sampling as in the speculative decoding paper (https://huggingface.co/papers/2211.17192, algorithm 1). Returns\n",
        "    the selected tokens, as well as the number of candidate matches.\n",
        "\n",
        "    NOTE: Unless otherwise stated, the variable names match those in the paper.\n",
        "    \"\"\"\n",
        "    new_candidate_input_ids = candidate_input_ids[:, -candidate_length:]\n",
        "    # Gets the probabilities from the logits. q_i and p_i denote the assistant and model probabilities of the tokens\n",
        "    # selected by the assistant, respectively.\n",
        "    q = candidate_logits.softmax(dim=-1)\n",
        "    q_i = q[:, torch.arange(candidate_length), new_candidate_input_ids].squeeze(0, 1)\n",
        "    p = new_logits.softmax(dim=-1)\n",
        "    p_i = p[:, torch.arange(candidate_length), new_candidate_input_ids].squeeze(0, 1)\n",
        "    probability_ratio = p_i / q_i\n",
        "\n",
        "    # When probability_ratio > 1 (i.e. q_i(x) < p_i(x), or \"assistant probability of the candidate token is smaller\n",
        "    # than the model probability for the same token\"), keep the token. Otherwise reject with p = 1 - probability_ratio\n",
        "    # (= keep with p = probability_ratio). Keep all the tokens until the first rejection\n",
        "    r_i = torch.rand_like(probability_ratio)\n",
        "    is_accepted = r_i <= probability_ratio\n",
        "    n_matches = ((~is_accepted).cumsum(dim=-1) < 1).sum()  # this is `n` in algorithm 1\n",
        "\n",
        "    # Ensure we don't generate beyond max_len or an EOS token (not in algorithm 1, but needed for correct behavior)\n",
        "    if is_done_candidate and n_matches == candidate_length:\n",
        "        # Output length is assumed to be `n_matches + 1`. Since we won't generate another token with the target model\n",
        "        # due to acceptance on EOS we fix `n_matches`\n",
        "        n_matches -= 1\n",
        "        valid_tokens = new_candidate_input_ids[:, : n_matches + 1]\n",
        "    else:\n",
        "        # Next token selection: if there is a rejection, adjust the distribution from the main model before sampling.\n",
        "        gamma = candidate_logits.shape[1]\n",
        "        p_n_plus_1 = p[:, n_matches, :]\n",
        "        if n_matches < gamma:\n",
        "            q_n_plus_1 = q[:, n_matches, :]\n",
        "            p_prime = torch.clamp((p_n_plus_1 - q_n_plus_1), min=0)\n",
        "            p_prime.div_(p_prime.sum())\n",
        "        else:\n",
        "            p_prime = p_n_plus_1\n",
        "        t = torch.multinomial(p_prime, num_samples=1).squeeze(1)[None, :]\n",
        "\n",
        "        # The selected tokens include the matches (if any) plus the next sampled tokens\n",
        "        if n_matches > 0:\n",
        "            valid_tokens = torch.cat((new_candidate_input_ids[:, :n_matches], t), dim=-1)\n",
        "        else:\n",
        "            valid_tokens = t\n",
        "\n",
        "    return valid_tokens, n_matches\n",
        "\n",
        "\n",
        "def _split_model_outputs(outputs, new_outputs, cur_len, added_len, is_decoder_attention=False):\n",
        "    \"\"\"\n",
        "    Given the (decoder/cross attentions)/(decoder hidden states) for multiple generated tokens, splits it into a tuple\n",
        "    where each member corresponds to a single generated token.\n",
        "    \"\"\"\n",
        "    # Retrocompatibility: in our generation functions, the first iteration includes the attention/hidden states for the\n",
        "    # prompt.\n",
        "    if len(outputs) == 0:\n",
        "        new_tuple = ()\n",
        "        for layer in new_outputs:\n",
        "            last_dim_size = cur_len if is_decoder_attention else layer.shape[-1]\n",
        "            new_tuple += (layer[..., :cur_len, :last_dim_size],)\n",
        "        outputs += (new_tuple,)\n",
        "        # The first iteration contains the prompt + 1 generated token, let's update the length variables accordingly\n",
        "        cur_len += 1\n",
        "        added_len -= cur_len\n",
        "\n",
        "    for i in range(added_len):\n",
        "        new_tuple = ()\n",
        "        for layer in new_outputs:\n",
        "            last_dim_size = cur_len + i if is_decoder_attention else layer.shape[-1]\n",
        "            new_tuple += (layer[..., i : i + 1, :last_dim_size],)\n",
        "        outputs += (new_tuple,)\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def _ranking_fast(\n",
        "    context_hidden: torch.FloatTensor,\n",
        "    next_hidden: torch.FloatTensor,\n",
        "    next_top_k_probs: torch.FloatTensor,\n",
        "    cosine_matrix_mask: torch.LongTensor,\n",
        "    alpha: float,\n",
        "    beam_width: int,\n",
        ") -> torch.FloatTensor:\n",
        "    \"\"\"\n",
        "    Reranks the top_k candidates based on a degeneration penalty (cosine similarity with previous tokens), as described\n",
        "    in the paper \"A Contrastive Framework for Neural Text Generation\". Returns the index of the best candidate for each\n",
        "    row in the batch.\n",
        "    \"\"\"\n",
        "    norm_context_hidden = context_hidden / context_hidden.norm(dim=2, keepdim=True)\n",
        "    norm_next_hidden = next_hidden / next_hidden.norm(dim=2, keepdim=True)\n",
        "    cosine_matrix = torch.matmul(norm_context_hidden, norm_next_hidden.transpose(1, 2)).squeeze(-1)  # [B*K, S]\n",
        "\n",
        "    # Penalize cosine_matrix based on the cosine_matrix_mask (ignore padding positions)\n",
        "    # Using a large negative value for masked positions\n",
        "    cosine_matrix_mask = cosine_matrix_mask.to(dtype=cosine_matrix.dtype)\n",
        "    cosine_matrix_mask = (1 - cosine_matrix_mask) * torch.finfo(cosine_matrix.dtype).min\n",
        "    cosine_matrix = cosine_matrix + cosine_matrix_mask\n",
        "\n",
        "    degeneration_penalty, _ = torch.max(cosine_matrix, dim=-1)  # [B*K]\n",
        "    next_top_k_probs = next_top_k_probs.view(-1)  # [B*K]\n",
        "    contrastive_score = (1.0 - alpha) * next_top_k_probs - alpha * degeneration_penalty\n",
        "    contrastive_score = torch.stack(torch.split(contrastive_score, beam_width))  # [B, K]\n",
        "    _, selected_idx = contrastive_score.max(dim=-1)  # [B]\n",
        "    return selected_idx\n",
        "\n",
        "\n",
        "def stack_model_outputs(model_outputs: list[ModelOutput], config: PretrainedConfig) -> ModelOutput:\n",
        "    \"\"\"\n",
        "    Stack a list of ModelOutput objects (or its subclasses) along the batch_size dimension. The function infers the\n",
        "    specific ModelOutput subclass from the list provided.\n",
        "    \"\"\"\n",
        "    if not model_outputs:\n",
        "        raise ValueError(\"Input list is empty.\")\n",
        "\n",
        "    # Infer the class from the first object in the list\n",
        "    model_output_cls = type(model_outputs[0])\n",
        "\n",
        "    # Ensure all objects are of the same type\n",
        "    if not all(isinstance(obj, model_output_cls) for obj in model_outputs):\n",
        "        raise ValueError(\"All elements in the list should be of the same type.\")\n",
        "\n",
        "    # Helper function to concat tensors or tuples of tensors\n",
        "    def _concat(data):\n",
        "        \"\"\"\n",
        "        Reverse of `_split` function above.\n",
        "        \"\"\"\n",
        "        if any(data is None for data in data):\n",
        "            return None\n",
        "        if isinstance(data[0], torch.Tensor):\n",
        "            return torch.cat(data, dim=0)\n",
        "        elif isinstance(data[0], tuple):\n",
        "            # If the elements of the tuple are also tuples (e.g., past_key_values in our earlier example)\n",
        "            if isinstance(data[0][0], tuple):\n",
        "                return tuple(\n",
        "                    tuple(torch.cat([attr[i][j] for attr in data], dim=0) for j in range(len(data[0][0])))\n",
        "                    for i in range(len(data[0]))\n",
        "                )\n",
        "            else:\n",
        "                return tuple(torch.cat([attr[i] for attr in data], dim=0) for i in range(len(data[0])))\n",
        "        elif isinstance(data[0], (int, float)):\n",
        "            # If the elements are integers or floats, return a tensor\n",
        "            return torch.tensor(data)\n",
        "        else:\n",
        "            raise TypeError(f\"Unexpected attribute type: {type(data[0])}\")\n",
        "\n",
        "    # Use a dictionary comprehension to gather attributes from all objects and concatenate them\n",
        "    concatenated_data = {\n",
        "        k: _concat([getattr(model_output, k) for model_output in model_outputs])\n",
        "        for k in model_output_cls.__dataclass_fields__\n",
        "    }\n",
        "\n",
        "    # Return a new object of the inferred class with the concatenated attributes\n",
        "    return model_output_cls(**concatenated_data)\n",
        "\n",
        "\n",
        "def _relative_top_filter(\n",
        "    scores: torch.FloatTensor,\n",
        "    baseline_scores: torch.FloatTensor,\n",
        "    relative_top: float = 0.1,\n",
        "    filter_value: float = -float(\"Inf\"),\n",
        "    base_filter_value=-1e-3,\n",
        "    min_tokens_to_keep: int = 1,\n",
        ") -> torch.FloatTensor:\n",
        "    \"\"\"\n",
        "    Reference: https://github.com/XiangLi1999/ContrastiveDecoding/blob/170e9142e92159c1237d731e240f5eb14aabf428/transformers/src/transformers/generation_logits_process.py#L235\n",
        "    Apply filtering to only keep tokens with a probability above a certain threshold. The threshold is defined as `relative_top` * max probability in the distribution.\n",
        "    \"\"\"\n",
        "    scores_normalized = scores.log_softmax(dim=-1)\n",
        "    baseline_scores_normalized = baseline_scores.log_softmax(dim=-1)\n",
        "    sorted_logits, sorted_indices = torch.sort(scores_normalized, descending=True)\n",
        "    min_thresh = sorted_logits[..., min_tokens_to_keep - 1]\n",
        "    probs_max = torch.max(scores_normalized, dim=-1).values\n",
        "    probs_thresh = probs_max + np.log(relative_top)\n",
        "    probs_thresh = torch.min(min_thresh, probs_thresh)\n",
        "    probs_thresh = probs_thresh.unsqueeze(-1)\n",
        "    baseline_scores_normalized[scores_normalized < probs_thresh] = base_filter_value\n",
        "    scores_normalized[scores_normalized < probs_thresh] = filter_value\n",
        "    return scores_normalized, baseline_scores_normalized\n",
        "\n",
        "\n",
        "def _dola_select_contrast(\n",
        "    candidate_premature_layers: list[int],\n",
        "    candidate_premature_logits: dict[int, torch.FloatTensor],\n",
        "    final_logits: torch.FloatTensor,\n",
        ") -> torch.FloatTensor:\n",
        "    if len(candidate_premature_layers) == 1:\n",
        "        base_logits = candidate_premature_logits[candidate_premature_layers[0]]\n",
        "        final_logits, base_logits = _relative_top_filter(final_logits, base_logits)\n",
        "        logits = final_logits - base_logits\n",
        "        return logits\n",
        "\n",
        "    # 1. Stacking all premature_layers into a new dimension\n",
        "    stacked_premature_layers = torch.stack([candidate_premature_logits[i] for i in candidate_premature_layers], dim=0)\n",
        "\n",
        "    # 2. Calculate the softmax values for mature_layer and all premature_layers\n",
        "    # shape: (batch_size, vocab_size)\n",
        "    softmax_mature_layer = F.softmax(final_logits, dim=-1)\n",
        "    # shape: (num_premature_layers, batch_size, vocab_size)\n",
        "    softmax_premature_layers = F.softmax(stacked_premature_layers, dim=-1)\n",
        "\n",
        "    # 3. Calculate the average distribution\n",
        "    # shape: (num_premature_layers, batch_size, vocab_size)\n",
        "    avg_dist = 0.5 * (softmax_mature_layer[None, :, :] + softmax_premature_layers)\n",
        "\n",
        "    # 4. Calculate log-softmax for the KL divergence\n",
        "    # shape: (batch_size, vocab_size)\n",
        "    log_softmax_mature_layer = F.log_softmax(final_logits, dim=-1)\n",
        "    # shape: (num_premature_layers, batch_size, vocab_size)\n",
        "    log_softmax_premature_layers = F.log_softmax(stacked_premature_layers, dim=-1)\n",
        "\n",
        "    # 5. Calculate the KL divergences and then the JS divergences\n",
        "    # shape: (num_premature_layers, batch_size)\n",
        "    kl1 = F.kl_div(log_softmax_mature_layer[None, :, :], avg_dist, reduction=\"none\").mean(-1)\n",
        "    # shape: (num_premature_layers, batch_size)\n",
        "    kl2 = F.kl_div(log_softmax_premature_layers, avg_dist, reduction=\"none\").mean(-1)\n",
        "    js_divs = 0.5 * (kl1 + kl2)  # shape: (num_premature_layers, batch_size)\n",
        "\n",
        "    # 6. Reduce the batchmean\n",
        "    js_divs = js_divs.mean(-1)  # shape: (num_premature_layers,)\n",
        "    premature_layer = candidate_premature_layers[int(js_divs.argmax().item())]\n",
        "\n",
        "    base_logits = candidate_premature_logits[premature_layer]\n",
        "    final_logits, base_logits = _relative_top_filter(final_logits, base_logits)\n",
        "    logits = final_logits - base_logits\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "pkBU8ZLW-l5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "شغال\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/transformers/generation/__init__.py\n",
        "\n",
        "\n",
        "\n",
        "# Copyright 2022 The HuggingFace Team. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "from typing import TYPE_CHECKING\n",
        "\n",
        "from ..utils import OptionalDependencyNotAvailable, _LazyModule, is_flax_available, is_tf_available, is_torch_available\n",
        "\n",
        "\n",
        "_import_structure = {\n",
        "    \"configuration_utils\": [\n",
        "        \"BaseWatermarkingConfig\",\n",
        "        \"CompileConfig\",\n",
        "        \"GenerationConfig\",\n",
        "        \"GenerationMode\",\n",
        "        \"SynthIDTextWatermarkingConfig\",\n",
        "        \"WatermarkingConfig\",\n",
        "    ],\n",
        "    \"streamers\": [\"AsyncTextIteratorStreamer\", \"BaseStreamer\", \"TextIteratorStreamer\", \"TextStreamer\"],\n",
        "}\n",
        "\n",
        "try:\n",
        "    if not is_torch_available():\n",
        "        raise OptionalDependencyNotAvailable()\n",
        "except OptionalDependencyNotAvailable:\n",
        "    pass\n",
        "else:\n",
        "    _import_structure[\"beam_constraints\"] = [\n",
        "        \"Constraint\",\n",
        "        \"ConstraintListState\",\n",
        "        \"DisjunctiveConstraint\",\n",
        "        \"PhrasalConstraint\",\n",
        "    ]\n",
        "    _import_structure[\"beam_search\"] = [\n",
        "        \"BeamHypotheses\",\n",
        "        \"BeamScorer\",\n",
        "        \"BeamSearchScorer\",\n",
        "        \"ConstrainedBeamSearchScorer\",\n",
        "    ]\n",
        "    _import_structure[\"candidate_generator\"] = [\n",
        "        \"AssistedCandidateGenerator\",\n",
        "        \"CandidateGenerator\",\n",
        "        \"EarlyExitCandidateGenerator\",\n",
        "        \"PromptLookupCandidateGenerator\",\n",
        "    ]\n",
        "    _import_structure[\"logits_process\"] = [\n",
        "        \"AlternatingCodebooksLogitsProcessor\",\n",
        "        \"ClassifierFreeGuidanceLogitsProcessor\",\n",
        "        \"EncoderNoRepeatNGramLogitsProcessor\",\n",
        "        \"EncoderRepetitionPenaltyLogitsProcessor\",\n",
        "        \"EpsilonLogitsWarper\",\n",
        "        \"EtaLogitsWarper\",\n",
        "        \"ExponentialDecayLengthPenalty\",\n",
        "        \"ForcedBOSTokenLogitsProcessor\",\n",
        "        \"ForcedEOSTokenLogitsProcessor\",\n",
        "        \"HammingDiversityLogitsProcessor\",\n",
        "        \"InfNanRemoveLogitsProcessor\",\n",
        "        \"LogitNormalization\",\n",
        "        \"LogitsProcessor\",\n",
        "        \"LogitsProcessorList\",\n",
        "        \"MinLengthLogitsProcessor\",\n",
        "        \"MinNewTokensLengthLogitsProcessor\",\n",
        "        \"MinPLogitsWarper\",\n",
        "        \"NoBadWordsLogitsProcessor\",\n",
        "        \"NoRepeatNGramLogitsProcessor\",\n",
        "        \"PrefixConstrainedLogitsProcessor\",\n",
        "        \"RepetitionPenaltyLogitsProcessor\",\n",
        "        \"SequenceBiasLogitsProcessor\",\n",
        "        \"SuppressTokensLogitsProcessor\",\n",
        "        \"SuppressTokensAtBeginLogitsProcessor\",\n",
        "        \"SynthIDTextWatermarkLogitsProcessor\",\n",
        "        \"TemperatureLogitsWarper\",\n",
        "        \"TopKLogitsWarper\",\n",
        "        \"TopPLogitsWarper\",\n",
        "        \"TypicalLogitsWarper\",\n",
        "        \"UnbatchedClassifierFreeGuidanceLogitsProcessor\",\n",
        "        \"WhisperTimeStampLogitsProcessor\",\n",
        "        \"WatermarkLogitsProcessor\",\n",
        "    ]\n",
        "    _import_structure[\"stopping_criteria\"] = [\n",
        "        \"MaxLengthCriteria\",\n",
        "        \"MaxTimeCriteria\",\n",
        "        \"ConfidenceCriteria\",\n",
        "        \"EosTokenCriteria\",\n",
        "        \"StoppingCriteria\",\n",
        "        \"StoppingCriteriaList\",\n",
        "        \"validate_stopping_criteria\",\n",
        "        \"StopStringCriteria\",\n",
        "    ]\n",
        "    _import_structure[\"continuous_batching\"] = [\n",
        "        \"ContinuousMixin\",\n",
        "    ]\n",
        "    _import_structure[\"utils\"] = [\n",
        "        \"GenerationMixin\",\n",
        "        \"GreedySearchEncoderDecoderOutput\",\n",
        "        \"GreedySearchDecoderOnlyOutput\",\n",
        "        \"SampleEncoderDecoderOutput\",\n",
        "        \"SampleDecoderOnlyOutput\",\n",
        "        \"BeamSearchEncoderDecoderOutput\",\n",
        "        \"BeamSearchDecoderOnlyOutput\",\n",
        "        \"BeamSampleEncoderDecoderOutput\",\n",
        "        \"BeamSampleDecoderOnlyOutput\",\n",
        "        \"ContrastiveSearchEncoderDecoderOutput\",\n",
        "        \"ContrastiveSearchDecoderOnlyOutput\",\n",
        "        \"GenerateBeamDecoderOnlyOutput\",\n",
        "        \"GenerateBeamEncoderDecoderOutput\",\n",
        "        \"GenerateDecoderOnlyOutput\",\n",
        "        \"GenerateEncoderDecoderOutput\",\n",
        "    ]\n",
        "    _import_structure[\"watermarking\"] = [\n",
        "        \"WatermarkDetector\",\n",
        "        \"WatermarkDetectorOutput\",\n",
        "        \"BayesianDetectorModel\",\n",
        "        \"BayesianDetectorConfig\",\n",
        "        \"SynthIDTextWatermarkDetector\",\n",
        "    ]\n",
        "\n",
        "try:\n",
        "    if not is_tf_available():\n",
        "        raise OptionalDependencyNotAvailable()\n",
        "except OptionalDependencyNotAvailable:\n",
        "    pass\n",
        "else:\n",
        "    _import_structure[\"tf_logits_process\"] = [\n",
        "        \"TFForcedBOSTokenLogitsProcessor\",\n",
        "        \"TFForcedEOSTokenLogitsProcessor\",\n",
        "        \"TFForceTokensLogitsProcessor\",\n",
        "        \"TFLogitsProcessor\",\n",
        "        \"TFLogitsProcessorList\",\n",
        "        \"TFLogitsWarper\",\n",
        "        \"TFMinLengthLogitsProcessor\",\n",
        "        \"TFNoBadWordsLogitsProcessor\",\n",
        "        \"TFNoRepeatNGramLogitsProcessor\",\n",
        "        \"TFRepetitionPenaltyLogitsProcessor\",\n",
        "        \"TFSuppressTokensAtBeginLogitsProcessor\",\n",
        "        \"TFSuppressTokensLogitsProcessor\",\n",
        "        \"TFTemperatureLogitsWarper\",\n",
        "        \"TFTopKLogitsWarper\",\n",
        "        \"TFTopPLogitsWarper\",\n",
        "    ]\n",
        "    _import_structure[\"tf_utils\"] = [\n",
        "        \"TFGenerationMixin\",\n",
        "        \"TFGreedySearchDecoderOnlyOutput\",\n",
        "        \"TFGreedySearchEncoderDecoderOutput\",\n",
        "        \"TFSampleEncoderDecoderOutput\",\n",
        "        \"TFSampleDecoderOnlyOutput\",\n",
        "        \"TFBeamSearchEncoderDecoderOutput\",\n",
        "        \"TFBeamSearchDecoderOnlyOutput\",\n",
        "        \"TFBeamSampleEncoderDecoderOutput\",\n",
        "        \"TFBeamSampleDecoderOnlyOutput\",\n",
        "        \"TFContrastiveSearchEncoderDecoderOutput\",\n",
        "        \"TFContrastiveSearchDecoderOnlyOutput\",\n",
        "    ]\n",
        "\n",
        "try:\n",
        "    if not is_flax_available():\n",
        "        raise OptionalDependencyNotAvailable()\n",
        "except OptionalDependencyNotAvailable:\n",
        "    pass\n",
        "else:\n",
        "    _import_structure[\"flax_logits_process\"] = [\n",
        "        \"FlaxForcedBOSTokenLogitsProcessor\",\n",
        "        \"FlaxForcedEOSTokenLogitsProcessor\",\n",
        "        \"FlaxForceTokensLogitsProcessor\",\n",
        "        \"FlaxLogitsProcessor\",\n",
        "        \"FlaxLogitsProcessorList\",\n",
        "        \"FlaxLogitsWarper\",\n",
        "        \"FlaxMinLengthLogitsProcessor\",\n",
        "        \"FlaxSuppressTokensAtBeginLogitsProcessor\",\n",
        "        \"FlaxSuppressTokensLogitsProcessor\",\n",
        "        \"FlaxTemperatureLogitsWarper\",\n",
        "        \"FlaxTopKLogitsWarper\",\n",
        "        \"FlaxTopPLogitsWarper\",\n",
        "        \"FlaxWhisperTimeStampLogitsProcessor\",\n",
        "        \"FlaxNoRepeatNGramLogitsProcessor\",\n",
        "    ]\n",
        "    _import_structure[\"flax_utils\"] = [\n",
        "        \"FlaxGenerationMixin\",\n",
        "        \"FlaxGreedySearchOutput\",\n",
        "        \"FlaxSampleOutput\",\n",
        "        \"FlaxBeamSearchOutput\",\n",
        "    ]\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    from .configuration_utils import (\n",
        "        BaseWatermarkingConfig,\n",
        "        CompileConfig,\n",
        "        GenerationConfig,\n",
        "        GenerationMode,\n",
        "        SynthIDTextWatermarkingConfig,\n",
        "        WatermarkingConfig,\n",
        "    )\n",
        "    from .streamers import AsyncTextIteratorStreamer, BaseStreamer, TextIteratorStreamer, TextStreamer\n",
        "\n",
        "    try:\n",
        "        if not is_torch_available():\n",
        "            raise OptionalDependencyNotAvailable()\n",
        "    except OptionalDependencyNotAvailable:\n",
        "        pass\n",
        "    else:\n",
        "        from .beam_constraints import Constraint, ConstraintListState, DisjunctiveConstraint, PhrasalConstraint\n",
        "        from .beam_search import BeamHypotheses, BeamScorer, BeamSearchScorer, ConstrainedBeamSearchScorer\n",
        "        from .candidate_generator import (\n",
        "            AssistedCandidateGenerator,\n",
        "            CandidateGenerator,\n",
        "            EarlyExitCandidateGenerator,\n",
        "            PromptLookupCandidateGenerator,\n",
        "        )\n",
        "        from .continuous_batching import ContinuousMixin\n",
        "        from .logits_process import (\n",
        "            AlternatingCodebooksLogitsProcessor,\n",
        "            ClassifierFreeGuidanceLogitsProcessor,\n",
        "            EncoderNoRepeatNGramLogitsProcessor,\n",
        "            EncoderRepetitionPenaltyLogitsProcessor,\n",
        "            EpsilonLogitsWarper,\n",
        "            EtaLogitsWarper,\n",
        "            ExponentialDecayLengthPenalty,\n",
        "            ForcedBOSTokenLogitsProcessor,\n",
        "            ForcedEOSTokenLogitsProcessor,\n",
        "            HammingDiversityLogitsProcessor,\n",
        "            InfNanRemoveLogitsProcessor,\n",
        "            LogitNormalization,\n",
        "            LogitsProcessor,\n",
        "            LogitsProcessorList,\n",
        "            MinLengthLogitsProcessor,\n",
        "            MinNewTokensLengthLogitsProcessor,\n",
        "            MinPLogitsWarper,\n",
        "            NoBadWordsLogitsProcessor,\n",
        "            NoRepeatNGramLogitsProcessor,\n",
        "            PrefixConstrainedLogitsProcessor,\n",
        "            RepetitionPenaltyLogitsProcessor,\n",
        "            SequenceBiasLogitsProcessor,\n",
        "            SuppressTokensAtBeginLogitsProcessor,\n",
        "            SuppressTokensLogitsProcessor,\n",
        "            SynthIDTextWatermarkLogitsProcessor,\n",
        "            TemperatureLogitsWarper,\n",
        "            TopKLogitsWarper,\n",
        "            TopPLogitsWarper,\n",
        "            TypicalLogitsWarper,\n",
        "            UnbatchedClassifierFreeGuidanceLogitsProcessor,\n",
        "            WatermarkLogitsProcessor,\n",
        "            WhisperTimeStampLogitsProcessor,\n",
        "        )\n",
        "        from .stopping_criteria import (\n",
        "            ConfidenceCriteria,\n",
        "            EosTokenCriteria,\n",
        "            MaxLengthCriteria,\n",
        "            MaxTimeCriteria,\n",
        "            StoppingCriteria,\n",
        "            StoppingCriteriaList,\n",
        "            StopStringCriteria,\n",
        "            validate_stopping_criteria,\n",
        "        )\n",
        "        from .utils import (\n",
        "            BeamSampleDecoderOnlyOutput,\n",
        "            BeamSampleEncoderDecoderOutput,\n",
        "            BeamSearchDecoderOnlyOutput,\n",
        "            BeamSearchEncoderDecoderOutput,\n",
        "            ContrastiveSearchDecoderOnlyOutput,\n",
        "            ContrastiveSearchEncoderDecoderOutput,\n",
        "            GenerateBeamDecoderOnlyOutput,\n",
        "            GenerateBeamEncoderDecoderOutput,\n",
        "            GenerateDecoderOnlyOutput,\n",
        "            GenerateEncoderDecoderOutput,\n",
        "            GenerationMixin,\n",
        "            GreedySearchDecoderOnlyOutput,\n",
        "            GreedySearchEncoderDecoderOutput,\n",
        "            SampleDecoderOnlyOutput,\n",
        "            SampleEncoderDecoderOutput,\n",
        "        )\n",
        "        from .watermarking import (\n",
        "            BayesianDetectorConfig,\n",
        "            BayesianDetectorModel,\n",
        "            SynthIDTextWatermarkDetector,\n",
        "            WatermarkDetector,\n",
        "            WatermarkDetectorOutput,\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        if not is_tf_available():\n",
        "            raise OptionalDependencyNotAvailable()\n",
        "    except OptionalDependencyNotAvailable:\n",
        "        pass\n",
        "    else:\n",
        "        from .tf_logits_process import (\n",
        "            TFForcedBOSTokenLogitsProcessor,\n",
        "            TFForcedEOSTokenLogitsProcessor,\n",
        "            TFForceTokensLogitsProcessor,\n",
        "            TFLogitsProcessor,\n",
        "            TFLogitsProcessorList,\n",
        "            TFLogitsWarper,\n",
        "            TFMinLengthLogitsProcessor,\n",
        "            TFNoBadWordsLogitsProcessor,\n",
        "            TFNoRepeatNGramLogitsProcessor,\n",
        "            TFRepetitionPenaltyLogitsProcessor,\n",
        "            TFSuppressTokensAtBeginLogitsProcessor,\n",
        "            TFSuppressTokensLogitsProcessor,\n",
        "            TFTemperatureLogitsWarper,\n",
        "            TFTopKLogitsWarper,\n",
        "            TFTopPLogitsWarper,\n",
        "        )\n",
        "        from .tf_utils import (\n",
        "            TFBeamSampleDecoderOnlyOutput,\n",
        "            TFBeamSampleEncoderDecoderOutput,\n",
        "            TFBeamSearchDecoderOnlyOutput,\n",
        "            TFBeamSearchEncoderDecoderOutput,\n",
        "            TFContrastiveSearchDecoderOnlyOutput,\n",
        "            TFContrastiveSearchEncoderDecoderOutput,\n",
        "            TFGenerationMixin,\n",
        "            TFGreedySearchDecoderOnlyOutput,\n",
        "            TFGreedySearchEncoderDecoderOutput,\n",
        "            TFSampleDecoderOnlyOutput,\n",
        "            TFSampleEncoderDecoderOutput,\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        if not is_flax_available():\n",
        "            raise OptionalDependencyNotAvailable()\n",
        "    except OptionalDependencyNotAvailable:\n",
        "        pass\n",
        "    else:\n",
        "        from .flax_logits_process import (\n",
        "            FlaxForcedBOSTokenLogitsProcessor,\n",
        "            FlaxForcedEOSTokenLogitsProcessor,\n",
        "            FlaxForceTokensLogitsProcessor,\n",
        "            FlaxLogitsProcessor,\n",
        "            FlaxLogitsProcessorList,\n",
        "            FlaxLogitsWarper,\n",
        "            FlaxMinLengthLogitsProcessor,\n",
        "            FlaxNoRepeatNGramLogitsProcessor,\n",
        "            FlaxSuppressTokensAtBeginLogitsProcessor,\n",
        "            FlaxSuppressTokensLogitsProcessor,\n",
        "            FlaxTemperatureLogitsWarper,\n",
        "            FlaxTopKLogitsWarper,\n",
        "            FlaxTopPLogitsWarper,\n",
        "            FlaxWhisperTimeStampLogitsProcessor,\n",
        "        )\n",
        "        from .flax_utils import FlaxBeamSearchOutput, FlaxGenerationMixin, FlaxGreedySearchOutput, FlaxSampleOutput\n",
        "else:\n",
        "    import sys\n",
        "\n",
        "    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n"
      ],
      "metadata": {
        "id": "iPSASE_2T9i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLS-8VR8_j65",
        "outputId": "690ac015-2c4c-4b87-c2a4-8dd763f64e5d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beam_constraints.py\tflax_utils.py\t      tf_logits_process.py\n",
            "beam_search.py\t\t__init__.py\t      tf_utils.py\n",
            "candidate_generator.py\tlogits_process.py     utils.py\n",
            "configuration_utils.py\t__pycache__\t      watermarking.py\n",
            "continuous_batching.py\tstopping_criteria.py\n",
            "flax_logits_process.py\tstreamers.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/old_text/new_text/g' utils.py"
      ],
      "metadata": {
        "id": "8v0L6_Gz_lD5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get nano"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlMnzHcy_4Q5",
        "outputId": "1455e15d-b1cc-4543-b058-bbf3ca1751ef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Invalid operation nano\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!nano utils.py"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKSjamqIABWB",
        "outputId": "24e1bca9-b6d6-4a45-bbc7-28e4a1adbe74"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?1l\u001b>\u001b[?2004lReceived SIGHUP or SIGTERM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIufcLeACUe6",
        "outputId": "e0a3063e-326a-4b95-e631-4d8392eb29cf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.55.0\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: compressed-tensors, peft, sentence-transformers, vllm, xgrammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. تأكيد تثبيت مكتبة transformers ومعرفة مسارها\n",
        "!pip show transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbaDcr9fCUxB",
        "outputId": "c975aed9-cf90-4e8c-97a7-ecd5552edc93"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.55.0\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: compressed-tensors, peft, sentence-transformers, vllm, xgrammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Evptu5dC3JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7e49854",
        "outputId": "ebeb8a7b-f843-472f-e783-765174ad3f6f"
      },
      "source": [
        "import transformers\n",
        "import os\n",
        "\n",
        "path = os.path.join(os.path.dirname(transformers.__file__), \"generation\", \"__init__.py\")\n",
        "print(path)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57746c8e",
        "outputId": "3c743bd8-b651-428d-d507-a1a9590b73b9"
      },
      "source": [
        "%cd /usr/local/lib/python3.11/dist-packages/transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM\n",
        "llm = LLM(model=\"meta-llama/Llama-3.2-1B\", model_impl=\"transformers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "VuPh5NyYFpk6",
        "outputId": "6dc9413b-6795-41dc-da4b-ce5d2f92e81a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'ProcessorMixin' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2865366499.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"meta-llama/Llama-3.2-1B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_impl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"transformers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__package__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from vllm.beam_search import (BeamSearchInstance, BeamSearchOutput,\n\u001b[0m\u001b[1;32m     18\u001b[0m                               \u001b[0mBeamSearchSequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               create_sort_beams_key_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/beam_search.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/sequence.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSingletonInputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimodal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiModalKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiModalPlaceholderDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mTokensPrompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_explicit_enc_dec_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    to_enc_dec_tuple_list, token_inputs, zip_enc_dec_prompts)\n\u001b[0;32m----> 9\u001b[0;31m from .registry import (DummyData, InputContext, InputProcessingContext,\n\u001b[0m\u001b[1;32m     10\u001b[0m                        InputRegistry)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/registry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ProcessorMixin' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "[d for d in dir(transformers) if \"GenerationMixin\" in d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-5nTw2EFqEa",
        "outputId": "62f59b0a-103d-4430-b00e-e73935b10bf1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['FlaxGenerationMixin', 'GenerationMixin', 'TFGenerationMixin']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5BVz8QiGOxR",
        "outputId": "94c181d9-9b78-4099-d550-060f29ccb79d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ProcessorMixin\n",
        "print(\"ProcessorMixin imported successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "nAftkCjHGjlS",
        "outputId": "f7456987-2f33-4a2c-fe9e-b16f6c0d87c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "Could not import module 'ProcessorMixin'. Are this object's requirements defined correctly?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrender_jinja_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torchvision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2315615460.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ProcessorMixin imported successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2295\u001b[0;31m                 raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m   2296\u001b[0m                     \u001b[0;34mf\"Could not import module '{name}'. Are this object's requirements defined correctly?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m                 ) from e\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: Could not import module 'ProcessorMixin'. Are this object's requirements defined correctly?",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yHjSsRmGmNy",
        "outputId": "6e78d018-7460-45ea-e3a3-bbccf7ab31f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ProcessorMixin\n",
        "print(\"تم الاستيراد بنجاح:\", ProcessorMixin)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "gAwcTLymGx2q",
        "outputId": "f62ea39f-523b-4e62-d700-b9e844eb0e05"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "Could not import module 'ProcessorMixin'. Are this object's requirements defined correctly?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrender_jinja_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torchvision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-299780778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"تم الاستيراد بنجاح:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2295\u001b[0;31m                 raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m   2296\u001b[0m                     \u001b[0;34mf\"Could not import module '{name}'. Are this object's requirements defined correctly?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m                 ) from e\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: Could not import module 'ProcessorMixin'. Are this object's requirements defined correctly?",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements/cpu-build.txt --torch-backend auto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcmDO9xRG0XW",
        "outputId": "c8bcf76a-60ef-42ed-bfd8-296b8a43d1fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip install [options] [-e] <vcs project url> ...\n",
            "  pip install [options] [-e] <local project path> ...\n",
            "  pip install [options] <archive url/path> ...\n",
            "\n",
            "no such option: --torch-backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZSUXzoXEG_vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "9mzV9jKCHLzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd vllm_source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg9H8JmRHP5D",
        "outputId": "bb853d3e-2621-4b01-b04a-9d3ecbeb0aa0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vllm_source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -r requirements/cpu-build.txt --torch-backend auto\n",
        "!uv pip install -r requirements/cpu.txt --torch-backend auto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYMH9IVHHQrC",
        "outputId": "89d9bd90-1fd6-4d5b-d948-0d4ded549218"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: File not found: `requirements/cpu-build.txt`\n",
            "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: File not found: `requirements/cpu.txt`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q0jMjIyAHUky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f77692d3",
        "outputId": "fc5538c7-6ff9-48d7-c00a-bf55d35d3a95"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vllm-project/vllm.git vllm_source\n",
        "%cd vllm_source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc0vVwJwITBD",
        "outputId": "b7840db9-ee11-4e90-a846-db016c76614b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vllm_source'...\n",
            "remote: Enumerating objects: 98107, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (174/174), done.\u001b[K\n",
            "remote: Total 98107 (delta 122), reused 35 (delta 31), pack-reused 97902 (from 4)\u001b[K\n",
            "Receiving objects: 100% (98107/98107), 69.53 MiB | 22.22 MiB/s, done.\n",
            "Resolving deltas: 100% (77447/77447), done.\n",
            "/content/ي/vllm_source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install -v -r requirements/cpu-build.txt --extra-index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install -v -r requirements/cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKf4pLoJIWo-",
        "outputId": "8298339d-eb60-4a20-bab3-abb1232c0914"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\n",
            "Using pip 25.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: cmake>=3.26.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu-build.txt (line 3)) (3.31.6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu-build.txt (line 4)) (1.11.1.4)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu-build.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: setuptools<80.0.0,>=77.0.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu-build.txt (line 6)) (79.0.1)\n",
            "Requirement already satisfied: setuptools-scm>=8 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu-build.txt (line 7)) (8.3.1)\n",
            "Requirement already satisfied: torch==2.6.0+cpu in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu-build.txt (line 9)) (2.6.0+cpu)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu-build.txt (line 10)) (0.45.1)\n",
            "Requirement already satisfied: jinja2>=3.1.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu-build.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu-build.txt (line 12)) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu-build.txt (line 9)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu-build.txt (line 9)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu-build.txt (line 9)) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu-build.txt (line 9)) (2025.3.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu-build.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0+cpu->-r requirements/cpu-build.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.6->-r requirements/cpu-build.txt (line 11)) (3.0.2)\n",
            "Using pip 25.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu\n",
            "Ignoring importlib_metadata: markers 'python_version < \"3.10\"' don't match your environment\n",
            "Ignoring six: markers 'python_version > \"3.11\"' don't match your environment\n",
            "Ignoring setuptools: markers 'python_version > \"3.11\"' don't match your environment\n",
            "Ignoring numba: markers 'python_version == \"3.9\"' don't match your environment\n",
            "Ignoring torch: markers 'platform_system == \"Darwin\"' don't match your environment\n",
            "Ignoring torch: markers 'platform_machine == \"ppc64le\"' don't match your environment\n",
            "Ignoring torch: markers 'platform_machine == \"aarch64\"' don't match your environment\n",
            "Ignoring torchaudio: markers 'platform_machine == \"ppc64le\"' don't match your environment\n",
            "Ignoring torchvision: markers 'platform_machine == \"ppc64le\"' don't match your environment\n",
            "Ignoring py-cpuinfo: markers 'platform_machine == \"aarch64\"' don't match your environment\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 2)) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 8)) (1.0.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 9)) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.55.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 10)) (4.55.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.33.0->-r /content/ي/vllm_source/requirements/common.txt (line 11)) (0.34.3)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 12)) (0.21.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 13)) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.116.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 15)) (3.12.15)\n",
            "Requirement already satisfied: openai>=1.98.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 16)) (1.98.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 17)) (2.11.7)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 18)) (0.22.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 19)) (11.3.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 20)) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 21)) (0.9.0)\n",
            "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 22)) (0.10.12)\n",
            "Requirement already satisfied: llguidance<0.8.0,>=0.7.11 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 23)) (0.7.30)\n",
            "Requirement already satisfied: outlines_core==0.2.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 24)) (0.2.10)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 26)) (5.6.3)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 27)) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.21 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 28)) (0.1.21)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 29)) (4.14.1)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 30)) (3.18.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 31)) (0.2.1.1.post6)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 32)) (26.2.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 33)) (0.19.0)\n",
            "Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 34)) (0.17.1)\n",
            "Requirement already satisfied: mistral_common>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (1.8.3)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 37)) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 38)) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 41)) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.10.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 42)) (0.10.2)\n",
            "Requirement already satisfied: depyf==0.19.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 43)) (0.19.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 44)) (3.1.1)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 45)) (1.1.0)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 46)) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 47)) (1.16.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 48)) (1.11.1.4)\n",
            "Requirement already satisfied: pybase64 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 49)) (1.4.2)\n",
            "Requirement already satisfied: cbor2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 50)) (5.6.5)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 51)) (1.3.6)\n",
            "Requirement already satisfied: openai-harmony>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/ي/vllm_source/requirements/common.txt (line 52)) (0.0.3)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 5)) (0.61.2)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 8)) (25.0)\n",
            "Requirement already satisfied: setuptools<80.0.0,>=77.0.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 9)) (79.0.1)\n",
            "Requirement already satisfied: torch==2.6.0+cpu in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 11)) (2.6.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 17)) (2.6.0+cu124)\n",
            "Collecting torchvision (from -r requirements/cpu.txt (line 21))\n",
            "  Obtaining dependency information for torchvision from https://download.pytorch.org/whl/cpu/torchvision-0.23.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.23.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 23)) (4.0.0)\n",
            "Requirement already satisfied: intel-openmp==2024.2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 26)) (2024.2.1)\n",
            "Requirement already satisfied: intel_extension_for_pytorch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 27)) (2.6.0)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/cpu.txt (line 28)) (3.2.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->-r /content/ي/vllm_source/requirements/common.txt (line 43)) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->-r /content/ي/vllm_source/requirements/common.txt (line 43)) (0.3.8)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.61.2->-r requirements/cpu.txt (line 5)) (0.44.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (2025.3.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (1.13.1)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.1 in /usr/local/lib/python3.11/dist-packages (from intel-openmp==2024.2.1->-r requirements/cpu.txt (line 26)) (2024.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer<0.11,>=0.10.11->-r /content/ي/vllm_source/requirements/common.txt (line 22)) (0.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r /content/ي/vllm_source/requirements/common.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r /content/ي/vllm_source/requirements/common.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r /content/ي/vllm_source/requirements/common.txt (line 6)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->-r /content/ي/vllm_source/requirements/common.txt (line 6)) (2025.7.14)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->-r /content/ي/vllm_source/requirements/common.txt (line 10)) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->-r /content/ي/vllm_source/requirements/common.txt (line 11)) (1.1.5)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.47.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->-r /content/ي/vllm_source/requirements/common.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->-r /content/ي/vllm_source/requirements/common.txt (line 17)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->-r /content/ي/vllm_source/requirements/common.txt (line 17)) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/ي/vllm_source/requirements/common.txt (line 15)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/ي/vllm_source/requirements/common.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/ي/vllm_source/requirements/common.txt (line 15)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/ي/vllm_source/requirements/common.txt (line 15)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/ي/vllm_source/requirements/common.txt (line 15)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/ي/vllm_source/requirements/common.txt (line 15)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r /content/ي/vllm_source/requirements/common.txt (line 15)) (1.20.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.98.0->-r /content/ي/vllm_source/requirements/common.txt (line 16)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.98.0->-r /content/ي/vllm_source/requirements/common.txt (line 16)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.98.0->-r /content/ي/vllm_source/requirements/common.txt (line 16)) (0.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.98.0->-r /content/ي/vllm_source/requirements/common.txt (line 16)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.98.0->-r /content/ي/vllm_source/requirements/common.txt (line 16)) (0.16.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (4.25.0)\n",
            "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (2.10.5)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/79/9c/fcb09aff941c8147d9e6aa6c8f67412a05622b0c750bcf796be4c85a58d4/torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Obtaining dependency information for torchvision from https://download.pytorch.org/whl/cpu/torchvision-0.22.1%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.22.1%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/c3/1a/63eb241598b36d37a0221e10af357da34bd33402ccf5c0765e389642218a/torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Obtaining dependency information for torchvision from https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/09/42/6908bff012a1dcc4fc515e52339652d7f488e208986542765c02ea775c2f/torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Obtaining dependency information for torchvision from https://download.pytorch.org/whl/cpu/torchvision-0.21.0%2Bcpu-cp311-cp311-linux_x86_64.whl.metadata\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.21.0%2Bcpu-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/cpu.txt (line 23)) (18.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/cpu.txt (line 23)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/cpu.txt (line 23)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/cpu.txt (line 23)) (0.70.16)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.8 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.0.8)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.0.20)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (2.2.0)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.35.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (2.7.0)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.16.0)\n",
            "Requirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.14.9)\n",
            "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.1.5)\n",
            "Requirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.6.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (2.34.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0+cpu->-r requirements/cpu.txt (line 11)) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (0.26.0)\n",
            "Requirement already satisfied: pycountry>=23 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (24.6.1)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (8.2.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.1.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->-r /content/ي/vllm_source/requirements/common.txt (line 14)) (15.0.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (2.22)\n",
            "Requirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->-r /content/ي/vllm_source/requirements/common.txt (line 36)) (0.5.0.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements/cpu.txt (line 23)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements/cpu.txt (line 23)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->-r requirements/cpu.txt (line 23)) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements/cpu.txt (line 23)) (1.17.0)\n",
            "Downloading https://download.pytorch.org/whl/cpu/torchvision-0.21.0%2Bcpu-cp311-cp311-linux_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "Successfully installed torchvision-0.21.0+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!LD_PRELOAD=\"/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4:$LD_PRELOAD\""
      ],
      "metadata": {
        "id": "ONf31Y4GIePS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!VLLM_TARGET_DEVICE=cpu python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1lwTlvnI1rK",
        "outputId": "5861dd15-477f-4a5e-d851-a6824b4ed916"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running install\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:90: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating vllm.egg-info\n",
            "writing vllm.egg-info/PKG-INFO\n",
            "writing dependency_links to vllm.egg-info/dependency_links.txt\n",
            "writing entry points to vllm.egg-info/entry_points.txt\n",
            "writing requirements to vllm.egg-info/requires.txt\n",
            "writing top-level names to vllm.egg-info/top_level.txt\n",
            "writing manifest file 'vllm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'vllm.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/collect_env.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/version.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_custom_ops.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/logits_process.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/sampling_params.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/pooling_params.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_ipex_ops.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_version.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/scripts.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/beam_search.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/connections.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/sequence.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/scalar_type.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/envs.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/tasks.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/outputs.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/config.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/logger.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/jsontree.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/tracing.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/env_override.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/forward_context.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/test_utils.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/ray\n",
            "copying vllm/ray/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/ray\n",
            "copying vllm/ray/lazy_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/ray\n",
            "copying vllm/ray/ray_env.py -> build/lib.linux-x86_64-cpython-311/vllm/ray\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/image.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/video.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/parse.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/audio.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/profiling.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/inputs.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/processing.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/hasher.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/base.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/image.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/video.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/audio.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/base.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/ray_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/uniproc_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/executor_base.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/ray_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/msgspec_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/mp_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/multiproc_worker_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuron_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/pooling_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuron_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/enc_dec_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_neuron_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/model_runner_base.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_neuronx_distributed_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuronx_distributed_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cache_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/communication_op.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/kv_events.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/parallel_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/tpu_distributed_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/plugins\n",
            "copying vllm/plugins/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/plugins\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/preprocess.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/data.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/parse.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/glm4_moe_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/qwen3_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/abs_reasoning_parsers.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/step3_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/gptoss_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/granite_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/hunyuan_a13b_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/deepseek_r1_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/mistral_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "copying vllm/triton_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "copying vllm/triton_utils/importing.py -> build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "copying vllm/device_allocator/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "copying vllm/device_allocator/cumem.py -> build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/parameter.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/pooling_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/custom_op.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/sampling_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/score_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/tool_server.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/harmony_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/chat_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/launcher.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/llm.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/api_server.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/ssl.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/logger.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/context.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/tool.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/layer.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/selector.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "copying vllm/usage/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "copying vllm/usage/usage_lib.py -> build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/models.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/request.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/async_llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/async_timeout.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/protocol.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/arg_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/metrics_types.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "copying vllm/third_party/pynvml.py -> build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "copying vllm/third_party/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/logging_utils/dump_input.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/logging_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/logging_utils/formatter.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/tokenizer_group.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/tokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/tokenizer_base.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/detokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/dynamic_module.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/s3_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/detokenizer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/config.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/processor.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/placeholder_block_space_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/block_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/evictor.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/cuda.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/rocm.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/neuron.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/cpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/tpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/xpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/models.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/fully_sharded_layers.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/lora.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/request.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/peft_helper.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/resolver.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/request.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/kv_cache_interface.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/outputs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/serial_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "copying vllm/utils/flashinfer.py -> build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "copying vllm/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "copying vllm/utils/tensor_schema.py -> build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "copying vllm/utils/deep_gemm.py -> build/lib.linux-x86_64-cpython-311/vllm/utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/layerwise_profile.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/throughput.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/datasets.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/latency.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/compiler_interface.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/decorators.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/counter.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/backends.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/vllm_inductor_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fusion_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fix_functionalization.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/base_piecewise_backend.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/monitor.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/activation_quant_fusion.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/pass_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/sequence_parallelism.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fx_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/collective_fusion.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/inductor_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/torch25_custom_graph_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/noop_elimination.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/cuda_piecewise_backend.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fusion.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/multi_output_match.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/kv_transfer_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "copying vllm/distributed/eplb/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "copying vllm/distributed/eplb/rebalance_execute.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "copying vllm/distributed/eplb/eplb_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "copying vllm/distributed/eplb/rebalance_algo.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/tpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/ray_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cuda_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/all2all.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/base_device_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/neuron_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/custom_all_reduce_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/pynccl_wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/quick_all_reduce.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/xpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/shm_broadcast.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/custom_all_reduce.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/pynccl.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cuda_wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/factory.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers\n",
            "copying vllm/plugins/lora_resolvers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers\n",
            "copying vllm/plugins/lora_resolvers/filesystem_resolver.py -> build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aimv2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_5_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/pixtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interfaces_base.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpm_eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granite.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ernie45.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_vl_01.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/idefics3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bloom.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/fairseq2_llama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/dots1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_j.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/intern_vit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/grok1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mllama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mimo_mtp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpmv.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/voxtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ernie45_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_mtp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_audio.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/stablelm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_onevision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/clip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/adapters.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bailing_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/hunyuan_v1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mimo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/constant_size_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_5_omni_thinker.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4_moe_mtp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/idefics2_vision_model.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bart.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmo2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama_eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bert_with_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/tarsier.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/molmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/teleflm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/module_mapping.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mixtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/zamba2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/telechat2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4_1v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jais.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/exaone4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama_eagle3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/hyperclovax_vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/dbrx.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/step3_text.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_v2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/kimi_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mllama4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/orion.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/whisper.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/opt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/prithvi_geospatial_mae.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jina_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internlm2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/smolvlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3n.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_bigcode.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/baichuan.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpm3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoeshared.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mixtral_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internvl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/arctic.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/blip2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phimoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nvlm_d.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internlm2_ve.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ovis.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/transformers.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/siglip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron_nas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_rm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mpt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/commandr.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4_multimodal.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mlp_speculator.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/plamo2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/chatglm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_next_video.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aya_vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/falcon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/chameleon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_text_01.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ultravox.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interns1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bert.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/arcee.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/starcoder2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/config.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/modernbert.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/blip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granite_speech.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/fuyu.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama4_eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm_audio.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3_mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoehybrid.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/solar.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4flash.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/keye.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/paligemma.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/exaone.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_neox.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/persimmon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mistral3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/skyworkr1v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_oss.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aria.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gritlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_next.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/moonvit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron_h.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/florence2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen3_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/roberta.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interns1_vit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/step3_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/falcon_h1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/h2ovl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/linear.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/pooler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/layernorm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/resampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/lightning_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/activation.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/logits_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/vocab_parallel_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/sharded_state_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/runai_streamer_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/neuron.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/tensorizer_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/tensorizer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/neuronx_distributed.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/dummy_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/gguf_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/weight_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/base_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/tpu.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/bitsandbytes_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/default_loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/input_quant_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/schema.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/torchao.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/ipex_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/bitblas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/experts_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/mxfp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gguf.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/aqlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/modelopt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/fbgemm_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/auto_round.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq_triton.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/base_config.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_bitblas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/qqq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/tpu_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/moe_wna16.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/inc.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/kv_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_marlin_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/rtn.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/bitsandbytes.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/ptpc_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/hqq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/deepspeedfp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/neuron_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/deepgemm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/layer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_batched_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/cutlass_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deep_gemm_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_torch_iterative.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/cpu_fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/modular_kernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/config.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_align_block_size.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_marlin_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/mrope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/llama3_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/common.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/base.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "copying vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_mixer2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_mixer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba2_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/quark.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/quark_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels\n",
            "copying vllm/model_executor/layers/quantization/kernels/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/machete_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/fp8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/w8a8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/int8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/layer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/allspark_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/quant_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/gptq_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/bitblas_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/mxfp4_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/flashinfer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/layernorm_gated.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_state_passing.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_bmm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/causal_conv1d.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/mamba_ssm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_combined.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_responses.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_transcription.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/cli_args.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/speech_to_text.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_chat.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_completion.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_pooling.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/run_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/logits_processors.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/api_server.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_score.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_classification.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_tokenization.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_models.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/protocol.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/collect_env.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/types.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/openai.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/main.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/run_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/throughput.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/main.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/latency.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/base.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flashinfer.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/xformers.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/dual_chunk_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/differential_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/rocm_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/triton_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/placeholder_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/rocm_aiter_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_decode_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_unified_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_merge_attn_states.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_flash_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/prefix_prefill.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/chunked_prefill_paged_decode.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/nki_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/rocm_aiter_paged_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/pallas_kv_cache_update.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/paged_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/rocm_aiter_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/merge_attn_states.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention/utils\n",
            "copying vllm/attention/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/utils\n",
            "copying vllm/attention/utils/fa_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/utils\n",
            "copying vllm/attention/utils/kv_sharing_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/utils\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "copying vllm/attention/backends/mla/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "copying vllm/attention/backends/mla/common.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/client.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/single_step.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/multi_step.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/stop_checker.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/util.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mllama.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/jais.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nemotron.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mistral.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/kimi_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/arctic.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nvlm_d.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/ovis.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mlp_speculator.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/chatglm.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/falcon.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/ultravox.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nemotron_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/moonvit.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nemotron_h.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/step3_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "copying vllm/transformers_utils/tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "copying vllm/transformers_utils/tokenizers/mistral.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/transformers_utils/processors/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/transformers_utils/processors/ovis.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/transformers_utils/processors/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators\n",
            "copying vllm/transformers_utils/configs/speculators/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators\n",
            "copying vllm/transformers_utils/configs/speculators/algos.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators\n",
            "copying vllm/transformers_utils/configs/speculators/base.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/prefix_caching_block.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/common.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/naive_block.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/block_table.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/cpu_gpu_block_allocator.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_base.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_selector.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_cpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_gpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_tpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_xpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops\n",
            "copying vllm/lora/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_shrink_op.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_kernel_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_expand_op.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/kernel_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops\n",
            "copying vllm/lora/ops/ipex_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops\n",
            "copying vllm/lora/ops/ipex_ops/lora_ops.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops\n",
            "copying vllm/lora/ops/xla_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops\n",
            "copying vllm/lora/ops/xla_ops/lora_ops.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "copying vllm/lora/ops/torch_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "copying vllm/lora/ops/torch_ops/lora_ops.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/ray_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/multiproc_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_guidance.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_xgrammar.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/request.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_outlines.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_types.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/reader.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/loggers.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/stats.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/prometheus.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/ray_wrappers.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/lora_model_runner_mixin.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/xpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/kv_connector_model_runner_mixin.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/cpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/xpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/cpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_input_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/block_table.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_input_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/pool\n",
            "copying vllm/v1/pool/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/pool\n",
            "copying vllm/v1/pool/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/pool\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/rejection_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/logits_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/attention\n",
            "copying vllm/v1/attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/core.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/mm_input_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/core_client.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/detokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/parallel_sampling.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/logprobs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/output_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/exceptions.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/async_llm.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/coordinator.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/ngram_proposer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/block_pool.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_coordinator.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/single_type_kv_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/encoder_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/bad_words.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/topk_topp_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/logprobs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/penalties.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/mamba_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/flashinfer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/xformers.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/triton_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/flex_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/mamba1_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/mamba_selectors.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/rocm_aiter_fa.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/tree_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/cpu_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/common.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/triton_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/rocm_aiter_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/cutlass_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/output.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/async_scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/request_queue.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/benchmarks/lib/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/benchmarks/lib/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/benchmarks/lib/ready_checker.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/benchmarks/lib/endpoint_request_func.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib\n",
            "copying vllm/py.typed -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "creating build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn\n",
            "copying vllm/vllm_flash_attn/.gitkeep -> build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn\n",
            "copying vllm/distributed/kv_transfer/README.md -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/plugins/lora_resolvers/README.md -> build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/README -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/transformers_utils/chat_templates/template_basic.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/template_blip2.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/template_chatml.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/template_deepseek_vl2.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "copying vllm/transformers_utils/chat_templates/template_fuyu.jinja -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates\n",
            "running build_ext\n",
            "-- The CXX compiler identification is GNU 12.3.0\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Build type: RelWithDebInfo\n",
            "-- Target device: cpu\n",
            "-- Found Python: /usr/bin/python3 (found version \"3.11.13\") found components: Interpreter Development.Module Development.SABIModule\n",
            "-- Found python matching: /usr/bin/python3.\n",
            "\u001b[33mCMake Warning at /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:22 (message):\n",
            "  static library kineto_LIBRARY-NOTFOUND not found.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:121 (append_torchlib_if_found)\n",
            "  CMakeLists.txt:80 (find_package)\n",
            "\n",
            "\u001b[0m\n",
            "-- Found Torch: /usr/local/lib/python3.11/dist-packages/torch/lib/libtorch.so\n",
            "\u001b[33mCMake Warning at cmake/cpu_extension.cmake:143 (message):\n",
            "  vLLM CPU backend using AVX2 ISA\n",
            "Call Stack (most recent call first):\n",
            "  CMakeLists.txt:97 (include)\n",
            "\n",
            "\u001b[0m\n",
            "-- CPU extension compile flags: -mf16c;-fopenmp;-DVLLM_CPU_EXTENSION;-mavx2\n",
            "-- CPU extension source files: csrc/cpu/activation.cpp;csrc/cpu/attention.cpp;csrc/cpu/cache.cpp;csrc/cpu/utils.cpp;csrc/cpu/layernorm.cpp;csrc/cpu/mla_decode.cpp;csrc/cpu/pos_encoding.cpp;csrc/cpu/torch_bindings.cpp\n",
            "-- Enabling C extension.\n",
            "-- Configuring done (3.8s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/ي/vllm_source/build/temp.linux-x86_64-cpython-311\n",
            "[9/9] Linking CXX shared module _C.abi3.so\u001b[K\n",
            "-- Install configuration: \"RelWithDebInfo\"\n",
            "-- Installing: /content/ي/vllm_source/build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so\n",
            "-- Set non-toolchain portion of runtime path of \"/content/ي/vllm_source/build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so\" to \"\"\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/collect_env.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/__init__.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/lazy_utils.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/ray_env.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/version.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/image.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/utils.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/__init__.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/registry.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/video.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/parse.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/audio.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/profiling.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/inputs.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/processing.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/hasher.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/base.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "creating build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/image.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/__init__.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/video.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/audio.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/base.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "creating build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/ray_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/uniproc_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/executor_base.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/ray_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/msgspec_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/mp_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/multiproc_worker_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/__init__.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_custom_ops.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logits_process.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/worker_base.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuron_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/utils.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/__init__.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/pooling_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuron_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/enc_dec_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_neuron_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/model_runner_base.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_neuronx_distributed_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuronx_distributed_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cache_engine.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/README.md -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_transfer_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/factory.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/communication_op.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/rebalance_execute.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/eplb_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/rebalance_algo.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/tpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/ray_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cuda_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/all2all.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/base_device_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/neuron_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/custom_all_reduce_utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/pynccl_wrapper.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/quick_all_reduce.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/xpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/shm_broadcast.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/custom_all_reduce.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/pynccl.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cuda_wrapper.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_events.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/parallel_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/tpu_distributed_utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/plugins\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/__init__.py -> build/bdist.linux-x86_64/egg/vllm/plugins\n",
            "creating build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/README.md -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/filesystem_resolver.py -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/preprocess.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/__init__.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/registry.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/data.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/parse.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/sampling_params.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/glm4_moe_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/qwen3_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/abs_reasoning_parsers.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/step3_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/gptoss_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/__init__.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/granite_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/hunyuan_a13b_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/deepseek_r1_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/mistral_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/pooling_params.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_ipex_ops.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn/.gitkeep -> build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "creating build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/triton_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/triton_utils/importing.py -> build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/device_allocator/__init__.py -> build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/device_allocator/cumem.py -> build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_version.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/scripts.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/parameter.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aimv2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_5_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/pixtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interfaces_base.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granite.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ernie45.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_vl_01.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/idefics3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bloom.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/fairseq2_llama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/dots1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_j.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/intern_vit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/grok1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mllama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mimo_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpmv.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/voxtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ernie45_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_audio.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/stablelm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_onevision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/clip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/medusa.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/adapters.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bailing_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/hunyuan_v1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mimo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/constant_size_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_5_omni_thinker.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_moe_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/idefics2_vision_model.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/registry.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bart.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmo2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bert_with_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/tarsier.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/molmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/teleflm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/module_mapping.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mixtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/zamba2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/telechat2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_1v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jais.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/exaone4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama_eagle3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/hyperclovax_vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/dbrx.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/step3_text.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_v2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/kimi_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mllama4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/orion.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/whisper.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/opt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/prithvi_geospatial_mae.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jina_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internlm2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/smolvlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3n.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_bigcode.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/baichuan.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoeshared.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mixtral_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internvl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/arctic.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/blip2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phimoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nvlm_d.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internlm2_ve.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ovis.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/transformers.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/siglip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_nas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_rm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mpt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/commandr.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4_multimodal.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mlp_speculator.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/plamo2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/chatglm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_next_video.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aya_vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/falcon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/chameleon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_text_01.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ultravox.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interns1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bert.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/arcee.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/starcoder2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/modernbert.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/blip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granite_speech.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/fuyu.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama4_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm_audio.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3_mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoehybrid.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/solar.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4flash.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/keye.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/paligemma.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/exaone.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_neox.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/persimmon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mistral3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/skyworkr1v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_oss.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aria.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gritlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_next.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/moonvit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_h.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/florence2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen3_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/roberta.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interns1_vit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/step3_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/falcon_h1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/h2ovl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/input_quant_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/schema.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/torchao.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/ipex_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/experts_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/quark.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/quark_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/mxfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gguf.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/aqlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/modelopt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/fbgemm_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/auto_round.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq_triton.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/base_config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/qqq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/tpu_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/moe_wna16.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/inc.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kv_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_marlin_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/rtn.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/bitsandbytes.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/ptpc_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/hqq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/machete_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/fp8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/w8a8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/int8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/layer_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/allspark_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/quant_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/gptq_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/bitblas_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/mxfp4_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/flashinfer_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/deepspeedfp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/neuron_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/deepgemm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/linear.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/layer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/README -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_batched_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/cutlass_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_pallas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deep_gemm_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_torch_iterative.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/cpu_fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/modular_kernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_align_block_size.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_marlin_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/mrope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/llama3_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/common.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/base.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/pooler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/layernorm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/resampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/layernorm_gated.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_state_passing.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_bmm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/causal_conv1d.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/mamba_ssm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_combined.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/abstract.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_mixer2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_mixer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba2_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/lightning_attn.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/activation.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/logits_processor.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/vocab_parallel_embedding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/pooling_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/sharded_state_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/runai_streamer_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/neuron.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tensorizer_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tensorizer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/neuronx_distributed.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/dummy_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/gguf_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/weight_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/base_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tpu.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/bitsandbytes_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/default_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/custom_op.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/sampling_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/score_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_engine.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_responses.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_transcription.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/cli_args.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/speech_to_text.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_chat.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_completion.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_pooling.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/run_batch.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/logits_processors.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/api_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_score.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_embedding.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_classification.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_tokenization.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_models.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/protocol.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/tool_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/harmony_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/chat_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/launcher.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/llm.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/api_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/collect_env.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/types.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/openai.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/main.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/serve.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/run_batch.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/throughput.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/main.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/serve.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/latency.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/base.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/ssl.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/logger.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/context.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/tool.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/beam_search.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/connections.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/layer.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/xformers.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/dual_chunk_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/differential_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/rocm_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/abstract.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/triton_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla/common.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/placeholder_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_decode_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_unified_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_merge_attn_states.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_flash_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/prefix_prefill.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/chunked_prefill_paged_decode.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/nki_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/rocm_aiter_paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/pallas_kv_cache_update.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/merge_attn_states.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/selector.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/fa_utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/kv_sharing_utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/usage\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/usage/__init__.py -> build/bdist.linux-x86_64/egg/vllm/usage\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/usage/usage_lib.py -> build/bdist.linux-x86_64/egg/vllm/usage\n",
            "creating build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/models.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/utils.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/__init__.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/request.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/layers.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/metrics.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/async_llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/async_timeout.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/client.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/engine.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/single_step.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/multi_step.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/stop_checker.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/util.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/protocol.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/arg_utils.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/metrics_types.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/third_party/pynvml.py -> build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/third_party/__init__.py -> build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "creating build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/dump_input.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/formatter.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/sequence.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/scalar_type.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_chatml.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_deepseek_vl2.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/registry.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_blip2.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_fuyu.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_basic.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mllama.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/medusa.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/jais.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mistral.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/kimi_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/arctic.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nvlm_d.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/ovis.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mlp_speculator.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/eagle.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/chatglm.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/algos.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/base.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/falcon.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/ultravox.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/moonvit.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron_h.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/step3_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_base.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/detokenizer.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/dynamic_module.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/s3_utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers/mistral.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/detokenizer_utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/config.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/ovis.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processor.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/envs.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/__init__.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/placeholder_block_space_manager.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block_manager.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/utils.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/__init__.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/prefix_caching_block.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/common.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/naive_block.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/block_table.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/cpu_gpu_block_allocator.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/evictor.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/scheduler.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/cuda.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/rocm.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/__init__.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/neuron.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/interface.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/cpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/tpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/xpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/models.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/fully_sharded_layers.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_base.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_selector.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_cpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_gpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_tpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_xpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/lora.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_shrink_op.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_kernel_metadata.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_expand_op.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/kernel_utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/request.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/peft_helper.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/resolver.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/layers.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/tasks.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/outputs.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/ray_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/multiproc_executor.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/abstract.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_guidance.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_xgrammar.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/request.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_outlines.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_types.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/reader.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/loggers.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/stats.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/prometheus.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/ray_wrappers.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/worker_base.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/lora_model_runner_mixin.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/xpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/kv_connector_model_runner_mixin.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/cpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/xpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/cpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_input_batch.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/block_table.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_input_batch.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/pool/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/pool/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/rejection_sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/bad_words.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/topk_topp_sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/logprobs.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/penalties.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/logits_processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/xformers.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/triton_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flex_attention.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba1_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba_selectors.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/common.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/triton_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/cutlass_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/rocm_aiter_fa.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/tree_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/cpu_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/pallas.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/request.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/core.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/mm_input_cache.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/core_client.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/detokenizer.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/parallel_sampling.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/logprobs.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/output_processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/exceptions.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/async_llm.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/coordinator.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/medusa.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/metrics.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/eagle.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/ngram_proposer.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/kv_cache_interface.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/block_pool.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_coordinator.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/single_type_kv_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/encoder_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/interface.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/output.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/async_scheduler.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/scheduler.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/request_queue.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/outputs.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/serial_utils.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/config.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logger.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/tensor_schema.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/deep_gemm.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/jsontree.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/utils.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/__init__.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/layerwise_profile.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/py.typed -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/__init__.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/throughput.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/datasets.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/serve.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/latency.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "creating build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/utils.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/__init__.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/ready_checker.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/endpoint_request_func.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/tracing.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/env_override.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/forward_context.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/test_utils.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/compiler_interface.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/decorators.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/__init__.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/counter.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/wrapper.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/backends.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/vllm_inductor_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fusion_attn.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fix_functionalization.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/base_piecewise_backend.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/monitor.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/activation_quant_fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/pass_manager.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/sequence_parallelism.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fx_utils.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/collective_fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/inductor_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/torch25_custom_graph_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/noop_elimination.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/cuda_piecewise_backend.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/multi_output_match.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/collect_env.py to collect_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/lazy_utils.py to lazy_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/ray_env.py to ray_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/version.py to version.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/image.py to image.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/video.py to video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/parse.py to parse.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/audio.py to audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/profiling.py to profiling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/inputs.py to inputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/processing.py to processing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/hasher.py to hasher.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/image.py to image.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/video.py to video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/audio.py to audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/ray_distributed_executor.py to ray_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/uniproc_executor.py to uniproc_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/executor_base.py to executor_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/ray_utils.py to ray_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/msgspec_utils.py to msgspec_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/mp_distributed_executor.py to mp_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/multiproc_worker_utils.py to multiproc_worker_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_custom_ops.py to _custom_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logits_process.py to logits_process.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/worker_base.py to worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuron_worker.py to neuron_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_model_runner.py to multi_step_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/pooling_model_runner.py to pooling_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuron_model_runner.py to neuron_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/model_runner.py to model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/enc_dec_model_runner.py to enc_dec_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_neuron_model_runner.py to multi_step_neuron_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_worker.py to multi_step_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/model_runner_base.py to model_runner_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_neuronx_distributed_model_runner.py to multi_step_neuronx_distributed_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/worker.py to worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuronx_distributed_model_runner.py to neuronx_distributed_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cache_engine.py to cache_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py to pynccl_pipe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py to mooncake_pipe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py to simple_buffer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py to mooncake_store.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_transfer_state.py to kv_transfer_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/factory.py to factory.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py to shared_storage_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py to nixl_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py to p2p_nccl_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py to p2p_nccl_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py to tensor_memory_pool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py to multi_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py to lmcache_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/communication_op.py to communication_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/rebalance_execute.py to rebalance_execute.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/eplb_state.py to eplb_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/rebalance_algo.py to rebalance_algo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/tpu_communicator.py to tpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/ray_communicator.py to ray_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cpu_communicator.py to cpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cuda_communicator.py to cuda_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/all2all.py to all2all.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/base_device_communicator.py to base_device_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/neuron_communicator.py to neuron_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/custom_all_reduce_utils.py to custom_all_reduce_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/pynccl_wrapper.py to pynccl_wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/quick_all_reduce.py to quick_all_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/xpu_communicator.py to xpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/shm_broadcast.py to shm_broadcast.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/custom_all_reduce.py to custom_all_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/pynccl.py to pynccl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cuda_wrapper.py to cuda_wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_events.py to kv_events.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/parallel_state.py to parallel_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/tpu_distributed_utils.py to tpu_distributed_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers/filesystem_resolver.py to filesystem_resolver.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/preprocess.py to preprocess.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/data.py to data.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/parse.py to parse.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/sampling_params.py to sampling_params.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/glm4_moe_reasoning_parser.py to glm4_moe_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/qwen3_reasoning_parser.py to qwen3_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/abs_reasoning_parsers.py to abs_reasoning_parsers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/step3_reasoning_parser.py to step3_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/gptoss_reasoning_parser.py to gptoss_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/granite_reasoning_parser.py to granite_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/hunyuan_a13b_reasoning_parser.py to hunyuan_a13b_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/deepseek_r1_reasoning_parser.py to deepseek_r1_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/mistral_reasoning_parser.py to mistral_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/pooling_params.py to pooling_params.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_ipex_ops.py to _ipex_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/triton_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/triton_utils/importing.py to importing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/device_allocator/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/device_allocator/cumem.py to cumem.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_version.py to _version.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/scripts.py to scripts.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/parameter.py to parameter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aimv2.py to aimv2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm.py to minicpm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_5_vl.py to qwen2_5_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/pixtral.py to pixtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interfaces_base.py to interfaces_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm_eagle.py to minicpm_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granite.py to granite.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ernie45.py to ernie45.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi.py to phi.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_vl_01.py to minimax_vl_01.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/idefics3.py to idefics3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bloom.py to bloom.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/fairseq2_llama.py to fairseq2_llama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/dots1.py to dots1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_j.py to gpt_j.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/intern_vit.py to intern_vit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/grok1.py to grok1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek.py to deepseek.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mllama.py to mllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mimo_mtp.py to mimo_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpmv.py to minicpmv.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/voxtral.py to voxtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma2.py to gemma2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ernie45_moe.py to ernie45_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_mtp.py to deepseek_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_audio.py to qwen2_audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/stablelm.py to stablelm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/vision.py to vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_onevision.py to llava_onevision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/clip.py to clip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/adapters.py to adapters.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bailing_moe.py to bailing_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/hunyuan_v1.py to hunyuan_v1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mimo.py to mimo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava.py to llava.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/constant_size_cache.py to constant_size_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_5_omni_thinker.py to qwen2_5_omni_thinker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3.py to phi3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_moe_mtp.py to glm4_moe_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/idefics2_vision_model.py to idefics2_vision_model.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bart.py to bart.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma.py to gemma.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmo2.py to olmo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen3.py to qwen3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama_eagle.py to llama_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bert_with_rope.py to bert_with_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/tarsier.py to tarsier.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2.py to qwen2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/molmo.py to molmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/teleflm.py to teleflm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba_cache.py to mamba_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_vl.py to qwen2_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/module_mapping.py to module_mapping.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mixtral.py to mixtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/zamba2.py to zamba2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3v.py to phi3v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/telechat2.py to telechat2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_1v.py to glm4_1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jais.py to jais.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/exaone4.py to exaone4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4.py to glm4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama_eagle3.py to llama_eagle3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_moe.py to qwen2_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/hyperclovax_vision.py to hyperclovax_vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron.py to nemotron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/dbrx.py to dbrx.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/step3_text.py to step3_text.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_v2.py to deepseek_v2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/kimi_vl.py to kimi_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_cache.py to minimax_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mllama4.py to mllama4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/orion.py to orion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/whisper.py to whisper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/opt.py to opt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/prithvi_geospatial_mae.py to prithvi_geospatial_mae.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm_utils.py to phi4mm_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jina_vl.py to jina_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmoe.py to olmoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internlm2.py to internlm2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/smolvlm.py to smolvlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3n.py to gemma3n.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_bigcode.py to gpt_bigcode.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/baichuan.py to baichuan.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm3.py to minicpm3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoeshared.py to granitemoeshared.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm.py to glm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen.py to qwen.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mixtral_quant.py to mixtral_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba2.py to mamba2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internvl.py to internvl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba.py to mamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/arctic.py to arctic.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/blip2.py to blip2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phimoe.py to phimoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama.py to llama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nvlm_d.py to nvlm_d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_moe.py to glm4_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internlm2_ve.py to internlm2_ve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/transformers.py to transformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/siglip.py to siglip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_nas.py to nemotron_nas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_rm.py to qwen2_rm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bamba.py to bamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mpt.py to mpt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/commandr.py to commandr.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt2.py to gpt2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmo.py to olmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4_multimodal.py to phi4_multimodal.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mlp_speculator.py to mlp_speculator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/plamo2.py to plamo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm.py to phi4mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/chatglm.py to chatglm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_next_video.py to llava_next_video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aya_vision.py to aya_vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen_vl.py to qwen_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/falcon.py to falcon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3.py to gemma3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/chameleon.py to chameleon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_text_01.py to minimax_text_01.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ultravox.py to ultravox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interns1.py to interns1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bert.py to bert.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/arcee.py to arcee.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/starcoder2.py to starcoder2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4v.py to glm4v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jamba.py to jamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/modernbert.py to modernbert.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/blip.py to blip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granite_speech.py to granite_speech.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/fuyu.py to fuyu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_vl.py to nemotron_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoe.py to granitemoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama4_eagle.py to llama4_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm_audio.py to phi4mm_audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3_mm.py to gemma3_mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama4.py to llama4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoehybrid.py to granitemoehybrid.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/solar.py to solar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4flash.py to phi4flash.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/keye.py to keye.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/paligemma.py to paligemma.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/exaone.py to exaone.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_neox.py to gpt_neox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/persimmon.py to persimmon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mistral3.py to mistral3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/skyworkr1v.py to skyworkr1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_oss.py to gpt_oss.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aria.py to aria.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gritlm.py to gritlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_next.py to llava_next.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpmo.py to minicpmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/moonvit.py to moonvit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_h.py to nemotron_h.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/florence2.py to florence2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen3_moe.py to qwen3_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/roberta.py to roberta.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interns1_vit.py to interns1_vit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/step3_vl.py to step3_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/falcon_h1.py to falcon_h1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/h2ovl.py to h2ovl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/input_quant_fp8.py to input_quant_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/schema.py to schema.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/torchao.py to torchao.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/marlin.py to marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/fp8.py to fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/ipex_quant.py to ipex_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/bitblas.py to bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/experts_int8.py to experts_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/quark.py to quark.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py to quark_w4a4_mxfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py to quark_w8a8_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py to quark_w8a8_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py to quark_scheme.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/quark_moe.py to quark_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/mxfp4.py to mxfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gguf.py to gguf.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq.py to gptq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq_marlin.py to awq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/aqlm.py to aqlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/modelopt.py to modelopt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py to conch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py to marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py to bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py to exllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py to machete.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py to dynamic_4bit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py to MPLinearKernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py to allspark.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py to aiter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py to cutlass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py to triton.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py to xla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py to ScaledMMLinearKernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq.py to awq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/fbgemm_fp8.py to fbgemm_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py to compressed_tensors_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py to compressed_tensors_wNa16.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py to compressed_tensors_w8a16_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py to compressed_tensors_w4a8_int.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py to compressed_tensors_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py to compressed_tensors_scheme.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py to compressed_tensors_w8a8_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py to compressed_tensors_w4a4_nvfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py to compressed_tensors_w8a8_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py to compressed_tensors_w4a16_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py to compressed_tensors_w4a16_nvfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py to triton_scaled_mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py to compressed_tensors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/auto_round.py to auto_round.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq_triton.py to awq_triton.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/base_config.py to base_config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_bitblas.py to gptq_bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/qqq.py to qqq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/tpu_int8.py to tpu_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/moe_wna16.py to moe_wna16.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/inc.py to inc.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kv_cache.py to kv_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_marlin_24.py to gptq_marlin_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/rtn.py to rtn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/bitsandbytes.py to bitsandbytes.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_marlin.py to gptq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/ptpc_fp8.py to ptpc_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/hqq_marlin.py to hqq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/machete_utils.py to machete_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py to nvfp4_emulation_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py to nvfp4_moe_support.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/fp8_utils.py to fp8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/w8a8_utils.py to w8a8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/int8_utils.py to int8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py to marlin_utils_test_qqq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py to marlin_utils_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test.py to marlin_utils_test.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/layer_utils.py to layer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/allspark_utils.py to allspark_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/quant_utils.py to quant_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py to marlin_utils_test_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils.py to marlin_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/gptq_utils.py to gptq_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/bitblas_utils.py to bitblas_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py to flashinfer_fp4_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py to marlin_utils_fp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/mxfp4_utils.py to mxfp4_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/flashinfer_utils.py to flashinfer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/deepspeedfp.py to deepspeedfp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/neuron_quant.py to neuron_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/deepgemm.py to deepgemm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/linear.py to linear.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/layer.py to layer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deep_gemm_moe.py to deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_moe.py to fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py to flashinfer_cutlass_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_batched_moe.py to fused_batched_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/cutlass_moe.py to cutlass_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py to moe_permute_unpermute.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_pallas.py to moe_pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/prepare_finalize.py to prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py to pplx_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py to deepep_ht_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deep_gemm_utils.py to deep_gemm_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py to flashinfer_cutlass_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py to triton_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_torch_iterative.py to moe_torch_iterative.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py to topk_weight_and_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/cpu_fused_moe.py to cpu_fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/modular_kernel.py to modular_kernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py to batched_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_align_block_size.py to moe_align_block_size.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_marlin_moe.py to fused_marlin_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py to batched_triton_or_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py to deepep_ll_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py to rocm_aiter_fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py to yarn_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/mrope.py to mrope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py to dynamic_ntk_alpha_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/llama3_rope.py to llama3_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py to ntk_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py to deepseek_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py to linear_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py to dual_chunk_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py to dynamic_ntk_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py to phi3_long_rope_scaled_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py to llama4_vision_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/pooler.py to pooler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/layernorm.py to layernorm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/resampler.py to resampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/layernorm_gated.py to layernorm_gated.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_state_passing.py to ssd_state_passing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py to ssd_chunk_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py to ssd_chunk_scan.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_bmm.py to ssd_bmm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/causal_conv1d.py to causal_conv1d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/mamba_ssm.py to mamba_ssm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_combined.py to ssd_combined.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_mixer2.py to mamba_mixer2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_mixer.py to mamba_mixer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba2_metadata.py to mamba2_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_utils.py to mamba_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/lightning_attn.py to lightning_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/activation.py to activation.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/logits_processor.py to logits_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/vocab_parallel_embedding.py to vocab_parallel_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/pooling_metadata.py to pooling_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/sharded_state_loader.py to sharded_state_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/runai_streamer_loader.py to runai_streamer_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/neuron.py to neuron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tensorizer_loader.py to tensorizer_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tensorizer.py to tensorizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/neuronx_distributed.py to neuronx_distributed.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/dummy_loader.py to dummy_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/gguf_loader.py to gguf_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/weight_utils.py to weight_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/base_loader.py to base_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tpu.py to tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/bitsandbytes_loader.py to bitsandbytes_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/default_loader.py to default_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/custom_op.py to custom_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/sampling_metadata.py to sampling_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/score_utils.py to score_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_engine.py to serving_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_responses.py to serving_responses.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_transcription.py to serving_transcription.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/cli_args.py to cli_args.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/speech_to_text.py to speech_to_text.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_chat.py to serving_chat.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_completion.py to serving_completion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_pooling.py to serving_pooling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/run_batch.py to run_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py to minimax_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py to mistral_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py to xlam_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py to phi4mini_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py to hermes_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py to step3_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py to llama_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py to granite_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py to internlm2_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py to deepseekv3_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py to glm4_moe_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py to pythonic_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py to jamba_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py to abstract_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py to granite_20b_fc_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py to kimi_k2_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py to llama4_pythonic_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py to hunyuan_a13b_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py to qwen3coder_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/logits_processors.py to logits_processors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/api_server.py to api_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_score.py to serving_score.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_embedding.py to serving_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_classification.py to serving_classification.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_tokenization.py to serving_tokenization.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_models.py to serving_models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/protocol.py to protocol.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/tool_server.py to tool_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/harmony_utils.py to harmony_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/chat_utils.py to chat_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/launcher.py to launcher.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/llm.py to llm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/api_server.py to api_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/collect_env.py to collect_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/types.py to types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/openai.py to openai.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/main.py to main.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/run_batch.py to run_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/throughput.py to throughput.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/main.py to main.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/latency.py to latency.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/ssl.py to ssl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/logger.py to logger.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/context.py to context.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/tool.py to tool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/beam_search.py to beam_search.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/connections.py to connections.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/layer.py to layer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flash_attn.py to flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/xformers.py to xformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/dual_chunk_flash_attn.py to dual_chunk_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/differential_flash_attn.py to differential_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/rocm_flash_attn.py to rocm_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/triton_mla.py to triton_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/mla/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/mla/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/placeholder_attn.py to placeholder_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_decode_attention.py to triton_decode_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_unified_attention.py to triton_unified_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_merge_attn_states.py to triton_merge_attn_states.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_flash_attention.py to triton_flash_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/prefix_prefill.py to prefix_prefill.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/chunked_prefill_paged_decode.py to chunked_prefill_paged_decode.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/nki_flash_attn.py to nki_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/rocm_aiter_paged_attn.py to rocm_aiter_paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/pallas_kv_cache_update.py to pallas_kv_cache_update.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/paged_attn.py to paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/merge_attn_states.py to merge_attn_states.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/selector.py to selector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/fa_utils.py to fa_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/kv_sharing_utils.py to kv_sharing_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/usage/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/usage/usage_lib.py to usage_lib.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/llm_engine.py to llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/async_llm_engine.py to async_llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/async_timeout.py to async_timeout.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/client.py to client.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/engine.py to engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/single_step.py to single_step.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/multi_step.py to multi_step.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/stop_checker.py to stop_checker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/util.py to util.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/protocol.py to protocol.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/arg_utils.py to arg_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/metrics_types.py to metrics_types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/third_party/pynvml.py to pynvml.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/third_party/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/dump_input.py to dump_input.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/formatter.py to formatter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/sequence.py to sequence.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/scalar_type.py to scalar_type.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group.py to tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer.py to tokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mllama.py to mllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/jais.py to jais.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron.py to nemotron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mistral.py to mistral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/kimi_vl.py to kimi_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/arctic.py to arctic.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nvlm_d.py to nvlm_d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mlp_speculator.py to mlp_speculator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/chatglm.py to chatglm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/algos.py to algos.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/falcon.py to falcon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/ultravox.py to ultravox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron_vl.py to nemotron_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/moonvit.py to moonvit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron_h.py to nemotron_h.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/step3_vl.py to step3_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_base.py to tokenizer_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/detokenizer.py to detokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/dynamic_module.py to dynamic_module.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/s3_utils.py to s3_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers/mistral.py to mistral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/detokenizer_utils.py to detokenizer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processor.py to processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/envs.py to envs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/placeholder_block_space_manager.py to placeholder_block_space_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block_manager.py to block_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/prefix_caching_block.py to prefix_caching_block.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/naive_block.py to naive_block.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/block_table.py to block_table.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/cpu_gpu_block_allocator.py to cpu_gpu_block_allocator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/evictor.py to evictor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/scheduler.py to scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/cuda.py to cuda.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/rocm.py to rocm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/neuron.py to neuron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/cpu.py to cpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/tpu.py to tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/xpu.py to xpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/fully_sharded_layers.py to fully_sharded_layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_base.py to punica_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_selector.py to punica_selector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_cpu.py to punica_cpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_gpu.py to punica_gpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_tpu.py to punica_tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_xpu.py to punica_xpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/lora.py to lora.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_shrink_op.py to lora_shrink_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_kernel_metadata.py to lora_kernel_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_expand_op.py to lora_expand_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/kernel_utils.py to kernel_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/peft_helper.py to peft_helper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/resolver.py to resolver.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/tasks.py to tasks.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/outputs.py to outputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/ray_distributed_executor.py to ray_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/multiproc_executor.py to multiproc_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_guidance.py to backend_guidance.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_xgrammar.py to backend_xgrammar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_outlines.py to backend_outlines.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_types.py to backend_types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/reader.py to reader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/loggers.py to loggers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/stats.py to stats.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/prometheus.py to prometheus.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/ray_wrappers.py to ray_wrappers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/worker_base.py to worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_worker.py to gpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_model_runner.py to gpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_model_runner.py to tpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/lora_model_runner_mixin.py to lora_model_runner_mixin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/xpu_model_runner.py to xpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/kv_connector_model_runner_mixin.py to kv_connector_model_runner_mixin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/cpu_worker.py to cpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/xpu_worker.py to xpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_worker.py to tpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/cpu_model_runner.py to cpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_input_batch.py to tpu_input_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/block_table.py to block_table.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_input_batch.py to gpu_input_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/pool/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/pool/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/rejection_sampler.py to rejection_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/bad_words.py to bad_words.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/topk_topp_sampler.py to topk_topp_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/logprobs.py to logprobs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/penalties.py to penalties.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/logits_processor.py to logits_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba_attn.py to mamba_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flash_attn.py to flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/xformers.py to xformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/triton_attn.py to triton_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flex_attention.py to flex_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba1_attn.py to mamba1_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba_selectors.py to mamba_selectors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/triton_mla.py to triton_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/cutlass_mla.py to cutlass_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/rocm_aiter_fa.py to rocm_aiter_fa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/tree_attn.py to tree_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/cpu_attn.py to cpu_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/pallas.py to pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/core.py to core.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/mm_input_cache.py to mm_input_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/core_client.py to core_client.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/detokenizer.py to detokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/llm_engine.py to llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/parallel_sampling.py to parallel_sampling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/logprobs.py to logprobs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/output_processor.py to output_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/exceptions.py to exceptions.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/async_llm.py to async_llm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/coordinator.py to coordinator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/processor.py to processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/ngram_proposer.py to ngram_proposer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/kv_cache_interface.py to kv_cache_interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/block_pool.py to block_pool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_coordinator.py to kv_cache_coordinator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/single_type_kv_cache_manager.py to single_type_kv_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_utils.py to kv_cache_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/encoder_cache_manager.py to encoder_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/output.py to output.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/async_scheduler.py to async_scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/scheduler.py to scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/request_queue.py to request_queue.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_manager.py to kv_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/outputs.py to outputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/serial_utils.py to serial_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logger.py to logger.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/tensor_schema.py to tensor_schema.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/deep_gemm.py to deep_gemm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/jsontree.py to jsontree.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/layerwise_profile.py to layerwise_profile.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/throughput.py to throughput.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/datasets.py to datasets.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/latency.py to latency.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/ready_checker.py to ready_checker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/endpoint_request_func.py to endpoint_request_func.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/tracing.py to tracing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/env_override.py to env_override.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/forward_context.py to forward_context.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/test_utils.py to test_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/compiler_interface.py to compiler_interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/decorators.py to decorators.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/counter.py to counter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/wrapper.py to wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/backends.py to backends.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/vllm_inductor_pass.py to vllm_inductor_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fusion_attn.py to fusion_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fix_functionalization.py to fix_functionalization.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/base_piecewise_backend.py to base_piecewise_backend.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/monitor.py to monitor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/activation_quant_fusion.py to activation_quant_fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/pass_manager.py to pass_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/sequence_parallelism.py to sequence_parallelism.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fx_utils.py to fx_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/collective_fusion.py to collective_fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/inductor_pass.py to inductor_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/torch25_custom_graph_pass.py to torch25_custom_graph_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/noop_elimination.py to noop_elimination.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/cuda_piecewise_backend.py to cuda_piecewise_backend.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fusion.py to fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/multi_output_match.py to multi_output_match.cpython-311.pyc\n",
            "creating stub loader for vllm/_C.abi3.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_C.py to _C.cpython-311.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "vllm.__pycache__._C.cpython-311: module references __file__\n",
            "vllm.__pycache__.config.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.__pycache__.logger.cpython-311: module references __file__\n",
            "vllm.compilation.__pycache__.inductor_pass.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.distributed.device_communicators.__pycache__.custom_all_reduce_utils.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.fused_moe.__pycache__.fused_moe.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.quantization.utils.__pycache__.fp8_utils.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.quantization.utils.__pycache__.int8_utils.cpython-311: module references __file__\n",
            "vllm.transformers_utils.chat_templates.__pycache__.registry.cpython-311: module references __file__\n",
            "vllm.utils.__pycache__.__init__.cpython-311: module MAY be using inspect.getsource\n",
            "creating dist\n",
            "creating 'dist/vllm-0.10.1.dev411+ge8961e963.cpu-py3.11-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing vllm-0.10.1.dev411+ge8961e963.cpu-py3.11-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev411+ge8961e963.cpu-py3.11-linux-x86_64.egg\n",
            "Extracting vllm-0.10.1.dev411+ge8961e963.cpu-py3.11-linux-x86_64.egg to /usr/local/lib/python3.11/dist-packages\n",
            "Adding vllm 0.10.1.dev411+ge8961e963.cpu to easy-install.pth file\n",
            "Installing vllm script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev411+ge8961e963.cpu-py3.11-linux-x86_64.egg\n",
            "Processing dependencies for vllm==0.10.1.dev411+ge8961e963.cpu\n",
            "Searching for numba==0.61.2\n",
            "Best match: numba 0.61.2\n",
            "Adding numba 0.61.2 to easy-install.pth file\n",
            "detected new path './vllm-0.10.1.dev411+ge8961e963.cpu-py3.11-linux-x86_64.egg'\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for llguidance==0.7.30\n",
            "Best match: llguidance 0.7.30\n",
            "Adding llguidance 0.7.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for xgrammar==0.1.21\n",
            "Best match: xgrammar 0.1.21\n",
            "Adding xgrammar 0.1.21 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for triton==3.2.0\n",
            "Best match: triton 3.2.0\n",
            "Adding triton 3.2.0 to easy-install.pth file\n",
            "Installing proton script to /usr/local/bin\n",
            "Installing proton-viewer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for intel-extension-for-pytorch==2.6.0\n",
            "Best match: intel-extension-for-pytorch 2.6.0\n",
            "Adding intel-extension-for-pytorch 2.6.0 to easy-install.pth file\n",
            "Installing ipexrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for intel-openmp==2024.2.1\n",
            "Best match: intel-openmp 2024.2.1\n",
            "Adding intel-openmp 2024.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torch==2.6.0+cpu\n",
            "Best match: torch 2.6.0+cpu\n",
            "Adding torch 2.6.0+cpu to easy-install.pth file\n",
            "Installing torchfrtrace script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torchvision==0.21.0+cpu\n",
            "Best match: torchvision 0.21.0+cpu\n",
            "Adding torchvision 0.21.0+cpu to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torchaudio==2.6.0+cu124\n",
            "Best match: torchaudio 2.6.0+cu124\n",
            "Adding torchaudio 2.6.0+cu124 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for datasets==4.0.0\n",
            "Best match: datasets 4.0.0\n",
            "Adding datasets 4.0.0 to easy-install.pth file\n",
            "Installing datasets-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for setuptools==79.0.1\n",
            "Best match: setuptools 79.0.1\n",
            "Adding setuptools 79.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for packaging==25.0\n",
            "Best match: packaging 25.0\n",
            "Adding packaging 25.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for openai-harmony==0.0.3\n",
            "Best match: openai-harmony 0.0.3\n",
            "Adding openai-harmony 0.0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for setproctitle==1.3.6\n",
            "Best match: setproctitle 1.3.6\n",
            "Adding setproctitle 1.3.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cbor2==5.6.5\n",
            "Best match: cbor2 5.6.5\n",
            "Adding cbor2 5.6.5 to easy-install.pth file\n",
            "Installing cbor2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pybase64==1.4.2\n",
            "Best match: pybase64 1.4.2\n",
            "Adding pybase64 1.4.2 to easy-install.pth file\n",
            "Installing pybase64 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for ninja==1.11.1.4\n",
            "Best match: ninja 1.11.1.4\n",
            "Adding ninja 1.11.1.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for scipy==1.16.1\n",
            "Best match: scipy 1.16.1\n",
            "Adding scipy 1.16.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-json-logger==3.3.0\n",
            "Best match: python-json-logger 3.3.0\n",
            "Adding python-json-logger 3.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for watchfiles==1.1.0\n",
            "Best match: watchfiles 1.1.0\n",
            "Adding watchfiles 1.1.0 to easy-install.pth file\n",
            "Installing watchfiles script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cloudpickle==3.1.1\n",
            "Best match: cloudpickle 3.1.1\n",
            "Adding cloudpickle 3.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for depyf==0.19.0\n",
            "Best match: depyf 0.19.0\n",
            "Adding depyf 0.19.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for compressed-tensors==0.10.2\n",
            "Best match: compressed-tensors 0.10.2\n",
            "Adding compressed-tensors 0.10.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for einops==0.8.1\n",
            "Best match: einops 0.8.1\n",
            "Adding einops 0.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for PyYAML==6.0.2\n",
            "Best match: PyYAML 6.0.2\n",
            "Adding PyYAML 6.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opencv-python-headless==4.12.0.88\n",
            "Best match: opencv-python-headless 4.12.0.88\n",
            "Adding opencv-python-headless 4.12.0.88 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mistral-common==1.8.3\n",
            "Best match: mistral-common 1.8.3\n",
            "Adding mistral-common 1.8.3 to easy-install.pth file\n",
            "Installing mistral_common script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for gguf==0.17.1\n",
            "Best match: gguf 0.17.1\n",
            "Adding gguf 0.17.1 to easy-install.pth file\n",
            "Installing gguf-convert-endian script to /usr/local/bin\n",
            "Installing gguf-dump script to /usr/local/bin\n",
            "Installing gguf-editor-gui script to /usr/local/bin\n",
            "Installing gguf-new-metadata script to /usr/local/bin\n",
            "Installing gguf-set-metadata script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for msgspec==0.19.0\n",
            "Best match: msgspec 0.19.0\n",
            "Adding msgspec 0.19.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pyzmq==26.2.1\n",
            "Best match: pyzmq 26.2.1\n",
            "Adding pyzmq 26.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for partial-json-parser==0.2.1.1.post6\n",
            "Best match: partial-json-parser 0.2.1.1.post6\n",
            "Adding partial-json-parser 0.2.1.1.post6 to easy-install.pth file\n",
            "Installing json-playground script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for filelock==3.18.0\n",
            "Best match: filelock 3.18.0\n",
            "Adding filelock 3.18.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typing-extensions==4.14.1\n",
            "Best match: typing-extensions 4.14.1\n",
            "Adding typing-extensions 4.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for lark==1.2.2\n",
            "Best match: lark 1.2.2\n",
            "Adding lark 1.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for diskcache==5.6.3\n",
            "Best match: diskcache 5.6.3\n",
            "Adding diskcache 5.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for outlines-core==0.2.10\n",
            "Best match: outlines-core 0.2.10\n",
            "Adding outlines-core 0.2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for lm-format-enforcer==0.10.12\n",
            "Best match: lm-format-enforcer 0.10.12\n",
            "Adding lm-format-enforcer 0.10.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tiktoken==0.9.0\n",
            "Best match: tiktoken 0.9.0\n",
            "Adding tiktoken 0.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for prometheus-fastapi-instrumentator==7.1.0\n",
            "Best match: prometheus-fastapi-instrumentator 7.1.0\n",
            "Adding prometheus-fastapi-instrumentator 7.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pillow==11.3.0\n",
            "Best match: pillow 11.3.0\n",
            "Adding pillow 11.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for prometheus-client==0.22.1\n",
            "Best match: prometheus-client 0.22.1\n",
            "Adding prometheus-client 0.22.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic==2.11.7\n",
            "Best match: pydantic 2.11.7\n",
            "Adding pydantic 2.11.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for openai==1.98.0\n",
            "Best match: openai 1.98.0\n",
            "Adding openai 1.98.0 to easy-install.pth file\n",
            "Installing openai script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiohttp==3.12.15\n",
            "Best match: aiohttp 3.12.15\n",
            "Adding aiohttp 3.12.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi==0.116.1\n",
            "Best match: fastapi 0.116.1\n",
            "Adding fastapi 0.116.1 to easy-install.pth file\n",
            "Installing fastapi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for protobuf==5.29.5\n",
            "Best match: protobuf 5.29.5\n",
            "Adding protobuf 5.29.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tokenizers==0.21.4\n",
            "Best match: tokenizers 0.21.4\n",
            "Adding tokenizers 0.21.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for huggingface-hub==0.34.3\n",
            "Best match: huggingface-hub 0.34.3\n",
            "Adding huggingface-hub 0.34.3 to easy-install.pth file\n",
            "Installing hf script to /usr/local/bin\n",
            "Installing huggingface-cli script to /usr/local/bin\n",
            "Installing tiny-agents script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for transformers==4.55.0\n",
            "Best match: transformers 4.55.0\n",
            "Adding transformers 4.55.0 to easy-install.pth file\n",
            "Installing transformers script to /usr/local/bin\n",
            "Installing transformers-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for py-cpuinfo==9.0.0\n",
            "Best match: py-cpuinfo 9.0.0\n",
            "Adding py-cpuinfo 9.0.0 to easy-install.pth file\n",
            "Installing cpuinfo script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for blake3==1.0.5\n",
            "Best match: blake3 1.0.5\n",
            "Adding blake3 1.0.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tqdm==4.67.1\n",
            "Best match: tqdm 4.67.1\n",
            "Adding tqdm 4.67.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for requests==2.32.3\n",
            "Best match: requests 2.32.3\n",
            "Adding requests 2.32.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for numpy==2.0.2\n",
            "Best match: numpy 2.0.2\n",
            "Adding numpy 2.0.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing numpy-config script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sentencepiece==0.2.0\n",
            "Best match: sentencepiece 0.2.0\n",
            "Adding sentencepiece 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for psutil==5.9.5\n",
            "Best match: psutil 5.9.5\n",
            "Adding psutil 5.9.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cachetools==5.5.2\n",
            "Best match: cachetools 5.5.2\n",
            "Adding cachetools 5.5.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for regex==2024.11.6\n",
            "Best match: regex 2024.11.6\n",
            "Adding regex 2024.11.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for llvmlite==0.44.0\n",
            "Best match: llvmlite 0.44.0\n",
            "Adding llvmlite 0.44.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for intel-cmplr-lib-ur==2024.2.1\n",
            "Best match: intel-cmplr-lib-ur 2024.2.1\n",
            "Adding intel-cmplr-lib-ur 2024.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sympy==1.13.1\n",
            "Best match: sympy 1.13.1\n",
            "Adding sympy 1.13.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fsspec==2025.3.0\n",
            "Best match: fsspec 2025.3.0\n",
            "Adding fsspec 2025.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jinja2==3.1.6\n",
            "Best match: jinja2 3.1.6\n",
            "Adding jinja2 3.1.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for networkx==3.5\n",
            "Best match: networkx 3.5\n",
            "Adding networkx 3.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for multiprocess==0.70.16\n",
            "Best match: multiprocess 0.70.16\n",
            "Adding multiprocess 0.70.16 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for xxhash==3.5.0\n",
            "Best match: xxhash 3.5.0\n",
            "Adding xxhash 3.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pandas==2.2.2\n",
            "Best match: pandas 2.2.2\n",
            "Adding pandas 2.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for dill==0.3.8\n",
            "Best match: dill 0.3.8\n",
            "Adding dill 0.3.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pyarrow==18.1.0\n",
            "Best match: pyarrow 18.1.0\n",
            "Adding pyarrow 18.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for anyio==4.9.0\n",
            "Best match: anyio 4.9.0\n",
            "Adding anyio 4.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for astor==0.8.1\n",
            "Best match: astor 0.8.1\n",
            "Adding astor 0.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic-extra-types==2.10.5\n",
            "Best match: pydantic-extra-types 2.10.5\n",
            "Adding pydantic-extra-types 2.10.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jsonschema==4.25.0\n",
            "Best match: jsonschema 4.25.0\n",
            "Adding jsonschema 4.25.0 to easy-install.pth file\n",
            "Installing jsonschema script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for interegular==0.3.3\n",
            "Best match: interegular 0.3.3\n",
            "Adding interegular 0.3.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for starlette==0.47.2\n",
            "Best match: starlette 0.47.2\n",
            "Adding starlette 0.47.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typing-inspection==0.4.1\n",
            "Best match: typing-inspection 0.4.1\n",
            "Adding typing-inspection 0.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic-core==2.33.2\n",
            "Best match: pydantic-core 2.33.2\n",
            "Adding pydantic-core 2.33.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for annotated-types==0.7.0\n",
            "Best match: annotated-types 0.7.0\n",
            "Adding annotated-types 0.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sniffio==1.3.1\n",
            "Best match: sniffio 1.3.1\n",
            "Adding sniffio 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jiter==0.10.0\n",
            "Best match: jiter 0.10.0\n",
            "Adding jiter 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httpx==0.28.1\n",
            "Best match: httpx 0.28.1\n",
            "Adding httpx 0.28.1 to easy-install.pth file\n",
            "Installing httpx script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for distro==1.9.0\n",
            "Best match: distro 1.9.0\n",
            "Adding distro 1.9.0 to easy-install.pth file\n",
            "Installing distro script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for yarl==1.20.1\n",
            "Best match: yarl 1.20.1\n",
            "Adding yarl 1.20.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for propcache==0.3.2\n",
            "Best match: propcache 0.3.2\n",
            "Adding propcache 0.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for multidict==6.6.3\n",
            "Best match: multidict 6.6.3\n",
            "Adding multidict 6.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for frozenlist==1.7.0\n",
            "Best match: frozenlist 1.7.0\n",
            "Adding frozenlist 1.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for attrs==25.3.0\n",
            "Best match: attrs 25.3.0\n",
            "Adding attrs 25.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiosignal==1.4.0\n",
            "Best match: aiosignal 1.4.0\n",
            "Adding aiosignal 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiohappyeyeballs==2.6.1\n",
            "Best match: aiohappyeyeballs 2.6.1\n",
            "Adding aiohappyeyeballs 2.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for uvicorn==0.35.0\n",
            "Best match: uvicorn 0.35.0\n",
            "Adding uvicorn 0.35.0 to easy-install.pth file\n",
            "Installing uvicorn script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for email-validator==2.2.0\n",
            "Best match: email-validator 2.2.0\n",
            "Adding email-validator 2.2.0 to easy-install.pth file\n",
            "Installing email_validator script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-multipart==0.0.20\n",
            "Best match: python-multipart 0.0.20\n",
            "Adding python-multipart 0.0.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi-cli==0.0.8\n",
            "Best match: fastapi-cli 0.0.8\n",
            "Adding fastapi-cli 0.0.8 to easy-install.pth file\n",
            "Installing fastapi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for hf-xet==1.1.5\n",
            "Best match: hf-xet 1.1.5\n",
            "Adding hf-xet 1.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for safetensors==0.5.3\n",
            "Best match: safetensors 0.5.3\n",
            "Adding safetensors 0.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for certifi==2025.7.14\n",
            "Best match: certifi 2025.7.14\n",
            "Adding certifi 2025.7.14 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for urllib3==2.5.0\n",
            "Best match: urllib3 2.5.0\n",
            "Adding urllib3 2.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for idna==3.10\n",
            "Best match: idna 3.10\n",
            "Adding idna 3.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for charset-normalizer==3.4.2\n",
            "Best match: charset-normalizer 3.4.2\n",
            "Adding charset-normalizer 3.4.2 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for MarkupSafe==3.0.2\n",
            "Best match: MarkupSafe 3.0.2\n",
            "Adding MarkupSafe 3.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tzdata==2025.2\n",
            "Best match: tzdata 2025.2\n",
            "Adding tzdata 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pytz==2025.2\n",
            "Best match: pytz 2025.2\n",
            "Adding pytz 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-dateutil==2.9.0.post0\n",
            "Best match: python-dateutil 2.9.0.post0\n",
            "Adding python-dateutil 2.9.0.post0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for soxr==0.5.0.post1\n",
            "Best match: soxr 0.5.0.post1\n",
            "Adding soxr 0.5.0.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for soundfile==0.13.1\n",
            "Best match: soundfile 0.13.1\n",
            "Adding soundfile 0.13.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pycountry==24.6.1\n",
            "Best match: pycountry 24.6.1\n",
            "Adding pycountry 24.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rpds-py==0.26.0\n",
            "Best match: rpds-py 0.26.0\n",
            "Adding rpds-py 0.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for referencing==0.36.2\n",
            "Best match: referencing 0.36.2\n",
            "Adding referencing 0.36.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jsonschema-specifications==2025.4.1\n",
            "Best match: jsonschema-specifications 2025.4.1\n",
            "Adding jsonschema-specifications 2025.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httpcore==1.0.9\n",
            "Best match: httpcore 1.0.9\n",
            "Adding httpcore 1.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for websockets==15.0.1\n",
            "Best match: websockets 15.0.1\n",
            "Adding websockets 15.0.1 to easy-install.pth file\n",
            "Installing websockets script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for uvloop==0.21.0\n",
            "Best match: uvloop 0.21.0\n",
            "Adding uvloop 0.21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-dotenv==1.1.1\n",
            "Best match: python-dotenv 1.1.1\n",
            "Adding python-dotenv 1.1.1 to easy-install.pth file\n",
            "Installing dotenv script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httptools==0.6.4\n",
            "Best match: httptools 0.6.4\n",
            "Adding httptools 0.6.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for h11==0.16.0\n",
            "Best match: h11 0.16.0\n",
            "Adding h11 0.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for click==8.2.1\n",
            "Best match: click 8.2.1\n",
            "Adding click 8.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for dnspython==2.7.0\n",
            "Best match: dnspython 2.7.0\n",
            "Adding dnspython 2.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi-cloud-cli==0.1.5\n",
            "Best match: fastapi-cloud-cli 0.1.5\n",
            "Adding fastapi-cloud-cli 0.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rich-toolkit==0.14.9\n",
            "Best match: rich-toolkit 0.14.9\n",
            "Adding rich-toolkit 0.14.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typer==0.16.0\n",
            "Best match: typer 0.16.0\n",
            "Adding typer 0.16.0 to easy-install.pth file\n",
            "Installing typer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for six==1.17.0\n",
            "Best match: six 1.17.0\n",
            "Adding six 1.17.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cffi==1.17.1\n",
            "Best match: cffi 1.17.1\n",
            "Adding cffi 1.17.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sentry-sdk==2.34.1\n",
            "Best match: sentry-sdk 2.34.1\n",
            "Adding sentry-sdk 2.34.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rignore==0.6.4\n",
            "Best match: rignore 0.6.4\n",
            "Adding rignore 0.6.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rich==13.9.4\n",
            "Best match: rich 13.9.4\n",
            "Adding rich 13.9.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for shellingham==1.5.4\n",
            "Best match: shellingham 1.5.4\n",
            "Adding shellingham 1.5.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pycparser==2.22\n",
            "Best match: pycparser 2.22\n",
            "Adding pycparser 2.22 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pygments==2.19.2\n",
            "Best match: pygments 2.19.2\n",
            "Adding pygments 2.19.2 to easy-install.pth file\n",
            "Installing pygmentize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for markdown-it-py==3.0.0\n",
            "Best match: markdown-it-py 3.0.0\n",
            "Adding markdown-it-py 3.0.0 to easy-install.pth file\n",
            "Installing markdown-it script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mdurl==0.1.2\n",
            "Best match: mdurl 0.1.2\n",
            "Adding mdurl 0.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Finished processing dependencies for vllm==0.10.1.dev411+ge8961e963.cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM\n",
        "\n",
        "# Initialize the vLLM engine.\n",
        "llm = LLM(model=\"facebook/opt-125m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "yL0hMjmKI6Nq",
        "outputId": "1407cc92-0927-45a7-92d6-06f56443f62b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3955221052.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Initialize the vLLM engine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"facebook/opt-125m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__package__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from vllm.beam_search import (BeamSearchInstance, BeamSearchOutput,\n\u001b[0m\u001b[1;32m     18\u001b[0m                               \u001b[0mBeamSearchSequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               create_sort_beams_key_function)\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/beam_search.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/sequence.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSingletonInputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimodal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiModalKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiModalPlaceholderDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/inputs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mTokensPrompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_explicit_enc_dec_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    to_enc_dec_tuple_list, token_inputs, zip_enc_dec_prompts)\n\u001b[0;32m----> 9\u001b[0;31m from .registry import (DummyData, InputContext, InputProcessingContext,\n\u001b[0m\u001b[1;32m     10\u001b[0m                        InputRegistry)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/inputs/registry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjsontree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJSONTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_map_leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_processor_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_allowed_kwarg_only_overrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/transformers_utils/processor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from transformers import (AutoFeatureExtractor, AutoImageProcessor,\n\u001b[0m\u001b[1;32m      8\u001b[0m                           AutoProcessor)\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/feature_extraction_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFEATURE_EXTRACTOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m from .configuration_auto import (\n\u001b[1;32m     31\u001b[0m     \u001b[0mCONFIG_MAPPING_NAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "gY-93aMJKdRT",
        "outputId": "7476b8a3-2294-4599-f1d4-90bac1a4999d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3321835182.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/ي/vllm_source/vllm/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__package__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from vllm.beam_search import (BeamSearchInstance, BeamSearchOutput,\n\u001b[0m\u001b[1;32m     18\u001b[0m                               \u001b[0mBeamSearchSequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               create_sort_beams_key_function)\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/beam_search.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/sequence.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSingletonInputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimodal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiModalKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiModalPlaceholderDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/inputs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mTokensPrompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_explicit_enc_dec_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    to_enc_dec_tuple_list, token_inputs, zip_enc_dec_prompts)\n\u001b[0;32m----> 9\u001b[0;31m from .registry import (DummyData, InputContext, InputProcessingContext,\n\u001b[0m\u001b[1;32m     10\u001b[0m                        InputRegistry)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/inputs/registry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjsontree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJSONTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_map_leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_processor_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_allowed_kwarg_only_overrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ي/vllm_source/vllm/transformers_utils/processor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from transformers import (AutoFeatureExtractor, AutoImageProcessor,\n\u001b[0m\u001b[1;32m      8\u001b[0m                           AutoProcessor)\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/feature_extraction_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFEATURE_EXTRACTOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m from .configuration_auto import (\n\u001b[1;32m     31\u001b[0m     \u001b[0mCONFIG_MAPPING_NAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray  # Requires ray>=2.44.1\n",
        "from ray.data.llm import vLLMEngineProcessorConfig, build_llm_processor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "YajomZZnKdkD",
        "outputId": "614fb5a4-bf2d-47b7-8057-229c18f0de7d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ray'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2365860309.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m  \u001b[0;31m# Requires ray>=2.44.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvLLMEngineProcessorConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_llm_processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ي/vllm_source"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSf2h3J0Kiss",
        "outputId": "c83e95ca-e427-4ff4-8e0b-f93ec25fc2ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ي/vllm_source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ي/vllm_source/examples/offline_inference/basic/basic.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdFzKHSiKqCX",
        "outputId": "d387fe84-adf0-4679-ac43-f71a20aff6c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-07 01:35:45.825207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754530545.856732   32238 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754530545.866671   32238 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754530545.890590   32238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754530545.890644   32238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754530545.890649   32238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754530545.890653   32238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ي/vllm_source/examples/offline_inference/basic/basic.py\", line 4, in <module>\n",
            "    from vllm import LLM, SamplingParams\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/__init__.py\", line 64, in __getattr__\n",
            "    module = import_module(module_name, __package__)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/entrypoints/llm.py\", line 17, in <module>\n",
            "    from vllm.beam_search import (BeamSearchInstance, BeamSearchOutput,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/beam_search.py\", line 8, in <module>\n",
            "    from vllm.sequence import Logprob\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/sequence.py\", line 18, in <module>\n",
            "    from vllm.inputs import SingletonInputs\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/__init__.py\", line 9, in <module>\n",
            "    from .registry import (DummyData, InputContext, InputProcessingContext,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/registry.py\", line 13, in <module>\n",
            "    from vllm.transformers_utils.processor import cached_processor_from_config\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/transformers_utils/processor.py\", line 7, in <module>\n",
            "    from transformers import (AutoFeatureExtractor, AutoImageProcessor,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2292, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2322, in _get_module\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2320, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/feature_extraction_auto.py\", line 29, in <module>\n",
            "    from .auto_factory import _LazyAutoMapping\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 43, in <module>\n",
            "    from ...generation import GenerationMixin\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2292, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2322, in _get_module\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2320, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 16, in <module>\n",
            "    from transformers.generation.utils import GenerationMixin\n",
            "ImportError: cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git rev-parse HEAD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ispKQZpMK2fK",
        "outputId": "e4eb1a36-160d-4c0a-94c1-93c7d8a2656d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e8961e963a76feb3e2c080220e79d2d5a9d272f9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout 471fe6563"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-BPNekfLP5T",
        "outputId": "2843466f-e605-4331-face-3cf7a7709e24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: switching to '471fe6563'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 471fe6563 [TPU][V1] Implicitly adjust page size when there's SMEM OOM (#16871)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"importlib-metadata>=6.0,<=8.0.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohPkld8LM-iM",
        "outputId": "1e0c1a4c-af9d-4407-ba74-55f232812cdc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting importlib-metadata<=8.0.0,>=6.0\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.0.0,>=6.0) (3.23.0)\n",
            "Downloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: importlib-metadata\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-api 1.26.0 requires deprecated>=1.2.6, which is not installed.\n",
            "opentelemetry-sdk 1.26.0 requires opentelemetry-semantic-conventions==0.47b0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-http 1.26.0 requires deprecated>=1.2.6, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-http 1.26.0 requires opentelemetry-exporter-otlp-proto-common==1.26.0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-http 1.26.0 requires opentelemetry-proto==1.26.0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.26.0 requires deprecated>=1.2.6, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.26.0 requires opentelemetry-exporter-otlp-proto-common==1.26.0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-grpc 1.26.0 requires opentelemetry-proto==1.26.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed importlib-metadata-8.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"protobuf>=3.19,<5.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "wNADiMsRNewE",
        "outputId": "c63d45b5-d76d-44ec-dbb6-c96f3ac82a21"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf<5.0,>=3.19\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-4.25.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "44999ff17d1048d5bbd4e6e97d43396d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ي/vllm_source\n",
        "!VLLM_TARGET_DEVICE=cpu python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sExWRCrbLS5z",
        "outputId": "bece9007-920b-4a9f-f188-4a87a1de7d8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ي/vllm_source\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/config/_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
            "\n",
            "        By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
            "        or your builds will no longer be supported.\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  corresp(dist, value, root_dir)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/config/_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: Apache Software License\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist._finalize_license_expression()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "\n",
            "        License :: OSI Approved :: Apache Software License\n",
            "\n",
            "        See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self._finalize_license_expression()\n",
            "running install\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:90: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing vllm.egg-info/PKG-INFO\n",
            "writing dependency_links to vllm.egg-info/dependency_links.txt\n",
            "writing entry points to vllm.egg-info/entry_points.txt\n",
            "writing requirements to vllm.egg-info/requires.txt\n",
            "writing top-level names to vllm.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'vllm.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying vllm/collect_env.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/version.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/utils.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_custom_ops.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/logits_process.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/sampling_params.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/pooling_params.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_ipex_ops.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/_version.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/scripts.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/beam_search.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/connections.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/sequence.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/scalar_type.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/envs.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/outputs.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/config.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/logger.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/jsontree.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/tracing.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/env_override.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/forward_context.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/test_utils.py -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/multimodal/image.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/video.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/parse.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/audio.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/profiling.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/inputs.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/processing.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/hasher.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/multimodal/base.py -> build/lib.linux-x86_64-cpython-311/vllm/multimodal\n",
            "copying vllm/assets/image.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/video.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/audio.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/assets/base.py -> build/lib.linux-x86_64-cpython-311/vllm/assets\n",
            "copying vllm/executor/ray_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/uniproc_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/executor_base.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/ray_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/msgspec_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/mp_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/executor/multiproc_worker_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/executor\n",
            "copying vllm/worker/worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/hpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuron_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cpu_pooling_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/pooling_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_hpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/tpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/neuron_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/hpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/xpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cpu_enc_dec_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_tpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/enc_dec_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/xpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/multi_step_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/tpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/model_runner_base.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/worker.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/worker/cache_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/worker\n",
            "copying vllm/distributed/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/communication_op.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/distributed/parallel_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed\n",
            "copying vllm/plugins/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/plugins\n",
            "copying vllm/inputs/preprocess.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/data.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/inputs/parse.py -> build/lib.linux-x86_64-cpython-311/vllm/inputs\n",
            "copying vllm/reasoning/abs_reasoning_parsers.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/granite_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/reasoning/deepseek_r1_reasoning_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/reasoning\n",
            "copying vllm/triton_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "copying vllm/triton_utils/importing.py -> build/lib.linux-x86_64-cpython-311/vllm/triton_utils\n",
            "copying vllm/device_allocator/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "copying vllm/device_allocator/cumem.py -> build/lib.linux-x86_64-cpython-311/vllm/device_allocator\n",
            "copying vllm/model_executor/parameter.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/pooling_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/custom_op.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/model_executor/sampling_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor\n",
            "copying vllm/entrypoints/score_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/chat_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/launcher.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/llm.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/api_server.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/ssl.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/entrypoints/logger.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints\n",
            "copying vllm/attention/layer.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/attention/selector.py -> build/lib.linux-x86_64-cpython-311/vllm/attention\n",
            "copying vllm/usage/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "copying vllm/usage/usage_lib.py -> build/lib.linux-x86_64-cpython-311/vllm/usage\n",
            "copying vllm/adapter_commons/models.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/request.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/adapter_commons/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/adapter_commons\n",
            "copying vllm/engine/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/async_llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/async_timeout.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/protocol.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/arg_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/engine/metrics_types.py -> build/lib.linux-x86_64-cpython-311/vllm/engine\n",
            "copying vllm/third_party/pynvml.py -> build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "copying vllm/third_party/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/third_party\n",
            "copying vllm/logging_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/logging_utils/formatter.py -> build/lib.linux-x86_64-cpython-311/vllm/logging_utils\n",
            "copying vllm/spec_decode/spec_decode_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/mlp_speculator_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/top1_proposer.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/proposer_worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/smaller_tp_proposer_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/util.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/mqa_scorer.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/draft_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/multi_step_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/medusa_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/ngram_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/batch_expansion.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/spec_decode/target_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/spec_decode\n",
            "copying vllm/transformers_utils/tokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/tokenizer_base.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/detokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/s3_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/detokenizer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/config.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/transformers_utils/processor.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils\n",
            "copying vllm/core/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/placeholder_block_space_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/block_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/evictor.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/core/scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/core\n",
            "copying vllm/platforms/cuda.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/rocm.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/neuron.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/cpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/hpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/tpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/platforms/xpu.py -> build/lib.linux-x86_64-cpython-311/vllm/platforms\n",
            "copying vllm/lora/models.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/fully_sharded_layers.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/lora.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/request.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/peft_helper.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/resolver.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/lora/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/lora\n",
            "copying vllm/v1/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/request.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/kv_cache_interface.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/outputs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/v1/serial_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1\n",
            "copying vllm/profiler/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/profiler/layerwise_profile.py -> build/lib.linux-x86_64-cpython-311/vllm/profiler\n",
            "copying vllm/prompt_adapter/models.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/worker_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/request.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/prompt_adapter/layers.py -> build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter\n",
            "copying vllm/compilation/compiler_interface.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/decorators.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/counter.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/backends.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/vllm_inductor_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fix_functionalization.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/monitor.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/pass_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fx_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/inductor_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/torch25_custom_graph_pass.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/noop_elimination.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/fusion.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/compilation/multi_output_match.py -> build/lib.linux-x86_64-cpython-311/vllm/compilation\n",
            "copying vllm/distributed/kv_transfer/kv_connector_agent.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/kv_transfer_state.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/device_communicators/tpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cuda_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/base_device_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/neuron_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/custom_all_reduce_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/pynccl_wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/hpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/xpu_communicator.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/shm_broadcast.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/custom_all_reduce.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/pynccl.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/device_communicators/cuda_wrapper.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_pipe/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_lookup_buffer/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying vllm/distributed/kv_transfer/kv_connector/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/mooncake_store_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/factory.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/simple_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/lmcache_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/distributed/kv_transfer/kv_connector/v1/base.py -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying vllm/model_executor/models/minicpm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_5_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/pixtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interfaces_base.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granite.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/idefics3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bloom.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/fairseq2_llama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_j.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/intern_vit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/grok1.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mllama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpmv.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_mtp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_audio.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/stablelm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_onevision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/clip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/adapters.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/constant_size_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_5_omni_thinker.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/idefics2_vision_model.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/registry.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bart.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmo2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama_eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/molmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/teleflm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/module_mapping.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3_small.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mixtral.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/zamba2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi3v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/telechat2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jais.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/dbrx.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_v2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/kimi_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mllama4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/orion.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/whisper.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/opt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/prithvi_geospatial_mae.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internlm2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/smolvlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_bigcode.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/baichuan.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpm3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoeshared.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mixtral_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internvl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/arctic.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/blip2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phimoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nvlm_d.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/internlm2_ve.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/transformers.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/siglip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/nemotron_nas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen2_rm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mpt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/commandr.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/olmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mlp_speculator.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/plamo2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/chatglm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_next_video.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aya_vision.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/falcon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/chameleon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minimax_text_01.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/ultravox.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/bert.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/starcoder2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/glm4v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/jamba.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/modernbert.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/blip.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/fuyu.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/granitemoe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/phi4mm_audio.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gemma3_mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llama4.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/solar.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/paligemma.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/exaone.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gpt_neox.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/persimmon.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/mistral3.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/skyworkr1v.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/aria.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/gritlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/llava_next.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/minicpmo.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/moonvit.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/florence2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/qwen3_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/roberta.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/models/h2ovl.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/models\n",
            "copying vllm/model_executor/layers/rejection_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/rotary_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/linear.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/pooler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/layernorm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/resampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/typical_acceptance_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/lightning_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/activation.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/spec_decode_base_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/logits_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/layers/vocab_parallel_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers\n",
            "copying vllm/model_executor/model_loader/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/loader.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/neuron.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/tensorizer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/model_loader/weight_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader\n",
            "copying vllm/model_executor/guided_decoding/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/guided_fields.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/outlines_decoding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/xgrammar_decoding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/guidance_logits_processors.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/outlines_logits_processors.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/guided_decoding/guidance_decoding.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding\n",
            "copying vllm/model_executor/layers/quantization/schema.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/torchao.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/ipex_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/experts_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gguf.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/aqlm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/modelopt.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/fbgemm_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/awq_triton.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/base_config.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/qqq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/tpu_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/moe_wna16.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/kv_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_marlin_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/bitsandbytes.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/gptq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/ptpc_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/hqq_marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/deepspeedfp.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/quantization/neuron_quant.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization\n",
            "copying vllm/model_executor/layers/fused_moe/layer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/deep_gemm_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/cutlass_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_torch_iterative.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/moe_align_block_size.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/fused_marlin_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe\n",
            "copying vllm/model_executor/layers/mamba/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_mixer2.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba_mixer.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/mamba/mamba2_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba\n",
            "copying vllm/model_executor/layers/quantization/quark/quark.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/quark/quark_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark\n",
            "copying vllm/model_executor/layers/quantization/kernels/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying vllm/model_executor/layers/quantization/utils/machete_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/fp8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/w8a8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/int8_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/layer_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/allspark_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/quant_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/marlin_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/utils/gptq_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying vllm/model_executor/layers/mamba/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_state_passing.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_bmm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/causal_conv1d.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/mamba_ssm.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/layers/mamba/ops/ssd_combined.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops\n",
            "copying vllm/model_executor/guided_decoding/reasoner/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/reasoner\n",
            "copying vllm/entrypoints/openai/serving_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_transcription.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/cli_args.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_chat.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_completion.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_pooling.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/run_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/logits_processors.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/api_server.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_score.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_embedding.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_tokenization.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/serving_models.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/openai/protocol.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai\n",
            "copying vllm/entrypoints/cli/collect_env.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/types.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/openai.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/main.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/cli/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli\n",
            "copying vllm/entrypoints/openai/tool_parsers/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers\n",
            "copying vllm/entrypoints/cli/benchmark/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/throughput.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/main.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/latency.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/entrypoints/cli/benchmark/base.py -> build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark\n",
            "copying vllm/attention/backends/flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flashinfer.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/xformers.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/ipex_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/cpu_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/hpu_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/rocm_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/triton_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/blocksparse_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/placeholder_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/torch_sdpa.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/backends/pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends\n",
            "copying vllm/attention/ops/triton_decode_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_merge_attn_states.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/triton_flash_attention.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/ipex_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/hpu_paged_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/prefix_prefill.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/chunked_prefill_paged_decode.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/nki_flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/paged_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/ops/merge_attn_states.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops\n",
            "copying vllm/attention/backends/mla/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "copying vllm/attention/backends/mla/common.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla\n",
            "copying vllm/attention/ops/blocksparse_attention/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention\n",
            "copying vllm/attention/ops/blocksparse_attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention\n",
            "copying vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention\n",
            "copying vllm/attention/ops/blocksparse_attention/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention\n",
            "copying vllm/engine/multiprocessing/client.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/multiprocessing/engine.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing\n",
            "copying vllm/engine/output_processor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/single_step.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/multi_step.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/stop_checker.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/util.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/engine/output_processor/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor\n",
            "copying vllm/transformers_utils/configs/mllama.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/medusa.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/olmo2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/telechat2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/jais.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nemotron.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/dbrx.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/kimi_vl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/internvl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/arctic.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/nvlm_d.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mpt.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/mlp_speculator.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/chatglm.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/cohere2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/falcon.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/ultravox.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/solar.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/exaone.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/skyworkr1v.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/moonvit.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/configs/h2ovl.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs\n",
            "copying vllm/transformers_utils/tokenizer_group/tokenizer_group.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group\n",
            "copying vllm/transformers_utils/tokenizer_group/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group\n",
            "copying vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group\n",
            "copying vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group\n",
            "copying vllm/transformers_utils/tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "copying vllm/transformers_utils/tokenizers/mistral.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers\n",
            "copying vllm/transformers_utils/processors/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/transformers_utils/processors/deepseek_vl2.py -> build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors\n",
            "copying vllm/core/block/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/prefix_caching_block.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/common.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/interfaces.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/naive_block.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/block_table.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/core/block/cpu_gpu_block_allocator.py -> build/lib.linux-x86_64-cpython-311/vllm/core/block\n",
            "copying vllm/lora/punica_wrapper/punica_hpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_base.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_selector.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_cpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/punica_wrapper/punica_gpu.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper\n",
            "copying vllm/lora/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops\n",
            "copying vllm/lora/ops/triton_ops/lora_expand.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_kernel_metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/lora_shrink.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/triton_ops/kernel_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops\n",
            "copying vllm/lora/ops/torch_ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "copying vllm/lora/ops/torch_ops/lora_ops.py -> build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops\n",
            "copying vllm/v1/executor/ray_distributed_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/multiproc_executor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/executor/abstract.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/executor\n",
            "copying vllm/v1/structured_output/backend_guidance.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_xgrammar.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/request.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/structured_output/backend_types.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output\n",
            "copying vllm/v1/metrics/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/loggers.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/metrics/stats.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/metrics\n",
            "copying vllm/v1/worker/worker_base.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_model_runner.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/lora_model_runner_mixin.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/tpu_worker.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/block_table.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/worker/gpu_input_batch.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/worker\n",
            "copying vllm/v1/stats/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/stats\n",
            "copying vllm/v1/stats/common.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/stats\n",
            "copying vllm/v1/sample/rejection_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/sample/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample\n",
            "copying vllm/v1/attention/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention\n",
            "copying vllm/v1/engine/core.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/mm_input_cache.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/core_client.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/detokenizer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/llm_engine.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/parallel_sampling.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/logprobs.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/output_processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/exceptions.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/async_llm.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/engine/processor.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/engine\n",
            "copying vllm/v1/spec_decode/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/metrics.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/eagle.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/spec_decode/ngram_proposer.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode\n",
            "copying vllm/v1/core/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/block_pool.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/specialized_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/encoder_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/core/kv_cache_manager.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core\n",
            "copying vllm/v1/sample/ops/bad_words.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/topk_topp_sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/ops/penalties.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops\n",
            "copying vllm/v1/sample/tpu/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/metadata.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/sample/tpu/sampler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu\n",
            "copying vllm/v1/attention/backends/flash_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/triton_attn.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/pallas.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends\n",
            "copying vllm/v1/attention/backends/mla/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/common.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/flashmla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/attention/backends/mla/triton_mla.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla\n",
            "copying vllm/v1/core/sched/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/__init__.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/interface.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/output.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "copying vllm/v1/core/sched/scheduler.py -> build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:212: _Warning: Package 'vllm.benchmarks' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'vllm.benchmarks' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'vllm.benchmarks' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'vllm.benchmarks' to be distributed and are\n",
            "        already explicitly excluding 'vllm.benchmarks' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:212: _Warning: Package 'vllm.model_executor.layers.fused_moe.configs' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'vllm.model_executor.layers.fused_moe.configs' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'vllm.model_executor.layers.fused_moe.configs' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'vllm.model_executor.layers.fused_moe.configs' to be distributed and are\n",
            "        already explicitly excluding 'vllm.model_executor.layers.fused_moe.configs' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:212: _Warning: Package 'vllm.model_executor.layers.quantization.utils.configs' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'vllm.model_executor.layers.quantization.utils.configs' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'vllm.model_executor.layers.quantization.utils.configs' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'vllm.model_executor.layers.quantization.utils.configs' to be distributed and are\n",
            "        already explicitly excluding 'vllm.model_executor.layers.quantization.utils.configs' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:212: _Warning: Package 'vllm.vllm_flash_attn' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'vllm.vllm_flash_attn' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'vllm.vllm_flash_attn' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'vllm.vllm_flash_attn' to be distributed and are\n",
            "        already explicitly excluding 'vllm.vllm_flash_attn' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "copying vllm/py.typed -> build/lib.linux-x86_64-cpython-311/vllm\n",
            "copying vllm/benchmarks/datasets.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/endpoint_request_func.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/latency.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/serve.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/throughput.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/benchmarks/utils.py -> build/lib.linux-x86_64-cpython-311/vllm/benchmarks\n",
            "copying vllm/vllm_flash_attn/.gitkeep -> build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn\n",
            "copying vllm/vllm_flash_attn/fa_utils.py -> build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/distributed/kv_transfer/README.md -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg -> build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/fused_moe/configs/README -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs\n",
            "running build_ext\n",
            "-- Build type: RelWithDebInfo\n",
            "-- Target device: cpu\n",
            "-- Found python matching: /usr/bin/python3.\n",
            "\u001b[33mCMake Warning at /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:22 (message):\n",
            "  static library kineto_LIBRARY-NOTFOUND not found.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/share/cmake/Torch/TorchConfig.cmake:121 (append_torchlib_if_found)\n",
            "  CMakeLists.txt:81 (find_package)\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[33mCMake Warning at cmake/cpu_extension.cmake:107 (message):\n",
            "  vLLM CPU backend using AVX2 ISA\n",
            "Call Stack (most recent call first):\n",
            "  CMakeLists.txt:89 (include)\n",
            "\n",
            "\u001b[0m\n",
            "-- CPU extension compile flags: -mf16c;-fopenmp;-DVLLM_CPU_EXTENSION;-mavx2\n",
            "-- Enabling C extension.\n",
            "-- Configuring done (6.1s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/ي/vllm_source/build/temp.linux-x86_64-cpython-311\n",
            "ninja: no work to do.\n",
            "-- Install configuration: \"RelWithDebInfo\"\n",
            "-- Up-to-date: /content/ي/vllm_source/build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so\n",
            "Copying build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn/fa_utils.py to vllm/vllm_flash_attn/fa_utils.py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/collect_env.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/__init__.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/lazy_utils.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/ray/ray_env.py -> build/bdist.linux-x86_64/egg/vllm/ray\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/version.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/image.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/utils.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/__init__.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/registry.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/video.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/parse.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/audio.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/profiling.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/inputs.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/processing.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/hasher.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/multimodal/base.py -> build/bdist.linux-x86_64/egg/vllm/multimodal\n",
            "creating build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/image.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/__init__.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/video.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/audio.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/assets/base.py -> build/bdist.linux-x86_64/egg/vllm/assets\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/ray_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/uniproc_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/executor_base.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/ray_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/msgspec_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/mp_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/executor/multiproc_worker_utils.py -> build/bdist.linux-x86_64/egg/vllm/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/__init__.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_custom_ops.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logits_process.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/worker_base.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/hpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuron_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/utils.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/__init__.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cpu_pooling_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/pooling_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_hpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/tpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuron_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/hpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/xpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cpu_enc_dec_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_tpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/enc_dec_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/xpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_neuron_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/tpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/model_runner_base.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/multi_step_neuronx_distributed_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/worker.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/neuronx_distributed_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/worker/cache_engine.py -> build/bdist.linux-x86_64/egg/vllm/worker\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector_agent.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/README.md -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_pipe/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_lookup_buffer/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_transfer_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/mooncake_store_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/factory.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/simple_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/base.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_transfer/kv_connector/lmcache_connector.py -> build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/communication_op.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/rebalance_execute.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/eplb_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/eplb/rebalance_algo.py -> build/bdist.linux-x86_64/egg/vllm/distributed/eplb\n",
            "creating build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/tpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/ray_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/__init__.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cuda_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/all2all.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/base_device_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/neuron_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/custom_all_reduce_utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/pynccl_wrapper.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/quick_all_reduce.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/hpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/xpu_communicator.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/shm_broadcast.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/custom_all_reduce.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/pynccl.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/device_communicators/cuda_wrapper.py -> build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/kv_events.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/parallel_state.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/distributed/tpu_distributed_utils.py -> build/bdist.linux-x86_64/egg/vllm/distributed\n",
            "creating build/bdist.linux-x86_64/egg/vllm/plugins\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/__init__.py -> build/bdist.linux-x86_64/egg/vllm/plugins\n",
            "creating build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/README.md -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/plugins/lora_resolvers/filesystem_resolver.py -> build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/preprocess.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/__init__.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/registry.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/data.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/inputs/parse.py -> build/bdist.linux-x86_64/egg/vllm/inputs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/sampling_params.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/glm4_moe_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/qwen3_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/abs_reasoning_parsers.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/step3_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/gptoss_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/__init__.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/granite_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/hunyuan_a13b_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/deepseek_r1_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/reasoning/mistral_reasoning_parser.py -> build/bdist.linux-x86_64/egg/vllm/reasoning\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/pooling_params.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_ipex_ops.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn/fa_utils.py -> build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/vllm_flash_attn/.gitkeep -> build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn\n",
            "creating build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/triton_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/triton_utils/importing.py -> build/bdist.linux-x86_64/egg/vllm/triton_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/device_allocator/__init__.py -> build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/device_allocator/cumem.py -> build/bdist.linux-x86_64/egg/vllm/device_allocator\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_version.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/scripts.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/parameter.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aimv2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_5_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/pixtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interfaces_base.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granite.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ernie45.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_vl_01.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/idefics3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bloom.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/fairseq2_llama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/dots1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_j.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/intern_vit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/grok1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mllama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mimo_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpmv.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/voxtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ernie45_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_audio.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/stablelm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_onevision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/clip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/medusa.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/adapters.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bailing_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/hunyuan_v1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mimo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/constant_size_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_5_omni_thinker.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_moe_mtp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/idefics2_vision_model.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/registry.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bart.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmo2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bert_with_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/tarsier.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/molmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/teleflm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/module_mapping.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3_small.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mixtral.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/zamba2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi3v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/telechat2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_1v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jais.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/exaone4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama_eagle3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/hyperclovax_vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/dbrx.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/step3_text.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_v2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/kimi_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mllama4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/orion.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/whisper.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/opt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/prithvi_geospatial_mae.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jina_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internlm2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/smolvlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3n.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_bigcode.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/baichuan.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpm3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoeshared.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mixtral_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internvl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/arctic.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/blip2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phimoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nvlm_d.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/internlm2_ve.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ovis.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/transformers.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/siglip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_nas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen2_rm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mpt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/commandr.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/olmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4_multimodal.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mlp_speculator.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/plamo2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/chatglm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_next_video.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aya_vision.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/falcon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/chameleon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minimax_text_01.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/ultravox.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interns1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/bert.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/arcee.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/starcoder2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/glm4v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/jamba.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/modernbert.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/blip.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granite_speech.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/fuyu.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama4_eagle.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4mm_audio.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gemma3_mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llama4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/granitemoehybrid.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/solar.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/phi4flash.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/keye.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/paligemma.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/exaone.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_neox.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/persimmon.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/mistral3.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/skyworkr1v.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gpt_oss.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/aria.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/gritlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/llava_next.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/minicpmo.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/moonvit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/nemotron_h.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/florence2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/qwen3_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/roberta.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/interns1_vit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/step3_vl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/falcon_h1.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/models/h2ovl.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/models\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/input_quant_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/schema.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/torchao.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/ipex_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/experts_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/quark.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/quark/quark_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/mxfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gguf.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/aqlm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/modelopt.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/fbgemm_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/auto_round.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/awq_triton.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/base_config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_bitblas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/qqq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/tpu_int8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/moe_wna16.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/inc.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/kv_cache.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_marlin_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/rtn.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/bitsandbytes.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/gptq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/ptpc_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/hqq_marlin.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/machete_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/fp8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/w8a8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/int8_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/layer_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/allspark_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/quant_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/gptq_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/bitblas_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/mxfp4_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/utils/flashinfer_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/deepspeedfp.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/neuron_quant.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/quantization/deepgemm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rejection_sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/linear.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/layer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=72,N=384,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=72,N=768,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=160,N=320,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/README -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-40GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_H100.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=2688,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=62,N=256,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=62,N=512,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=NVIDIA_B200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20-3e.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20-3e,dtype=fp8_w8a8,block_shape=[128,128].json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_L40S.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=16,N=1344,device_name=NVIDIA_A100-SXM4-80GB.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_batched_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/cutlass_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_pallas.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deep_gemm_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_torch_iterative.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/cpu_fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/modular_kernel.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/config.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/moe_align_block_size.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/fused_marlin_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/mrope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/llama3_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/common.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/base.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/pooler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/layernorm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/resampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/typical_acceptance_sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/layernorm_gated.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_state_passing.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_bmm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/causal_conv1d.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/mamba_ssm.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/ops/ssd_combined.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/abstract.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_mixer2.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_mixer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba2_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/mamba/mamba_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/lightning_attn.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/activation.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/spec_decode_base_sampler.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/logits_processor.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/layers/vocab_parallel_embedding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/layers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/pooling_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/sharded_state_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/runai_streamer_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/neuron.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tensorizer_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tensorizer.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/neuronx_distributed.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/dummy_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/gguf_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/weight_utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/base_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/tpu.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/bitsandbytes_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/model_loader/default_loader.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/utils.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/guided_fields.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/outlines_decoding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/xgrammar_decoding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/guidance_logits_processors.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "creating build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/reasoner\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/reasoner/__init__.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/reasoner\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/outlines_logits_processors.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/guided_decoding/guidance_decoding.py -> build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/custom_op.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/model_executor/sampling_metadata.py -> build/bdist.linux-x86_64/egg/vllm/model_executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/score_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_engine.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_responses.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_transcription.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/cli_args.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/speech_to_text.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_chat.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_completion.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_pooling.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/run_batch.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/logits_processors.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/api_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_score.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_embedding.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_classification.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_tokenization.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/serving_models.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/openai/protocol.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/openai\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/tool_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/harmony_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/chat_utils.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/launcher.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/llm.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/api_server.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/collect_env.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/types.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/openai.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/main.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/serve.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/run_batch.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli\n",
            "creating build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/__init__.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/throughput.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/main.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/serve.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/latency.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/cli/benchmark/base.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/ssl.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/logger.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/context.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/entrypoints/tool.py -> build/bdist.linux-x86_64/egg/vllm/entrypoints\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/beam_search.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/connections.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/layer.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/xformers.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/dual_chunk_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/ipex_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/differential_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/cpu_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/hpu_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/rocm_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/abstract.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/triton_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/mla/common.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/blocksparse_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/placeholder_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/torch_sdpa.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/pallas.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/backends/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_decode_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_unified_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_merge_attn_states.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/triton_flash_attention.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention/utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/blocksparse_attention/interface.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/ipex_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/hpu_paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/prefix_prefill.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/chunked_prefill_paged_decode.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/nki_flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/rocm_aiter_paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/pallas_kv_cache_update.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/paged_attn.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/ops/merge_attn_states.py -> build/bdist.linux-x86_64/egg/vllm/attention/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/selector.py -> build/bdist.linux-x86_64/egg/vllm/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/fa_utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/attention/utils/kv_sharing_utils.py -> build/bdist.linux-x86_64/egg/vllm/attention/utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/usage\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/usage/__init__.py -> build/bdist.linux-x86_64/egg/vllm/usage\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/usage/usage_lib.py -> build/bdist.linux-x86_64/egg/vllm/usage\n",
            "creating build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/models.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/utils.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/__init__.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/request.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/adapter_commons/layers.py -> build/bdist.linux-x86_64/egg/vllm/adapter_commons\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/metrics.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/async_llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/async_timeout.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/client.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/multiprocessing/engine.py -> build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing\n",
            "creating build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/single_step.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/multi_step.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/stop_checker.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/util.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/output_processor/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/engine/output_processor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/protocol.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/arg_utils.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/engine/metrics_types.py -> build/bdist.linux-x86_64/egg/vllm/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/third_party/pynvml.py -> build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/third_party/__init__.py -> build/bdist.linux-x86_64/egg/vllm/third_party\n",
            "creating build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/dump_input.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logging_utils/formatter.py -> build/bdist.linux-x86_64/egg/vllm/logging_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/sequence.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/spec_decode_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/__init__.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/mlp_speculator_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/metrics.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/top1_proposer.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/proposer_worker_base.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/smaller_tp_proposer_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/util.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/mqa_scorer.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/draft_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/multi_step_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/medusa_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/ngram_worker.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/batch_expansion.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/spec_decode/target_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/scalar_type.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/_C.abi3.so -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_chatml.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_deepseek_vl2.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/registry.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_blip2.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_fuyu.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/chat_templates/template_basic.jinja -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mllama.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/medusa.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/olmo2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/telechat2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/jais.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mistral.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/dbrx.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/kimi_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/internvl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/arctic.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nvlm_d.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/ovis.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mpt.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/mlp_speculator.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/eagle.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/chatglm.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/algos.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/speculators/base.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/cohere2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/falcon.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/ultravox.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/solar.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/exaone.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/skyworkr1v.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/moonvit.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/nemotron_h.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/step3_vl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/configs/h2ovl.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_base.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/detokenizer.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/dynamic_module.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/s3_utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group/tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/tokenizers/mistral.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/detokenizer_utils.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/config.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "creating build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/__init__.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/ovis.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processors/deepseek_vl2.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/transformers_utils/processor.py -> build/bdist.linux-x86_64/egg/vllm/transformers_utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/envs.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/__init__.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/placeholder_block_space_manager.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block_manager.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/utils.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/__init__.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/prefix_caching_block.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/common.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/naive_block.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/block_table.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/block/cpu_gpu_block_allocator.py -> build/bdist.linux-x86_64/egg/vllm/core/block\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/evictor.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/interfaces.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/core/scheduler.py -> build/bdist.linux-x86_64/egg/vllm/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/cuda.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/rocm.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/__init__.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/neuron.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/interface.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/cpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/hpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/tpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/platforms/xpu.py -> build/bdist.linux-x86_64/egg/vllm/platforms\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/models.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/fully_sharded_layers.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_hpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_base.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_selector.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_cpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_gpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_tpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/punica_wrapper/punica_xpu.py -> build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/lora.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_expand.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_shrink_op.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_kernel_metadata.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_expand_op.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/lora_shrink.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/triton_ops/kernel_utils.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/ipex_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/xla_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/ops/torch_ops/lora_ops.py -> build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/request.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/peft_helper.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/resolver.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/lora/layers.py -> build/bdist.linux-x86_64/egg/vllm/lora\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/tasks.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/outputs.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/ray_distributed_executor.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/multiproc_executor.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/executor/abstract.py -> build/bdist.linux-x86_64/egg/vllm/v1/executor\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_guidance.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_xgrammar.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/request.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_outlines.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/structured_output/backend_types.py -> build/bdist.linux-x86_64/egg/vllm/v1/structured_output\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/reader.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/loggers.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/stats.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/prometheus.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/metrics/ray_wrappers.py -> build/bdist.linux-x86_64/egg/vllm/v1/metrics\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/worker_base.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/lora_model_runner_mixin.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/xpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/kv_connector_model_runner_mixin.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/cpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/xpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_worker.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/cpu_model_runner.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/tpu_input_batch.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/block_table.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/worker/gpu_input_batch.py -> build/bdist.linux-x86_64/egg/vllm/v1/worker\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/stats\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/stats/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/stats\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/stats/common.py -> build/bdist.linux-x86_64/egg/vllm/v1/stats\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/pool/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/pool/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/pool\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/rejection_sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/bad_words.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/topk_topp_sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/logprobs.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/ops/penalties.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/ops\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/tpu/sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/sampler.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/sample/logits_processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/sample\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flash_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/xformers.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/triton_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/flex_attention.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba1_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mamba_selectors.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/common.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/flashmla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/triton_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/rocm_aiter_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/mla/cutlass_mla.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/rocm_aiter_fa.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/tree_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/cpu_attn.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/attention/backends/pallas.py -> build/bdist.linux-x86_64/egg/vllm/v1/attention/backends\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/request.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/core.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/mm_input_cache.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/core_client.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/detokenizer.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/llm_engine.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/parallel_sampling.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/logprobs.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/output_processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/exceptions.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/async_llm.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/coordinator.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/engine/processor.py -> build/bdist.linux-x86_64/egg/vllm/v1/engine\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/metadata.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/medusa.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/metrics.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/eagle.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/spec_decode/ngram_proposer.py -> build/bdist.linux-x86_64/egg/vllm/v1/spec_decode\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/kv_cache_interface.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/block_pool.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_coordinator.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/specialized_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/single_type_kv_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/encoder_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "creating build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/utils.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/__init__.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/interface.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/output.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/async_scheduler.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/scheduler.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/sched/request_queue.py -> build/bdist.linux-x86_64/egg/vllm/v1/core/sched\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/core/kv_cache_manager.py -> build/bdist.linux-x86_64/egg/vllm/v1/core\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/outputs.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/v1/serial_utils.py -> build/bdist.linux-x86_64/egg/vllm/v1\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/config.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/logger.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/flashinfer.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/__init__.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/tensor_schema.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/utils/deep_gemm.py -> build/bdist.linux-x86_64/egg/vllm/utils\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/jsontree.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/utils.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/__init__.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/profiler/layerwise_profile.py -> build/bdist.linux-x86_64/egg/vllm/profiler\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/py.typed -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/utils.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/__init__.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/endpoint_request_func.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/throughput.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/datasets.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/serve.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/latency.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks\n",
            "creating build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/utils.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/__init__.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/ready_checker.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/benchmarks/lib/endpoint_request_func.py -> build/bdist.linux-x86_64/egg/vllm/benchmarks/lib\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/tracing.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/models.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/utils.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/__init__.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/worker_manager.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/request.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/prompt_adapter/layers.py -> build/bdist.linux-x86_64/egg/vllm/prompt_adapter\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/env_override.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/forward_context.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/test_utils.py -> build/bdist.linux-x86_64/egg/vllm\n",
            "creating build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/compiler_interface.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/decorators.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/__init__.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/counter.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/wrapper.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/backends.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/vllm_inductor_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fusion_attn.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fix_functionalization.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/base_piecewise_backend.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/monitor.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/activation_quant_fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/pass_manager.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/sequence_parallelism.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fx_utils.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/collective_fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/inductor_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/torch25_custom_graph_pass.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/noop_elimination.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/cuda_piecewise_backend.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/fusion.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "copying build/lib.linux-x86_64-cpython-311/vllm/compilation/multi_output_match.py -> build/bdist.linux-x86_64/egg/vllm/compilation\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/collect_env.py to collect_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/lazy_utils.py to lazy_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/ray/ray_env.py to ray_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/version.py to version.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/image.py to image.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/video.py to video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/parse.py to parse.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/audio.py to audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/profiling.py to profiling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/inputs.py to inputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/processing.py to processing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/hasher.py to hasher.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/multimodal/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/image.py to image.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/video.py to video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/audio.py to audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/assets/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/ray_distributed_executor.py to ray_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/uniproc_executor.py to uniproc_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/executor_base.py to executor_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/ray_utils.py to ray_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/msgspec_utils.py to msgspec_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/mp_distributed_executor.py to mp_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/executor/multiproc_worker_utils.py to multiproc_worker_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_custom_ops.py to _custom_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logits_process.py to logits_process.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/worker_base.py to worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/hpu_model_runner.py to hpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuron_worker.py to neuron_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_model_runner.py to multi_step_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cpu_pooling_model_runner.py to cpu_pooling_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/pooling_model_runner.py to pooling_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_hpu_worker.py to multi_step_hpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/tpu_model_runner.py to tpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuron_model_runner.py to neuron_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/hpu_worker.py to hpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/xpu_model_runner.py to xpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cpu_enc_dec_model_runner.py to cpu_enc_dec_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/model_runner.py to model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cpu_worker.py to cpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_tpu_worker.py to multi_step_tpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/enc_dec_model_runner.py to enc_dec_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/xpu_worker.py to xpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_neuron_model_runner.py to multi_step_neuron_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_worker.py to multi_step_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/tpu_worker.py to tpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cpu_model_runner.py to cpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/model_runner_base.py to model_runner_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/multi_step_neuronx_distributed_model_runner.py to multi_step_neuronx_distributed_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/worker.py to worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/neuronx_distributed_model_runner.py to neuronx_distributed_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/worker/cache_engine.py to cache_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector_agent.py to kv_connector_agent.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py to pynccl_pipe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py to mooncake_pipe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_pipe/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py to simple_buffer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py to mooncake_store.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_lookup_buffer/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_transfer_state.py to kv_transfer_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/mooncake_store_connector.py to mooncake_store_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/factory.py to factory.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py to shared_storage_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py to nixl_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py to p2p_nccl_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py to p2p_nccl_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py to tensor_memory_pool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py to multi_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py to lmcache_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/simple_connector.py to simple_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_transfer/kv_connector/lmcache_connector.py to lmcache_connector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/communication_op.py to communication_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/rebalance_execute.py to rebalance_execute.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/eplb_state.py to eplb_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/eplb/rebalance_algo.py to rebalance_algo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/tpu_communicator.py to tpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/ray_communicator.py to ray_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cpu_communicator.py to cpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cuda_communicator.py to cuda_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/all2all.py to all2all.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/base_device_communicator.py to base_device_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/neuron_communicator.py to neuron_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/custom_all_reduce_utils.py to custom_all_reduce_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/pynccl_wrapper.py to pynccl_wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/quick_all_reduce.py to quick_all_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/hpu_communicator.py to hpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/xpu_communicator.py to xpu_communicator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/shm_broadcast.py to shm_broadcast.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/custom_all_reduce.py to custom_all_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/pynccl.py to pynccl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/device_communicators/cuda_wrapper.py to cuda_wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/kv_events.py to kv_events.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/parallel_state.py to parallel_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/distributed/tpu_distributed_utils.py to tpu_distributed_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/plugins/lora_resolvers/filesystem_resolver.py to filesystem_resolver.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/preprocess.py to preprocess.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/data.py to data.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/inputs/parse.py to parse.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/sampling_params.py to sampling_params.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/glm4_moe_reasoning_parser.py to glm4_moe_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/qwen3_reasoning_parser.py to qwen3_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/abs_reasoning_parsers.py to abs_reasoning_parsers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/step3_reasoning_parser.py to step3_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/gptoss_reasoning_parser.py to gptoss_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/granite_reasoning_parser.py to granite_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/hunyuan_a13b_reasoning_parser.py to hunyuan_a13b_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/deepseek_r1_reasoning_parser.py to deepseek_r1_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/reasoning/mistral_reasoning_parser.py to mistral_reasoning_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/pooling_params.py to pooling_params.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_ipex_ops.py to _ipex_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/vllm_flash_attn/fa_utils.py to fa_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/triton_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/triton_utils/importing.py to importing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/device_allocator/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/device_allocator/cumem.py to cumem.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_version.py to _version.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/scripts.py to scripts.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/parameter.py to parameter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aimv2.py to aimv2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm.py to minicpm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_5_vl.py to qwen2_5_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/pixtral.py to pixtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interfaces_base.py to interfaces_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm_eagle.py to minicpm_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granite.py to granite.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ernie45.py to ernie45.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi.py to phi.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_vl_01.py to minimax_vl_01.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/idefics3.py to idefics3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bloom.py to bloom.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/fairseq2_llama.py to fairseq2_llama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/dots1.py to dots1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_j.py to gpt_j.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/intern_vit.py to intern_vit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/grok1.py to grok1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek.py to deepseek.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mllama.py to mllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mimo_mtp.py to mimo_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpmv.py to minicpmv.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/voxtral.py to voxtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma2.py to gemma2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ernie45_moe.py to ernie45_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_mtp.py to deepseek_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_audio.py to qwen2_audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/stablelm.py to stablelm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/vision.py to vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_onevision.py to llava_onevision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/clip.py to clip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/adapters.py to adapters.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bailing_moe.py to bailing_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/hunyuan_v1.py to hunyuan_v1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mimo.py to mimo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava.py to llava.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/constant_size_cache.py to constant_size_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_5_omni_thinker.py to qwen2_5_omni_thinker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3.py to phi3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_moe_mtp.py to glm4_moe_mtp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/idefics2_vision_model.py to idefics2_vision_model.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bart.py to bart.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma.py to gemma.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmo2.py to olmo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen3.py to qwen3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama_eagle.py to llama_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bert_with_rope.py to bert_with_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/tarsier.py to tarsier.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2.py to qwen2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/molmo.py to molmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/teleflm.py to teleflm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba_cache.py to mamba_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_vl.py to qwen2_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/module_mapping.py to module_mapping.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3_small.py to phi3_small.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mixtral.py to mixtral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/zamba2.py to zamba2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi3v.py to phi3v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/telechat2.py to telechat2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_1v.py to glm4_1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jais.py to jais.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/exaone4.py to exaone4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4.py to glm4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama_eagle3.py to llama_eagle3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_moe.py to qwen2_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/hyperclovax_vision.py to hyperclovax_vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron.py to nemotron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/dbrx.py to dbrx.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/step3_text.py to step3_text.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_v2.py to deepseek_v2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/kimi_vl.py to kimi_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_cache.py to minimax_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mllama4.py to mllama4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/orion.py to orion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/whisper.py to whisper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/opt.py to opt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/prithvi_geospatial_mae.py to prithvi_geospatial_mae.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm_utils.py to phi4mm_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jina_vl.py to jina_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmoe.py to olmoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internlm2.py to internlm2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/smolvlm.py to smolvlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3n.py to gemma3n.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_bigcode.py to gpt_bigcode.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/baichuan.py to baichuan.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpm3.py to minicpm3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoeshared.py to granitemoeshared.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm.py to glm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen.py to qwen.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mixtral_quant.py to mixtral_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba2.py to mamba2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internvl.py to internvl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mamba.py to mamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/arctic.py to arctic.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/blip2.py to blip2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phimoe.py to phimoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama.py to llama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nvlm_d.py to nvlm_d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4_moe.py to glm4_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/internlm2_ve.py to internlm2_ve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/transformers.py to transformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/siglip.py to siglip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_nas.py to nemotron_nas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen2_rm.py to qwen2_rm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bamba.py to bamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mpt.py to mpt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/commandr.py to commandr.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt2.py to gpt2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/olmo.py to olmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4_multimodal.py to phi4_multimodal.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mlp_speculator.py to mlp_speculator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/plamo2.py to plamo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm.py to phi4mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/chatglm.py to chatglm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_next_video.py to llava_next_video.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aya_vision.py to aya_vision.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen_vl.py to qwen_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/falcon.py to falcon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3.py to gemma3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/chameleon.py to chameleon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minimax_text_01.py to minimax_text_01.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/ultravox.py to ultravox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interns1.py to interns1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/bert.py to bert.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/arcee.py to arcee.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/starcoder2.py to starcoder2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/glm4v.py to glm4v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/jamba.py to jamba.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/modernbert.py to modernbert.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/blip.py to blip.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granite_speech.py to granite_speech.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/fuyu.py to fuyu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_vl.py to nemotron_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoe.py to granitemoe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama4_eagle.py to llama4_eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4mm_audio.py to phi4mm_audio.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gemma3_mm.py to gemma3_mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llama4.py to llama4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/granitemoehybrid.py to granitemoehybrid.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/solar.py to solar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/phi4flash.py to phi4flash.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/keye.py to keye.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/paligemma.py to paligemma.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/exaone.py to exaone.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_neox.py to gpt_neox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/persimmon.py to persimmon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/mistral3.py to mistral3.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/skyworkr1v.py to skyworkr1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gpt_oss.py to gpt_oss.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/aria.py to aria.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/gritlm.py to gritlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/llava_next.py to llava_next.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/minicpmo.py to minicpmo.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/moonvit.py to moonvit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/nemotron_h.py to nemotron_h.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/florence2.py to florence2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/qwen3_moe.py to qwen3_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/roberta.py to roberta.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/interns1_vit.py to interns1_vit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/step3_vl.py to step3_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/falcon_h1.py to falcon_h1.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/models/h2ovl.py to h2ovl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/input_quant_fp8.py to input_quant_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/schema.py to schema.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/torchao.py to torchao.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/marlin.py to marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/fp8.py to fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/ipex_quant.py to ipex_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/bitblas.py to bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/experts_int8.py to experts_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/quark.py to quark.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py to quark_w4a4_mxfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py to quark_w8a8_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py to quark_w8a8_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py to quark_scheme.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/quark/quark_moe.py to quark_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/mxfp4.py to mxfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gguf.py to gguf.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq.py to gptq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq_marlin.py to awq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/aqlm.py to aqlm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/modelopt.py to modelopt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py to conch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py to marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py to bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py to exllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py to machete.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py to dynamic_4bit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py to MPLinearKernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py to allspark.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py to aiter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py to cutlass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py to triton.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py to xla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py to ScaledMMLinearKernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq.py to awq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/fbgemm_fp8.py to fbgemm_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py to compressed_tensors_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py to compressed_tensors_wNa16.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py to compressed_tensors_w8a16_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py to compressed_tensors_w4a8_int.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py to compressed_tensors_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py to compressed_tensors_scheme.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py to compressed_tensors_w8a8_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py to compressed_tensors_w4a4_nvfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py to compressed_tensors_w8a8_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py to compressed_tensors_w4a16_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py to compressed_tensors_w4a16_nvfp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py to triton_scaled_mm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py to compressed_tensors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/auto_round.py to auto_round.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/awq_triton.py to awq_triton.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/base_config.py to base_config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_bitblas.py to gptq_bitblas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/qqq.py to qqq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/tpu_int8.py to tpu_int8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/moe_wna16.py to moe_wna16.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/inc.py to inc.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/kv_cache.py to kv_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_marlin_24.py to gptq_marlin_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/rtn.py to rtn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/bitsandbytes.py to bitsandbytes.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/gptq_marlin.py to gptq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/ptpc_fp8.py to ptpc_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/hqq_marlin.py to hqq_marlin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/machete_utils.py to machete_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py to nvfp4_emulation_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py to nvfp4_moe_support.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/fp8_utils.py to fp8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/w8a8_utils.py to w8a8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/int8_utils.py to int8_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py to marlin_utils_test_qqq.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py to marlin_utils_fp8.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test.py to marlin_utils_test.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/layer_utils.py to layer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/allspark_utils.py to allspark_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/quant_utils.py to quant_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py to marlin_utils_test_24.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils.py to marlin_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/gptq_utils.py to gptq_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/bitblas_utils.py to bitblas_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py to flashinfer_fp4_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py to marlin_utils_fp4.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/mxfp4_utils.py to mxfp4_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/utils/flashinfer_utils.py to flashinfer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/deepspeedfp.py to deepspeedfp.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/neuron_quant.py to neuron_quant.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/quantization/deepgemm.py to deepgemm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rejection_sampler.py to rejection_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding.py to rotary_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/linear.py to linear.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/layer.py to layer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deep_gemm_moe.py to deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_moe.py to fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py to flashinfer_cutlass_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_batched_moe.py to fused_batched_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/cutlass_moe.py to cutlass_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py to moe_permute_unpermute.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_pallas.py to moe_pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/prepare_finalize.py to prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py to pplx_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py to deepep_ht_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deep_gemm_utils.py to deep_gemm_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py to flashinfer_cutlass_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py to triton_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_torch_iterative.py to moe_torch_iterative.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py to topk_weight_and_reduce.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/cpu_fused_moe.py to cpu_fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/modular_kernel.py to modular_kernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py to batched_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/moe_align_block_size.py to moe_align_block_size.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/fused_marlin_moe.py to fused_marlin_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py to batched_triton_or_deep_gemm_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py to deepep_ll_prepare_finalize.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py to rocm_aiter_fused_moe.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py to yarn_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/mrope.py to mrope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py to dynamic_ntk_alpha_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/llama3_rope.py to llama3_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py to ntk_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py to deepseek_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py to linear_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py to dual_chunk_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py to dynamic_ntk_scaling_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py to phi3_long_rope_scaled_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py to llama4_vision_rope.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/pooler.py to pooler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/layernorm.py to layernorm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/resampler.py to resampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/typical_acceptance_sampler.py to typical_acceptance_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/layernorm_gated.py to layernorm_gated.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_state_passing.py to ssd_state_passing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py to ssd_chunk_state.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py to ssd_chunk_scan.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_bmm.py to ssd_bmm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/causal_conv1d.py to causal_conv1d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/mamba_ssm.py to mamba_ssm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/ops/ssd_combined.py to ssd_combined.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_mixer2.py to mamba_mixer2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_mixer.py to mamba_mixer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba2_metadata.py to mamba2_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/mamba/mamba_utils.py to mamba_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/lightning_attn.py to lightning_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/activation.py to activation.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/spec_decode_base_sampler.py to spec_decode_base_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/logits_processor.py to logits_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/layers/vocab_parallel_embedding.py to vocab_parallel_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/pooling_metadata.py to pooling_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/sharded_state_loader.py to sharded_state_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/loader.py to loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/runai_streamer_loader.py to runai_streamer_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/neuron.py to neuron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tensorizer_loader.py to tensorizer_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tensorizer.py to tensorizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/neuronx_distributed.py to neuronx_distributed.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/dummy_loader.py to dummy_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/gguf_loader.py to gguf_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/weight_utils.py to weight_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/base_loader.py to base_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/tpu.py to tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/bitsandbytes_loader.py to bitsandbytes_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/model_loader/default_loader.py to default_loader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/guided_fields.py to guided_fields.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/outlines_decoding.py to outlines_decoding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py to lm_format_enforcer_decoding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/xgrammar_decoding.py to xgrammar_decoding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/guidance_logits_processors.py to guidance_logits_processors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/reasoner/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/outlines_logits_processors.py to outlines_logits_processors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/guided_decoding/guidance_decoding.py to guidance_decoding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/custom_op.py to custom_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/model_executor/sampling_metadata.py to sampling_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/score_utils.py to score_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_engine.py to serving_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_responses.py to serving_responses.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_transcription.py to serving_transcription.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/cli_args.py to cli_args.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/speech_to_text.py to speech_to_text.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_chat.py to serving_chat.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_completion.py to serving_completion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_pooling.py to serving_pooling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/run_batch.py to run_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py to minimax_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py to mistral_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py to xlam_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py to phi4mini_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py to hermes_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py to step3_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py to llama_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py to granite_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py to internlm2_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py to deepseekv3_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py to glm4_moe_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py to pythonic_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py to jamba_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py to abstract_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py to granite_20b_fc_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py to kimi_k2_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py to llama4_pythonic_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py to hunyuan_a13b_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py to qwen3coder_tool_parser.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/logits_processors.py to logits_processors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/api_server.py to api_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_score.py to serving_score.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_embedding.py to serving_embedding.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_classification.py to serving_classification.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_tokenization.py to serving_tokenization.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/serving_models.py to serving_models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/openai/protocol.py to protocol.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/tool_server.py to tool_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/harmony_utils.py to harmony_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/chat_utils.py to chat_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/launcher.py to launcher.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/llm.py to llm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/api_server.py to api_server.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/collect_env.py to collect_env.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/types.py to types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/openai.py to openai.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/main.py to main.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/run_batch.py to run_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/throughput.py to throughput.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/main.py to main.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/latency.py to latency.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/cli/benchmark/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/ssl.py to ssl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/logger.py to logger.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/context.py to context.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/entrypoints/tool.py to tool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/beam_search.py to beam_search.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/connections.py to connections.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/layer.py to layer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flash_attn.py to flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/xformers.py to xformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/dual_chunk_flash_attn.py to dual_chunk_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/ipex_attn.py to ipex_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/differential_flash_attn.py to differential_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/cpu_mla.py to cpu_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/hpu_attn.py to hpu_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/rocm_flash_attn.py to rocm_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/triton_mla.py to triton_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/mla/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/mla/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/blocksparse_attn.py to blocksparse_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/placeholder_attn.py to placeholder_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/torch_sdpa.py to torch_sdpa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/pallas.py to pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/backends/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_decode_attention.py to triton_decode_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_unified_attention.py to triton_unified_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_merge_attn_states.py to triton_merge_attn_states.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/triton_flash_attention.py to triton_flash_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py to blocksparse_attention_kernel.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/blocksparse_attention/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/ipex_attn.py to ipex_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/hpu_paged_attn.py to hpu_paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/prefix_prefill.py to prefix_prefill.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/chunked_prefill_paged_decode.py to chunked_prefill_paged_decode.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/nki_flash_attn.py to nki_flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/rocm_aiter_paged_attn.py to rocm_aiter_paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/pallas_kv_cache_update.py to pallas_kv_cache_update.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/paged_attn.py to paged_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/ops/merge_attn_states.py to merge_attn_states.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/selector.py to selector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/fa_utils.py to fa_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/attention/utils/kv_sharing_utils.py to kv_sharing_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/usage/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/usage/usage_lib.py to usage_lib.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/adapter_commons/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/llm_engine.py to llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/async_llm_engine.py to async_llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/async_timeout.py to async_timeout.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/client.py to client.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/multiprocessing/engine.py to engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/single_step.py to single_step.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/multi_step.py to multi_step.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/stop_checker.py to stop_checker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/util.py to util.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/output_processor/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/protocol.py to protocol.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/arg_utils.py to arg_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/engine/metrics_types.py to metrics_types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/third_party/pynvml.py to pynvml.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/third_party/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/dump_input.py to dump_input.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logging_utils/formatter.py to formatter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/sequence.py to sequence.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/spec_decode_worker.py to spec_decode_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/mlp_speculator_worker.py to mlp_speculator_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/top1_proposer.py to top1_proposer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/proposer_worker_base.py to proposer_worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/smaller_tp_proposer_worker.py to smaller_tp_proposer_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/util.py to util.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/mqa_scorer.py to mqa_scorer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/draft_model_runner.py to draft_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/multi_step_worker.py to multi_step_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/medusa_worker.py to medusa_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/ngram_worker.py to ngram_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/batch_expansion.py to batch_expansion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/spec_decode/target_model_runner.py to target_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/scalar_type.py to scalar_type.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group.py to tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer.py to tokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/chat_templates/registry.py to registry.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mllama.py to mllama.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/olmo2.py to olmo2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/telechat2.py to telechat2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/jais.py to jais.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron.py to nemotron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mistral.py to mistral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/dbrx.py to dbrx.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/kimi_vl.py to kimi_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/internvl.py to internvl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/arctic.py to arctic.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nvlm_d.py to nvlm_d.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mpt.py to mpt.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/mlp_speculator.py to mlp_speculator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/chatglm.py to chatglm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/algos.py to algos.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/speculators/base.py to base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/cohere2.py to cohere2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/falcon.py to falcon.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/ultravox.py to ultravox.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron_vl.py to nemotron_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/solar.py to solar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/exaone.py to exaone.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/skyworkr1v.py to skyworkr1v.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/moonvit.py to moonvit.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/nemotron_h.py to nemotron_h.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/step3_vl.py to step3_vl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/configs/h2ovl.py to h2ovl.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_base.py to tokenizer_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/detokenizer.py to detokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/dynamic_module.py to dynamic_module.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/s3_utils.py to s3_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group/tokenizer_group.py to tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py to ray_tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py to base_tokenizer_group.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/tokenizers/mistral.py to mistral.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/detokenizer_utils.py to detokenizer_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/ovis.py to ovis.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processors/deepseek_vl2.py to deepseek_vl2.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/transformers_utils/processor.py to processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/envs.py to envs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/placeholder_block_space_manager.py to placeholder_block_space_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block_manager.py to block_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/prefix_caching_block.py to prefix_caching_block.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/naive_block.py to naive_block.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/block_table.py to block_table.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/block/cpu_gpu_block_allocator.py to cpu_gpu_block_allocator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/evictor.py to evictor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/interfaces.py to interfaces.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/core/scheduler.py to scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/cuda.py to cuda.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/rocm.py to rocm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/neuron.py to neuron.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/cpu.py to cpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/hpu.py to hpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/tpu.py to tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/platforms/xpu.py to xpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/fully_sharded_layers.py to fully_sharded_layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_hpu.py to punica_hpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_base.py to punica_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_selector.py to punica_selector.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_cpu.py to punica_cpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_gpu.py to punica_gpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_tpu.py to punica_tpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/punica_wrapper/punica_xpu.py to punica_xpu.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/lora.py to lora.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_expand.py to lora_expand.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_shrink_op.py to lora_shrink_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_kernel_metadata.py to lora_kernel_metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_expand_op.py to lora_expand_op.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/lora_shrink.py to lora_shrink.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/triton_ops/kernel_utils.py to kernel_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/ipex_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/xla_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/ops/torch_ops/lora_ops.py to lora_ops.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/peft_helper.py to peft_helper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/resolver.py to resolver.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/lora/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/tasks.py to tasks.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/outputs.py to outputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/ray_distributed_executor.py to ray_distributed_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/multiproc_executor.py to multiproc_executor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/executor/abstract.py to abstract.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_guidance.py to backend_guidance.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_xgrammar.py to backend_xgrammar.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_outlines.py to backend_outlines.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/structured_output/backend_types.py to backend_types.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/reader.py to reader.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/loggers.py to loggers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/stats.py to stats.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/prometheus.py to prometheus.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/metrics/ray_wrappers.py to ray_wrappers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/worker_base.py to worker_base.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_worker.py to gpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_model_runner.py to gpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_model_runner.py to tpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/lora_model_runner_mixin.py to lora_model_runner_mixin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/xpu_model_runner.py to xpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/kv_connector_model_runner_mixin.py to kv_connector_model_runner_mixin.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/cpu_worker.py to cpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/xpu_worker.py to xpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_worker.py to tpu_worker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/cpu_model_runner.py to cpu_model_runner.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/tpu_input_batch.py to tpu_input_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/block_table.py to block_table.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/worker/gpu_input_batch.py to gpu_input_batch.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/stats/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/stats/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/pool/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/pool/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/rejection_sampler.py to rejection_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/bad_words.py to bad_words.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/topk_topp_sampler.py to topk_topp_sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/logprobs.py to logprobs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/ops/penalties.py to penalties.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/tpu/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/sampler.py to sampler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/sample/logits_processor.py to logits_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba_attn.py to mamba_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flash_attn.py to flash_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/xformers.py to xformers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/triton_attn.py to triton_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/flex_attention.py to flex_attention.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba1_attn.py to mamba1_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mamba_selectors.py to mamba_selectors.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/common.py to common.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/flashmla.py to flashmla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/triton_mla.py to triton_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/rocm_aiter_mla.py to rocm_aiter_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/mla/cutlass_mla.py to cutlass_mla.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/rocm_aiter_fa.py to rocm_aiter_fa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/tree_attn.py to tree_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/cpu_attn.py to cpu_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/attention/backends/pallas.py to pallas.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/core.py to core.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/mm_input_cache.py to mm_input_cache.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/core_client.py to core_client.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/detokenizer.py to detokenizer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/llm_engine.py to llm_engine.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/parallel_sampling.py to parallel_sampling.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/logprobs.py to logprobs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/output_processor.py to output_processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/exceptions.py to exceptions.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/async_llm.py to async_llm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/coordinator.py to coordinator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/engine/processor.py to processor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/metadata.py to metadata.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/medusa.py to medusa.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/metrics.py to metrics.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/eagle.py to eagle.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/spec_decode/ngram_proposer.py to ngram_proposer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/kv_cache_interface.py to kv_cache_interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/block_pool.py to block_pool.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_coordinator.py to kv_cache_coordinator.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/specialized_manager.py to specialized_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/single_type_kv_cache_manager.py to single_type_kv_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_utils.py to kv_cache_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/encoder_cache_manager.py to encoder_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/interface.py to interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/output.py to output.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/async_scheduler.py to async_scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/scheduler.py to scheduler.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/sched/request_queue.py to request_queue.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/core/kv_cache_manager.py to kv_cache_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/outputs.py to outputs.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/v1/serial_utils.py to serial_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/config.py to config.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/logger.py to logger.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/flashinfer.py to flashinfer.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/tensor_schema.py to tensor_schema.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/utils/deep_gemm.py to deep_gemm.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/jsontree.py to jsontree.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/profiler/layerwise_profile.py to layerwise_profile.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/endpoint_request_func.py to endpoint_request_func.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/throughput.py to throughput.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/datasets.py to datasets.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/serve.py to serve.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/latency.py to latency.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/ready_checker.py to ready_checker.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/benchmarks/lib/endpoint_request_func.py to endpoint_request_func.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/tracing.py to tracing.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/models.py to models.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/utils.py to utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/worker_manager.py to worker_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/request.py to request.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/prompt_adapter/layers.py to layers.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/env_override.py to env_override.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/forward_context.py to forward_context.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/test_utils.py to test_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/compiler_interface.py to compiler_interface.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/decorators.py to decorators.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/counter.py to counter.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/wrapper.py to wrapper.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/backends.py to backends.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/vllm_inductor_pass.py to vllm_inductor_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fusion_attn.py to fusion_attn.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fix_functionalization.py to fix_functionalization.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/base_piecewise_backend.py to base_piecewise_backend.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/monitor.py to monitor.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/activation_quant_fusion.py to activation_quant_fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/pass_manager.py to pass_manager.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/sequence_parallelism.py to sequence_parallelism.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fx_utils.py to fx_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/collective_fusion.py to collective_fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/inductor_pass.py to inductor_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/torch25_custom_graph_pass.py to torch25_custom_graph_pass.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/noop_elimination.py to noop_elimination.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/cuda_piecewise_backend.py to cuda_piecewise_backend.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/fusion.py to fusion.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/compilation/multi_output_match.py to multi_output_match.cpython-311.pyc\n",
            "creating stub loader for vllm/_C.abi3.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/vllm/_C.py to _C.cpython-311.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying vllm.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "vllm.__pycache__._C.cpython-311: module references __file__\n",
            "vllm.__pycache__.config.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.__pycache__.logger.cpython-311: module references __file__\n",
            "vllm.__pycache__.utils.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.compilation.__pycache__.inductor_pass.cpython-311: module MAY be using inspect.getsource\n",
            "vllm.distributed.device_communicators.__pycache__.custom_all_reduce_utils.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.fused_moe.__pycache__.fused_moe.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.quantization.utils.__pycache__.fp8_utils.cpython-311: module references __file__\n",
            "vllm.model_executor.layers.quantization.utils.__pycache__.int8_utils.cpython-311: module references __file__\n",
            "vllm.transformers_utils.chat_templates.__pycache__.registry.cpython-311: module references __file__\n",
            "vllm.utils.__pycache__.__init__.cpython-311: module MAY be using inspect.getsource\n",
            "creating 'dist/vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.11/dist-packages/vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.11/dist-packages/vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg\n",
            "Extracting vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg to /usr/local/lib/python3.11/dist-packages\n",
            "Adding vllm 0.8.5.dev120+g471fe6563.cpu to easy-install.pth file\n",
            "Installing vllm script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.11/dist-packages/vllm-0.8.5.dev120+g471fe6563.cpu-py3.11-linux-x86_64.egg\n",
            "Processing dependencies for vllm==0.8.5.dev120+g471fe6563.cpu\n",
            "Searching for llguidance==0.7.30\n",
            "Best match: llguidance 0.7.30\n",
            "Adding llguidance 0.7.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for xgrammar==0.1.18\n",
            "Best match: xgrammar 0.1.18\n",
            "Processing xgrammar-0.1.18-py3.11-linux-x86_64.egg\n",
            "Adding xgrammar 0.1.18 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/xgrammar-0.1.18-py3.11-linux-x86_64.egg\n",
            "Searching for triton==3.2.0\n",
            "Best match: triton 3.2.0\n",
            "Adding triton 3.2.0 to easy-install.pth file\n",
            "Installing proton script to /usr/local/bin\n",
            "Installing proton-viewer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torch==2.6.0+cpu\n",
            "Best match: torch 2.6.0+cpu\n",
            "Adding torch 2.6.0+cpu to easy-install.pth file\n",
            "Installing torchfrtrace script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torchvision==0.21.0+cpu\n",
            "Best match: torchvision 0.21.0+cpu\n",
            "Adding torchvision 0.21.0+cpu to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for torchaudio==2.6.0+cu124\n",
            "Best match: torchaudio 2.6.0+cu124\n",
            "Adding torchaudio 2.6.0+cu124 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for datasets==4.0.0\n",
            "Best match: datasets 4.0.0\n",
            "Adding datasets 4.0.0 to easy-install.pth file\n",
            "Installing datasets-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opentelemetry-semantic-conventions-ai==0.4.12\n",
            "Best match: opentelemetry-semantic-conventions-ai 0.4.12\n",
            "Processing opentelemetry_semantic_conventions_ai-0.4.12-py3.11.egg\n",
            "Adding opentelemetry-semantic-conventions-ai 0.4.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_semantic_conventions_ai-0.4.12-py3.11.egg\n",
            "Searching for opentelemetry-exporter-otlp==1.26.0\n",
            "Best match: opentelemetry-exporter-otlp 1.26.0\n",
            "Processing opentelemetry_exporter_otlp-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-exporter-otlp 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_exporter_otlp-1.26.0-py3.11.egg\n",
            "Searching for opentelemetry-api==1.26.0\n",
            "Best match: opentelemetry-api 1.26.0\n",
            "Processing opentelemetry_api-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-api 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_api-1.26.0-py3.11.egg\n",
            "Searching for opentelemetry-sdk==1.26.0\n",
            "Best match: opentelemetry-sdk 1.26.0\n",
            "Processing opentelemetry_sdk-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-sdk 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_sdk-1.26.0-py3.11.egg\n",
            "Searching for ninja==1.11.1.4\n",
            "Best match: ninja 1.11.1.4\n",
            "Adding ninja 1.11.1.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for scipy==1.16.1\n",
            "Best match: scipy 1.16.1\n",
            "Adding scipy 1.16.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-json-logger==3.3.0\n",
            "Best match: python-json-logger 3.3.0\n",
            "Adding python-json-logger 3.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for watchfiles==1.1.0\n",
            "Best match: watchfiles 1.1.0\n",
            "Adding watchfiles 1.1.0 to easy-install.pth file\n",
            "Installing watchfiles script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cloudpickle==3.1.1\n",
            "Best match: cloudpickle 3.1.1\n",
            "Adding cloudpickle 3.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for depyf==0.18.0\n",
            "Best match: depyf 0.18.0\n",
            "Processing depyf-0.18.0-py3.11.egg\n",
            "Adding depyf 0.18.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/depyf-0.18.0-py3.11.egg\n",
            "Searching for compressed-tensors==0.9.3\n",
            "Best match: compressed-tensors 0.9.3\n",
            "Processing compressed_tensors-0.9.3-py3.11.egg\n",
            "Adding compressed-tensors 0.9.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/compressed_tensors-0.9.3-py3.11.egg\n",
            "Searching for einops==0.8.1\n",
            "Best match: einops 0.8.1\n",
            "Adding einops 0.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for PyYAML==6.0.2\n",
            "Best match: PyYAML 6.0.2\n",
            "Adding PyYAML 6.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opencv-python-headless==4.12.0.88\n",
            "Best match: opencv-python-headless 4.12.0.88\n",
            "Adding opencv-python-headless 4.12.0.88 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mistral-common==1.8.3\n",
            "Best match: mistral-common 1.8.3\n",
            "Adding mistral-common 1.8.3 to easy-install.pth file\n",
            "Installing mistral_common script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for importlib-metadata==8.0.0\n",
            "Best match: importlib-metadata 8.0.0\n",
            "Adding importlib-metadata 8.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/setuptools/_vendor\n",
            "Searching for gguf==0.17.1\n",
            "Best match: gguf 0.17.1\n",
            "Adding gguf 0.17.1 to easy-install.pth file\n",
            "detected new path './setuptools/_vendor'\n",
            "Installing gguf-convert-endian script to /usr/local/bin\n",
            "Installing gguf-dump script to /usr/local/bin\n",
            "Installing gguf-editor-gui script to /usr/local/bin\n",
            "Installing gguf-new-metadata script to /usr/local/bin\n",
            "Installing gguf-set-metadata script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for msgspec==0.19.0\n",
            "Best match: msgspec 0.19.0\n",
            "Adding msgspec 0.19.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pyzmq==26.2.1\n",
            "Best match: pyzmq 26.2.1\n",
            "Adding pyzmq 26.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for partial-json-parser==0.2.1.1.post6\n",
            "Best match: partial-json-parser 0.2.1.1.post6\n",
            "Adding partial-json-parser 0.2.1.1.post6 to easy-install.pth file\n",
            "Installing json-playground script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for filelock==3.18.0\n",
            "Best match: filelock 3.18.0\n",
            "Adding filelock 3.18.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typing-extensions==4.14.1\n",
            "Best match: typing-extensions 4.14.1\n",
            "Adding typing-extensions 4.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for lark==1.2.2\n",
            "Best match: lark 1.2.2\n",
            "Adding lark 1.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for outlines==0.1.11\n",
            "Best match: outlines 0.1.11\n",
            "Processing outlines-0.1.11-py3.11.egg\n",
            "Adding outlines 0.1.11 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/outlines-0.1.11-py3.11.egg\n",
            "Searching for lm-format-enforcer==0.10.12\n",
            "Best match: lm-format-enforcer 0.10.12\n",
            "Adding lm-format-enforcer 0.10.12 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tiktoken==0.9.0\n",
            "Best match: tiktoken 0.9.0\n",
            "Adding tiktoken 0.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for prometheus-fastapi-instrumentator==7.1.0\n",
            "Best match: prometheus-fastapi-instrumentator 7.1.0\n",
            "Adding prometheus-fastapi-instrumentator 7.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pillow==11.3.0\n",
            "Best match: pillow 11.3.0\n",
            "Adding pillow 11.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for prometheus-client==0.22.1\n",
            "Best match: prometheus-client 0.22.1\n",
            "Adding prometheus-client 0.22.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic==2.11.7\n",
            "Best match: pydantic 2.11.7\n",
            "Adding pydantic 2.11.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for openai==1.98.0\n",
            "Best match: openai 1.98.0\n",
            "Adding openai 1.98.0 to easy-install.pth file\n",
            "Installing openai script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiohttp==3.12.15\n",
            "Best match: aiohttp 3.12.15\n",
            "Adding aiohttp 3.12.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi==0.116.1\n",
            "Best match: fastapi 0.116.1\n",
            "Adding fastapi 0.116.1 to easy-install.pth file\n",
            "Installing fastapi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for protobuf==4.25.8\n",
            "Best match: protobuf 4.25.8\n",
            "Adding protobuf 4.25.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tokenizers==0.21.4\n",
            "Best match: tokenizers 0.21.4\n",
            "Adding tokenizers 0.21.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for huggingface-hub==0.34.3\n",
            "Best match: huggingface-hub 0.34.3\n",
            "Adding huggingface-hub 0.34.3 to easy-install.pth file\n",
            "Installing hf script to /usr/local/bin\n",
            "Installing huggingface-cli script to /usr/local/bin\n",
            "Installing tiny-agents script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for transformers==4.55.0\n",
            "Best match: transformers 4.55.0\n",
            "Adding transformers 4.55.0 to easy-install.pth file\n",
            "Installing transformers script to /usr/local/bin\n",
            "Installing transformers-cli script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for py-cpuinfo==9.0.0\n",
            "Best match: py-cpuinfo 9.0.0\n",
            "Adding py-cpuinfo 9.0.0 to easy-install.pth file\n",
            "Installing cpuinfo script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for blake3==1.0.5\n",
            "Best match: blake3 1.0.5\n",
            "Adding blake3 1.0.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tqdm==4.67.1\n",
            "Best match: tqdm 4.67.1\n",
            "Adding tqdm 4.67.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for requests==2.32.3\n",
            "Best match: requests 2.32.3\n",
            "Adding requests 2.32.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for numpy==2.0.2\n",
            "Best match: numpy 2.0.2\n",
            "Adding numpy 2.0.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing numpy-config script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sentencepiece==0.2.0\n",
            "Best match: sentencepiece 0.2.0\n",
            "Adding sentencepiece 0.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for psutil==5.9.5\n",
            "Best match: psutil 5.9.5\n",
            "Adding psutil 5.9.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for cachetools==5.5.2\n",
            "Best match: cachetools 5.5.2\n",
            "Adding cachetools 5.5.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sympy==1.13.1\n",
            "Best match: sympy 1.13.1\n",
            "Adding sympy 1.13.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fsspec==2025.3.0\n",
            "Best match: fsspec 2025.3.0\n",
            "Adding fsspec 2025.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jinja2==3.1.6\n",
            "Best match: jinja2 3.1.6\n",
            "Adding jinja2 3.1.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for networkx==3.5\n",
            "Best match: networkx 3.5\n",
            "Adding networkx 3.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for packaging==25.0\n",
            "Best match: packaging 25.0\n",
            "Adding packaging 25.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for multiprocess==0.70.16\n",
            "Best match: multiprocess 0.70.16\n",
            "Adding multiprocess 0.70.16 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for xxhash==3.5.0\n",
            "Best match: xxhash 3.5.0\n",
            "Adding xxhash 3.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pandas==2.2.2\n",
            "Best match: pandas 2.2.2\n",
            "Adding pandas 2.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for dill==0.3.8\n",
            "Best match: dill 0.3.8\n",
            "Adding dill 0.3.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pyarrow==18.1.0\n",
            "Best match: pyarrow 18.1.0\n",
            "Adding pyarrow 18.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opentelemetry-exporter-otlp-proto-http==1.26.0\n",
            "Best match: opentelemetry-exporter-otlp-proto-http 1.26.0\n",
            "Processing opentelemetry_exporter_otlp_proto_http-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-exporter-otlp-proto-http 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_exporter_otlp_proto_http-1.26.0-py3.11.egg\n",
            "Searching for opentelemetry-exporter-otlp-proto-grpc==1.26.0\n",
            "Best match: opentelemetry-exporter-otlp-proto-grpc 1.26.0\n",
            "Processing opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-exporter-otlp-proto-grpc 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3.11.egg\n",
            "Searching for Deprecated==1.2.18\n",
            "Best match: Deprecated 1.2.18\n",
            "Processing Deprecated-1.2.18-py3.11.egg\n",
            "Adding Deprecated 1.2.18 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/Deprecated-1.2.18-py3.11.egg\n",
            "Searching for opentelemetry-semantic-conventions==0.47b0\n",
            "Best match: opentelemetry-semantic-conventions 0.47b0\n",
            "Processing opentelemetry_semantic_conventions-0.47b0-py3.11.egg\n",
            "Adding opentelemetry-semantic-conventions 0.47b0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_semantic_conventions-0.47b0-py3.11.egg\n",
            "Searching for anyio==4.9.0\n",
            "Best match: anyio 4.9.0\n",
            "Adding anyio 4.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for astor==0.8.1\n",
            "Best match: astor 0.8.1\n",
            "Adding astor 0.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic-extra-types==2.10.5\n",
            "Best match: pydantic-extra-types 2.10.5\n",
            "Adding pydantic-extra-types 2.10.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jsonschema==4.25.0\n",
            "Best match: jsonschema 4.25.0\n",
            "Adding jsonschema 4.25.0 to easy-install.pth file\n",
            "Installing jsonschema script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for zipp==3.23.0\n",
            "Best match: zipp 3.23.0\n",
            "Adding zipp 3.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for outlines-core==0.1.26\n",
            "Best match: outlines-core 0.1.26\n",
            "Processing outlines_core-0.1.26-py3.11-linux-x86_64.egg\n",
            "Adding outlines-core 0.1.26 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/outlines_core-0.1.26-py3.11-linux-x86_64.egg\n",
            "Searching for airportsdata==20250706\n",
            "Best match: airportsdata 20250706\n",
            "Processing airportsdata-20250706-py3.11.egg\n",
            "Adding airportsdata 20250706 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/airportsdata-20250706-py3.11.egg\n",
            "Searching for pycountry==24.6.1\n",
            "Best match: pycountry 24.6.1\n",
            "Adding pycountry 24.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for referencing==0.36.2\n",
            "Best match: referencing 0.36.2\n",
            "Adding referencing 0.36.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for diskcache==5.6.3\n",
            "Best match: diskcache 5.6.3\n",
            "Adding diskcache 5.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for nest-asyncio==1.6.0\n",
            "Best match: nest-asyncio 1.6.0\n",
            "Adding nest-asyncio 1.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for interegular==0.3.3\n",
            "Best match: interegular 0.3.3\n",
            "Adding interegular 0.3.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for regex==2024.11.6\n",
            "Best match: regex 2024.11.6\n",
            "Adding regex 2024.11.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for starlette==0.47.2\n",
            "Best match: starlette 0.47.2\n",
            "Adding starlette 0.47.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typing-inspection==0.4.1\n",
            "Best match: typing-inspection 0.4.1\n",
            "Adding typing-inspection 0.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pydantic-core==2.33.2\n",
            "Best match: pydantic-core 2.33.2\n",
            "Adding pydantic-core 2.33.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for annotated-types==0.7.0\n",
            "Best match: annotated-types 0.7.0\n",
            "Adding annotated-types 0.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sniffio==1.3.1\n",
            "Best match: sniffio 1.3.1\n",
            "Adding sniffio 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jiter==0.10.0\n",
            "Best match: jiter 0.10.0\n",
            "Adding jiter 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httpx==0.28.1\n",
            "Best match: httpx 0.28.1\n",
            "Adding httpx 0.28.1 to easy-install.pth file\n",
            "Installing httpx script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for distro==1.9.0\n",
            "Best match: distro 1.9.0\n",
            "Adding distro 1.9.0 to easy-install.pth file\n",
            "Installing distro script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for yarl==1.20.1\n",
            "Best match: yarl 1.20.1\n",
            "Adding yarl 1.20.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for propcache==0.3.2\n",
            "Best match: propcache 0.3.2\n",
            "Adding propcache 0.3.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for multidict==6.6.3\n",
            "Best match: multidict 6.6.3\n",
            "Adding multidict 6.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for frozenlist==1.7.0\n",
            "Best match: frozenlist 1.7.0\n",
            "Adding frozenlist 1.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for attrs==25.3.0\n",
            "Best match: attrs 25.3.0\n",
            "Adding attrs 25.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiosignal==1.4.0\n",
            "Best match: aiosignal 1.4.0\n",
            "Adding aiosignal 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for aiohappyeyeballs==2.6.1\n",
            "Best match: aiohappyeyeballs 2.6.1\n",
            "Adding aiohappyeyeballs 2.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for uvicorn==0.35.0\n",
            "Best match: uvicorn 0.35.0\n",
            "Adding uvicorn 0.35.0 to easy-install.pth file\n",
            "Installing uvicorn script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for email-validator==2.2.0\n",
            "Best match: email-validator 2.2.0\n",
            "Adding email-validator 2.2.0 to easy-install.pth file\n",
            "Installing email_validator script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-multipart==0.0.20\n",
            "Best match: python-multipart 0.0.20\n",
            "Adding python-multipart 0.0.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi-cli==0.0.8\n",
            "Best match: fastapi-cli 0.0.8\n",
            "Adding fastapi-cli 0.0.8 to easy-install.pth file\n",
            "Installing fastapi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for hf-xet==1.1.5\n",
            "Best match: hf-xet 1.1.5\n",
            "Adding hf-xet 1.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for safetensors==0.5.3\n",
            "Best match: safetensors 0.5.3\n",
            "Adding safetensors 0.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for certifi==2025.7.14\n",
            "Best match: certifi 2025.7.14\n",
            "Adding certifi 2025.7.14 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for urllib3==2.5.0\n",
            "Best match: urllib3 2.5.0\n",
            "Adding urllib3 2.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for idna==3.10\n",
            "Best match: idna 3.10\n",
            "Adding idna 3.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for charset-normalizer==3.4.2\n",
            "Best match: charset-normalizer 3.4.2\n",
            "Adding charset-normalizer 3.4.2 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for MarkupSafe==3.0.2\n",
            "Best match: MarkupSafe 3.0.2\n",
            "Adding MarkupSafe 3.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for tzdata==2025.2\n",
            "Best match: tzdata 2025.2\n",
            "Adding tzdata 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pytz==2025.2\n",
            "Best match: pytz 2025.2\n",
            "Adding pytz 2025.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-dateutil==2.9.0.post0\n",
            "Best match: python-dateutil 2.9.0.post0\n",
            "Adding python-dateutil 2.9.0.post0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for opentelemetry-proto==1.26.0\n",
            "Best match: opentelemetry-proto 1.26.0\n",
            "Processing opentelemetry_proto-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-proto 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_proto-1.26.0-py3.11.egg\n",
            "Searching for opentelemetry-exporter-otlp-proto-common==1.26.0\n",
            "Best match: opentelemetry-exporter-otlp-proto-common 1.26.0\n",
            "Processing opentelemetry_exporter_otlp_proto_common-1.26.0-py3.11.egg\n",
            "Adding opentelemetry-exporter-otlp-proto-common 1.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages/opentelemetry_exporter_otlp_proto_common-1.26.0-py3.11.egg\n",
            "Searching for googleapis-common-protos==1.70.0\n",
            "Best match: googleapis-common-protos 1.70.0\n",
            "Adding googleapis-common-protos 1.70.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for grpcio==1.74.0\n",
            "Best match: grpcio 1.74.0\n",
            "Adding grpcio 1.74.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for wrapt==1.17.2\n",
            "Best match: wrapt 1.17.2\n",
            "Adding wrapt 1.17.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rpds-py==0.26.0\n",
            "Best match: rpds-py 0.26.0\n",
            "Adding rpds-py 0.26.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for jsonschema-specifications==2025.4.1\n",
            "Best match: jsonschema-specifications 2025.4.1\n",
            "Adding jsonschema-specifications 2025.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httpcore==1.0.9\n",
            "Best match: httpcore 1.0.9\n",
            "Adding httpcore 1.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for websockets==15.0.1\n",
            "Best match: websockets 15.0.1\n",
            "Adding websockets 15.0.1 to easy-install.pth file\n",
            "Installing websockets script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for uvloop==0.21.0\n",
            "Best match: uvloop 0.21.0\n",
            "Adding uvloop 0.21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for python-dotenv==1.1.1\n",
            "Best match: python-dotenv 1.1.1\n",
            "Adding python-dotenv 1.1.1 to easy-install.pth file\n",
            "Installing dotenv script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for httptools==0.6.4\n",
            "Best match: httptools 0.6.4\n",
            "Adding httptools 0.6.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for h11==0.16.0\n",
            "Best match: h11 0.16.0\n",
            "Adding h11 0.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for click==8.2.1\n",
            "Best match: click 8.2.1\n",
            "Adding click 8.2.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for dnspython==2.7.0\n",
            "Best match: dnspython 2.7.0\n",
            "Adding dnspython 2.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for fastapi-cloud-cli==0.1.5\n",
            "Best match: fastapi-cloud-cli 0.1.5\n",
            "Adding fastapi-cloud-cli 0.1.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rich-toolkit==0.14.9\n",
            "Best match: rich-toolkit 0.14.9\n",
            "Adding rich-toolkit 0.14.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for typer==0.16.0\n",
            "Best match: typer 0.16.0\n",
            "Adding typer 0.16.0 to easy-install.pth file\n",
            "Installing typer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for six==1.17.0\n",
            "Best match: six 1.17.0\n",
            "Adding six 1.17.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for sentry-sdk==2.34.1\n",
            "Best match: sentry-sdk 2.34.1\n",
            "Adding sentry-sdk 2.34.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rignore==0.6.4\n",
            "Best match: rignore 0.6.4\n",
            "Adding rignore 0.6.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for rich==13.9.4\n",
            "Best match: rich 13.9.4\n",
            "Adding rich 13.9.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for shellingham==1.5.4\n",
            "Best match: shellingham 1.5.4\n",
            "Adding shellingham 1.5.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for pygments==2.19.2\n",
            "Best match: pygments 2.19.2\n",
            "Adding pygments 2.19.2 to easy-install.pth file\n",
            "Installing pygmentize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for markdown-it-py==3.0.0\n",
            "Best match: markdown-it-py 3.0.0\n",
            "Adding markdown-it-py 3.0.0 to easy-install.pth file\n",
            "Installing markdown-it script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Searching for mdurl==0.1.2\n",
            "Best match: mdurl 0.1.2\n",
            "Adding mdurl 0.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Finished processing dependencies for vllm==0.8.5.dev120+g471fe6563.cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!VLLM_TARGET_DEVICE=cpu python /content/ي/vllm_source/examples/offline_inference/basic/basic.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCli7Yg-LXBz",
        "outputId": "942791fe-8c74-4a0c-cfab-228d2a3411ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-07 01:58:19.178614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754531899.203795   38060 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754531899.211196   38060 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754531899.230089   38060 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754531899.230134   38060 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754531899.230138   38060 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754531899.230142   38060 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-07 01:58:19.236114: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ي/vllm_source/examples/offline_inference/basic/basic.py\", line 3, in <module>\n",
            "    from vllm import LLM, SamplingParams\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/__init__.py\", line 64, in __getattr__\n",
            "    module = import_module(module_name, __package__)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/entrypoints/llm.py\", line 17, in <module>\n",
            "    from vllm.beam_search import (BeamSearchInstance, BeamSearchOutput,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/beam_search.py\", line 8, in <module>\n",
            "    from vllm.sequence import Logprob\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/sequence.py\", line 18, in <module>\n",
            "    from vllm.inputs import SingletonInputs\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/__init__.py\", line 9, in <module>\n",
            "    from .registry import (DummyData, InputContext, InputProcessingContext,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/registry.py\", line 13, in <module>\n",
            "    from vllm.transformers_utils.processor import cached_processor_from_config\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/transformers_utils/processor.py\", line 7, in <module>\n",
            "    from transformers import (AutoFeatureExtractor, AutoImageProcessor,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2292, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2322, in _get_module\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2320, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/feature_extraction_auto.py\", line 29, in <module>\n",
            "    from .auto_factory import _LazyAutoMapping\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 43, in <module>\n",
            "    from ...generation import GenerationMixin\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2292, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2322, in _get_module\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2320, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 16, in <module>\n",
            "    from transformers.generation.utils import GenerationMixin\n",
            "ImportError: cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3gCnecyN024"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "521c6f0d",
        "outputId": "59a4d8d3-12f1-4861-b268-a4512f8692c9"
      },
      "source": [
        "%cd /usr/local/lib/python3.11/dist-packages/transformers/generation"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2022 The HuggingFace Team. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "from typing import TYPE_CHECKING\n",
        "\n",
        "from ..utils import OptionalDependencyNotAvailable, _LazyModule, is_flax_available, is_tf_available, is_torch_available\n",
        "\n",
        "_import_structure = {\n",
        "    \"configuration_utils\": [\n",
        "        \"BaseWatermarkingConfig\",\n",
        "        \"CompileConfig\",\n",
        "        \"GenerationConfig\",\n",
        "        \"GenerationMode\",\n",
        "        \"SynthIDTextWatermarkingConfig\",\n",
        "        \"WatermarkingConfig\",\n",
        "    ],\n",
        "    \"streamers\": [\"AsyncTextIteratorStreamer\", \"BaseStreamer\", \"TextIteratorStreamer\", \"TextStreamer\"],\n",
        "}\n",
        "\n",
        "try:\n",
        "    if not is_torch_available():\n",
        "        raise OptionalDependencyNotAvailable()\n",
        "except OptionalDependencyNotAvailable:\n",
        "    pass\n",
        "else:\n",
        "    _import_structure[\"beam_constraints\"] = [\n",
        "        \"Constraint\",\n",
        "        \"ConstraintListState\",\n",
        "        \"DisjunctiveConstraint\",\n",
        "        \"PhrasalConstraint\",\n",
        "    ]\n",
        "    _import_structure[\"beam_search\"] = [\n",
        "        \"BeamHypotheses\",\n",
        "        \"BeamScorer\",\n",
        "        \"BeamSearchScorer\",\n",
        "        \"ConstrainedBeamSearchScorer\",\n",
        "    ]\n",
        "    _import_structure[\"candidate_generator\"] = [\n",
        "        \"AssistedCandidateGenerator\",\n",
        "        \"CandidateGenerator\",\n",
        "        \"EarlyExitCandidateGenerator\",\n",
        "        \"PromptLookupCandidateGenerator\",\n",
        "    ]\n",
        "    _import_structure[\"logits_process\"] = [\n",
        "        \"AlternatingCodebooksLogitsProcessor\",\n",
        "        \"ClassifierFreeGuidanceLogitsProcessor\",\n",
        "        \"EncoderNoRepeatNGramLogitsProcessor\",\n",
        "        \"EncoderRepetitionPenaltyLogitsProcessor\",\n",
        "        \"EpsilonLogitsWarper\",\n",
        "        \"EtaLogitsWarper\",\n",
        "        \"ExponentialDecayLengthPenalty\",\n",
        "        \"ForcedBOSTokenLogitsProcessor\",\n",
        "        \"ForcedEOSTokenLogitsProcessor\",\n",
        "        \"HammingDiversityLogitsProcessor\",\n",
        "        \"InfNanRemoveLogitsProcessor\",\n",
        "        \"LogitNormalization\",\n",
        "        \"LogitsProcessor\",\n",
        "        \"LogitsProcessorList\",\n",
        "        \"MinLengthLogitsProcessor\",\n",
        "        \"MinNewTokensLengthLogitsProcessor\",\n",
        "        \"MinPLogitsWarper\",\n",
        "        \"NoBadWordsLogitsProcessor\",\n",
        "        \"NoRepeatNGramLogitsProcessor\",\n",
        "        \"PrefixConstrainedLogitsProcessor\",\n",
        "        \"RepetitionPenaltyLogitsProcessor\",\n",
        "        \"SequenceBiasLogitsProcessor\",\n",
        "        \"SuppressTokensLogitsProcessor\",\n",
        "        \"SuppressTokensAtBeginLogitsProcessor\",\n",
        "        \"SynthIDTextWatermarkLogitsProcessor\",\n",
        "        \"TemperatureLogitsWarper\",\n",
        "        \"TopKLogitsWarper\",\n",
        "        \"TopPLogitsWarper\",\n",
        "        \"TypicalLogitsWarper\",\n",
        "        \"UnbatchedClassifierFreeGuidanceLogitsProcessor\",\n",
        "        \"WhisperTimeStampLogitsProcessor\",\n",
        "        \"WatermarkLogitsProcessor\",\n",
        "    ]\n",
        "    _import_structure[\"stopping_criteria\"] = [\n",
        "        \"MaxLengthCriteria\",\n",
        "        \"MaxTimeCriteria\",\n",
        "        \"ConfidenceCriteria\",\n",
        "        \"EosTokenCriteria\",\n",
        "        \"StoppingCriteria\",\n",
        "        \"StoppingCriteriaList\",\n",
        "        \"validate_stopping_criteria\",\n",
        "        \"StopStringCriteria\",\n",
        "    ]\n",
        "    _import_structure[\"continuous_batching\"] = [\n",
        "        \"ContinuousMixin\",\n",
        "    ]\n",
        "    _import_structure[\"utils\"] = [\n",
        "        \"GenerationMixin\",\n",
        "        \"GreedySearchEncoderDecoderOutput\",\n",
        "        \"GreedySearchDecoderOnlyOutput\",\n",
        "        \"SampleEncoderDecoderOutput\",\n",
        "        \"SampleDecoderOnlyOutput\",\n",
        "        \"BeamSearchEncoderDecoderOutput\",\n",
        "        \"BeamSearchDecoderOnlyOutput\",\n",
        "        \"BeamSampleEncoderDecoderOutput\",\n",
        "        \"BeamSampleDecoderOnlyOutput\",\n",
        "        \"ContrastiveSearchEncoderDecoderOutput\",\n",
        "        \"ContrastiveSearchDecoderOnlyOutput\",\n",
        "        \"GenerateBeamDecoderOnlyOutput\",\n",
        "        \"GenerateBeamEncoderDecoderOutput\",\n",
        "        \"GenerateDecoderOnlyOutput\",\n",
        "        \"GenerateEncoderDecoderOutput\",\n",
        "    ]\n",
        "    _import_structure[\"watermarking\"] = [\n",
        "        \"WatermarkDetector\",\n",
        "        \"WatermarkDetectorOutput\",\n",
        "        \"BayesianDetectorModel\",\n",
        "        \"BayesianDetectorConfig\",\n",
        "        \"SynthIDTextWatermarkDetector\",\n",
        "    ]\n",
        "\n",
        "try:\n",
        "    if not is_tf_available():\n",
        "        raise OptionalDependencyNotAvailable()\n",
        "except OptionalDependencyNotAvailable:\n",
        "    pass\n",
        "else:\n",
        "    _import_structure[\"tf_logits_process\"] = [\n",
        "        \"TFForcedBOSTokenLogitsProcessor\",\n",
        "        \"TFForcedEOSTokenLogitsProcessor\",\n",
        "        \"TFForceTokensLogitsProcessor\",\n",
        "        \"TFLogitsProcessor\",\n",
        "        \"TFLogitsProcessorList\",\n",
        "        \"TFLogitsWarper\",\n",
        "        \"TFMinLengthLogitsProcessor\",\n",
        "        \"TFNoBadWordsLogitsProcessor\",\n",
        "        \"TFNoRepeatNGramLogitsProcessor\",\n",
        "        \"TFRepetitionPenaltyLogitsProcessor\",\n",
        "        \"TFSuppressTokensAtBeginLogitsProcessor\",\n",
        "        \"TFSuppressTokensLogitsProcessor\",\n",
        "        \"TFTemperatureLogitsWarper\",\n",
        "        \"TFTopKLogitsWarper\",\n",
        "        \"TFTopPLogitsWarper\",\n",
        "    ]\n",
        "    _import_structure[\"tf_utils\"] = [\n",
        "        \"TFGenerationMixin\",\n",
        "        \"TFGreedySearchDecoderOnlyOutput\",\n",
        "        \"TFGreedySearchEncoderDecoderOutput\",\n",
        "        \"TFSampleEncoderDecoderOutput\",\n",
        "        \"TFSampleDecoderOnlyOutput\",\n",
        "        \"TFBeamSearchEncoderDecoderOutput\",\n",
        "        \"TFBeamSearchDecoderOnlyOutput\",\n",
        "        \"TFBeamSampleEncoderDecoderOutput\",\n",
        "        \"TFBeamSampleDecoderOnlyOutput\",\n",
        "        \"TFContrastiveSearchEncoderDecoderOutput\",\n",
        "        \"TFContrastiveSearchDecoderOnlyOutput\",\n",
        "    ]\n",
        "\n",
        "try:\n",
        "    if not is_flax_available():\n",
        "        raise OptionalDependencyNotAvailable()\n",
        "except OptionalDependencyNotAvailable:\n",
        "    pass\n",
        "else:\n",
        "    _import_structure[\"flax_logits_process\"] = [\n",
        "        \"FlaxForcedBOSTokenLogitsProcessor\",\n",
        "        \"FlaxForcedEOSTokenLogitsProcessor\",\n",
        "        \"FlaxForceTokensLogitsProcessor\",\n",
        "        \"FlaxLogitsProcessor\",\n",
        "        \"FlaxLogitsProcessorList\",\n",
        "        \"FlaxLogitsWarper\",\n",
        "        \"FlaxMinLengthLogitsProcessor\",\n",
        "        \"FlaxSuppressTokensAtBeginLogitsProcessor\",\n",
        "        \"FlaxSuppressTokensLogitsProcessor\",\n",
        "        \"FlaxTemperatureLogitsWarper\",\n",
        "        \"FlaxTopKLogitsWarper\",\n",
        "        \"FlaxTopPLogitsWarper\",\n",
        "        \"FlaxWhisperTimeStampLogitsProcessor\",\n",
        "        \"FlaxNoRepeatNGramLogitsProcessor\",\n",
        "    ]\n",
        "    _import_structure[\"flax_utils\"] = [\n",
        "        \"FlaxGenerationMixin\",\n",
        "        \"FlaxGreedySearchOutput\",\n",
        "        \"FlaxSampleOutput\",\n",
        "        \"FlaxBeamSearchOutput\",\n",
        "    ]\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    from .configuration_utils import (\n",
        "        BaseWatermarkingConfig,\n",
        "        CompileConfig,\n",
        "        GenerationConfig,\n",
        "        GenerationMode,\n",
        "        SynthIDTextWatermarkingConfig,\n",
        "        WatermarkingConfig,\n",
        "    )\n",
        "    from .streamers import AsyncTextIteratorStreamer, BaseStreamer, TextIteratorStreamer, TextStreamer\n",
        "\n",
        "    try:\n",
        "        if not is_torch_available():\n",
        "            raise OptionalDependencyNotAvailable()\n",
        "    except OptionalDependencyNotAvailable:\n",
        "        pass\n",
        "    else:\n",
        "        from .beam_constraints import Constraint, ConstraintListState, DisjunctiveConstraint, PhrasalConstraint\n",
        "        from .beam_search import BeamHypotheses, BeamScorer, BeamSearchScorer, ConstrainedBeamSearchScorer\n",
        "        from .candidate_generator import (\n",
        "            AssistedCandidateGenerator,\n",
        "            CandidateGenerator,\n",
        "            EarlyExitCandidateGenerator,\n",
        "            PromptLookupCandidateGenerator,\n",
        "        )\n",
        "        from .continuous_batching import ContinuousMixin\n",
        "        from .logits_process import (\n",
        "            AlternatingCodebooksLogitsProcessor,\n",
        "            ClassifierFreeGuidanceLogitsProcessor,\n",
        "            EncoderNoRepeatNGramLogitsProcessor,\n",
        "            EncoderRepetitionPenaltyLogitsProcessor,\n",
        "            EpsilonLogitsWarper,\n",
        "            EtaLogitsWarper,\n",
        "            ExponentialDecayLengthPenalty,\n",
        "            ForcedBOSTokenLogitsProcessor,\n",
        "            ForcedEOSTokenLogitsProcessor,\n",
        "            HammingDiversityLogitsProcessor,\n",
        "            InfNanRemoveLogitsProcessor,\n",
        "            LogitNormalization,\n",
        "            LogitsProcessor,\n",
        "            LogitsProcessorList,\n",
        "            MinLengthLogitsProcessor,\n",
        "            MinNewTokensLengthLogitsProcessor,\n",
        "            MinPLogitsWarper,\n",
        "            NoBadWordsLogitsProcessor,\n",
        "            NoRepeatNGramLogitsProcessor,\n",
        "            PrefixConstrainedLogitsProcessor,\n",
        "            RepetitionPenaltyLogitsProcessor,\n",
        "            SequenceBiasLogitsProcessor,\n",
        "            SuppressTokensAtBeginLogitsProcessor,\n",
        "            SuppressTokensLogitsProcessor,\n",
        "            SynthIDTextWatermarkLogitsProcessor,\n",
        "            TemperatureLogitsWarper,\n",
        "            TopKLogitsWarper,\n",
        "            TopPLogitsWarper,\n",
        "            TypicalLogitsWarper,\n",
        "            UnbatchedClassifierFreeGuidanceLogitsProcessor,\n",
        "            WatermarkLogitsProcessor,\n",
        "            WhisperTimeStampLogitsProcessor,\n",
        "        )\n",
        "        from .stopping_criteria import (\n",
        "            ConfidenceCriteria,\n",
        "            EosTokenCriteria,\n",
        "            MaxLengthCriteria,\n",
        "            MaxTimeCriteria,\n",
        "            StoppingCriteria,\n",
        "            StoppingCriteriaList,\n",
        "            StopStringCriteria,\n",
        "            validate_stopping_criteria,\n",
        "        )\n",
        "        from .utils import (\n",
        "            BeamSampleDecoderOnlyOutput,\n",
        "            BeamSampleEncoderDecoderOutput,\n",
        "            BeamSearchDecoderOnlyOutput,\n",
        "            BeamSearchEncoderDecoderOutput,\n",
        "            ContrastiveSearchDecoderOnlyOutput,\n",
        "            ContrastiveSearchEncoderDecoderOutput,\n",
        "            GenerateBeamDecoderOnlyOutput,\n",
        "            GenerateBeamEncoderDecoderOutput,\n",
        "            GenerateDecoderOnlyOutput,\n",
        "            GenerateEncoderDecoderOutput,\n",
        "            GenerationMixin,\n",
        "            GreedySearchDecoderOnlyOutput,\n",
        "            GreedySearchEncoderDecoderOutput,\n",
        "            SampleDecoderOnlyOutput,\n",
        "            SampleEncoderDecoderOutput,\n",
        "        )\n",
        "        from .watermarking import (\n",
        "            BayesianDetectorConfig,\n",
        "            BayesianDetectorModel,\n",
        "            SynthIDTextWatermarkDetector,\n",
        "            WatermarkDetector,\n",
        "            WatermarkDetectorOutput,\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        if not is_tf_available():\n",
        "            raise OptionalDependencyNotAvailable()\n",
        "    except OptionalDependencyNotAvailable:\n",
        "        pass\n",
        "    else:\n",
        "        from .tf_logits_process import (\n",
        "            TFForcedBOSTokenLogitsProcessor,\n",
        "            TFForcedEOSTokenLogitsProcessor,\n",
        "            TFForceTokensLogitsProcessor,\n",
        "            TFLogitsProcessor,\n",
        "            TFLogitsProcessorList,\n",
        "            TFLogitsWarper,\n",
        "            TFMinLengthLogitsProcessor,\n",
        "            TFNoBadWordsLogitsProcessor,\n",
        "            TFNoRepeatNGramLogitsProcessor,\n",
        "            TFRepetitionPenaltyLogitsProcessor,\n",
        "            TFSuppressTokensAtBeginLogitsProcessor,\n",
        "            TFSuppressTokensLogitsProcessor,\n",
        "            TFTemperatureLogitsWarper,\n",
        "            TFTopKLogitsWarper,\n",
        "            TFTopPLogitsWarper,\n",
        "        )\n",
        "        from .tf_utils import (\n",
        "            TFBeamSampleDecoderOnlyOutput,\n",
        "            TFBeamSampleEncoderDecoderOutput,\n",
        "            TFBeamSearchDecoderOnlyOutput,\n",
        "            TFBeamSearchEncoderDecoderOutput,\n",
        "            TFContrastiveSearchDecoderOnlyOutput,\n",
        "            TFContrastiveSearchEncoderDecoderOutput,\n",
        "            TFGenerationMixin,\n",
        "            TFGreedySearchDecoderOnlyOutput,\n",
        "            TFGreedySearchEncoderDecoderOutput,\n",
        "            TFSampleDecoderOnlyOutput,\n",
        "            TFSampleEncoderDecoderOutput,\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        if not is_flax_available():\n",
        "            raise OptionalDependencyNotAvailable()\n",
        "    except OptionalDependencyNotAvailable:\n",
        "        pass\n",
        "    else:\n",
        "        from .flax_logits_process import (\n",
        "            FlaxForcedBOSTokenLogitsProcessor,\n",
        "            FlaxForcedEOSTokenLogitsProcessor,\n",
        "            FlaxForceTokensLogitsProcessor,\n",
        "            FlaxLogitsProcessor,\n",
        "            FlaxLogitsProcessorList,\n",
        "            FlaxLogitsWarper,\n",
        "            FlaxMinLengthLogitsProcessor,\n",
        "            FlaxNoRepeatNGramLogitsProcessor,\n",
        "            FlaxSuppressTokensAtBeginLogitsProcessor,\n",
        "            FlaxSuppressTokensLogitsProcessor,\n",
        "            FlaxTemperatureLogitsWarper,\n",
        "            FlaxTopKLogitsWarper,\n",
        "            FlaxTopPLogitsWarper,\n",
        "            FlaxWhisperTimeStampLogitsProcessor,\n",
        "        )\n",
        "        from .flax_utils import FlaxBeamSearchOutput, FlaxGenerationMixin, FlaxGreedySearchOutput, FlaxSampleOutput\n",
        "else:\n",
        "    import sys\n",
        "\n",
        "    sys.modules[__name__] = _LazyModule(__name__, globals()[\"__file__\"], _import_structure, module_spec=__spec__)\n"
      ],
      "metadata": {
        "id": "5MFjxJMKO-EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. تحقق من إصدار المكتبة الحالية\n",
        "import transformers\n",
        "print(transformers.__version__)\n",
        "\n",
        "# 2. محاولة التحديث\n",
        "!pip install --upgrade transformers\n",
        "\n",
        "# 3. اختبار الاستيراد بعد التحديث\n",
        "from transformers import GenerationMixin\n",
        "print(\"Import successful:\", GenerationMixin)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "VRAKXu9iQTYu",
        "outputId": "a8474bc4-2413-4c8a-a493-ca40a4fdb42f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.55.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2199277177.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 3. اختبار الاستيراد بعد التحديث\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Import successful:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m                 raise ModuleNotFoundError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "rH5GevhSQxm9",
        "outputId": "7b57fa0e-2129-43e5-838b-7d5b45f99264"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-ru6sr6ir\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-ru6sr6ir\n",
            "  Resolved https://github.com/huggingface/transformers to commit 513f76853b00bb30ee6d152d689c0e7f5359e55f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.56.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.0.dev0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.0.dev0) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.56.0.dev0) (2025.7.14)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.56.0.dev0-py3-none-any.whl size=12229080 sha256=a52e4010cf81e80e3a1b3f92c3c7daf8a0f7c701af2ece6d5915b15f60068b3e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_ze0wguf/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.0\n",
            "    Uninstalling transformers-4.55.0:\n",
            "      Successfully uninstalled transformers-4.55.0\n",
            "Successfully installed transformers-4.56.0.dev0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "21b30c2ab59a4d0db26d1e66822e2dc2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qkRa5srrUq-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### شغال"
      ],
      "metadata": {
        "id": "izJfm06zUx_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ي/vllm_source\n",
        "!git rev-parse HEAD\n",
        "!git checkout 471fe6563\n",
        "!pip install \"importlib-metadata>=6.0,<=8.0.0\"\n",
        "\n",
        "!pip install \"protobuf>=3.19,<5.0\"\n",
        "%cd /content/ي/vllm_source\n",
        "!VLLM_TARGET_DEVICE=cpu python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83e95ca-e427-4ff4-8e0b-f93ec25fc2ce",
        "id": "f7EdQBoMUrx4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ي/vllm_source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM\n",
        "llm = LLM(model=\"meta-llama/Llama-3.2-1B\", model_impl=\"transformers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "afa9xJkjQgY3",
        "outputId": "14d0af16-1b70-494c-a61f-000e827a5d95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2865366499.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"meta-llama/Llama-3.2-1B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_impl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"transformers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMODULE_ATTRS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__package__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from vllm.beam_search import (BeamSearchInstance, BeamSearchOutput,\n\u001b[0m\u001b[1;32m     18\u001b[0m                               \u001b[0mBeamSearchSequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               create_sort_beams_key_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/beam_search.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/sequence.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSingletonInputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoRARequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimodal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiModalKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiModalPlaceholderDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mTokensPrompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_explicit_enc_dec_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeds_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                    to_enc_dec_tuple_list, token_inputs, zip_enc_dec_prompts)\n\u001b[0;32m----> 9\u001b[0;31m from .registry import (DummyData, InputContext, InputProcessingContext,\n\u001b[0m\u001b[1;32m     10\u001b[0m                        InputRegistry)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/inputs/registry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjsontree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJSONTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_map_leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_processor_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_allowed_kwarg_only_overrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/transformers_utils/processor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from transformers import (AutoFeatureExtractor, AutoImageProcessor,\n\u001b[0m\u001b[1;32m      8\u001b[0m                           AutoProcessor)\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/feature_extraction_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFEATURE_EXTRACTOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m from .configuration_auto import (\n\u001b[1;32m     31\u001b[0m     \u001b[0mCONFIG_MAPPING_NAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GenerationMixin' from partially initialized module 'transformers.generation.utils' (most likely due to a circular import) (/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM\n",
        "llm = LLM(model=\"facebook/opt-125m\", model_impl=\"transformers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "4sB_hjOvQgrc",
        "outputId": "108965de-45ec-4be7-b06f-26b84f75a68c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 08-07 02:05:59 [utils.py:326] non-default args: {'model': 'facebook/opt-125m', 'disable_log_stats': True, 'model_impl': 'transformers'}\n",
            "INFO 08-07 02:05:59 [config.py:726] Resolved architecture: TransformersForCausalLM\n",
            "INFO 08-07 02:05:59 [config.py:1765] Using max model len 2048\n",
            "INFO 08-07 02:05:59 [config.py:2594] Chunked prefill is enabled with max_num_batched_tokens=4096.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1282950423.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"facebook/opt-125m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_impl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"transformers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, runner, convert, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, override_pooler_config, compilation_config, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# Create the Engine (autoselects V0 vs V1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         self.llm_engine = LLMEngine.from_engine_args(\n\u001b[0m\u001b[1;32m    278\u001b[0m             engine_args=engine_args, usage_context=UsageContext.LLM_CLASS)\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36mfrom_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mengine_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV1LLMEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         return engine_cls.from_vllm_config(\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0mvllm_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvllm_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0musage_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musage_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/v1/engine/llm_engine.py\u001b[0m in \u001b[0;36mfrom_vllm_config\u001b[0;34m(cls, vllm_config, usage_context, stat_loggers, disable_log_stats)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mdisable_log_stats\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     ) -> \"LLMEngine\":\n\u001b[0;32m--> 127\u001b[0;31m         return cls(vllm_config=vllm_config,\n\u001b[0m\u001b[1;32m    128\u001b[0m                    \u001b[0mexecutor_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvllm_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                    \u001b[0mlog_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdisable_log_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/v1/engine/llm_engine.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, mm_registry, use_cached_outputs, multiprocess_mode)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# EngineCore (gets EngineCoreRequests and gives EngineCoreOutputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         self.engine_core = EngineCoreClient.make_client(\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mmultiprocess_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocess_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0masyncio_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/v1/engine/core_client.py\u001b[0m in \u001b[0;36mmake_client\u001b[0;34m(multiprocess_mode, asyncio_mode, vllm_config, executor_class, log_stats)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmultiprocess_mode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masyncio_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mSyncMPClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvllm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mInprocClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvllm_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/v1/engine/core_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vllm_config, executor_class, log_stats)\u001b[0m\n\u001b[1;32m    564\u001b[0m     def __init__(self, vllm_config: VllmConfig, executor_class: type[Executor],\n\u001b[1;32m    565\u001b[0m                  log_stats: bool):\n\u001b[0;32m--> 566\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0masyncio_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mvllm_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvllm_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vllm-0.10.1.dev405+g31f09c615.cpu-py3.11-linux-x86_64.egg/vllm/v1/engine/core_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, asyncio_mode, vllm_config, executor_class, log_stats, client_addresses)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0msync_input_socket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshadow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_socket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0midentities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msync_input_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m                     raise TimeoutError(\"Timed out waiting for engines to send\"\n\u001b[1;32m    470\u001b[0m                                        \"initial message on input socket.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poller_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mevts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;31m# return 0 if no events, otherwise return event bitfield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mevts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zmq/sugar/poll.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mzmq_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zmq/backend/cython/_zmq.cpython-311-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mzmq.backend.cython._zmq.zmq_poll\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/zmq/backend/cython/_zmq.cpython-311-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mzmq.backend.cython._zmq._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM\n",
        "\n",
        "# For generative models (runner=generate) only\n",
        "llm = LLM(model=\"facebook/opt-125m\", runner=\"generate\")  # Name or path of your model\n",
        "output = llm.generate(\"Hello, my name is\")\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "e1db394233fa43899307fad2e46b8934",
            "b16fa795b5714f7a965701d99fa5a6a9",
            "58bdb957986541dfae7c96870683f0e3",
            "e31352de146a4543a9943a4ffe7b7885",
            "de1cf4db0965418893affdff728e4657",
            "fbc2f64073f241e788b0471c1a819fc4",
            "767aff20608c4efab57c067b3c5b39c7",
            "d5dcff209678465cabc3bf3e93ca3110",
            "802c4974333d4337981fb0b12b1ceb3f",
            "efbce2f3117e4b7eb7af101d0c4cae2c",
            "b0461e28d9fd408ca24c61176ac56288",
            "22fd0008f1464101af99c34b8a45b409",
            "a4de452e80eb4dda94d8b4b60914d161",
            "88e684e7311d49c1a3349e81fb5ebea2",
            "d349d312108745eca23204d198667a33",
            "65482ce7b6eb4dcf8e5b9759391cb15c",
            "8227e7243ce64a4288dc5918f11ff8cd",
            "207e4474a1e4468da07fc5882a9a3068",
            "0c5ae18af56a471ebfe85f5768f4bbaa",
            "05ec6172671440fd8c8cdc6d7e52ecf9",
            "609cd13afa714ebaaa167fad49af815c",
            "458e7f4658254ed09d8384d83933bb44"
          ]
        },
        "id": "1cXmNMZsRekF",
        "outputId": "3d3ee3ca-c939-43a7-8871-c53b32f2c3e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 08-07 02:06:10 [utils.py:326] non-default args: {'model': 'facebook/opt-125m', 'runner': 'generate', 'disable_log_stats': True}\n",
            "INFO 08-07 02:06:29 [config.py:726] Resolved architecture: OPTForCausalLM\n",
            "INFO 08-07 02:06:29 [config.py:1765] Using max model len 2048\n",
            "INFO 08-07 02:06:29 [config.py:2594] Chunked prefill is enabled with max_num_batched_tokens=4096.\n",
            "INFO 08-07 02:07:45 [llm.py:290] Supported_tasks: ['generate']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1db394233fa43899307fad2e46b8934"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22fd0008f1464101af99c34b8a45b409"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RequestOutput(request_id=0, prompt='Hello, my name is', prompt_token_ids=[2, 31414, 6, 127, 766, 16], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=' Aubrey and I am here to help you grow your fashion website store from yesterday', token_ids=[17095, 5460, 8, 38, 524, 259, 7, 244, 47, 1733, 110, 2734, 998, 1400, 31, 2350], cumulative_logprob=None, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=None, lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SPDX-License-Identifier: Apache-2.0\n",
        "# SPDX-FileCopyrightText: Copyright contributors to the vLLM project\n",
        "\n",
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "# Sample prompts.\n",
        "prompts = [\n",
        "    \"Hello, my name is\",\n",
        "    \"The president of the United States is\",\n",
        "    \"The capital of France is\",\n",
        "    \"The future of AI is\",\n",
        "]\n",
        "# Create a sampling params object.\n",
        "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Create an LLM.\n",
        "    llm = LLM(model=\"facebook/opt-125m\")\n",
        "    # Generate texts from the prompts.\n",
        "    # The output is a list of RequestOutput objects\n",
        "    # that contain the prompt, generated text, and other information.\n",
        "    outputs = llm.generate(prompts, sampling_params)\n",
        "    # Print the outputs.\n",
        "    print(\"\\nGenerated Outputs:\\n\" + \"-\" * 60)\n",
        "    for output in outputs:\n",
        "        prompt = output.prompt\n",
        "        generated_text = output.outputs[0].text\n",
        "        print(f\"Prompt:    {prompt!r}\")\n",
        "        print(f\"Output:    {generated_text!r}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428,
          "referenced_widgets": [
            "160fe0dd4b264d47831c5f554060fa4b",
            "5730cbd9f21841aca8f61729349030fc",
            "b6081c134a094923ae1e2a2bcab381de",
            "99a0b8a1ebab484ba5a77f07ddaa5ce3",
            "e1f27c991dce47099655d9740e5adf9a",
            "21d3e513d7834142b0cf433388273ef1",
            "3bdad1c10a4a4ca392bcd433c01238ff",
            "0e7f2783e1d64f5f81ae9e0f2511a182",
            "eaf9bb6c171741c9867df0cfd5ae08df",
            "5497467f238d48b8b113446dd75ace4f",
            "c43fe18d4e1b4f44b41367734ee516e6",
            "652f0cdcbe434d939f1865d97030f793",
            "83ecb9f98f744dc79ace01f5f31bf950",
            "533896b7ee584251aa6182749fbda9c0",
            "51ad4ca0fecd411cac0c4778189027bf",
            "e3b9f0b62cb540d69f51c8628c0cb125",
            "3c2b15e10a5a4300b6bf835986fb5ad0",
            "268cad636f6c4d8a99140c22b2d978ad",
            "842d7c0393204c99b7d8f66b57b23c23",
            "64541266cc1c4a30a4dd505b36e40c49",
            "bb87852fcc6a4884aa1e9a5d039484bd",
            "f1d894247278493db9f62fdfc9d9de74"
          ]
        },
        "id": "mRlgbJ2dSMat",
        "outputId": "0a78384c-235a-494c-e0a8-41dbc654879b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 08-07 02:07:53 [utils.py:326] non-default args: {'model': 'facebook/opt-125m', 'disable_log_stats': True}\n",
            "INFO 08-07 02:07:53 [config.py:726] Resolved architecture: OPTForCausalLM\n",
            "INFO 08-07 02:07:53 [config.py:1765] Using max model len 2048\n",
            "INFO 08-07 02:07:53 [config.py:2594] Chunked prefill is enabled with max_num_batched_tokens=4096.\n",
            "INFO 08-07 02:08:42 [llm.py:290] Supported_tasks: ['generate']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding requests:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "160fe0dd4b264d47831c5f554060fa4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "652f0cdcbe434d939f1865d97030f793"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Outputs:\n",
            "------------------------------------------------------------\n",
            "Prompt:    'Hello, my name is'\n",
            "Output:    \" Aubrey.  I'm a musician and I love it!   I\"\n",
            "------------------------------------------------------------\n",
            "Prompt:    'The president of the United States is'\n",
            "Output:    ' once again saying he will not campaign for Joe Biden in 2020.\\n\\nT'\n",
            "------------------------------------------------------------\n",
            "Prompt:    'The capital of France is'\n",
            "Output:    \" a firehouse?\\nYes it is, it's an old school firehouse\"\n",
            "------------------------------------------------------------\n",
            "Prompt:    'The future of AI is'\n",
            "Output:    ' here, and we are in the middle of a revolution\\n\\nHumans are'\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For pooling models (runner=pooling) only\n",
        "llm = LLM(model=..., runner=\"pooling\")  # Name or path of your model\n",
        "output = llm.encode(\"Hello, my name is\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "xmt6DDnURsmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM\n",
        "llm = LLM(model=facebook/opt-125m)  # Name or path of your model\n",
        "llm.apply_model(lambda model: print(type(model)))"
      ],
      "metadata": {
        "id": "MTWOi_WtRApc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}